<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Andrew&#x27;s Notes</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-3d639fc2.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-d0f23d9a.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">Andrew&#x27;s Notes</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="andrews-notes"><a class="header" href="#andrews-notes">Andrew’s Notes</a></h1>
<p>I’m a bit of a meticulous note taker–in part because it helps me retain information that is meaningful to me, and also because it provides an avenue for fleshing out ideas. I like to keep my notes on a wiki-style website for ease-of-access on my computer and mobile devices. While the vast majority of these notes are password-protected, occasionally I polish some notes to make publicly available. Below are my publicly published notes and articles on technical and non-technical topics.</p>
<p><a href="https://andrewtorgesen.com">Return to main site</a></p>
<ul>
<li><a href="#autonomy">Autonomy</a>
<ul>
<li><a href="#control">Control</a>
<ul>
<li><a href="#controllers">Controllers</a></li>
</ul>
</li>
<li><a href="#estimation">Estimation</a>
<ul>
<li><a href="#applied-statistics-for-stochastic-processes">Applied Statistics for Stochastic Processes</a>
<ul>
<li><a href="#bayesian-inference">Bayesian Inference</a></li>
</ul>
</li>
<li><a href="#filter-based-estimation-algorithms">Filter-Based Estimation Algorithms</a>
<ul>
<li><a href="#filters-overview">Filters Overview</a></li>
<li><a href="#the-kalman-filter-time-varying-lqe">The Kalman Filter (Time-Varying LQE)</a></li>
<li><a href="#the-kinematic-filters">The Kinematic Filters</a></li>
<li><a href="#the-luenberger-observer-lqe">The Luenberger Observer (LQE)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#math-fundamentals">Math Fundamentals</a>
<ul>
<li><a href="#3d-geometry">3D Geometry</a>
<ul>
<li><a href="#implementing-rotations-a-robotics-field-guide">Rotations Robotics Field Guide</a></li>
</ul>
</li>
<li><a href="#linear-algebra">Linear Algebra</a>
<ul>
<li><a href="#visualizing-matrices">Visualizing Matrices</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#perception">Perception</a>
<ul>
<li><a href="#computer-vision">Computer Vision</a>
<ul>
<li><a href="#the-pinhole-camera-model-fundamentals-for-geometric-computer-vision">The Pinhole Camera Model</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#search-and-optimization">Search and Optimization</a>
<ul>
<li><a href="#least-squares-optimization">Least-Squares Optimization</a></li>
<li><a href="#nonlinear-optimization">Nonlinear Optimization</a></li>
<li><a href="#optimization-over-lie-groups">Optimization Over Lie Groups</a></li>
</ul>
</li>
<li><a href="#systems-implementation">Systems Implementation</a>
<ul>
<li><a href="#computer-science">Computer Science</a>
<ul>
<li><a href="#algorithms">Algorithms</a></li>
<li><a href="#data-structures">Data Structures</a></li>
</ul>
</li>
<li><a href="#computer-simulations">Computer Simulations</a>
<ul>
<li><a href="#event-based-collision-detection">Event-Based Collision Detection</a></li>
<li><a href="#the-inertial-measurement-unit-imu-sensor">The Inertial Measurement Unit (IMU) Sensor</a></li>
<li><a href="#the-rotor-blade-flapping-effect">The Rotor Blade Flapping Effect</a></li>
</ul>
</li>
<li><a href="#operating-systems">Operating Systems</a>
<ul>
<li><a href="#a-key-press">A Key Press</a></li>
<li><a href="#multithreaded-executable">Multithreaded Executable</a></li>
<li><a href="#networking-layers">Networking Layers</a></li>
</ul>
</li>
<li><a href="#optimization-libraries">Optimization Libraries</a>
<ul>
<li><a href="#2d-range-bearing-landmark-resolution-with-ceres">2D Range-Bearing Landmark Resolution with Ceres</a></li>
<li><a href="#ceres-solver-python-tutorial">Ceres Solver Python Tutorial</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#systems-theory">Systems Theory</a>
<ul>
<li><a href="#mechanics">Mechanics</a>
<ul>
<li><a href="#the-transport-theorem-and-fictitious-forces">The Transport Theorem</a></li>
</ul>
</li>
<li><a href="#signals">Signals</a>
<ul>
<li><a href="#algorithms-in-continuous-vs-discrete-time">Algorithms in Continuous vs Discrete Time</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#philosophy">Philosophy</a>
<ul>
<li><a href="#aristotelian-science-review-and-evaluation">Aristotelian Science</a></li>
<li><a href="#logical-fallacies-as-failures-of-probabilistic-reasoning">Logical Fallacies as Bayesian Failures</a></li>
<li><a href="#realism-vs-nominalism">Realism vs Nominalism</a></li>
<li><a href="#thomas-aquinas-on-reason-and-revelation">Thomas Aquinas on Reason and Revelation</a></li>
</ul>
</li>
<li><a href="#random">Random</a>
<ul>
<li><a href="#money-balancing-math">Money Balancing Math</a></li>
<li><a href="#tenet-timelines">Tenet Timelines</a></li>
</ul>
</li>
<li><a href="#recipes">Recipes</a>
<ul>
<li><a href="#appetizer-recipes">Appetizers</a></li>
<li><a href="#breakfast-recipes">Breakfast</a></li>
<li><a href="#dessert-recipes">Dessert</a></li>
<li><a href="#dinner-recipes">Dinner</a></li>
<li><a href="#quick-stats">Quick Stats</a></li>
</ul>
</li>
<li><a href="#software-runbooks">Software Runbooks</a>
<ul>
<li><a href="#avahi-runbook">Avahi Runbook</a></li>
<li><a href="#metrics-pipeline-debugging-runbook">Metrics Pipeline Debugging</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="autonomy"><a class="header" href="#autonomy">Autonomy</a></h1>
<ul>
<li><a href="#control">Control</a>
<ul>
<li><a href="#controllers">Controllers</a></li>
</ul>
</li>
<li><a href="#estimation">Estimation</a>
<ul>
<li><a href="#applied-statistics-for-stochastic-processes">Applied Statistics for Stochastic Processes</a>
<ul>
<li><a href="#bayesian-inference">Bayesian Inference</a></li>
</ul>
</li>
<li><a href="#filter-based-estimation-algorithms">Filter-Based Estimation Algorithms</a>
<ul>
<li><a href="#filters-overview">Filters Overview</a></li>
<li><a href="#the-kalman-filter-time-varying-lqe">The Kalman Filter (Time-Varying LQE)</a></li>
<li><a href="#the-kinematic-filters">The Kinematic Filters</a></li>
<li><a href="#the-luenberger-observer-lqe">The Luenberger Observer (LQE)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#math-fundamentals">Math Fundamentals</a>
<ul>
<li><a href="#3d-geometry">3D Geometry</a>
<ul>
<li><a href="#implementing-rotations-a-robotics-field-guide">Rotations Robotics Field Guide</a></li>
</ul>
</li>
<li><a href="#linear-algebra">Linear Algebra</a>
<ul>
<li><a href="#visualizing-matrices">Visualizing Matrices</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#perception">Perception</a>
<ul>
<li><a href="#computer-vision">Computer Vision</a>
<ul>
<li><a href="#the-pinhole-camera-model-fundamentals-for-geometric-computer-vision">The Pinhole Camera Model</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#search-and-optimization">Search and Optimization</a>
<ul>
<li><a href="#least-squares-optimization">Least-Squares Optimization</a></li>
<li><a href="#nonlinear-optimization">Nonlinear Optimization</a></li>
<li><a href="#optimization-over-lie-groups">Optimization Over Lie Groups</a></li>
</ul>
</li>
<li><a href="#systems-implementation">Systems Implementation</a>
<ul>
<li><a href="#computer-science">Computer Science</a>
<ul>
<li><a href="#algorithms">Algorithms</a></li>
<li><a href="#data-structures">Data Structures</a></li>
</ul>
</li>
<li><a href="#computer-simulations">Computer Simulations</a>
<ul>
<li><a href="#event-based-collision-detection">Event-Based Collision Detection</a></li>
<li><a href="#the-inertial-measurement-unit-imu-sensor">The Inertial Measurement Unit (IMU) Sensor</a></li>
<li><a href="#the-rotor-blade-flapping-effect">The Rotor Blade Flapping Effect</a></li>
</ul>
</li>
<li><a href="#operating-systems">Operating Systems</a>
<ul>
<li><a href="#a-key-press">A Key Press</a></li>
<li><a href="#multithreaded-executable">Multithreaded Executable</a></li>
<li><a href="#networking-layers">Networking Layers</a></li>
</ul>
</li>
<li><a href="#optimization-libraries">Optimization Libraries</a>
<ul>
<li><a href="#2d-range-bearing-landmark-resolution-with-ceres">2D Range-Bearing Landmark Resolution with Ceres</a></li>
<li><a href="#ceres-solver-python-tutorial">Ceres Solver Python Tutorial</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#systems-theory">Systems Theory</a>
<ul>
<li><a href="#mechanics">Mechanics</a>
<ul>
<li><a href="#the-transport-theorem-and-fictitious-forces">The Transport Theorem</a></li>
</ul>
</li>
<li><a href="#signals">Signals</a>
<ul>
<li><a href="#algorithms-in-continuous-vs-discrete-time">Algorithms in Continuous vs Discrete Time</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="control"><a class="header" href="#control">Control</a></h1>
<ul>
<li><a href="#controllers">Controllers</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="controllers"><a href="#controllers" class="header">Controllers</a></h1>

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Controllers Overview</title>
    <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
<pre><code>    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
        padding: 40px 20px;
        min-height: 100vh;
    }

    .container {
        max-width: 1400px;
        margin: 0 auto;
        background: white;
        border-radius: 20px;
        padding: 40px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
    }

    h1 {
        text-align: center;
        color: #2d3748;
        margin-bottom: 10px;
        font-size: 2.5em;
    }

    .subtitle {
        text-align: center;
        color: #718096;
        margin-bottom: 15px;
        font-size: 1.1em;
    }

    .legend {
        text-align: center;
        color: #a0aec0;
        margin-bottom: 45px;
        font-size: 0.9em;
        font-style: italic;
    }

    .tier {
        display: grid;
        grid-template-columns: 200px 1fr 350px;
        gap: 30px;
        margin-bottom: 40px;
        align-items: start;
    }

    .tier-label {
        color: white;
        padding: 20px;
        border-radius: 12px;
        font-weight: bold;
        font-size: 1.05em;
        text-align: center;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        min-height: 100px;
    }

    .tier-label .tier-subtitle {
        font-weight: normal;
        font-size: 0.8em;
        margin-top: 6px;
        opacity: 0.85;
    }

    .tier-fundamental .tier-label {
        background: linear-gradient(135deg, #2e7d32 0%, #43a047 100%);
        box-shadow: 0 4px 15px rgba(46, 125, 50, 0.4);
    }

    .tier-classical .tier-label {
        background: linear-gradient(135deg, #1565c0 0%, #2196f3 100%);
        box-shadow: 0 4px 15px rgba(21, 101, 192, 0.4);
    }

    .tier-statespace .tier-label {
        background: linear-gradient(135deg, #6a1b9a 0%, #ab47bc 100%);
        box-shadow: 0 4px 15px rgba(106, 27, 154, 0.4);
    }

    .tier-advanced .tier-label {
        background: linear-gradient(135deg, #bf360c 0%, #e64a19 100%);
        box-shadow: 0 4px 15px rgba(191, 54, 12, 0.4);
    }

    .tier-principles .tier-label {
        background: linear-gradient(135deg, #37474f 0%, #607d8b 100%);
        box-shadow: 0 4px 15px rgba(55, 71, 79, 0.4);
    }

    .tier-components {
        display: flex;
        flex-direction: column;
        gap: 12px;
    }

    .ctrl-card {
        background: #f7fafc;
        border: 2px solid #e2e8f0;
        border-radius: 10px;
        padding: 15px 20px;
        cursor: pointer;
        transition: all 0.3s ease;
        position: relative;
    }

    .ctrl-card:hover {
        transform: translateX(5px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        border-color: #2563a8;
    }

    .ctrl-card .card-title {
        font-weight: bold;
        color: #2d3748;
        margin-bottom: 4px;
    }

    .ctrl-card .card-detail {
        font-size: 0.9em;
        color: #718096;
    }

    .ctrl-card .card-tags {
        margin-top: 8px;
        display: flex;
        flex-wrap: wrap;
        gap: 6px;
    }

    .tag {
        display: inline-block;
        font-size: 0.72em;
        padding: 2px 8px;
        border-radius: 4px;
        font-weight: 600;
        text-transform: uppercase;
        letter-spacing: 0.3px;
    }

    .tag-linear {
        background: #e8f5e9;
        color: #2e7d32;
    }

    .tag-nonlinear {
        background: #fce4ec;
        color: #c62828;
    }

    .tag-optimal {
        background: #f3e5f5;
        color: #6a1b9a;
    }

    .tag-robust {
        background: #fff3e0;
        color: #e65100;
    }

    .tag-model {
        background: #e3f2fd;
        color: #1565c0;
    }

    .tag-adaptive {
        background: #fce4ec;
        color: #880e4f;
    }

    .explanation {
        background: #eff6ff;
        border-left: 4px solid #2563a8;
        padding: 20px;
        border-radius: 8px;
        line-height: 1.6;
        color: #2d3748;
    }

    .explanation h3 {
        color: #1e56b0;
        margin-bottom: 10px;
        font-size: 1.05em;
    }

    .arrow {
        text-align: center;
        margin: 0;
        line-height: 0;
        padding: 4px 0;
    }

    .arrow svg {
        display: inline-block;
        vertical-align: middle;
    }

    .footer-note {
        background: #edf2f7;
        padding: 20px;
        border-radius: 8px;
        text-align: center;
        margin-top: 40px;
        color: #4a5568;
        line-height: 1.6;
    }

    .footer-note strong {
        color: #2d3748;
    }

    .design-section {
        margin-top: 50px;
        padding-top: 30px;
        border-top: 2px solid #e2e8f0;
    }

    .design-section h2 {
        text-align: center;
        color: #2d3748;
        margin-bottom: 30px;
        font-size: 1.8em;
    }

    .principles-grid {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 20px;
        margin-bottom: 30px;
    }

    .principle-card {
        background: #f8fafc;
        border: 2px solid #e2e8f0;
        border-radius: 12px;
        padding: 24px;
        line-height: 1.6;
    }

    .principle-card h3 {
        color: #1e56b0;
        margin-bottom: 10px;
        font-size: 1.1em;
    }

    .principle-card p {
        color: #4a5568;
        margin-bottom: 8px;
    }

    .principle-card .principle-example {
        background: #fffbeb;
        border: 1px solid #fde68a;
        border-radius: 6px;
        padding: 10px 14px;
        margin-top: 10px;
        font-size: 0.9em;
        color: #92400e;
    }

    /* Modal styles */
    .modal {
        display: none;
        position: fixed;
        z-index: 1000;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(0, 0, 0, 0.6);
        animation: fadeIn 0.3s;
    }

    @keyframes fadeIn {
        from { opacity: 0; }
        to { opacity: 1; }
    }

    .modal-content {
        background-color: white;
        margin: 5% auto;
        padding: 40px;
        border-radius: 15px;
        width: 80%;
        max-width: 750px;
        max-height: 85vh;
        overflow-y: auto;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        position: relative;
        animation: slideIn 0.3s;
    }

    @keyframes slideIn {
        from { transform: translateY(-50px); opacity: 0; }
        to { transform: translateY(0); opacity: 1; }
    }

    .close {
        color: #a0aec0;
        position: absolute;
        right: 20px;
        top: 20px;
        font-size: 35px;
        font-weight: bold;
        cursor: pointer;
        transition: color 0.3s;
        line-height: 1;
    }

    .close:hover {
        color: #2d3748;
    }

    .modal-title {
        color: #1e56b0;
        font-size: 1.6em;
        margin-bottom: 20px;
        padding-bottom: 15px;
        border-bottom: 3px solid #2563a8;
        padding-right: 40px;
    }

    .modal-body {
        color: #2d3748;
        line-height: 1.8;
        font-size: 1.02em;
    }

    .modal-body p {
        margin-bottom: 14px;
    }

    .modal-body strong {
        color: #1e56b0;
    }

    .modal-body .formula-block {
        background: #f7fafc;
        border: 1px solid #e2e8f0;
        border-radius: 8px;
        padding: 16px 20px;
        margin: 16px 0;
        text-align: center;
        font-size: 1.05em;
        overflow-x: auto;
    }

    .modal-body .pros-cons {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 16px;
        margin: 16px 0;
    }

    .modal-body .pros, .modal-body .cons {
        padding: 14px;
        border-radius: 8px;
        font-size: 0.95em;
    }

    .modal-body .pros {
        background: #f0fdf4;
        border: 1px solid #bbf7d0;
    }

    .modal-body .cons {
        background: #fef2f2;
        border: 1px solid #fecaca;
    }

    .modal-body .pros h4 {
        color: #166534;
        margin-bottom: 8px;
    }

    .modal-body .cons h4 {
        color: #991b1b;
        margin-bottom: 8px;
    }

    .modal-body .pros li, .modal-body .cons li {
        margin-bottom: 4px;
        margin-left: 16px;
    }

    .modal-body .examples {
        background: #fffbeb;
        border: 1px solid #fde68a;
        border-radius: 8px;
        padding: 14px;
        margin: 16px 0;
    }

    .modal-body .examples h4 {
        color: #92400e;
        margin-bottom: 8px;
    }

    .modal-body .examples li {
        margin-bottom: 4px;
        margin-left: 16px;
    }

    /* Responsive */
    @media screen and (max-width: 768px) {
        body {
            padding: 20px 10px;
        }

        .container {
            padding: 20px 15px;
            border-radius: 12px;
        }

        h1 {
            font-size: 1.5em;
            margin-bottom: 8px;
        }

        .subtitle {
            font-size: 0.95em;
            margin-bottom: 10px;
        }

        .legend {
            margin-bottom: 30px;
        }

        .tier {
            grid-template-columns: 1fr;
            gap: 15px;
            margin-bottom: 30px;
        }

        .tier-label {
            padding: 15px;
            font-size: 1em;
            min-height: auto;
            flex-direction: row;
            gap: 8px;
        }

        .tier-label .tier-subtitle {
            margin-top: 0;
        }

        .ctrl-card {
            padding: 12px 15px;
        }

        .ctrl-card .card-title {
            font-size: 0.95em;
        }

        .ctrl-card .card-detail {
            font-size: 0.85em;
        }

        .explanation {
            padding: 15px;
            font-size: 0.9em;
        }

        .principles-grid {
            grid-template-columns: 1fr;
        }

        .modal-content {
            margin: 5% auto;
            padding: 25px;
            width: 95%;
            max-width: 95%;
            max-height: 90vh;
        }

        .modal-title {
            font-size: 1.3em;
        }

        .modal-body {
            font-size: 0.95em;
            line-height: 1.6;
        }

        .modal-body .pros-cons {
            grid-template-columns: 1fr;
            gap: 10px;
        }

        .close {
            right: 15px;
            top: 15px;
            font-size: 28px;
        }
    }

    @media screen and (min-width: 769px) and (max-width: 1024px) {
        .container {
            padding: 30px;
        }

        h1 {
            font-size: 2em;
        }

        .tier {
            grid-template-columns: 150px 1fr 280px;
            gap: 20px;
        }

        .tier-label {
            padding: 15px;
            font-size: 0.95em;
        }

        .explanation {
            font-size: 0.9em;
        }

        .principles-grid {
            grid-template-columns: 1fr 1fr;
        }
    }

    @media (hover: none) and (pointer: coarse) {
        .ctrl-card {
            padding: 15px 18px;
            margin: 3px 0;
        }

        .ctrl-card:active {
            transform: scale(0.98);
            background: #edf2f7;
        }
    }
&lt;/style&gt;
</code></pre>

<body>
    
<div id="modal" class="modal">
        
<div class="modal-content">
            <span class="close">×</span>
            
<h2 class="modal-title" id="modal-title"></h2>

            
<div class="modal-body" id="modal-body"></div>

        </div>

    </div>

<pre><code>&lt;div class="container"&gt;
    &lt;h1&gt;Controllers&lt;/h1&gt;
    &lt;p class="subtitle"&gt;A practical overview of feedback controllers, organized from simple to advanced&lt;/p&gt;
    &lt;p class="legend"&gt;Click any controller for detailed formulas, pros &amp;amp; cons, and real-world applications&lt;/p&gt;

    &lt;!-- Tier 1: Fundamental / Single-Loop --&gt;
    &lt;div class="tier tier-fundamental"&gt;
        &lt;div class="tier-label"&gt;
            FUNDAMENTAL
            &lt;span class="tier-subtitle"&gt;Single-Loop&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="tier-components"&gt;
            &lt;div class="ctrl-card" data-ctrl="bangbang"&gt;
                &lt;div class="card-title"&gt;Bang-Bang (On-Off) Controller&lt;/div&gt;
                &lt;div class="card-detail"&gt;Output switches between two states based on error sign&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-nonlinear"&gt;Nonlinear&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="ctrl-card" data-ctrl="p"&gt;
                &lt;div class="card-title"&gt;Proportional (P) Controller&lt;/div&gt;
                &lt;div class="card-detail"&gt;Output proportional to error &amp;mdash; the simplest linear controller&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-linear"&gt;Linear&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="ctrl-card" data-ctrl="pid"&gt;
                &lt;div class="card-title"&gt;PID Controller&lt;/div&gt;
                &lt;div class="card-detail"&gt;Proportional + Integral + Derivative &amp;mdash; the workhorse of industry&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-linear"&gt;Linear&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;Why Start Here&lt;/h3&gt;
            These controllers require no mathematical model of the plant. They operate directly on the error
            signal (desired minus measured) and produce a corrective output. Despite their simplicity, PID
            alone accounts for over 90% of industrial control loops. Most engineers never need anything beyond
            a well-tuned PID.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Tier 2: Classical / Frequency-Domain --&gt;
    &lt;div class="tier tier-classical"&gt;
        &lt;div class="tier-label"&gt;
            CLASSICAL
            &lt;span class="tier-subtitle"&gt;Frequency-Domain&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="tier-components"&gt;
            &lt;div class="ctrl-card" data-ctrl="lead"&gt;
                &lt;div class="card-title"&gt;Lead Compensator&lt;/div&gt;
                &lt;div class="card-detail"&gt;Adds phase lead near crossover to increase stability margins&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-linear"&gt;Linear&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="ctrl-card" data-ctrl="lag"&gt;
                &lt;div class="card-title"&gt;Lag Compensator&lt;/div&gt;
                &lt;div class="card-detail"&gt;Boosts low-frequency gain to reduce steady-state error&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-linear"&gt;Linear&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="ctrl-card" data-ctrl="leadlag"&gt;
                &lt;div class="card-title"&gt;Lead-Lag Compensator&lt;/div&gt;
                &lt;div class="card-detail"&gt;Combines lead and lag to simultaneously improve transient and steady-state response&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-linear"&gt;Linear&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;The Frequency-Domain Toolkit&lt;/h3&gt;
            Classical compensators are designed using Bode plots, root locus, and Nyquist diagrams. They shape
            the open-loop transfer function to achieve desired gain margin, phase margin, and bandwidth. This is
            the language of control engineering textbooks and remains the standard approach when the plant can be
            adequately described by a transfer function.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Tier 3: State-Space / Model-Based --&gt;
    &lt;div class="tier tier-statespace"&gt;
        &lt;div class="tier-label"&gt;
            STATE-SPACE
            &lt;span class="tier-subtitle"&gt;Model-Based&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="tier-components"&gt;
            &lt;div class="ctrl-card" data-ctrl="poleplacement"&gt;
                &lt;div class="card-title"&gt;Full-State Feedback (Pole Placement)&lt;/div&gt;
                &lt;div class="card-detail"&gt;Places closed-loop poles at desired locations via state feedback gain K&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-linear"&gt;Linear&lt;/span&gt;
                    &lt;span class="tag tag-model"&gt;Model-Based&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="ctrl-card" data-ctrl="lqr"&gt;
                &lt;div class="card-title"&gt;Linear Quadratic Regulator (LQR)&lt;/div&gt;
                &lt;div class="card-detail"&gt;Optimal state feedback minimizing a quadratic cost on states and inputs&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-linear"&gt;Linear&lt;/span&gt;
                    &lt;span class="tag tag-optimal"&gt;Optimal&lt;/span&gt;
                    &lt;span class="tag tag-model"&gt;Model-Based&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="ctrl-card" data-ctrl="lqg"&gt;
                &lt;div class="card-title"&gt;LQG (LQR + Kalman Filter)&lt;/div&gt;
                &lt;div class="card-detail"&gt;Optimal control with optimal estimation &amp;mdash; the separation principle in action&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-linear"&gt;Linear&lt;/span&gt;
                    &lt;span class="tag tag-optimal"&gt;Optimal&lt;/span&gt;
                    &lt;span class="tag tag-model"&gt;Model-Based&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;The Power of Models&lt;/h3&gt;
            State-space methods use an explicit mathematical model of the plant (matrices A, B, C, D) to
            compute control laws with guaranteed properties. Pole placement gives direct control over dynamics;
            LQR finds the best trade-off between performance and effort; LQG handles noisy measurements.
            These methods require the system to be controllable and (for LQG) observable.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Tier 4: Advanced / Nonlinear &amp; Robust --&gt;
    &lt;div class="tier tier-advanced"&gt;
        &lt;div class="tier-label"&gt;
            ADVANCED
            &lt;span class="tier-subtitle"&gt;Nonlinear &amp;amp; Robust&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="tier-components"&gt;
            &lt;div class="ctrl-card" data-ctrl="slidingmode"&gt;
                &lt;div class="card-title"&gt;Sliding Mode Control&lt;/div&gt;
                &lt;div class="card-detail"&gt;Forces state onto a sliding surface &amp;mdash; robust to matched uncertainties&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-nonlinear"&gt;Nonlinear&lt;/span&gt;
                    &lt;span class="tag tag-robust"&gt;Robust&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="ctrl-card" data-ctrl="mpc"&gt;
                &lt;div class="card-title"&gt;Model Predictive Control (MPC)&lt;/div&gt;
                &lt;div class="card-detail"&gt;Solves an optimization problem at each timestep over a receding horizon&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-optimal"&gt;Optimal&lt;/span&gt;
                    &lt;span class="tag tag-model"&gt;Model-Based&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="ctrl-card" data-ctrl="feedbacklin"&gt;
                &lt;div class="card-title"&gt;Feedback Linearization (NDI)&lt;/div&gt;
                &lt;div class="card-detail"&gt;Cancels nonlinearities algebraically to yield a linear closed-loop system&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-nonlinear"&gt;Nonlinear&lt;/span&gt;
                    &lt;span class="tag tag-model"&gt;Model-Based&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="ctrl-card" data-ctrl="indi"&gt;
                &lt;div class="card-title"&gt;Incremental NDI (INDI)&lt;/div&gt;
                &lt;div class="card-detail"&gt;Sensor-based incremental correction &amp;mdash; wraps unmodeled disturbances into measurements&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-nonlinear"&gt;Nonlinear&lt;/span&gt;
                    &lt;span class="tag tag-robust"&gt;Robust&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="ctrl-card" data-ctrl="geometric"&gt;
                &lt;div class="card-title"&gt;Geometric Control&lt;/div&gt;
                &lt;div class="card-detail"&gt;Control on Lie groups (SO(3), SE(3)) &amp;mdash; avoids singularities of local coordinates&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-nonlinear"&gt;Nonlinear&lt;/span&gt;
                    &lt;span class="tag tag-model"&gt;Model-Based&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="ctrl-card" data-ctrl="backstepping"&gt;
                &lt;div class="card-title"&gt;Backstepping&lt;/div&gt;
                &lt;div class="card-detail"&gt;Recursively constructs a Lyapunov function for strict-feedback nonlinear systems&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-nonlinear"&gt;Nonlinear&lt;/span&gt;
                    &lt;span class="tag tag-adaptive"&gt;Adaptive&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;When Is Nonlinear Control Necessary?&lt;/h3&gt;
            Real systems are generally second-order and nonlinear. No matter the approach, a restoring force
            (P term) and damping (D term) are always required. So when do you need &lt;em&gt;more&lt;/em&gt;?
            &lt;ul style="margin: 8px 0 0 16px; font-size: 0.95em;"&gt;
                &lt;li&gt;Systems underactuated w.r.t. the desired trajectory, where the gap is too large for simple feedforward/integrator terms (e.g., aggressive quadrotor trajectories)&lt;/li&gt;
                &lt;li&gt;Complex and/or non-holonomic constraints (friction, contact dynamics, car-like vehicles, cost coupling over a manifold)&lt;/li&gt;
                &lt;li&gt;Strong unmodeled disturbances&lt;/li&gt;
                &lt;li&gt;Topology mismatch with the mathematical representation (see Geometric Control)&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Tier 5: Design Principles --&gt;
    &lt;div class="design-section"&gt;
        &lt;h2&gt;General Design Principles&lt;/h2&gt;

        &lt;div class="principles-grid"&gt;
            &lt;div class="principle-card"&gt;
                &lt;h3&gt;The Fundamental Trade-off: Performance vs. Robustness&lt;/h3&gt;
                &lt;p&gt;Every controller navigates a tension between aggressive performance (fast response, tight tracking)
                and robustness (tolerance of modeling errors, disturbances, noise). High gain gives fast response but
                amplifies noise and can destabilize uncertain plants. The Bode sensitivity integral (waterbed effect)
                makes this precise: reducing sensitivity at one frequency &lt;em&gt;must&lt;/em&gt; increase it at another.&lt;/p&gt;
                &lt;div class="principle-example"&gt;
                    A PID tuned for blazing speed on the nominal plant will often oscillate or go unstable when deployed
                    on a real system with unmodeled dynamics. Back off the gains.
                &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class="principle-card"&gt;
                &lt;h3&gt;The Internal Model Principle&lt;/h3&gt;
                &lt;p&gt;To reject a disturbance or track a reference with zero steady-state error, the controller must
                contain an internal model of the signal it needs to handle. For step inputs, this means an integrator
                in the loop. For sinusoidal disturbances, a resonant pair. This is why the "I" in PID exists, and why
                repetitive controllers work for periodic disturbances.&lt;/p&gt;
                &lt;div class="principle-example"&gt;
                    A P-only controller will always have steady-state error to a step reference. Adding integral
                    action (PI) includes the model of a step (1/s) and eliminates the error &amp;mdash; guaranteed by
                    the internal model principle.
                &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class="principle-card"&gt;
                &lt;h3&gt;Separation of Estimation and Control&lt;/h3&gt;
                &lt;p&gt;For linear Gaussian systems, the optimal controller can be designed in two independent steps:
                first design a Kalman filter (optimal estimator), then design an LQR (optimal regulator) as if
                full state were available. The combined LQG controller is still optimal. This separation principle
                drastically simplifies design &amp;mdash; but it does &lt;em&gt;not&lt;/em&gt; hold for nonlinear systems or when
                robustness to model uncertainty is required.&lt;/p&gt;
                &lt;div class="principle-example"&gt;
                    LQG has famously poor robustness guarantees despite being "optimal." This motivated the development
                    of H-infinity and mu-synthesis methods that jointly consider performance and uncertainty.
                &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class="principle-card"&gt;
                &lt;h3&gt;You Cannot Control What You Cannot Observe&lt;/h3&gt;
                &lt;p&gt;Controllability and observability are binary prerequisites. If a state is uncontrollable, no
                control input can influence it. If unobservable, no sensor measurement reveals it. Before designing
                any controller, verify these structural properties from the (A, B) and (A, C) pairs. If the system
                fails either test, no amount of cleverness in the control law will compensate.&lt;/p&gt;
                &lt;div class="principle-example"&gt;
                    A quadrotor has 12 states (position, velocity, orientation, angular rate) but only 4 actuators
                    (rotor speeds). It is controllable &amp;mdash; but only because the coupling through orientation makes
                    all 12 states reachable. Lose that coupling (e.g., a planar model with no tilt) and you lose
                    controllability of lateral position.
                &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class="principle-card"&gt;
                &lt;h3&gt;Constraints Are Not Edge Cases&lt;/h3&gt;
                &lt;p&gt;Real actuators saturate. Valves have limits, motors have torque bounds, control surfaces have
                deflection stops. A controller designed without accounting for constraints will command physically
                impossible inputs, causing integrator windup, loss of phase margin, or violent transients when the
                constraint releases. MPC handles constraints natively; for PID, anti-windup schemes are essential.&lt;/p&gt;
                &lt;div class="principle-example"&gt;
                    An altitude-hold PID on a drone commands full throttle during a large descent. The integral term
                    accumulates enormous positive error. When the drone reaches the setpoint, the wound-up integrator
                    causes a massive overshoot before it unwinds. Anti-windup clamping prevents this.
                &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class="principle-card"&gt;
                &lt;h3&gt;Simplicity as a Design Goal&lt;/h3&gt;
                &lt;p&gt;The best controller is the simplest one that meets the specification. PID before LQR. LQR before
                MPC. Gain scheduling before adaptive control. Complex controllers are harder to tune, harder to verify,
                harder to debug when something goes wrong at 2 AM, and more sensitive to implementation details
                (discretization, numerical precision, timing jitter). Every layer of complexity must earn its place
                by solving a problem that simpler approaches cannot.&lt;/p&gt;
                &lt;div class="principle-example"&gt;
                    SpaceX's early Falcon 9 landing attempts used PID-based control for the final descent. The
                    algorithm that lands orbital rockets on drone ships is not exotic &amp;mdash; it is carefully
                    engineered simplicity with gain scheduling for the changing dynamics.
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="footer-note"&gt;
        &lt;strong&gt;Rule of thumb:&lt;/strong&gt; Start with PID. Move to frequency-domain compensators when you need
        precise phase/gain margin shaping. Reach for state-space methods when you have a reliable model and
        multiple states to coordinate. Use MPC when constraints dominate. Use nonlinear control when the
        operating envelope is too wide for any single linearization.
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
    const controllers = {
        'bangbang': {
            title: 'Bang-Bang (On-Off) Controller',
            content: `
                &lt;p&gt;The bang-bang controller is the simplest possible feedback controller. It has only two states: fully on or fully off (or equivalently, full positive and full negative). The output switches based on the sign of the error.&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$u(t) = \\begin{cases} u_{\\max} &amp; \\text{if } e(t) &gt; 0 \\\\ u_{\\min} &amp; \\text{if } e(t) &lt; 0 \\end{cases}$$
                &lt;/div&gt;

                &lt;p&gt;where \\(e(t) = r(t) - y(t)\\) is the error between the reference and the measured output.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Deadband variant:&lt;/strong&gt; In practice, a deadband (hysteresis) is added around zero to prevent rapid chattering when the error is small:&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$u(t) = \\begin{cases} u_{\\max} &amp; \\text{if } e(t) &gt; \\delta \\\\ u_{\\min} &amp; \\text{if } e(t) &lt; -\\delta \\\\ u_{\\text{prev}} &amp; \\text{otherwise} \\end{cases}$$
                &lt;/div&gt;

                &lt;p&gt;Despite being primitive, bang-bang control is actually &lt;strong&gt;time-optimal&lt;/strong&gt; for double-integrator systems (e.g., moving a mass from point A to point B as fast as possible). This is proven by Pontryagin's minimum principle.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Trivially simple to implement (one comparison)&lt;/li&gt;
                            &lt;li&gt;No tuning parameters beyond the switching threshold&lt;/li&gt;
                            &lt;li&gt;Time-optimal for certain system classes&lt;/li&gt;
                            &lt;li&gt;Robust &amp;mdash; works without any plant model&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Persistent oscillation (limit cycle) around the setpoint&lt;/li&gt;
                            &lt;li&gt;High-frequency switching wears out actuators&lt;/li&gt;
                            &lt;li&gt;No steady-state accuracy without hysteresis band&lt;/li&gt;
                            &lt;li&gt;Cannot shape the transient response&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Thermostat:&lt;/strong&gt; Home heating turns fully on below setpoint, fully off above&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Refrigerator compressor:&lt;/strong&gt; On/off cycling to maintain temperature band&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Spacecraft thrusters:&lt;/strong&gt; Reaction control jets fire at full thrust or not at all&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Iron/toaster:&lt;/strong&gt; Heating element cycles on and off around target temperature&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'p': {
            title: 'Proportional (P) Controller',
            content: `
                &lt;p&gt;The proportional controller produces an output directly proportional to the error signal. It is the simplest linear controller and the building block of all classical control design.&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$u(t) = K_p \\, e(t) = K_p \\big( r(t) - y(t) \\big)$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Transfer function:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$C(s) = K_p$$
                &lt;/div&gt;

                &lt;p&gt;The closed-loop transfer function for a plant G(s) becomes:&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$T(s) = \\frac{K_p \\, G(s)}{1 + K_p \\, G(s)}$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Steady-state error:&lt;/strong&gt; For a unity-feedback system with a step input, the steady-state error is \\(e_{ss} = 1/(1 + K_p G(0))\\). This is never zero &amp;mdash; the P controller always leaves a residual error called &lt;strong&gt;droop&lt;/strong&gt; or &lt;strong&gt;offset&lt;/strong&gt;. Increasing \\(K_p\\) reduces it but eventually destabilizes the system.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Single tuning parameter (K&lt;sub&gt;p&lt;/sub&gt;)&lt;/li&gt;
                            &lt;li&gt;Immediate, predictable response to error&lt;/li&gt;
                            &lt;li&gt;Stable for most plants at moderate gains&lt;/li&gt;
                            &lt;li&gt;No derivative noise amplification or integral windup&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Non-zero steady-state error to step inputs (droop)&lt;/li&gt;
                            &lt;li&gt;Cannot reject constant disturbances&lt;/li&gt;
                            &lt;li&gt;High gain needed for small error &amp;rarr; noise amplification and instability&lt;/li&gt;
                            &lt;li&gt;No anticipation of future error (unlike derivative action)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Cruise control (basic):&lt;/strong&gt; Throttle proportional to speed error &amp;mdash; works on flat roads, droops on hills&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Volume knob:&lt;/strong&gt; Audio gain is a proportional mapping from dial position to amplitude&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Manual piloting:&lt;/strong&gt; Human pilots effectively apply P control when correcting heading deviations&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Liquid level control:&lt;/strong&gt; Valve opening proportional to level error in process tanks&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'pid': {
            title: 'PID Controller',
            content: `
                &lt;p&gt;The PID (Proportional-Integral-Derivative) controller is the most widely used feedback controller in history. It combines three terms: proportional action for present error, integral action for accumulated past error, and derivative action for the predicted future trend of error.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Continuous-time (ideal) form:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$u(t) = K_p \\left[ e(t) + \\frac{1}{T_i} \\int_0^t e(\\tau)\\,d\\tau + T_d \\frac{de(t)}{dt} \\right]$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Transfer function:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$C(s) = K_p \\left(1 + \\frac{1}{T_i s} + T_d s\\right) = K_p + \\frac{K_i}{s} + K_d s$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Discrete-time implementation:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$u[k] = K_p \\, e[k] + K_i \\sum_{j=0}^{k} e[j]\\,\\Delta t + K_d \\frac{e[k] - e[k-1]}{\\Delta t}$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Practical modifications:&lt;/strong&gt;&lt;/p&gt;
                &lt;ul style="margin: 10px 0 10px 20px;"&gt;
                    &lt;li&gt;&lt;strong&gt;Derivative filter:&lt;/strong&gt; \\(K_d s \\rightarrow K_d s / (1 + \\tau_f s)\\) to avoid amplifying high-frequency noise&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Anti-windup:&lt;/strong&gt; Clamp or back-calculate the integrator when the output saturates&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Setpoint weighting:&lt;/strong&gt; Apply P and D to measurement only, not reference, to reduce overshoot on step changes&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Derivative kick prevention:&lt;/strong&gt; Differentiate measurement instead of error to avoid spikes on setpoint changes&lt;/li&gt;
                &lt;/ul&gt;

                &lt;p&gt;&lt;strong&gt;Tuning methods:&lt;/strong&gt; Ziegler-Nichols (ultimate gain), Cohen-Coon, relay autotuning, SIMC (Skogestad), lambda tuning, or direct optimization of the ISE/IAE/ITAE cost.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Zero steady-state error for step inputs (integral action)&lt;/li&gt;
                            &lt;li&gt;Predictive capability reduces overshoot (derivative action)&lt;/li&gt;
                            &lt;li&gt;Three intuitive tuning knobs (K&lt;sub&gt;p&lt;/sub&gt;, T&lt;sub&gt;i&lt;/sub&gt;, T&lt;sub&gt;d&lt;/sub&gt;)&lt;/li&gt;
                            &lt;li&gt;Vast library of tuning rules, autotuners, and practitioner knowledge&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Only three degrees of freedom &amp;mdash; limits achievable loop shapes&lt;/li&gt;
                            &lt;li&gt;Derivative amplifies noise (requires filtering)&lt;/li&gt;
                            &lt;li&gt;Integral windup during saturation (requires anti-windup)&lt;/li&gt;
                            &lt;li&gt;SISO only &amp;mdash; no native way to coordinate multiple inputs/outputs&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Industrial process control:&lt;/strong&gt; Temperature, pressure, flow, and level in chemical plants&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Drone flight controllers:&lt;/strong&gt; Separate PID loops for roll, pitch, yaw rate, and altitude&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;3D printer motion:&lt;/strong&gt; PID for hotend temperature; P for stepper motor position&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Automotive:&lt;/strong&gt; Cruise control, idle speed control, EGR valve control&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'lead': {
            title: 'Lead Compensator',
            content: `
                &lt;p&gt;A lead compensator adds positive phase (phase lead) in a targeted frequency range around the crossover frequency. This increases the phase margin of the open-loop system, improving stability and transient response (faster rise time, less overshoot) without significantly changing the low-frequency gain.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Transfer function:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$C(s) = K_c \\frac{s + z}{s + p} = K_c \\frac{\\tau s + 1}{\\alpha \\tau s + 1}, \\quad \\alpha &lt; 1$$
                &lt;/div&gt;

                &lt;p&gt;where \\(z = 1/\\tau\\) is the zero, \\(p = 1/(\\alpha\\tau)\\) is the pole, and \\(\\alpha = z/p &lt; 1\\). The maximum phase lead occurs at \\(\\omega_m = 1/(\\tau\\sqrt{\\alpha})\\) and equals:&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$\\phi_{\\max} = \\sin^{-1}\\frac{1-\\alpha}{1+\\alpha}$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Design procedure (Bode):&lt;/strong&gt;&lt;/p&gt;
                &lt;ol style="margin: 10px 0 10px 20px;"&gt;
                    &lt;li&gt;Determine the additional phase margin needed at the desired crossover frequency&lt;/li&gt;
                    &lt;li&gt;Compute \\(\\alpha\\) from the required \\(\\phi_{\\max}\\) (add 5&amp;ndash;12&amp;deg; safety margin because the gain increase shifts crossover)&lt;/li&gt;
                    &lt;li&gt;Place \\(\\omega_m\\) at the new desired crossover frequency&lt;/li&gt;
                    &lt;li&gt;Compute \\(K_c\\) to set the open-loop gain to 0 dB at the new crossover&lt;/li&gt;
                &lt;/ol&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Increases phase margin (improves relative stability)&lt;/li&gt;
                            &lt;li&gt;Increases bandwidth (faster closed-loop response)&lt;/li&gt;
                            &lt;li&gt;Straightforward Bode-plot design procedure&lt;/li&gt;
                            &lt;li&gt;Easy to implement as a simple first-order transfer function&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Increases high-frequency gain (amplifies sensor noise)&lt;/li&gt;
                            &lt;li&gt;Maximum phase lead per stage is limited (~60&amp;deg; practical max)&lt;/li&gt;
                            &lt;li&gt;Does not improve steady-state error&lt;/li&gt;
                            &lt;li&gt;Requires accurate knowledge of the plant's crossover region&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Servo systems:&lt;/strong&gt; Adding phase margin to motor position loops for faster response&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Op-amp circuits:&lt;/strong&gt; Compensation networks to stabilize feedback amplifiers&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Antenna tracking:&lt;/strong&gt; Improving slew rate while maintaining stability in tracking loops&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Power supplies:&lt;/strong&gt; Stabilizing voltage regulators with right-half-plane zeros&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'lag': {
            title: 'Lag Compensator',
            content: `
                &lt;p&gt;A lag compensator increases the low-frequency gain (reducing steady-state error) without significantly affecting the crossover frequency or phase margin. It achieves this by placing a pole-zero pair at low frequencies, boosting the DC gain while the crossover region sees only a small (negative) phase contribution.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Transfer function:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$C(s) = K_c \\frac{s + z}{s + p} = K_c \\frac{\\tau s + 1}{\\beta \\tau s + 1}, \\quad \\beta &gt; 1$$
                &lt;/div&gt;

                &lt;p&gt;where \\(z = 1/\\tau\\), \\(p = 1/(\\beta\\tau)\\), and \\(\\beta &gt; 1\\). The gain at DC is multiplied by \\(\\beta\\) compared to the gain at high frequencies.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Design idea:&lt;/strong&gt; Place the pole-zero pair well below the crossover frequency (typically a decade below). The compensator has settled to its full DC gain boost at low frequencies, but at crossover the magnitude and phase contributions are negligible. The small phase lag at crossover (&amp;minus;5&amp;deg; to &amp;minus;10&amp;deg;) is acceptable.&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$\\text{DC gain boost} = 20 \\log_{10}(\\beta) \\text{ dB}$$
                &lt;/div&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Reduces steady-state error by a factor of &amp;beta;&lt;/li&gt;
                            &lt;li&gt;Minimal impact on transient response and stability margins&lt;/li&gt;
                            &lt;li&gt;Does not amplify high-frequency noise&lt;/li&gt;
                            &lt;li&gt;Simple first-order implementation&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Slows down the transient response if placed too close to crossover&lt;/li&gt;
                            &lt;li&gt;Adds a small amount of phase lag (can erode phase margin slightly)&lt;/li&gt;
                            &lt;li&gt;Slow pole can cause a long settling tail&lt;/li&gt;
                            &lt;li&gt;Cannot improve bandwidth or speed up the response&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Process control:&lt;/strong&gt; Reducing steady-state offset in temperature and flow loops&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Type 0 to Type 1 upgrade:&lt;/strong&gt; Approximating integral action with a low-frequency lag&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Satellite attitude control:&lt;/strong&gt; Improving pointing accuracy without destabilizing flexible modes&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Audio systems:&lt;/strong&gt; Low-frequency shelving EQ is effectively a lag compensator&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'leadlag': {
            title: 'Lead-Lag Compensator',
            content: `
                &lt;p&gt;The lead-lag compensator is the series combination of a lead section and a lag section. It addresses both transient performance (via lead) and steady-state accuracy (via lag) simultaneously. This is the most common classical compensator topology in practice.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Transfer function:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$C(s) = K_c \\underbrace{\\frac{\\tau_1 s + 1}{\\alpha \\tau_1 s + 1}}_{\\text{Lead}} \\cdot \\underbrace{\\frac{\\tau_2 s + 1}{\\beta \\tau_2 s + 1}}_{\\text{Lag}}, \\quad \\alpha &lt; 1,\\; \\beta &gt; 1$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Design procedure:&lt;/strong&gt;&lt;/p&gt;
                &lt;ol style="margin: 10px 0 10px 20px;"&gt;
                    &lt;li&gt;Design the lead section first to achieve the desired phase margin and crossover frequency&lt;/li&gt;
                    &lt;li&gt;Design the lag section to provide the necessary DC gain boost for steady-state accuracy&lt;/li&gt;
                    &lt;li&gt;Place the lag pole-zero pair well below the crossover so it does not interfere with the lead design&lt;/li&gt;
                    &lt;li&gt;Verify the combined design on Bode/Nyquist plots and iterate if needed&lt;/li&gt;
                &lt;/ol&gt;

                &lt;p&gt;&lt;strong&gt;Relationship to PID:&lt;/strong&gt; A lead-lag compensator is structurally similar to a PID controller. The lead section approximates PD action, and the lag section approximates PI action. The difference is that lead-lag is designed in the frequency domain with explicit margin targets, while PID is tuned in the time domain.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Simultaneously improves transient response and steady-state accuracy&lt;/li&gt;
                            &lt;li&gt;Provides more design freedom than PID (independent placement of poles and zeros)&lt;/li&gt;
                            &lt;li&gt;Transparent frequency-domain design with explicit margin guarantees&lt;/li&gt;
                            &lt;li&gt;Can be cascaded for more complex loop shaping&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;More parameters to tune than PID (4+ vs. 3)&lt;/li&gt;
                            &lt;li&gt;Requires frequency response data or a transfer function model&lt;/li&gt;
                            &lt;li&gt;Lead section still amplifies high-frequency noise&lt;/li&gt;
                            &lt;li&gt;SISO only &amp;mdash; same limitation as all classical methods&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Aerospace autopilots:&lt;/strong&gt; Flight control loops shaped to meet MIL-spec gain/phase margins&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Disk drive head positioning:&lt;/strong&gt; Fast seek (lead) with precise track following (lag)&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Industrial robots:&lt;/strong&gt; Joint servo loops requiring both speed and accuracy&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Power electronics:&lt;/strong&gt; Voltage and current loop compensation in switch-mode converters&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'poleplacement': {
            title: 'Full-State Feedback (Pole Placement)',
            content: `
                &lt;p&gt;Pole placement (or eigenvalue assignment) computes a state-feedback gain matrix &lt;strong&gt;K&lt;/strong&gt; such that the closed-loop system \\(\\dot{\\mathbf{x}} = (\\mathbf{A} - \\mathbf{B}\\mathbf{K})\\mathbf{x}\\) has its eigenvalues (poles) at arbitrary desired locations. This gives direct control over the closed-loop dynamics.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Control law:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\mathbf{u} = -\\mathbf{K}\\mathbf{x}$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Closed-loop dynamics:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\dot{\\mathbf{x}} = (\\mathbf{A} - \\mathbf{B}\\mathbf{K})\\mathbf{x}$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Requirement:&lt;/strong&gt; The system (A, B) must be &lt;strong&gt;controllable&lt;/strong&gt;, i.e., the controllability matrix \\(\\mathcal{C} = [\\mathbf{B} \\; \\mathbf{AB} \\; \\cdots \\; \\mathbf{A}^{n-1}\\mathbf{B}]\\) must have full rank.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Ackermann's formula&lt;/strong&gt; (single-input case):&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\mathbf{K} = \\mathbf{e}_n^T \\mathcal{C}^{-1} \\, \\Delta(\\mathbf{A})$$
                &lt;/div&gt;
                &lt;p&gt;where \\(\\Delta(s) = \\prod_i (s - p_i)\\) is the desired characteristic polynomial evaluated at the matrix A.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Observer:&lt;/strong&gt; In practice, full state is rarely measured. An observer (e.g., Luenberger observer) reconstructs the state from outputs, and the control law becomes \\(\\mathbf{u} = -\\mathbf{K}\\hat{\\mathbf{x}}\\). The observer poles should be placed 2&amp;ndash;5x faster than the controller poles.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Arbitrary pole placement (complete control over dynamics)&lt;/li&gt;
                            &lt;li&gt;Systematic, non-iterative design (compute K directly)&lt;/li&gt;
                            &lt;li&gt;Naturally handles MIMO systems&lt;/li&gt;
                            &lt;li&gt;Clear separation: controller design + observer design&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Requires a state-space model (A, B, C, D)&lt;/li&gt;
                            &lt;li&gt;Full-state measurement rarely available (need an observer)&lt;/li&gt;
                            &lt;li&gt;No guidance on &lt;em&gt;where&lt;/em&gt; to place the poles (that's the art)&lt;/li&gt;
                            &lt;li&gt;No guarantee of robustness or actuator effort optimality&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Inverted pendulum:&lt;/strong&gt; Classic demo &amp;mdash; place poles for desired settling time and damping&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Aircraft lateral control:&lt;/strong&gt; Assigning dutch-roll and roll-mode poles to meet handling qualities&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Active suspension:&lt;/strong&gt; Placing poles to achieve desired ride comfort dynamics&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Magnetic levitation:&lt;/strong&gt; Stabilizing an inherently unstable open-loop system&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'lqr': {
            title: 'Linear Quadratic Regulator (LQR)',
            content: `
                &lt;p&gt;LQR finds the optimal state-feedback gain &lt;strong&gt;K&lt;/strong&gt; that minimizes a quadratic cost function balancing state deviation and control effort. Unlike pole placement, LQR provides a principled answer to "where should the poles go?" by framing the question as an optimization problem.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Cost function (infinite horizon):&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$J = \\int_0^{\\infty} \\left( \\mathbf{x}^T \\mathbf{Q} \\mathbf{x} + \\mathbf{u}^T \\mathbf{R} \\mathbf{u} \\right) dt$$
                &lt;/div&gt;

                &lt;p&gt;where \\(\\mathbf{Q} \\succeq 0\\) penalizes state deviation and \\(\\mathbf{R} \\succ 0\\) penalizes control effort.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Optimal gain:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\mathbf{K} = \\mathbf{R}^{-1} \\mathbf{B}^T \\mathbf{P}$$
                &lt;/div&gt;

                &lt;p&gt;where &lt;strong&gt;P&lt;/strong&gt; is the unique positive-definite solution to the &lt;strong&gt;continuous algebraic Riccati equation (CARE):&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\mathbf{A}^T \\mathbf{P} + \\mathbf{P} \\mathbf{A} - \\mathbf{P} \\mathbf{B} \\mathbf{R}^{-1} \\mathbf{B}^T \\mathbf{P} + \\mathbf{Q} = 0$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Guaranteed margins:&lt;/strong&gt; LQR (with identity R) guarantees at least 60&amp;deg; phase margin and infinite gain margin at &lt;em&gt;each&lt;/em&gt; input channel independently. This is a remarkably strong robustness result for an "optimal" controller.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Tuning Q and R:&lt;/strong&gt; Think of Q/R as a ratio. Large Q/R &amp;rarr; aggressive (fast response, large control). Small Q/R &amp;rarr; gentle (slow response, small control). A common starting point is \\(Q = \\text{diag}(1/x_{i,\\max}^2)\\) and \\(R = \\text{diag}(1/u_{i,\\max}^2)\\) (Bryson's rule).&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Optimal trade-off between performance and effort&lt;/li&gt;
                            &lt;li&gt;Strong guaranteed stability margins (at the input)&lt;/li&gt;
                            &lt;li&gt;Systematic: adjust Q and R, solve Riccati, done&lt;/li&gt;
                            &lt;li&gt;Naturally handles MIMO systems&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Requires accurate (A, B) model&lt;/li&gt;
                            &lt;li&gt;Full-state measurement assumed (combine with observer for output feedback)&lt;/li&gt;
                            &lt;li&gt;Q and R tuning is still an art (Bryson's rule is a starting point, not the answer)&lt;/li&gt;
                            &lt;li&gt;No constraint handling (ignores actuator limits)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Quadrotor attitude control:&lt;/strong&gt; Balancing fast response against motor saturation&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Autonomous vehicles:&lt;/strong&gt; Lateral path-following with steering effort penalty&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Spacecraft detumbling:&lt;/strong&gt; Minimum-fuel reorientation with reaction wheels&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Balancing robots:&lt;/strong&gt; Segway-type platforms using LQR for tilt and velocity regulation&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'lqg': {
            title: 'LQG (LQR + Kalman Filter)',
            content: `
                &lt;p&gt;LQG combines the optimal controller (LQR) with the optimal estimator (Kalman filter) to handle systems where full state is not measured and measurements are corrupted by noise. The &lt;strong&gt;separation principle&lt;/strong&gt; guarantees that designing the controller and estimator independently yields the overall optimal output-feedback controller.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Architecture:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\text{Kalman filter: } \\dot{\\hat{\\mathbf{x}}} = \\mathbf{A}\\hat{\\mathbf{x}} + \\mathbf{B}\\mathbf{u} + \\mathbf{L}(\\mathbf{y} - \\mathbf{C}\\hat{\\mathbf{x}})$$
                    $$\\text{LQR: } \\mathbf{u} = -\\mathbf{K}\\hat{\\mathbf{x}}$$
                &lt;/div&gt;

                &lt;p&gt;where &lt;strong&gt;K&lt;/strong&gt; is the LQR gain (from solving the control Riccati equation with Q, R) and &lt;strong&gt;L&lt;/strong&gt; is the Kalman gain (from solving the estimation Riccati equation with process noise Q&lt;sub&gt;w&lt;/sub&gt; and measurement noise R&lt;sub&gt;v&lt;/sub&gt;).&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Separation principle:&lt;/strong&gt; The closed-loop poles are the union of the LQR poles (eigenvalues of A &amp;minus; BK) and the Kalman filter poles (eigenvalues of A &amp;minus; LC). They can be designed independently.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;The robustness problem:&lt;/strong&gt; Despite being "doubly optimal," LQG has notoriously poor robustness guarantees. The beautiful margins of LQR (60&amp;deg; phase, infinite gain) are &lt;em&gt;destroyed&lt;/em&gt; when the Kalman filter is inserted in the loop. An LQG controller can have arbitrarily small gain margin. This weakness motivated robust control theory (H-infinity, mu-synthesis).&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Optimal output-feedback controller for linear Gaussian systems&lt;/li&gt;
                            &lt;li&gt;Separation principle makes design tractable (two independent Riccati equations)&lt;/li&gt;
                            &lt;li&gt;Handles noisy measurements gracefully via the Kalman filter&lt;/li&gt;
                            &lt;li&gt;Systematic MIMO design with clear tuning knobs (Q, R, Q&lt;sub&gt;w&lt;/sub&gt;, R&lt;sub&gt;v&lt;/sub&gt;)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Poor robustness to model uncertainty (can have zero gain margin)&lt;/li&gt;
                            &lt;li&gt;Requires accurate A, B, C, D and noise covariance matrices&lt;/li&gt;
                            &lt;li&gt;No constraint handling&lt;/li&gt;
                            &lt;li&gt;Four matrices to tune (Q, R for LQR; Q&lt;sub&gt;w&lt;/sub&gt;, R&lt;sub&gt;v&lt;/sub&gt; for Kalman)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Aircraft autopilots:&lt;/strong&gt; Longitudinal and lateral control with noisy air data sensors&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Chemical process control:&lt;/strong&gt; Regulating unmeasured internal states from output measurements&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Telescope pointing:&lt;/strong&gt; Controlling mount axes with noisy star-tracker feedback&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Active vibration control:&lt;/strong&gt; Estimating structural modes from accelerometers and applying counterforces&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'slidingmode': {
            title: 'Sliding Mode Control (SMC)',
            content: `
                &lt;p&gt;Sliding mode control is best understood in the context of feedback linearization. Just like in FBL, you define your "desired" system dynamics (here called a &lt;strong&gt;sliding surface&lt;/strong&gt; in state space &amp;mdash; if you keep your system adhering to these dynamics, you are "sliding" on the surface). The &lt;strong&gt;first part&lt;/strong&gt; of the control law cancels your known dynamics, which is all that would be needed if you knew them perfectly (making it identical to FBL). However, real life is messy, so you tack on a &lt;strong&gt;discontinuous&lt;/strong&gt; switching term that forces the system onto the surface via high-rate, high-gain control. This makes SMC more robust to disturbances than FBL, at the cost of actuator chattering.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Sliding surface&lt;/strong&gt; (for a second-order system):&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\sigma = \\dot{e} + \\lambda e = 0$$
                &lt;/div&gt;
                &lt;p&gt;where \\(e = x - x_d\\) is the tracking error and \\(\\lambda &gt; 0\\). On the surface, \\(\\dot{e} = -\\lambda e\\), so the error decays exponentially with time constant \\(1/\\lambda\\).&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Control law:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$u = \\underbrace{u_{\\text{eq}}}_{\\text{FBL-like cancellation}} - \\underbrace{k \\, \\text{sgn}(\\sigma)}_{\\text{discontinuous forcing}}$$
                &lt;/div&gt;
                &lt;p&gt;where \\(u_{\\text{eq}}\\) is the equivalent control (the input needed to stay on the surface if already there) and \\(k\\, \\text{sgn}(\\sigma)\\) is the switching term that drives the state toward the surface.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Reaching condition:&lt;/strong&gt; Choose k large enough so that \\(\\sigma \\dot{\\sigma} &lt; 0\\) everywhere (the Lyapunov condition). This guarantees the state reaches the surface in finite time.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Chattering:&lt;/strong&gt; The discontinuous sgn function causes high-frequency switching in practice. Mitigation: replace sgn with a saturation function or boundary layer (\\(\\text{sat}(\\sigma/\\phi)\\)), or use higher-order sliding modes (super-twisting algorithm). (TODO: How exactly does higher-order SMC eliminate chattering?)&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;The unmatched disturbance problem:&lt;/strong&gt; SMC is only robust to &lt;strong&gt;matched&lt;/strong&gt; disturbances &amp;mdash; those entering the system through the same channel as the control input. Disturbances arising from unmodeled modes or entering through different channels are &lt;em&gt;unmatched&lt;/em&gt;, meaning the discontinuous term cannot directly override them. In these cases, you either need to augment the model to include the offending modes, or turn to more general robust control methods like H&lt;sub&gt;&amp;infin;&lt;/sub&gt;, depending on the trade-offs you are willing to accept.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Invariant to matched uncertainties and disturbances once on the surface&lt;/li&gt;
                            &lt;li&gt;Finite-time convergence to the sliding surface&lt;/li&gt;
                            &lt;li&gt;Simple design: choose a surface, verify reaching condition&lt;/li&gt;
                            &lt;li&gt;Reduced-order dynamics on the surface are easy to analyze&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Chattering from high-frequency switching (actuator wear, excites unmodeled dynamics)&lt;/li&gt;
                            &lt;li&gt;Not robust to &lt;em&gt;unmatched&lt;/em&gt; uncertainties (disturbances entering through different channels than the input)&lt;/li&gt;
                            &lt;li&gt;Boundary layer trades robustness for smoothness (finite steady-state error)&lt;/li&gt;
                            &lt;li&gt;Requires knowledge of uncertainty bounds for choosing k&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Electric motor drives:&lt;/strong&gt; Current and speed control in variable-frequency drives&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Robotic manipulators:&lt;/strong&gt; Trajectory tracking with uncertain payload mass&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Power converters:&lt;/strong&gt; Voltage regulation in DC-DC converters (natural switching system)&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Automotive ABS:&lt;/strong&gt; Wheel slip control near the optimal braking point&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'mpc': {
            title: 'Model Predictive Control (MPC)',
            content: `
                &lt;p&gt;MPC solves a finite-horizon optimal control problem at every timestep, applies only the first control input, then re-solves at the next timestep with updated state measurements. This "receding horizon" strategy naturally handles constraints on states and inputs &amp;mdash; the defining advantage of MPC over all other methods.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Optimization problem (at each timestep k):&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\min_{\\mathbf{u}_k, \\ldots, \\mathbf{u}_{k+N-1}} \\sum_{i=0}^{N-1} \\left( \\mathbf{x}_{k+i}^T \\mathbf{Q} \\mathbf{x}_{k+i} + \\mathbf{u}_{k+i}^T \\mathbf{R} \\mathbf{u}_{k+i} \\right) + \\mathbf{x}_{k+N}^T \\mathbf{P}_f \\mathbf{x}_{k+N}$$
                &lt;/div&gt;
                &lt;div class="formula-block"&gt;
                    $$\\text{subject to:} \\quad \\mathbf{x}_{k+i+1} = \\mathbf{A}\\mathbf{x}_{k+i} + \\mathbf{B}\\mathbf{u}_{k+i}$$
                    $$\\mathbf{u}_{\\min} \\leq \\mathbf{u}_{k+i} \\leq \\mathbf{u}_{\\max}$$
                    $$\\mathbf{x}_{\\min} \\leq \\mathbf{x}_{k+i} \\leq \\mathbf{x}_{\\max}$$
                &lt;/div&gt;

                &lt;p&gt;For linear systems with quadratic cost and linear constraints, this is a &lt;strong&gt;quadratic program (QP)&lt;/strong&gt; that can be solved in milliseconds with specialized solvers (OSQP, qpOASES).&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Nonlinear MPC (NMPC):&lt;/strong&gt; Uses a nonlinear model \\(\\mathbf{x}_{k+1} = f(\\mathbf{x}_k, \\mathbf{u}_k)\\). The optimization becomes a nonlinear program (NLP), which is harder but solvable in real time for many applications with methods like multiple shooting and tools like CasADi/acados.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Stability guarantee:&lt;/strong&gt; With a terminal cost \\(P_f\\) (from the Riccati equation) and a terminal constraint set, MPC is provably stable (Lyapunov argument via the cost function as a Lyapunov function).&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Handles input and state constraints natively&lt;/li&gt;
                            &lt;li&gt;Previews future reference trajectories (anticipatory action)&lt;/li&gt;
                            &lt;li&gt;Naturally handles MIMO and coupled systems&lt;/li&gt;
                            &lt;li&gt;Systematic: the cost function and constraints encode the specification directly&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Computationally expensive (solve an optimization at every timestep)&lt;/li&gt;
                            &lt;li&gt;Requires a predictive model (garbage model &amp;rarr; garbage control)&lt;/li&gt;
                            &lt;li&gt;Tuning the horizon length, Q, R, and terminal ingredients is non-trivial&lt;/li&gt;
                            &lt;li&gt;Harder to certify for safety-critical applications (solver convergence guarantees)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Chemical process control:&lt;/strong&gt; Refinery optimization with temperature, pressure, and flow constraints&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Autonomous driving:&lt;/strong&gt; Path planning and tracking with obstacle avoidance and steering limits&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Building HVAC:&lt;/strong&gt; Minimizing energy while maintaining comfort temperature bounds&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Rocket landing:&lt;/strong&gt; SpaceX uses convex MPC (powered descent guidance) for propellant-optimal landing&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'feedbacklin': {
            title: 'Feedback Linearization (NDI)',
            content: `
                &lt;p&gt;Feedback linearization (also called &lt;strong&gt;Nonlinear Dynamic Inversion&lt;/strong&gt;, NDI) uses a nonlinear coordinate change and a nonlinear control law to exactly cancel the plant's nonlinearities, producing an equivalent linear system in the new coordinates. Linear control techniques (pole placement, LQR) are then applied to the linearized system. In essence, it assumes your model is good enough to cancel the nonlinear dynamics exactly.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Input-output linearization&lt;/strong&gt; for a SISO system \\(\\dot{\\mathbf{x}} = f(\\mathbf{x}) + g(\\mathbf{x})u\\), \\(y = h(\\mathbf{x})\\):&lt;/p&gt;

                &lt;p&gt;Differentiate the output until the input u appears explicitly:&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$y^{(r)} = L_f^r h(\\mathbf{x}) + L_g L_f^{r-1} h(\\mathbf{x}) \\cdot u$$
                &lt;/div&gt;
                &lt;p&gt;where \\(r\\) is the &lt;strong&gt;relative degree&lt;/strong&gt;, \\(L_f\\) denotes the Lie derivative along f, and the term \\(L_g L_f^{r-1} h \\neq 0\\).&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Linearizing control law:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$u = \\frac{1}{L_g L_f^{r-1} h} \\left( v - L_f^r h \\right)$$
                &lt;/div&gt;
                &lt;p&gt;This yields \\(y^{(r)} = v\\), a chain of r integrators. The new input v can be chosen by any linear control law.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Zero dynamics:&lt;/strong&gt; If \\(r &lt; n\\) (relative degree less than system order), there are \\(n - r\\) internal dynamics that are unaffected by the linearizing transformation. These &lt;strong&gt;zero dynamics&lt;/strong&gt; must be stable (the system must be &lt;strong&gt;minimum phase&lt;/strong&gt;) for the approach to work.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Exact linearization (not an approximation around an operating point)&lt;/li&gt;
                            &lt;li&gt;Converts nonlinear design into a well-understood linear problem&lt;/li&gt;
                            &lt;li&gt;Global validity (not restricted to a neighborhood)&lt;/li&gt;
                            &lt;li&gt;Elegant Lie-algebraic theory with clear necessary/sufficient conditions&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Requires exact knowledge of f(x) and g(x) &amp;mdash; very sensitive to model error&lt;/li&gt;
                            &lt;li&gt;Cancelling nonlinearities can require large control effort&lt;/li&gt;
                            &lt;li&gt;Unstable zero dynamics make the method inapplicable (non-minimum phase systems)&lt;/li&gt;
                            &lt;li&gt;Does not address input constraints or disturbances&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Robotic manipulators:&lt;/strong&gt; Computed torque control cancels Coriolis and gravity terms&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Quadrotor control:&lt;/strong&gt; Linearizing the attitude dynamics for aggressive maneuvering&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Power systems:&lt;/strong&gt; Excitation control of synchronous generators&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Chemical reactors:&lt;/strong&gt; Controlling nonlinear reaction dynamics via input-output linearization&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'indi': {
            title: 'Incremental Nonlinear Dynamic Inversion (INDI)',
            content: `
                &lt;p&gt;INDI is a sensor-based variant of feedback linearization that replaces the model-dependent cancellation with &lt;strong&gt;measured&lt;/strong&gt; actuation. Instead of computing what the dynamics &lt;em&gt;should&lt;/em&gt; be from a model, INDI measures what they &lt;em&gt;actually are&lt;/em&gt; and applies an incremental correction. This wraps all unmodeled nonlinearities and disturbances into the measurement, adding substantial robustness over standard NDI.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Core idea:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$u = u_{\\text{current}} + G^{-1}\\big(\\ddot{x}_{\\text{desired}} - \\ddot{x}_{\\text{measured}}\\big)$$
                &lt;/div&gt;
                &lt;p&gt;The second term is the &lt;strong&gt;increment&lt;/strong&gt; at each timestep. The "actuation" being measured depends on the loop:&lt;/p&gt;
                &lt;ul style="margin: 10px 0 10px 20px;"&gt;
                    &lt;li&gt;&lt;strong&gt;Inner loop (attitude):&lt;/strong&gt; measured actuation can be motor RPM or angular acceleration from the gyroscope&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Outer loop (position):&lt;/strong&gt; measured actuation is acceleration, which for quadrotors depends on both IMU and motor speed measurements as external disturbances are considered&lt;/li&gt;
                &lt;/ul&gt;

                &lt;p&gt;&lt;strong&gt;Why it works far from equilibrium:&lt;/strong&gt; Although the control law looks like linear control about an operating point, the key insight is that &lt;em&gt;all&lt;/em&gt; nonlinearities and disturbances are lumped into the measurement term. The controller does not need to model them &amp;mdash; it just measures their net effect and corrects incrementally. This is what makes INDI work far from equilibrium, unlike Jacobian linearization.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Comparison with PID:&lt;/strong&gt; INDI is especially effective against fast, unpredictable disturbances because it reacts to measured actuation directly, rather than waiting for error to accumulate. PID may be more analytically stable with a good tune, but cannot be as directly reactive to sudden disturbance onset.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Highly robust to unmodeled dynamics and disturbances (they show up in the measurement)&lt;/li&gt;
                            &lt;li&gt;Works far from equilibrium despite looking like local linear control&lt;/li&gt;
                            &lt;li&gt;Minimal model dependency &amp;mdash; only the control-to-actuation mapping (G) is needed&lt;/li&gt;
                            &lt;li&gt;"Unmatched disturbances" are less of a concern than in SMC, since most real-world disturbances are detectable by sensors like the IMU&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Requires low-noise, high-bandwidth sensors (phase lag between measurement and reality is the enemy)&lt;/li&gt;
                            &lt;li&gt;Actuators must be fast enough to track the rapidly changing commands&lt;/li&gt;
                            &lt;li&gt;Computational overhead from inverting the control-to-actuation mapping&lt;/li&gt;
                            &lt;li&gt;Disturbances can still push the system into a less controllable regime&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Quadrotor attitude control:&lt;/strong&gt; Inner-loop angular rate control with gyro-measured angular acceleration&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Fixed-wing flight control:&lt;/strong&gt; INDI-based autopilots for aerobatic and fault-tolerant flight (TU Delft)&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Quadrotor position control:&lt;/strong&gt; Outer-loop using IMU-measured acceleration to reject wind gusts&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Tail-sitter VTOL:&lt;/strong&gt; Transition flight where aerodynamic models are highly uncertain&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'geometric': {
            title: 'Geometric Control',
            content: `
                &lt;p&gt;Geometric control methods design control laws directly on the manifold where the system state lives (e.g., SO(3) for rotation, SE(3) for rigid-body pose), rather than using local coordinates like Euler angles or quaternions that introduce singularities or ambiguities. The key insight is that the "right" error metrics and control laws come from the geometry of the Lie group itself.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Why does it always look like PD control?&lt;/strong&gt;&lt;/p&gt;
                &lt;p&gt;On SO(3), the most natural way to express orientation error is through a Lie-group-consistent potential function (e.g., \\(\\Psi(R) = \\frac{1}{2}\\text{tr}(I - R_d^T R)\\)). When you take the gradient of that error to build a stabilizing controller, you always get what looks like a &lt;strong&gt;proportional term&lt;/strong&gt; in the rotation error \\(e_R\\) plus a &lt;strong&gt;derivative term&lt;/strong&gt; in the angular velocity error \\(e_\\Omega\\):&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$\\boldsymbol{\\tau} = -K_R \\, e_R - K_\\Omega \\, e_\\Omega + \\text{feedforward terms}$$
                &lt;/div&gt;

                &lt;p&gt;This PD-like structure is not a simplification &amp;mdash; it is a consequence of the geometry. The error function is defined intrinsically on the manifold, so no coordinate singularities arise, and the resulting controller is almost globally asymptotically stable (the "almost" comes from the unavoidable topological obstruction on SO(3)).&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;When you still need more:&lt;/strong&gt; Geometric control solves the topology problem, but the system remains subject to all the other challenges discussed in the nonlinear control prelude: underactuation, non-holonomic constraints, and unmodeled disturbances still require additional techniques (feedforward, integral action, adaptive methods) layered on top of the geometric framework.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;No singularities (unlike Euler angles) or ambiguity (unlike quaternion double-cover)&lt;/li&gt;
                            &lt;li&gt;Almost-global stability guarantees on the full manifold&lt;/li&gt;
                            &lt;li&gt;Error metrics derived from the group structure are physically meaningful&lt;/li&gt;
                            &lt;li&gt;Clean, coordinate-free formulation enables rigorous Lyapunov analysis&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Requires familiarity with Lie groups and differential geometry&lt;/li&gt;
                            &lt;li&gt;Topological obstruction: no &lt;em&gt;globally&lt;/em&gt; stable continuous controller on SO(3) exists&lt;/li&gt;
                            &lt;li&gt;Still needs additional techniques for disturbance rejection, constraints, underactuation&lt;/li&gt;
                            &lt;li&gt;Implementation requires careful attention to exponential/logarithmic maps&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Quadrotor attitude control:&lt;/strong&gt; SO(3)-based controllers for aggressive flight without gimbal lock&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Spacecraft attitude control:&lt;/strong&gt; Large-angle slew maneuvers where Euler angles would singular&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Robotic manipulation on SE(3):&lt;/strong&gt; End-effector pose control respecting the group structure&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Underwater vehicles:&lt;/strong&gt; Full SE(3) control for 6-DOF pose regulation&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'backstepping': {
            title: 'Backstepping',
            content: `
                &lt;p&gt;Backstepping is a recursive Lyapunov-based design technique for nonlinear systems in &lt;strong&gt;strict-feedback form&lt;/strong&gt;. It builds a stabilizing controller and a Lyapunov function simultaneously, one state at a time, starting from the "innermost" subsystem and stepping backward to the actual control input.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Strict-feedback form:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\dot{x}_1 = f_1(x_1) + g_1(x_1) x_2$$
                    $$\\dot{x}_2 = f_2(x_1, x_2) + g_2(x_1, x_2) x_3$$
                    $$\\vdots$$
                    $$\\dot{x}_n = f_n(x_1, \\ldots, x_n) + g_n(x_1, \\ldots, x_n) u$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Design idea (two-step example):&lt;/strong&gt;&lt;/p&gt;
                &lt;ol style="margin: 10px 0 10px 20px;"&gt;
                    &lt;li&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Treat \\(x_2\\) as a virtual control for the \\(\\dot{x}_1\\) subsystem. Design \\(x_2 = \\alpha_1(x_1)\\) to stabilize \\(\\dot{x}_1\\) and find a Lyapunov function \\(V_1(x_1)\\).&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Define the error \\(z_2 = x_2 - \\alpha_1(x_1)\\). Augment the Lyapunov function to \\(V_2 = V_1 + \\frac{1}{2}z_2^2\\). Choose the actual input u to make \\(\\dot{V}_2 &lt; 0\\).&lt;/li&gt;
                &lt;/ol&gt;

                &lt;p&gt;Each step adds one state, one error variable, and extends the Lyapunov function. The final control law guarantees global asymptotic stability by construction.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Adaptive backstepping:&lt;/strong&gt; If the system contains unknown parameters \\(\\theta\\), a parameter estimate \\(\\hat{\\theta}\\) and update law can be incorporated into each backstep, yielding a controller that adapts to parametric uncertainty.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Constructive: produces both the controller and the stability proof&lt;/li&gt;
                            &lt;li&gt;Global stability (not just local)&lt;/li&gt;
                            &lt;li&gt;Handles parametric uncertainty via adaptive extensions&lt;/li&gt;
                            &lt;li&gt;Avoids cancelling useful nonlinearities (unlike feedback linearization)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Restricted to strict-feedback (or pure-feedback) structure&lt;/li&gt;
                            &lt;li&gt;Control law complexity grows rapidly with system order ("explosion of terms")&lt;/li&gt;
                            &lt;li&gt;Requires analytic expressions for f and g functions&lt;/li&gt;
                            &lt;li&gt;Resulting controller is often complex and non-intuitive&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Underactuated marine vehicles:&lt;/strong&gt; Path following for ships and AUVs with uncertain hydrodynamics&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Flexible-joint robots:&lt;/strong&gt; Controlling motor+link cascaded dynamics&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Power electronics:&lt;/strong&gt; Boost converter control where the cascaded structure is natural&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Flight control:&lt;/strong&gt; Adaptive backstepping for aircraft with uncertain aerodynamic coefficients&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        }
    };

    const modal = document.getElementById('modal');
    const modalTitle = document.getElementById('modal-title');
    const modalBody = document.getElementById('modal-body');
    const closeBtn = document.querySelector('.close');

    document.querySelectorAll('.ctrl-card').forEach(card =&gt; {
        card.addEventListener('click', function() {
            const key = this.getAttribute('data-ctrl');
            const info = controllers[key];
            if (info) {
                modalTitle.textContent = info.title;
                modalBody.innerHTML = info.content;
                modal.style.display = 'block';
                if (window.MathJax) {
                    MathJax.Hub.Queue(["Typeset", MathJax.Hub, modalBody]);
                }
            }
        });
    });

    closeBtn.addEventListener('click', function() {
        modal.style.display = 'none';
    });

    window.addEventListener('click', function(event) {
        if (event.target === modal) {
            modal.style.display = 'none';
        }
    });

    document.addEventListener('keydown', function(event) {
        if (event.key === 'Escape' &amp;&amp; modal.style.display === 'block') {
            modal.style.display = 'none';
        }
    });
&lt;/script&gt;
</code></pre>
</body>

</style></head></html><div style="break-before: page; page-break-before: always;"></div>
<h1 id="estimation"><a class="header" href="#estimation">Estimation</a></h1>
<ul>
<li><a href="#applied-statistics-for-stochastic-processes">Applied Statistics for Stochastic Processes</a>
<ul>
<li><a href="#bayesian-inference">Bayesian Inference</a></li>
</ul>
</li>
<li><a href="#filter-based-estimation-algorithms">Filter-Based Estimation Algorithms</a>
<ul>
<li><a href="#filters-overview">Filters Overview</a></li>
<li><a href="#the-kalman-filter-time-varying-lqe">The Kalman Filter (Time-Varying LQE)</a></li>
<li><a href="#the-kinematic-filters">The Kinematic Filters</a></li>
<li><a href="#the-luenberger-observer-lqe">The Luenberger Observer (LQE)</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="applied-statistics-for-stochastic-processes"><a class="header" href="#applied-statistics-for-stochastic-processes">Applied Statistics for Stochastic Processes</a></h1>
<ul>
<li><a href="#bayesian-inference">Bayesian Inference</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="bayesian-inference"><a class="header" href="#bayesian-inference">Bayesian Inference</a></h1>
<p><em>Fundamental theory of recovering state information from noisy data.</em></p>
<h2 id="bayesian-networks-and-their-joint-distributions"><a class="header" href="#bayesian-networks-and-their-joint-distributions">Bayesian Networks and Their Joint Distributions</a></h2>
<p>Inference is the mechanism by which observations are translated into useful data, and probabilistic inference is necessary to deal with uncertainty in both your sources of information and in your models. <strong>Bayes nets</strong> provide a way to visualize and think about arbitrary inference models. They represent these relationships with acyclic graphs (since it doesn’t make sense to have a circular inference relationship) like the one below:</p>
<img src="img/estimation/pdf_alphabet.svg" width="300" style="display: block; margin-left: auto; margin-right: auto;">
<p>where \(A\), \(B\), \(C\), \(D\), \(E\), \(F\), and \(G\) are all random variables (not just Gaussian, but arbitrary distributions) whose relationships are dictated by the edges in the graph. For example, an edge connecting \(A\) to \(D\) indicates an inference/generative/measurement model for \(D\) given an observation of \(A\). Take a second to think a little bit more about this relationship. There should be a function \(h(a\in A)\) that defines the \(D\) distribution as a function of the \(A\) distribution. So once \(A\) (and \(B\)) have been observed or input as priors, then we can calculate what \(D\) looks like as a distribution. <em>But there’s another possibility</em>. Say we suddenly got a direct observation of \(D\) and wanted to use that to infer about what \(A\) should look like, we could do so using Bayes’ rule:</p>
<p>$$P(A|D)=\frac{P(D|A)P(A)}{P(D)}=\eta P(D|A)P(A).$$</p>
<p>In the formula above, \(P(A|D)\) can be thought of as a posterior distribution for \(A\) (a refined version of the prior belief, \(P(A)\)) given the conditional encoded by \(h(a\in A)\) in the \(D\) node, which is formally expressed as \(P(D|A)\). This means that we can “reverse” the arrow in a sense to refine our knowledge of \(A\) given \(D\). It’s actually a little more complicated since \(B\) also feeds into \(D\), but we’re ignoring that for clarity. So in a Bayes net, the belief of a parent node both influences the shape of its child node‘s belief according to a measurement model and also can be refined by observations made on the child node via Bayes’ rule (also thanks to the measurement model). It’s very important to understand this concept for probabilistic intuition. That being said, it’s actually possible to get by without that intuition since the process for solving a query given observations on leaf nodes will essentially have Bayes’ rule baked into it. More on that later.</p>
<p>In aggregate, the entire net encodes the <em>joint</em> distribution of all of its random variables, \(P(A,B,C,D,E,F,G)\), which assigns a probability value to every possible permutation of the variables.</p>
<p>The shape of the Bayes net helps us calculate its joint distribution, but first we need to understand some fundamental principles:</p>
<hr>
<ul>
<li><strong>(Conditional) Independence:</strong> If \(A\) and \(B\) are independent, then their joint is just \(P(A,B)=P(A)P(B)\). Otherwise, it is given by \(P(A,B)=P(A|B)P(B)=P(B|A)P(A)\). Furthermore, in a Bayes net, <em>each node is independent of all other nodes, given its parents and children</em>.</li>
<li><strong>Chain Rule:</strong> The conditional probability rule can be repeatedly applied to break up a large joint distribution: \(P(A,B,C)=P(A|B,C)P(B,C)=P(A|B,C)P(B|C)P(C)\)</li>
</ul>
<hr>
<p>Applying these rules to the net above, we get its joint distribution:</p>
<p>$$P(A,B,C,D,E,F,G)=P(F|C,D)P(G|D,E)P(D|A,B)P(A)P(B)P(C)P(E)$$</p>
<h2 id="constraint-satisfaction-problems-and-their-application-to-solving-bayes-net-queries"><a class="header" href="#constraint-satisfaction-problems-and-their-application-to-solving-bayes-net-queries">Constraint Satisfaction Problems and Their Application to Solving Bayes Net Queries</a></h2>
<p>It’s great that we can derive joint distributions from a Bayes net, but what we usually actually care about is answering <em>queries</em>. That is, deducing the probabilities of arbitrary random variables in the net given some observations. In order to answer queries, we need to think of Bayes net as one giant constraint satisfaction problem (CSP). In essence, we can think of the individual probability distributions as “flexible” constraints, where the flexibility is afforded by uncertainty. Imagine if there were no process/measurement noise on any of the variables in a net. Then there would be ONE rigid/brittle explanation for a set of observations, and the explanation would be found by solving a CSP. In fact, lots of reasoning tasks can be cast as CSP’s, like sets of logical propositions, systems of linear equations, and, of course, Bayes nets for probabilistic inference.</p>
<p>All CSP’s can be solved with the same methodology, which can be summarized thus:</p>
<hr>
<p><strong>Given:</strong> A set of variables, corresponding variable domains, a family of constraints (together consisting a “knowledge base”), and some variable value observations.</p>
<p><strong>Desired:</strong> The allowable values of the specified variable(s) of interest that were not directly observed.</p>
<p>Perform the following steps*:</p>
<ul>
<li><strong>Determine all sets of variable value combinations that satisfy the entire family of constraints:</strong> This is done with a <em>join</em> operation on all of the constraints to create one giant (self-consistent) constraint, with the extraneous constraints automatically dropped.</li>
<li><strong>Query to obtain only the value(s) of the variable(s) of interest:</strong> This is done with a series of <em>project</em> operations to eliminate all of the assigned variable values from the giant constraint set.</li>
</ul>
<p>*If the structure of the knowledge base allows, you can interweave the join and project steps to avoid doing a massive join operation (or even allow for a recursive query algorithm to appear!).</p>
<hr>
<p>This process is like solving a system of equations, but allowing for multiple/many different solutions. It doesn’t get more general than that when it comes to constraints. An algorithmic manifestation of this process is called <em>bucket elimination</em>. So, what do these join and project operations look like when applied to Bayes Nets? This table will explain:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>CSP Terminology</th><th>Bayes Version</th></tr>
</thead>
<tbody>
<tr><td>Variables</td><td>Random variables</td></tr>
<tr><td>Variable Domains</td><td>All possible (discrete or continuous) values of the random variables</td></tr>
<tr><td>Join</td><td>Creation of a joint distribution</td></tr>
<tr><td>Project</td><td>Marginalization of random variables that haven’t been observed and aren’t part of the query set.</td></tr>
</tbody>
</table>
</div>
<p>You can also use Bayes rule to condition on variables whose values are actually knowable. Luckily, the conditional independence properties of Bayes nets also allows for interweaving the join/project operations via factoring. For example, take the Bayes net from the first section. Say we wanted to do a query to get the joint distribution of a subset of the variables, \(P(A,B,F,G)\). We would first start with the big join operation over all constraints (which are the inference models encoded by the graph) to get the global joint distribution:</p>
<p>$$P(A,B,C,D,E,F,G)=P(F|C,D)P(G|D,E)P(D|A,B)P(A)P(B)P(C)P(E)$$</p>
<p>Then we would marginalize out the un-queried variables to get our query answer:</p>
<p>$$P(A,B,F,G)=P(A)P(B)\sum_D P(D|A,B) \sum_C P(F|C,D)P(C) \sum_E P(G|D,E) P(E)$$</p>
<p>Notice how we intelligently rearranged the factors of the joint so that the summations from right to left feed into each successive sum.</p>
<h2 id="dynamic-bayes-nets"><a class="header" href="#dynamic-bayes-nets">Dynamic Bayes Nets</a></h2>
<p>A special case of the Bayes net is the dynamic Bayes net, which is also referred to as a hidden Markov model (HMM). Here’s an example of an HMM:</p>
<img src="img/estimation/pdf_dynamic.svg" width="300" style="display: block; margin-left: auto; margin-right: auto;">
<p>which encodes the joint probability distribution</p>
<p>$$P(Y_3|X_3)P(X_3|X_2)P(Y_2|X_2)P(X_2|X_1)P(Y_1|X_1)P(X_1|X_0)P(X_0)$$</p>
<p>Most <em>dynamic</em> (i.e. with a moving robot) robotics estimation problems can be cast into this form, where \(Y_i\) is a sensor observation, \(X_i\) is the robot state, and \(h(x)\) and \(f(x,u)\) are the measurement and dynamic models, respectively. The random variables \(X_i,Y_i\) need not be Gaussian, though they are often assumed to be. \(h(x)\) and \(f(x,u)\) define the mean and variance (and perhaps other properties, in the non-Gaussian case) for the \(Y_i\) and \(X_i\) distributions, which are all thought of as conditional (since they’re all child nodes) with \(i&gt;0\).</p>
<p>Let’s apply the join/project CSP technique to our HMM to derive some of the most important inference algorithms: <em>filtering</em> and <em>smoothing</em> for hidden (unobserved) state queries/estimation.</p>
<h3 id="derivation-of-filtering-query-algorithm"><a class="header" href="#derivation-of-filtering-query-algorithm">Derivation of Filtering Query Algorithm</a></h3>
<p>Let’s apply the filtering paradigm to the HMM above. For the filter calculation, we have available to us observations of \(Y_1\), \(Y_2\), and \(Y_3\), and wish to know the PDF of the most recent hidden state, \(X_3\). This basically means that we want \(P(X_3,Y_1,Y_2,Y_3)\) since it’s proportional to \(P(X_3|Y_1,Y_2,Y_3)\) via the law of independence.</p>
<p>Once again, step one is to begin with the join operation to get the joint of all constraints (distributions), which we already have:</p>
<p>$$P(X_i,Y_i)=P(Y_3|X_3)P(X_3|X_2)P(Y_2|X_2)P(X_2|X_1)P(Y_1|X_1)P(X_1|X_0)P(X_0)$$</p>
<p>The next step is to elminimate all variables that aren’t part of the query ($X_3,Y_1,Y_2,Y_3$) via marginalization:</p>
<p>$$P(X_3,Y_1,Y_2,Y_3)=P(Y_3|X_3)\sum_{X_2}P(X_3|X_2)P(Y_2|X_2)\sum_{X_1}P(X_2|X_1)P(Y_1|X_1)\sum_{X_0}P(X_1|X_0)P(X_0)$$</p>
<p>\[ =P(Y_3|X_3)\sum_{X_2}P(X_3|X_2)P(Y_2|X_2)\sum_{X_1}P(X_2|X_1)P(Y_1|X_1)P(X_1) \]</p>
<p>\[ =P(Y_3|X_3)\sum_{X_2}P(X_3|X_2)P(Y_2|X_2)\sum_{X_1}P(X_2|X_1)P(X_1,Y_1) \]</p>
<p>\[ =P(Y_3|X_3)\sum_{X_2}P(X_3|X_2)P(Y_2|X_2)P(X_2)P(Y_1) \]</p>
<p>\[ =P(Y_3|X_3)\sum_{X_2}P(X_3|X_2)P(X_2,Y_1,Y_2) \]</p>
<p>\[ =P(Y_3|X_3)P(X_3)P(Y_2)P(Y_1) \]</p>
<p>\[ =P(X_3,Y_1,Y_2,Y_3). \]</p>
<p>In the expansions above, the inter-variable (in)dependence relationships dictated by the HMM structure determine how individual PDF’s should be multiplied together. The expansions were also done to demonstrate a recursive relationship afforded by the fact that we ordered the summations intelligently.</p>
<p>The filtering algorithm can thus be summarized with the following recursive relation.</p>
<hr>
<p>$$k=0,1,\dots$$</p>
<p>$$P(X_k|Y_{1:k})=\eta P(X_k,Y_{1:k})=\eta P(Y_k|X_k)\sum_{X_{k-1}}[P(X_k|X_{k-1})P(X_{k-1}|Y_{1:k-1})],$$</p>
<p>$$P(X_0|Y_0)=P(X_0)~\text{(Prior)}.$$</p>
<hr>
<p>When the random variables are continuous, we substitute in integrals for the summations. We’ll also differentiate a prediction and update step for practical application:</p>
<hr>
<p>\[ k=0,1,\dots \]</p>
<p>\[ \text{Prediction Step:} \]</p>
<p>\[ \hat{x}^{-}_k=\int P(X_k|X_{k-1}=x)\hat{x}^{+}_{k-1}(X_{k-1}=x)dx \]</p>
<p>\[ x_k=\int P(X_k|X_{k-1})x_{k-1}(X_{k-1})dx \]</p>
<p>$$\text{Update Step:}$$</p>
<p>$$\hat{x}^+_k=\eta P(Y_k|X_k)\hat{x}^-_k$$</p>
<hr>
<p>where \( \hat{x}_k \triangleq P(X_k|Y_{1:k}) \). <strong>Particle filtering</strong> directly approximates this algorithm using Monte Carlo integration.</p>
<h3 id="derivation-of-smoothing-query-algorithm"><a class="header" href="#derivation-of-smoothing-query-algorithm">Derivation of Smoothing Query Algorithm</a></h3>
<p>We will now do a very similar derivation of the smoothing algorithm for HMM’s. This time, we have the same measurements \(Y_1\), \(Y_2\), \(Y_3\) available, but want to deduce \(X_1\), which is in the “past”. Similarly to above, what we want to find is \(P(X_1,Y_1,Y_2,Y_3)\) since it’s proportional to \(P(X_1|Y_1,Y_2,Y_3)\).</p>
<p>We start off with the same joint distribution as with the filtering derivation. First, notice that we can just apply the filtering algorithm up to \(X_1\) to obtain \(P(X_1,Y_1)\) so that we only have to deal with the terms with \(i&gt;1\). Next, the main difference here is that we are querying for a different hidden state, so we need to marginalize out \(X_2\) and \(X_3\) instead of \(X_1\) and \(X_2\) from the remaining joint terms:</p>
<p>$$P(Y_3|X_3)P(X_3|X_2)P(Y_2|X_2)P(X_2|X_1)$$</p>
<p>The marginalization is most easily done with a re-ordering of terms since we’ll need to start at \(i=3\) to end up back at \(X_1\):</p>
<p>$$\sum_{X_2}P(Y_2|X_2)P(X_2|X_1)\sum_{X_3}P(Y_3|X_3)P(X_3|X_2)=P(X_1,Y_2,Y_3).$$</p>
<p>This is the term encompassing the contribution of <em>future</em> measurements to the belief on \(X_1\). To get the final answer, multiply a normalization term with \(P(X_1,Y_1)\) and \(P(X_1,Y_2,Y_3)\) (since they’re conditionally independent distributions) to get the full \(P(X_1|Y_1,Y_2,Y_3)\).</p>
<p>With discrete probability distributions, the recursive algorithm can be summarized as</p>
<hr>
<p><strong>Query:</strong> \(X_N~~,~N\geq 1\)</p>
<p><strong>Observations:</strong> \(Y_1,\cdots,Y_M~~,~M&gt;N\)</p>
<ul>
<li>Filter to obtain \(P(X_N|Y_{1:N})\)</li>
<li>Obtain smoothing term \(P(X_N,Y_{N+1:M})\) through the recursive relationship:</li>
</ul>
<p>$$k=M,M-1,\cdots,N+1$$</p>
<p>$$P(X_{k-1},Y_{k:M})=\eta \sum_{X_k}P(Y_k|X_k)P(X_k|X_{k-1})P(X_k,Y_{k+1:M}),$$</p>
<p>$$P(X_{M-1},Y_{M:M})=\eta \sum_{X_M}P(Y_M|X_M)P(X_M|X_{M-1}).$$</p>
<p><strong>Answer:</strong> \(\eta P(X_N,Y_{N+1:M})P(X_N|Y_{1:N})\)</p>
<hr>
<h2 id="static-bayes-nets"><a class="header" href="#static-bayes-nets">Static Bayes Nets</a></h2>
<p>Contrast the dynamic Bayes net with that of a static process (where the “robot” state has no dynamics), pictured below:</p>
<img src="img/estimation/pdf_static.svg" width="200" style="display: block; margin-left: auto; margin-right: auto;">
<p>This net is also referred to as a <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">naive Bayes classifier</a>, an important tool in the world of statistics. The joint for this static configuration is given by</p>
<p>$$P(X_0,Y_1,Y_2,Y_3)=P(Y_3|X_0)P(Y_2|X_0)P(Y_1|X_0)P(X_0)$$</p>
<p>and querying for \(X_0\) given \(Y_i\) is conceptually simple; you just take the joint distribution as your answer, as there is no need to marginalize with no hidden states. While this is conceptually simple, practically there are different algorithmic approaches to take.</p>
<p>In robotics, if the random variables are Gaussian and the measurement models \(h_i(x) \sim P(Y_i|X_0)\) are linear, then we can use <em>linear static estimation</em> techniques (like weighted linear least squares) for queries on \(X_0\) given \(Y_i\). With Gaussian variables and nonlinear measurement models, we can use <em>nonlinear static estimation</em> techniques (like weighted nonlinear least squares) for such queries.</p>
<h2 id="beyond-the-basics"><a class="header" href="#beyond-the-basics">Beyond the Basics</a></h2>
<p>There are many algorithms used in different domains that leverage (or can be related directly to) Bayesian inference. Here are some that you will see pop up in robotics:</p>
<ul>
<li>Sequential Monte Carlo (Particle Filtering)</li>
<li>The Kalman filter and its variants</li>
<li>Weighted least squares regression</li>
<li>Markov Chain Monte Carlo</li>
</ul>
<p>A pretty good discussion on Bayesian inference, sequential Monte Carlo, and Markov Chain Monte Carlo can be found in <em>UPCcourse-handouts.pdf</em> from <a href="http://hedibert.org/markov-chain-monte-carlo-and-sequential-monte-carlo-methods-in-dynamic-models-and-stochastic-volatility-models/">this course website</a>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="filter-based-estimation-algorithms"><a class="header" href="#filter-based-estimation-algorithms">Filter-Based Estimation Algorithms</a></h1>
<ul>
<li><a href="#filters-overview">Filters Overview</a></li>
<li><a href="#the-kalman-filter-time-varying-lqe">The Kalman Filter (Time-Varying LQE)</a></li>
<li><a href="#the-kinematic-filters">The Kinematic Filters</a></li>
<li><a href="#the-luenberger-observer-lqe">The Luenberger Observer (LQE)</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="filters-overview"><a href="#filters-overview" class="header">Filters Overview</a></h1>

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Signal Processing Filters Overview</title>
    <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
<pre><code>    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background: linear-gradient(135deg, #0f3460 0%, #16537e 50%, #1a6e5c 100%);
        padding: 40px 20px;
        min-height: 100vh;
    }

    .container {
        max-width: 1400px;
        margin: 0 auto;
        background: white;
        border-radius: 20px;
        padding: 40px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
    }

    h1 {
        text-align: center;
        color: #2d3748;
        margin-bottom: 10px;
        font-size: 2.5em;
    }

    .subtitle {
        text-align: center;
        color: #718096;
        margin-bottom: 15px;
        font-size: 1.1em;
    }

    .legend {
        text-align: center;
        color: #a0aec0;
        margin-bottom: 45px;
        font-size: 0.9em;
        font-style: italic;
    }

    .tier {
        display: grid;
        grid-template-columns: 200px 1fr 350px;
        gap: 30px;
        margin-bottom: 40px;
        align-items: start;
    }

    .tier-label {
        color: white;
        padding: 20px;
        border-radius: 12px;
        font-weight: bold;
        font-size: 1.05em;
        text-align: center;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        min-height: 100px;
    }

    .tier-label .tier-subtitle {
        font-weight: normal;
        font-size: 0.8em;
        margin-top: 6px;
        opacity: 0.85;
    }

    .tier-fundamental .tier-label {
        background: linear-gradient(135deg, #2e7d32 0%, #43a047 100%);
        box-shadow: 0 4px 15px rgba(46, 125, 50, 0.4);
    }

    .tier-classical .tier-label {
        background: linear-gradient(135deg, #1565c0 0%, #2196f3 100%);
        box-shadow: 0 4px 15px rgba(21, 101, 192, 0.4);
    }

    .tier-optimal .tier-label {
        background: linear-gradient(135deg, #6a1b9a 0%, #ab47bc 100%);
        box-shadow: 0 4px 15px rgba(106, 27, 154, 0.4);
    }

    .tier-specialized .tier-label {
        background: linear-gradient(135deg, #bf360c 0%, #e64a19 100%);
        box-shadow: 0 4px 15px rgba(191, 54, 12, 0.4);
    }

    .tier-design .tier-label {
        background: linear-gradient(135deg, #37474f 0%, #607d8b 100%);
        box-shadow: 0 4px 15px rgba(55, 71, 79, 0.4);
    }

    .tier-components {
        display: flex;
        flex-direction: column;
        gap: 12px;
    }

    .filter-card {
        background: #f7fafc;
        border: 2px solid #e2e8f0;
        border-radius: 10px;
        padding: 15px 20px;
        cursor: pointer;
        transition: all 0.3s ease;
        position: relative;
    }

    .filter-card:hover {
        transform: translateX(5px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        border-color: #2563a8;
    }

    .filter-card .card-title {
        font-weight: bold;
        color: #2d3748;
        margin-bottom: 4px;
    }

    .filter-card .card-detail {
        font-size: 0.9em;
        color: #718096;
    }

    .filter-card .card-tags {
        margin-top: 8px;
        display: flex;
        flex-wrap: wrap;
        gap: 6px;
    }

    .tag {
        display: inline-block;
        font-size: 0.72em;
        padding: 2px 8px;
        border-radius: 4px;
        font-weight: 600;
        text-transform: uppercase;
        letter-spacing: 0.3px;
    }

    .tag-fir {
        background: #e8f5e9;
        color: #2e7d32;
    }

    .tag-iir {
        background: #e3f2fd;
        color: #1565c0;
    }

    .tag-nonlinear {
        background: #fce4ec;
        color: #c62828;
    }

    .tag-adaptive {
        background: #f3e5f5;
        color: #6a1b9a;
    }

    .tag-recursive {
        background: #fff3e0;
        color: #e65100;
    }

    .explanation {
        background: #eff6ff;
        border-left: 4px solid #2563a8;
        padding: 20px;
        border-radius: 8px;
        line-height: 1.6;
        color: #2d3748;
    }

    .explanation h3 {
        color: #1e56b0;
        margin-bottom: 10px;
        font-size: 1.05em;
    }

    .arrow {
        text-align: center;
        margin: 0;
        line-height: 0;
        padding: 4px 0;
    }

    .arrow svg {
        display: inline-block;
        vertical-align: middle;
    }

    .cross-cutting {
        margin-top: 50px;
        margin-bottom: 40px;
    }

    .cross-cutting h2 {
        color: #2d3748;
        font-size: 1.6em;
        margin-bottom: 6px;
    }

    .cross-cutting .section-subtitle {
        color: #718096;
        margin-bottom: 25px;
        font-size: 1em;
    }

    .principle-card {
        background: #f7fafc;
        border: 2px solid #e2e8f0;
        border-radius: 10px;
        padding: 20px 24px;
        margin-bottom: 16px;
    }

    .principle-card .principle-title {
        font-weight: bold;
        color: #2d3748;
        font-size: 1.05em;
        margin-bottom: 8px;
    }

    .principle-card .principle-body {
        color: #4a5568;
        line-height: 1.7;
        font-size: 0.95em;
    }

    .principle-card .principle-body p {
        margin-bottom: 10px;
    }

    .principle-card .principle-body p:last-child {
        margin-bottom: 0;
    }

    .principle-card .principle-examples {
        margin-top: 12px;
        padding-left: 20px;
    }

    .principle-card .principle-examples li {
        color: #4a5568;
        margin-bottom: 4px;
        line-height: 1.6;
    }

    .footer-note {
        background: #edf2f7;
        padding: 20px;
        border-radius: 8px;
        text-align: center;
        margin-top: 40px;
        color: #4a5568;
        line-height: 1.6;
    }

    .footer-note strong {
        color: #2d3748;
    }

    /* Modal styles */
    .modal {
        display: none;
        position: fixed;
        z-index: 1000;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(0, 0, 0, 0.6);
        animation: fadeIn 0.3s;
    }

    @keyframes fadeIn {
        from { opacity: 0; }
        to { opacity: 1; }
    }

    .modal-content {
        background-color: white;
        margin: 5% auto;
        padding: 40px;
        border-radius: 15px;
        width: 80%;
        max-width: 750px;
        max-height: 85vh;
        overflow-y: auto;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        position: relative;
        animation: slideIn 0.3s;
    }

    @keyframes slideIn {
        from { transform: translateY(-50px); opacity: 0; }
        to { transform: translateY(0); opacity: 1; }
    }

    .close {
        color: #a0aec0;
        position: absolute;
        right: 20px;
        top: 20px;
        font-size: 35px;
        font-weight: bold;
        cursor: pointer;
        transition: color 0.3s;
        line-height: 1;
    }

    .close:hover {
        color: #2d3748;
    }

    .modal-title {
        color: #1e56b0;
        font-size: 1.6em;
        margin-bottom: 20px;
        padding-bottom: 15px;
        border-bottom: 3px solid #2563a8;
        padding-right: 40px;
    }

    .modal-body {
        color: #2d3748;
        line-height: 1.8;
        font-size: 1.02em;
    }

    .modal-body p {
        margin-bottom: 14px;
    }

    .modal-body strong {
        color: #1e56b0;
    }

    .modal-body .formula-block {
        background: #f7fafc;
        border: 1px solid #e2e8f0;
        border-radius: 8px;
        padding: 16px 20px;
        margin: 16px 0;
        text-align: center;
        font-size: 1.05em;
        overflow-x: auto;
    }

    .modal-body .pros-cons {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 16px;
        margin: 16px 0;
    }

    .modal-body .pros, .modal-body .cons {
        padding: 14px;
        border-radius: 8px;
        font-size: 0.95em;
    }

    .modal-body .pros {
        background: #f0fdf4;
        border: 1px solid #bbf7d0;
    }

    .modal-body .cons {
        background: #fef2f2;
        border: 1px solid #fecaca;
    }

    .modal-body .pros h4 {
        color: #166534;
        margin-bottom: 8px;
    }

    .modal-body .cons h4 {
        color: #991b1b;
        margin-bottom: 8px;
    }

    .modal-body .pros li, .modal-body .cons li {
        margin-bottom: 4px;
        margin-left: 16px;
    }

    .modal-body .examples {
        background: #fffbeb;
        border: 1px solid #fde68a;
        border-radius: 8px;
        padding: 14px;
        margin: 16px 0;
    }

    .modal-body .examples h4 {
        color: #92400e;
        margin-bottom: 8px;
    }

    .modal-body .examples li {
        margin-bottom: 4px;
        margin-left: 16px;
    }

    /* Responsive */
    @media screen and (max-width: 768px) {
        body {
            padding: 20px 10px;
        }

        .container {
            padding: 20px 15px;
            border-radius: 12px;
        }

        h1 {
            font-size: 1.5em;
            margin-bottom: 8px;
        }

        .subtitle {
            font-size: 0.95em;
            margin-bottom: 10px;
        }

        .legend {
            margin-bottom: 30px;
        }

        .tier {
            grid-template-columns: 1fr;
            gap: 15px;
            margin-bottom: 30px;
        }

        .tier-label {
            padding: 15px;
            font-size: 1em;
            min-height: auto;
            flex-direction: row;
            gap: 8px;
        }

        .tier-label .tier-subtitle {
            margin-top: 0;
        }

        .filter-card {
            padding: 12px 15px;
        }

        .filter-card .card-title {
            font-size: 0.95em;
        }

        .filter-card .card-detail {
            font-size: 0.85em;
        }

        .explanation {
            padding: 15px;
            font-size: 0.9em;
        }

        .modal-content {
            margin: 5% auto;
            padding: 25px;
            width: 95%;
            max-width: 95%;
            max-height: 90vh;
        }

        .modal-title {
            font-size: 1.3em;
        }

        .modal-body {
            font-size: 0.95em;
            line-height: 1.6;
        }

        .modal-body .pros-cons {
            grid-template-columns: 1fr;
            gap: 10px;
        }

        .close {
            right: 15px;
            top: 15px;
            font-size: 28px;
        }
    }

    @media screen and (min-width: 769px) and (max-width: 1024px) {
        .container {
            padding: 30px;
        }

        h1 {
            font-size: 2em;
        }

        .tier {
            grid-template-columns: 150px 1fr 280px;
            gap: 20px;
        }

        .tier-label {
            padding: 15px;
            font-size: 0.95em;
        }

        .explanation {
            font-size: 0.9em;
        }
    }

    @media (hover: none) and (pointer: coarse) {
        .filter-card {
            padding: 15px 18px;
            margin: 3px 0;
        }

        .filter-card:active {
            transform: scale(0.98);
            background: #edf2f7;
        }
    }
&lt;/style&gt;
</code></pre>

<body>
    
<div id="modal-1" class="modal">
        
<div class="modal-content">
            <span class="close">×</span>
            
<h2 class="modal-title" id="modal-title-1"></h2>

            
<div class="modal-body" id="modal-body-1"></div>

        </div>

    </div>

<pre><code>&lt;div class="container"&gt;
    &lt;h1&gt;Signal Processing Filters&lt;/h1&gt;
    &lt;p class="subtitle"&gt;A practical overview of the most widely used filters, organized from simple to advanced&lt;/p&gt;
    &lt;p class="legend"&gt;Click any filter for detailed formulas, pros &amp;amp; cons, and real-world applications&lt;/p&gt;

    &lt;!-- Tier 1: Fundamental / Time-Domain --&gt;
    &lt;div class="tier tier-fundamental"&gt;
        &lt;div class="tier-label"&gt;
            FUNDAMENTAL
            &lt;span class="tier-subtitle"&gt;Time-Domain&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="tier-components"&gt;
            &lt;div class="filter-card" data-filter="moving-average"&gt;
                &lt;div class="card-title"&gt;Moving Average Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Averages a sliding window of N samples to smooth noise&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-fir"&gt;FIR&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="ema"&gt;
                &lt;div class="card-title"&gt;Exponential Moving Average (EMA)&lt;/div&gt;
                &lt;div class="card-detail"&gt;Weighted average giving recent samples exponentially more influence&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-iir"&gt;IIR&lt;/span&gt;
                    &lt;span class="tag tag-recursive"&gt;Recursive&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="median"&gt;
                &lt;div class="card-title"&gt;Median Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Selects the median of a sliding window, rejecting outliers&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-nonlinear"&gt;Nonlinear&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;Why Start Here&lt;/h3&gt;
            These filters require no knowledge of frequency analysis or z-transforms. They operate directly on
            sample values in the time domain. Despite their simplicity, they solve the majority of noise-reduction
            problems encountered in embedded systems, sensor fusion, and data visualization.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Tier 2: Classical Frequency-Domain --&gt;
    &lt;div class="tier tier-classical"&gt;
        &lt;div class="tier-label"&gt;
            CLASSICAL
            &lt;span class="tier-subtitle"&gt;Frequency-Domain&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="tier-components"&gt;
            &lt;div class="filter-card" data-filter="butterworth"&gt;
                &lt;div class="card-title"&gt;Butterworth Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Maximally flat magnitude response in the passband&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-iir"&gt;IIR&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="chebyshev"&gt;
                &lt;div class="card-title"&gt;Chebyshev Filter (Type I &amp;amp; II)&lt;/div&gt;
                &lt;div class="card-detail"&gt;Sharper roll-off than Butterworth at the cost of passband ripple&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-iir"&gt;IIR&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="elliptic"&gt;
                &lt;div class="card-title"&gt;Elliptic (Cauer) Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Sharpest possible transition band for a given filter order&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-iir"&gt;IIR&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="bessel"&gt;
                &lt;div class="card-title"&gt;Bessel Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Maximally flat group delay &amp;mdash; preserves waveform shape&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-iir"&gt;IIR&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;The Analog Heritage&lt;/h3&gt;
            These are the workhorses of analog and digital filter design, each optimizing a different property
            of the frequency response. Choosing among them is an exercise in trade-offs: flat passband vs.
            sharp roll-off vs. linear phase. They are typically designed in the s-domain (Laplace) and converted
            to digital form via the bilinear transform.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Tier 3: Optimal / Adaptive --&gt;
    &lt;div class="tier tier-optimal"&gt;
        &lt;div class="tier-label"&gt;
            OPTIMAL &amp;amp;&lt;br&gt;ADAPTIVE
            &lt;span class="tier-subtitle"&gt;Model-Based&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="tier-components"&gt;
            &lt;div class="filter-card" data-filter="kalman"&gt;
                &lt;div class="card-title"&gt;Kalman Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Recursive Bayesian estimator &amp;mdash; optimal for linear Gaussian systems&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-iir"&gt;IIR&lt;/span&gt;
                    &lt;span class="tag tag-adaptive"&gt;Adaptive&lt;/span&gt;
                    &lt;span class="tag tag-recursive"&gt;Recursive&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="wiener"&gt;
                &lt;div class="card-title"&gt;Wiener Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Minimizes mean square error using signal and noise power spectra&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-fir"&gt;FIR or IIR&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="lms"&gt;
                &lt;div class="card-title"&gt;LMS Adaptive Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Online gradient descent that tracks time-varying statistics&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-fir"&gt;FIR&lt;/span&gt;
                    &lt;span class="tag tag-adaptive"&gt;Adaptive&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="particle"&gt;
                &lt;div class="card-title"&gt;Particle Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Sequential Monte Carlo for nonlinear, non-Gaussian estimation&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-nonlinear"&gt;Nonlinear&lt;/span&gt;
                    &lt;span class="tag tag-adaptive"&gt;Adaptive&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;Statistical Optimality&lt;/h3&gt;
            These filters use knowledge of the signal's statistical structure (or a dynamic model) to
            achieve performance that fixed-coefficient filters cannot match. The Kalman filter, in particular,
            is ubiquitous in navigation, control, and tracking. The Wiener filter is its frequency-domain
            counterpart. Adaptive filters like LMS learn online when statistics are unknown.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Tier 4: Specialized --&gt;
    &lt;div class="tier tier-specialized"&gt;
        &lt;div class="tier-label"&gt;
            SPECIALIZED
            &lt;span class="tier-subtitle"&gt;Purpose-Built&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="tier-components"&gt;
            &lt;div class="filter-card" data-filter="savitzky-golay"&gt;
                &lt;div class="card-title"&gt;Savitzky-Golay Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Polynomial least-squares fit that preserves peaks and edges&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-fir"&gt;FIR&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="notch"&gt;
                &lt;div class="card-title"&gt;Notch (Band-Stop) Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Surgically removes a narrow frequency band&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-iir"&gt;IIR&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="complementary"&gt;
                &lt;div class="card-title"&gt;Complementary Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Fuses high-frequency and low-frequency sensor data&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-iir"&gt;IIR&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="mahony"&gt;
                &lt;div class="card-title"&gt;Mahony Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Nonlinear complementary filter for attitude estimation on SO(3)&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-nonlinear"&gt;Nonlinear&lt;/span&gt;
                    &lt;span class="tag tag-recursive"&gt;Recursive&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="matched"&gt;
                &lt;div class="card-title"&gt;Matched Filter&lt;/div&gt;
                &lt;div class="card-detail"&gt;Maximizes SNR for detecting a known pulse shape in noise&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-fir"&gt;FIR&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;The Right Tool&lt;/h3&gt;
            General-purpose filters are not always the best choice. These specialized designs solve specific
            problems more elegantly: removing power-line hum, fusing accelerometer and gyroscope data, detecting
            radar pulses, or smoothing spectroscopy data without distorting peak shapes.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Tier 5: Design Paradigms --&gt;
    &lt;div class="tier tier-design"&gt;
        &lt;div class="tier-label"&gt;
            DESIGN&lt;br&gt;PARADIGMS
            &lt;span class="tier-subtitle"&gt;FIR vs IIR&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="tier-components"&gt;
            &lt;div class="filter-card" data-filter="fir"&gt;
                &lt;div class="card-title"&gt;Finite Impulse Response (FIR)&lt;/div&gt;
                &lt;div class="card-detail"&gt;Non-recursive: output depends only on current and past inputs&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-fir"&gt;FIR&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="filter-card" data-filter="iir"&gt;
                &lt;div class="card-title"&gt;Infinite Impulse Response (IIR)&lt;/div&gt;
                &lt;div class="card-detail"&gt;Recursive: output feeds back, achieving steep roll-off with fewer coefficients&lt;/div&gt;
                &lt;div class="card-tags"&gt;
                    &lt;span class="tag tag-iir"&gt;IIR&lt;/span&gt;
                    &lt;span class="tag tag-recursive"&gt;Recursive&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;The Fundamental Choice&lt;/h3&gt;
            Every digital filter is either FIR or IIR. FIR filters are always stable and can have exactly
            linear phase, but require many taps for sharp cutoffs. IIR filters are computationally efficient
            but can be unstable and introduce phase distortion. Understanding this trade-off is the foundation
            of all digital filter design.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="cross-cutting"&gt;
        &lt;h2&gt;Cross-Cutting Design Principles&lt;/h2&gt;
        &lt;p class="section-subtitle"&gt;Considerations that cut across every tier and influence filter selection regardless of category&lt;/p&gt;

        &lt;div class="principle-card"&gt;
            &lt;div class="principle-title"&gt;Statistical Consistency&lt;/div&gt;
            &lt;div class="principle-body"&gt;
                &lt;p&gt;Statistical consistency is about properly representing the statistical distribution of your input &amp;mdash; often in parametric form &amp;mdash; to your downstream consumer. What this really comes down to is your filter's ability to accurately represent probability.&lt;/p&gt;
                &lt;p&gt;This is a spectrum, not a binary property. At one end, the &lt;strong&gt;Kalman filter&lt;/strong&gt; commits fully: it assumes unbiased Gaussian distributions and propagates exact covariances, so its output is only statistically consistent when those assumptions hold. At the other end, the &lt;strong&gt;particle filter&lt;/strong&gt; can represent an arbitrarily complex likelihood function in theory, giving it the flexibility to remain consistent under non-Gaussian, multimodal, or heavily skewed distributions. In between, the &lt;strong&gt;complementary filter&lt;/strong&gt; works well for the opposite reason entirely: it makes no claims about the statistical model of its input and does not claim to be analytically optimal. It simply cannot be statistically &lt;em&gt;in&lt;/em&gt;consistent, because it never promised consistency in the first place.&lt;/p&gt;
                &lt;ul class="principle-examples"&gt;
                    &lt;li&gt;&lt;strong&gt;Kalman filter:&lt;/strong&gt; Restricted to unbiased Gaussian probabilities &amp;mdash; statistically consistent only when that assumption is met&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Particle filter:&lt;/strong&gt; Can define arbitrarily complex likelihood functions, so it can maintain consistency in a much wider range of scenarios&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Complementary filter:&lt;/strong&gt; Agnostic to the statistical model &amp;mdash; no optimality claims, so no consistency guarantees to violate&lt;/li&gt;
                &lt;/ul&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="footer-note"&gt;
        &lt;strong&gt;Rule of thumb:&lt;/strong&gt; Start simple. A moving average or EMA solves most noise problems.
        Move to classical IIR filters when you need precise frequency selectivity. Reach for Kalman or adaptive
        filters when the signal has known dynamics or the noise statistics change over time.
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
    const filters = {
        'moving-average': {
            title: 'Moving Average Filter',
            content: `
                &lt;p&gt;The moving average is the simplest and most intuitive digital filter. It computes the arithmetic mean of the last N samples, sliding the window forward one sample at a time.&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$y[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} x[n-k]$$
                &lt;/div&gt;

                &lt;p&gt;The window length &lt;strong&gt;N&lt;/strong&gt; controls the trade-off: larger N gives more smoothing but introduces more lag (group delay of (N&amp;minus;1)/2 samples).&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Frequency response:&lt;/strong&gt; The magnitude is a sinc-like function with nulls at multiples of f&lt;sub&gt;s&lt;/sub&gt;/N. It acts as a low-pass filter, but with poor stopband attenuation (only &amp;minus;13 dB at the first sidelobe).&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$H(f) = \\frac{1}{N} \\cdot \\frac{\\sin(\\pi f N / f_s)}{\\sin(\\pi f / f_s)}$$
                &lt;/div&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Trivial to implement (no multiply needed with equal weights)&lt;/li&gt;
                            &lt;li&gt;Always stable (FIR)&lt;/li&gt;
                            &lt;li&gt;Exactly linear phase (symmetric coefficients)&lt;/li&gt;
                            &lt;li&gt;Optimal for reducing white noise while keeping sharpest step response&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Poor frequency selectivity (wide transition band)&lt;/li&gt;
                            &lt;li&gt;Requires O(N) storage&lt;/li&gt;
                            &lt;li&gt;Fixed group delay of (N&amp;minus;1)/2 samples&lt;/li&gt;
                            &lt;li&gt;Treats all points in the window equally (no weighting)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Stock market analysis:&lt;/strong&gt; 20-day and 200-day moving averages to identify trends&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Sensor smoothing:&lt;/strong&gt; Averaging accelerometer or temperature readings on a microcontroller&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Audio metering:&lt;/strong&gt; VU meters average rectified audio to show perceived loudness&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Network monitoring:&lt;/strong&gt; Smoothing packet rate or latency measurements in dashboards&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'ema': {
            title: 'Exponential Moving Average (EMA)',
            content: `
                &lt;p&gt;The EMA is a first-order IIR low-pass filter that gives exponentially decreasing weight to older samples. It requires only one multiplication, one addition, and a single stored value &amp;mdash; the cheapest possible recursive filter.&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$y[n] = \\alpha \\cdot x[n] + (1 - \\alpha) \\cdot y[n-1]$$
                &lt;/div&gt;

                &lt;p&gt;The smoothing factor &lt;strong&gt;&amp;alpha;&lt;/strong&gt; &amp;isin; (0, 1] controls bandwidth. A small &amp;alpha; gives heavy smoothing (low cutoff frequency); &amp;alpha; = 1 means no filtering (output equals input).&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Cutoff frequency relationship:&lt;/strong&gt;&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$\\alpha = \\frac{2\\pi \\, f_c / f_s}{1 + 2\\pi \\, f_c / f_s} \\qquad \\text{or equivalently} \\qquad f_c = \\frac{\\alpha \\, f_s}{2\\pi(1 - \\alpha)}$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Transfer function:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$H(z) = \\frac{\\alpha}{1 - (1 - \\alpha) z^{-1}}$$
                &lt;/div&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Extremely low memory (one state variable)&lt;/li&gt;
                            &lt;li&gt;One multiply, one add per sample&lt;/li&gt;
                            &lt;li&gt;No window length to choose &amp;mdash; tunes continuously via &amp;alpha;&lt;/li&gt;
                            &lt;li&gt;Responds instantly to transients (no fixed look-back)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Nonlinear phase (distorts waveform shape)&lt;/li&gt;
                            &lt;li&gt;Only &amp;minus;20 dB/decade roll-off (gentle slope)&lt;/li&gt;
                            &lt;li&gt;Cannot achieve sharp cutoff without cascading stages&lt;/li&gt;
                            &lt;li&gt;Sensitive to initial condition (first output depends on y[&amp;minus;1])&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Embedded control:&lt;/strong&gt; Smoothing ADC readings on microcontrollers with limited RAM&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;TCP congestion control:&lt;/strong&gt; EWMA estimates of round-trip time in TCP/IP stacks&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Financial trading:&lt;/strong&gt; 12-day and 26-day EMA form the basis of the MACD indicator&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Touch input smoothing:&lt;/strong&gt; Reducing jitter in stylus/finger position on touchscreens&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'median': {
            title: 'Median Filter',
            content: `
                &lt;p&gt;The median filter replaces each sample with the median of itself and its neighbors. Unlike linear filters, it is fundamentally nonlinear &amp;mdash; you cannot describe it with a transfer function or impulse response.&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$y[n] = \\text{median}\\{x[n-k], \\ldots, x[n], \\ldots, x[n+k]\\}$$
                    &lt;br&gt;where the window has 2k+1 samples (always odd).
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Key property:&lt;/strong&gt; The median is immune to outliers. A single sample that is wildly different from its neighbors (an impulse, a spike, a salt-and-pepper pixel) is simply discarded, because one outlier cannot shift the median of a majority of good values.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Removes impulsive noise without blurring edges&lt;/li&gt;
                            &lt;li&gt;Preserves step edges and sharp transitions exactly&lt;/li&gt;
                            &lt;li&gt;No ringing or Gibbs-like artifacts&lt;/li&gt;
                            &lt;li&gt;Robust to extreme outliers (breakdown point of ~50%)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Computationally expensive (sorting required per window)&lt;/li&gt;
                            &lt;li&gt;Cannot be described by a transfer function (nonlinear)&lt;/li&gt;
                            &lt;li&gt;Destroys fine texture and thin features smaller than the window&lt;/li&gt;
                            &lt;li&gt;Not optimal for Gaussian noise (moving average is better for that)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Image processing:&lt;/strong&gt; Removing salt-and-pepper noise from camera images&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Radar/lidar:&lt;/strong&gt; Rejecting transient interference spikes from range measurements&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;ECG processing:&lt;/strong&gt; Removing baseline wander and motion artifacts from heart signals&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Ultrasonic sensors:&lt;/strong&gt; Filtering spurious readings from sonar range finders in robotics&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'butterworth': {
            title: 'Butterworth Filter',
            content: `
                &lt;p&gt;The Butterworth filter is designed for the flattest possible magnitude response in the passband. It has no ripple &amp;mdash; the magnitude decreases monotonically from the passband into the stopband. This "maximally flat magnitude" property makes it the default choice when you want clean passband behavior.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Analog prototype (low-pass):&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$|H(j\\omega)|^2 = \\frac{1}{1 + \\left(\\omega / \\omega_c\\right)^{2N}}$$
                &lt;/div&gt;

                &lt;p&gt;where N is the filter order and &amp;omega;&lt;sub&gt;c&lt;/sub&gt; is the cutoff frequency (&amp;minus;3 dB point). The roll-off is &amp;minus;20N dB/decade.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Pole placement:&lt;/strong&gt; The 2N poles of |H(s)|&amp;sup2; lie equally spaced on a circle of radius &amp;omega;&lt;sub&gt;c&lt;/sub&gt; in the s-plane. The stable filter uses the N poles in the left half-plane.&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$s_k = \\omega_c \\, e^{j\\pi(2k + N - 1)/(2N)}, \\quad k = 1, 2, \\ldots, N$$
                &lt;/div&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;No passband ripple (maximally flat)&lt;/li&gt;
                            &lt;li&gt;Monotonic magnitude response everywhere&lt;/li&gt;
                            &lt;li&gt;Well-understood, easy to design with standard tables&lt;/li&gt;
                            &lt;li&gt;Good all-round choice when no special constraints exist&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Wide transition band compared to Chebyshev or Elliptic&lt;/li&gt;
                            &lt;li&gt;Requires higher order (more computation) for sharp cutoff&lt;/li&gt;
                            &lt;li&gt;Nonlinear phase &amp;mdash; distorts waveform shape&lt;/li&gt;
                            &lt;li&gt;Group delay varies with frequency&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Audio crossovers:&lt;/strong&gt; Splitting audio into bass/mid/treble bands for speakers&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Anti-aliasing:&lt;/strong&gt; Low-pass before ADC sampling in data acquisition systems&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Seismology:&lt;/strong&gt; Band-pass filtering seismic data to isolate frequency bands of interest&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Biomedical:&lt;/strong&gt; Filtering EMG/EEG signals to standard clinical frequency bands&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'chebyshev': {
            title: 'Chebyshev Filter (Type I &amp; Type II)',
            content: `
                &lt;p&gt;Chebyshev filters trade passband flatness for a sharper transition from passband to stopband. They come in two variants:&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Type I (passband ripple):&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$|H(j\\omega)|^2 = \\frac{1}{1 + \\varepsilon^2 \\, T_N^2(\\omega / \\omega_c)}$$
                &lt;/div&gt;
                &lt;p&gt;where T&lt;sub&gt;N&lt;/sub&gt; is the Chebyshev polynomial of order N and &amp;epsilon; controls the ripple amplitude. The passband oscillates within a specified dB band, but the transition to stopband is much steeper than Butterworth of the same order.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Type II (stopband ripple):&lt;/strong&gt; Also called "inverse Chebyshev." The passband is flat (like Butterworth), but the stopband has equiripple behavior. Less commonly used because the roll-off is not as steep as Type I.&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$\\text{For Type I, ripple in dB:} \\quad R_p = 10 \\log_{10}(1 + \\varepsilon^2)$$
                &lt;/div&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Steeper roll-off than Butterworth for the same order&lt;/li&gt;
                            &lt;li&gt;Lower order needed to meet a given transition-band spec&lt;/li&gt;
                            &lt;li&gt;Type II gives flat passband with sharp roll-off&lt;/li&gt;
                            &lt;li&gt;Well-characterized design equations&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Passband ripple (Type I) distorts amplitude of signals in-band&lt;/li&gt;
                            &lt;li&gt;Worse group delay variation than Butterworth&lt;/li&gt;
                            &lt;li&gt;Phase response is more nonlinear&lt;/li&gt;
                            &lt;li&gt;More ringing in step response compared to Butterworth&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;RF/communications:&lt;/strong&gt; Channel selection filters where sharp roll-off is critical&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Power-line filtering:&lt;/strong&gt; Tight rejection of 50/60 Hz with minimal passband impact&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Audio equalization:&lt;/strong&gt; Where slight passband ripple is acceptable for steep cut&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Instrumentation:&lt;/strong&gt; Anti-alias filters in high-speed oscilloscopes&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'elliptic': {
            title: 'Elliptic (Cauer) Filter',
            content: `
                &lt;p&gt;The elliptic filter achieves the absolute sharpest transition band for a given filter order by allowing ripple in &lt;em&gt;both&lt;/em&gt; the passband and the stopband. It is the optimal solution when the transition width is the primary constraint.&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$|H(j\\omega)|^2 = \\frac{1}{1 + \\varepsilon^2 \\, R_N^2(\\xi, \\omega / \\omega_c)}$$
                &lt;/div&gt;

                &lt;p&gt;where R&lt;sub&gt;N&lt;/sub&gt; is the Nth-order Chebyshev rational function (ratio of Chebyshev polynomials), and &amp;xi; is related to the selectivity factor. The equiripple behavior in both bands is the mathematical consequence of the Chebyshev-like optimization in both regions.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Design parameters:&lt;/strong&gt; passband ripple R&lt;sub&gt;p&lt;/sub&gt;, stopband attenuation A&lt;sub&gt;s&lt;/sub&gt;, passband edge &amp;omega;&lt;sub&gt;p&lt;/sub&gt;, and stopband edge &amp;omega;&lt;sub&gt;s&lt;/sub&gt;. Given these four, the minimum required order N is uniquely determined.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Sharpest possible transition band for given order&lt;/li&gt;
                            &lt;li&gt;Lowest order needed to meet simultaneous passband/stopband specs&lt;/li&gt;
                            &lt;li&gt;Most computationally efficient for tight filter specs&lt;/li&gt;
                            &lt;li&gt;Generalizes both Butterworth and Chebyshev as special cases&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Ripple in both passband and stopband&lt;/li&gt;
                            &lt;li&gt;Worst group delay variation of the classical filters&lt;/li&gt;
                            &lt;li&gt;Most complex to design (elliptic integral calculations)&lt;/li&gt;
                            &lt;li&gt;Highest ringing in step/impulse response&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Telecommunications:&lt;/strong&gt; Tight channel-select filters in radio receivers&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Spectrum analyzers:&lt;/strong&gt; Resolution bandwidth filters requiring minimal transition width&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;ADSL modems:&lt;/strong&gt; Splitting voice and data bands on phone lines&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Medical ultrasound:&lt;/strong&gt; Band-pass filters to isolate narrow transducer frequency bands&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'bessel': {
            title: 'Bessel (Thomson) Filter',
            content: `
                &lt;p&gt;The Bessel filter is designed for maximally flat group delay. This means it passes all frequency components through the filter with nearly the same time delay, preserving the waveform shape of the signal. This is the opposite priority from Chebyshev/Elliptic, which optimize magnitude at the expense of phase.&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$H(s) = \\frac{\\theta_N(0)}{\\theta_N(s/\\omega_0)}$$
                &lt;/div&gt;

                &lt;p&gt;where &amp;theta;&lt;sub&gt;N&lt;/sub&gt;(s) is the reverse Bessel polynomial. The group delay is approximately constant up to roughly the &amp;minus;3 dB frequency.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Group delay:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\tau(\\omega) = -\\frac{d\\phi(\\omega)}{d\\omega} \\approx \\text{const} \\quad \\text{for } \\omega &lt; \\omega_c$$
                &lt;/div&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Best waveform preservation (near-linear phase)&lt;/li&gt;
                            &lt;li&gt;Minimal overshoot in step response&lt;/li&gt;
                            &lt;li&gt;No ringing &amp;mdash; ideal for pulse and transient signals&lt;/li&gt;
                            &lt;li&gt;Monotonic magnitude response (no ripple)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Very gradual roll-off (much worse than Butterworth)&lt;/li&gt;
                            &lt;li&gt;Requires high order for any meaningful stopband rejection&lt;/li&gt;
                            &lt;li&gt;Linear phase advantage lost in bilinear transform (use FIR instead for digital)&lt;/li&gt;
                            &lt;li&gt;Rarely the right choice for digital filters&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Oscilloscope front-ends:&lt;/strong&gt; Anti-alias filter must not distort pulse shapes&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Analog video processing:&lt;/strong&gt; Preserving sharp edges in composite video signals&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Pulse transmission:&lt;/strong&gt; Communications systems where pulse shape integrity matters&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Audio mastering:&lt;/strong&gt; Gentle low-pass without phase coloration&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'kalman': {
            title: 'Kalman Filter',
            content: `
                &lt;p&gt;The Kalman filter is a recursive algorithm that estimates the state of a linear dynamical system from noisy measurements. It is provably &lt;em&gt;optimal&lt;/em&gt; (minimum mean-square error) when the system is linear and the noise is Gaussian.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;State-space model:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\mathbf{x}_{k} = \\mathbf{F}\\mathbf{x}_{k-1} + \\mathbf{B}\\mathbf{u}_{k} + \\mathbf{w}_{k}, \\quad \\mathbf{w}_k \\sim \\mathcal{N}(0, \\mathbf{Q})$$
                    $$\\mathbf{z}_{k} = \\mathbf{H}\\mathbf{x}_{k} + \\mathbf{v}_{k}, \\quad \\mathbf{v}_k \\sim \\mathcal{N}(0, \\mathbf{R})$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Predict step:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\hat{\\mathbf{x}}_{k|k-1} = \\mathbf{F}\\hat{\\mathbf{x}}_{k-1|k-1} + \\mathbf{B}\\mathbf{u}_k$$
                    $$\\mathbf{P}_{k|k-1} = \\mathbf{F}\\mathbf{P}_{k-1|k-1}\\mathbf{F}^T + \\mathbf{Q}$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Update step:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\mathbf{K}_k = \\mathbf{P}_{k|k-1}\\mathbf{H}^T(\\mathbf{H}\\mathbf{P}_{k|k-1}\\mathbf{H}^T + \\mathbf{R})^{-1}$$
                    $$\\hat{\\mathbf{x}}_{k|k} = \\hat{\\mathbf{x}}_{k|k-1} + \\mathbf{K}_k(\\mathbf{z}_k - \\mathbf{H}\\hat{\\mathbf{x}}_{k|k-1})$$
                    $$\\mathbf{P}_{k|k} = (\\mathbf{I} - \\mathbf{K}_k\\mathbf{H})\\mathbf{P}_{k|k-1}$$
                &lt;/div&gt;

                &lt;p&gt;The &lt;strong&gt;Kalman gain K&lt;/strong&gt; automatically balances trust between the model prediction and the measurement, depending on the relative uncertainties P, Q, and R.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Provably optimal (MMSE) for linear Gaussian systems&lt;/li&gt;
                            &lt;li&gt;Adapts bandwidth in real time via the Kalman gain&lt;/li&gt;
                            &lt;li&gt;Fuses multiple sensors naturally via the measurement model&lt;/li&gt;
                            &lt;li&gt;Provides uncertainty estimate (covariance P) alongside the state&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Requires a known linear model (F, H, Q, R)&lt;/li&gt;
                            &lt;li&gt;Suboptimal if noise is non-Gaussian or system is nonlinear&lt;/li&gt;
                            &lt;li&gt;Sensitive to incorrect noise parameters (Q and R tuning is an art)&lt;/li&gt;
                            &lt;li&gt;Matrix operations can be expensive for high-dimensional state&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;GPS/INS navigation:&lt;/strong&gt; Fusing GPS position with inertial measurements for aircraft, spacecraft, and phones&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Object tracking:&lt;/strong&gt; Predicting and correcting the position of targets in radar and computer vision&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Robotics:&lt;/strong&gt; Estimating robot pose from odometry, lidar, and camera data (via EKF/UKF)&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Economics:&lt;/strong&gt; Estimating hidden state variables in macroeconomic models&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'wiener': {
            title: 'Wiener Filter',
            content: `
                &lt;p&gt;The Wiener filter is the frequency-domain counterpart to the Kalman filter. It finds the linear filter that minimizes the mean square error between the desired signal and the estimated signal, given knowledge of the signal and noise power spectral densities.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Non-causal Wiener filter:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$H(f) = \\frac{S_{xx}(f)}{S_{xx}(f) + S_{nn}(f)} = \\frac{\\text{SNR}(f)}{1 + \\text{SNR}(f)}$$
                &lt;/div&gt;

                &lt;p&gt;where S&lt;sub&gt;xx&lt;/sub&gt;(f) is the power spectral density of the clean signal and S&lt;sub&gt;nn&lt;/sub&gt;(f) is the noise PSD. At frequencies where SNR is high, H &amp;approx; 1 (pass the signal). Where SNR is low, H &amp;approx; 0 (suppress the noise).&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Wiener-Hopf equation (time-domain):&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\mathbf{R}_{xx} \\mathbf{h} = \\mathbf{r}_{xd}$$
                &lt;/div&gt;
                &lt;p&gt;where R&lt;sub&gt;xx&lt;/sub&gt; is the autocorrelation matrix of the input and r&lt;sub&gt;xd&lt;/sub&gt; is the cross-correlation between input and desired signal.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Optimal (MMSE) in the frequency domain for stationary signals&lt;/li&gt;
                            &lt;li&gt;Intuitive interpretation: attenuates based on local SNR&lt;/li&gt;
                            &lt;li&gt;Efficient to compute via FFT for block processing&lt;/li&gt;
                            &lt;li&gt;Foundation for spectral subtraction and denoising&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Requires known (or estimated) signal and noise PSDs&lt;/li&gt;
                            &lt;li&gt;Assumes stationarity &amp;mdash; performance degrades for time-varying signals&lt;/li&gt;
                            &lt;li&gt;Non-causal form is not realizable for real-time use&lt;/li&gt;
                            &lt;li&gt;Causal version is mathematically harder (spectral factorization)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Audio noise reduction:&lt;/strong&gt; Removing background noise from speech recordings&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Image deblurring:&lt;/strong&gt; Restoring images degraded by known point-spread functions&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Astronomy:&lt;/strong&gt; Denoising telescope images where noise statistics are well characterized&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Hearing aids:&lt;/strong&gt; Real-time speech enhancement in noisy environments&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'lms': {
            title: 'LMS (Least Mean Squares) Adaptive Filter',
            content: `
                &lt;p&gt;The LMS filter is an adaptive FIR filter that adjusts its coefficients in real time using stochastic gradient descent. It is the practical, online version of the Wiener filter &amp;mdash; it converges to the Wiener solution without needing to know the signal statistics in advance.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Update equations:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$y[n] = \\mathbf{w}^T[n] \\, \\mathbf{x}[n]$$
                    $$e[n] = d[n] - y[n]$$
                    $$\\mathbf{w}[n+1] = \\mathbf{w}[n] + \\mu \\, e[n] \\, \\mathbf{x}[n]$$
                &lt;/div&gt;

                &lt;p&gt;where &lt;strong&gt;&amp;mu;&lt;/strong&gt; is the step size (learning rate), &lt;strong&gt;w&lt;/strong&gt; is the coefficient vector, &lt;strong&gt;x&lt;/strong&gt; is the input vector, and &lt;strong&gt;d&lt;/strong&gt; is the desired (reference) signal. The step size must satisfy 0 &amp;lt; &amp;mu; &amp;lt; 2/(&amp;lambda;&lt;sub&gt;max&lt;/sub&gt;) for stability, where &amp;lambda;&lt;sub&gt;max&lt;/sub&gt; is the largest eigenvalue of the input autocorrelation matrix.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Normalized LMS (NLMS):&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\mathbf{w}[n+1] = \\mathbf{w}[n] + \\frac{\\mu}{\\|\\mathbf{x}[n]\\|^2 + \\delta} \\, e[n] \\, \\mathbf{x}[n]$$
                &lt;/div&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;No prior knowledge of signal statistics needed&lt;/li&gt;
                            &lt;li&gt;Tracks time-varying environments automatically&lt;/li&gt;
                            &lt;li&gt;Very simple to implement (one inner product + weight update)&lt;/li&gt;
                            &lt;li&gt;Guaranteed convergence with proper step size&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Slow convergence when input eigenvalue spread is large&lt;/li&gt;
                            &lt;li&gt;Step size trade-off: fast convergence vs. low steady-state error&lt;/li&gt;
                            &lt;li&gt;Requires a reference (desired) signal&lt;/li&gt;
                            &lt;li&gt;FIR structure means many taps needed for narrowband filtering&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Active noise cancellation:&lt;/strong&gt; ANC headphones use LMS to generate anti-noise in real time&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Echo cancellation:&lt;/strong&gt; Removing acoustic echo in speakerphone and conferencing systems&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Channel equalization:&lt;/strong&gt; Compensating for ISI in digital communication receivers&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Biomedical:&lt;/strong&gt; Removing 50/60 Hz interference from ECG using a reference electrode&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'particle': {
            title: 'Particle Filter (Sequential Monte Carlo)',
            content: `
                &lt;p&gt;The particle filter represents the posterior distribution of the state using a set of weighted samples ("particles"). Unlike the Kalman filter, it makes &lt;em&gt;no assumptions&lt;/em&gt; about linearity or Gaussianity &amp;mdash; it can handle arbitrary nonlinear dynamics and non-Gaussian noise.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Algorithm sketch:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\text{1. Sample: } \\mathbf{x}_k^{(i)} \\sim p(\\mathbf{x}_k | \\mathbf{x}_{k-1}^{(i)}) \\quad \\text{(propagate each particle through the dynamics)}$$
                    $$\\text{2. Weight: } w_k^{(i)} \\propto p(\\mathbf{z}_k | \\mathbf{x}_k^{(i)}) \\quad \\text{(score by measurement likelihood)}$$
                    $$\\text{3. Resample: draw N particles from } \\{\\mathbf{x}_k^{(i)}\\} \\text{ with probability } \\propto w_k^{(i)}$$
                &lt;/div&gt;

                &lt;p&gt;The state estimate is the weighted mean of the particles. As the number of particles N &amp;rarr; &amp;infin;, the estimate converges to the true Bayesian posterior.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Handles any nonlinear dynamics and observation models&lt;/li&gt;
                            &lt;li&gt;No Gaussian assumption &amp;mdash; represents multimodal distributions&lt;/li&gt;
                            &lt;li&gt;Conceptually simple and easy to implement&lt;/li&gt;
                            &lt;li&gt;Naturally handles ambiguity (e.g., "the robot might be here or there")&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Computationally expensive &amp;mdash; cost scales with particle count&lt;/li&gt;
                            &lt;li&gt;Particle degeneracy in high dimensions (curse of dimensionality)&lt;/li&gt;
                            &lt;li&gt;No closed-form uncertainty (must be estimated from particles)&lt;/li&gt;
                            &lt;li&gt;Difficult to tune: number of particles, resampling strategy&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Robot localization:&lt;/strong&gt; Monte Carlo Localization (MCL) for mobile robots using lidar maps&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;SLAM:&lt;/strong&gt; FastSLAM uses particles for robot pose and Kalman filters for landmarks&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Visual tracking:&lt;/strong&gt; Tracking faces or objects in video with occlusion and appearance change&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Finance:&lt;/strong&gt; Estimating stochastic volatility models with non-Gaussian jumps&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'savitzky-golay': {
            title: 'Savitzky-Golay Filter',
            content: `
                &lt;p&gt;The Savitzky-Golay filter fits a polynomial of degree p to a sliding window of 2m+1 points using least-squares, then evaluates the polynomial at the center point. It is equivalent to convolution with a specific set of FIR coefficients, but the coefficients are derived from the polynomial fit rather than frequency-domain design.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Key formula:&lt;/strong&gt; The filter coefficients are computed from the pseudoinverse of the Vandermonde matrix:&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\mathbf{h} = (\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{e}_0$$
                &lt;/div&gt;
                &lt;p&gt;where A is the Vandermonde matrix of the window indices and e&lt;sub&gt;0&lt;/sub&gt; selects the 0th-derivative (smoothing) row. By selecting different rows, the same framework gives smoothed derivatives of any order.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Example (quadratic, 5-point window):&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$y[n] = \\frac{-3 x[n-2] + 12 x[n-1] + 17 x[n] + 12 x[n+1] - 3 x[n+2]}{35}$$
                &lt;/div&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Preserves peak height, width, and position (unlike moving average)&lt;/li&gt;
                            &lt;li&gt;Simultaneously provides smoothed derivatives&lt;/li&gt;
                            &lt;li&gt;FIR &amp;mdash; always stable, exactly linear phase&lt;/li&gt;
                            &lt;li&gt;Polynomial order gives control over what features to preserve&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Poor at suppressing narrowband interference&lt;/li&gt;
                            &lt;li&gt;Window edges can introduce artifacts (Runge-like effects for high degree)&lt;/li&gt;
                            &lt;li&gt;Not optimal for any standard statistical criterion&lt;/li&gt;
                            &lt;li&gt;Choice of polynomial degree and window size can be tricky&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Spectroscopy:&lt;/strong&gt; Smoothing absorption/emission spectra without distorting peaks&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Chromatography:&lt;/strong&gt; Peak detection and baseline correction in HPLC and GC data&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Numerical differentiation:&lt;/strong&gt; Computing smooth velocity/acceleration from noisy position data&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Electrochemistry:&lt;/strong&gt; Smoothing voltammetry curves while preserving peak shapes&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'notch': {
            title: 'Notch (Band-Stop) Filter',
            content: `
                &lt;p&gt;A notch filter removes a narrow frequency band while passing everything else. It is the surgical instrument of signal processing: when you know exactly which frequency is the problem, a notch filter excises it with minimal damage to the rest of the spectrum.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Second-order IIR notch filter:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$H(z) = \\frac{1 - 2\\cos(\\omega_0) z^{-1} + z^{-2}}{1 - 2r\\cos(\\omega_0) z^{-1} + r^2 z^{-2}}$$
                &lt;/div&gt;

                &lt;p&gt;where &amp;omega;&lt;sub&gt;0&lt;/sub&gt; = 2&amp;pi;f&lt;sub&gt;0&lt;/sub&gt;/f&lt;sub&gt;s&lt;/sub&gt; is the normalized notch frequency and &lt;strong&gt;r&lt;/strong&gt; (0 &amp;lt; r &amp;lt; 1) controls the notch width. Closer to 1 gives a narrower notch. The numerator places zeros on the unit circle at &amp;omega;&lt;sub&gt;0&lt;/sub&gt;, giving exactly zero gain at that frequency. The denominator poles (at radius r) control how quickly the gain recovers.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Notch bandwidth:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\text{BW}_{-3\\text{dB}} \\approx \\frac{(1 - r^2)}{r} \\cdot \\frac{f_s}{2\\pi}$$
                &lt;/div&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Precisely removes a single interfering frequency&lt;/li&gt;
                            &lt;li&gt;Minimal disturbance to the rest of the spectrum&lt;/li&gt;
                            &lt;li&gt;Very low computational cost (second-order IIR)&lt;/li&gt;
                            &lt;li&gt;Can cascade multiple notches for harmonics&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Only works when interference frequency is known and stable&lt;/li&gt;
                            &lt;li&gt;Narrow notch &amp;rarr; pole close to unit circle &amp;rarr; sensitivity to coefficient quantization&lt;/li&gt;
                            &lt;li&gt;Phase distortion near the notch frequency&lt;/li&gt;
                            &lt;li&gt;If interference drifts in frequency, an adaptive notch is needed&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Power-line interference:&lt;/strong&gt; Removing 50/60 Hz hum from ECG, EEG, and audio recordings&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Guitar effects:&lt;/strong&gt; Feedback suppression by notching the resonant frequency&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Vibration analysis:&lt;/strong&gt; Removing known machine rotation frequencies to see anomalies&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Radio:&lt;/strong&gt; Rejecting a single strong interferer near the desired signal&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'complementary': {
            title: 'Complementary Filter',
            content: `
                &lt;p&gt;A complementary filter combines a high-pass and low-pass filter whose transfer functions sum to unity: H&lt;sub&gt;LP&lt;/sub&gt;(s) + H&lt;sub&gt;HP&lt;/sub&gt;(s) = 1. This is typically used to fuse two sensors that are accurate in complementary frequency ranges.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Classic form (first-order):&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\hat{\\theta} = \\alpha \\cdot (\\hat{\\theta}_{\\text{prev}} + \\omega_{\\text{gyro}} \\cdot \\Delta t) + (1 - \\alpha) \\cdot \\theta_{\\text{accel}}$$
                &lt;/div&gt;

                &lt;p&gt;The gyroscope is accurate at high frequencies but drifts at low frequencies. The accelerometer is accurate at low frequencies but noisy at high frequencies. The complementary filter takes the best of both:&lt;/p&gt;

                &lt;div class="formula-block"&gt;
                    $$H_{\\text{gyro}}(s) = \\frac{\\tau s}{1 + \\tau s}, \\qquad H_{\\text{accel}}(s) = \\frac{1}{1 + \\tau s}$$
                    $$H_{\\text{gyro}}(s) + H_{\\text{accel}}(s) = 1$$
                &lt;/div&gt;

                &lt;p&gt;The time constant &amp;tau; (or equivalently &amp;alpha;) determines the crossover frequency between the two sensors.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Extremely simple to implement (one line of code)&lt;/li&gt;
                            &lt;li&gt;No matrix math or model needed (unlike Kalman)&lt;/li&gt;
                            &lt;li&gt;Provides drift-free estimates from drifting sensors&lt;/li&gt;
                            &lt;li&gt;Unity gain at all frequencies (no signal attenuation)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Only one tuning parameter (crossover frequency)&lt;/li&gt;
                            &lt;li&gt;No formal uncertainty estimate&lt;/li&gt;
                            &lt;li&gt;Cannot handle sensor biases or scale factors explicitly&lt;/li&gt;
                            &lt;li&gt;Suboptimal compared to Kalman filter for the same sensor pair&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Drone attitude estimation:&lt;/strong&gt; Fusing gyroscope and accelerometer for roll/pitch&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Smartphone orientation:&lt;/strong&gt; Combining gyro, accel, and magnetometer in AHRS&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Camera stabilization:&lt;/strong&gt; Gimbal controllers fusing rate gyros with horizon references&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Balancing robots:&lt;/strong&gt; Estimating tilt angle from IMU for PID control&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'mahony': {
            title: 'Mahony Filter',
            content: `
                &lt;p&gt;The Mahony filter is a nonlinear complementary filter that estimates orientation (attitude) directly on the rotation group SO(3). It fuses gyroscope and accelerometer (and optionally magnetometer) data using a proportional-integral correction scheme applied to the rotation kinematics, avoiding the singularities and linearization errors of Euler-angle or quaternion-based EKFs.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Core idea:&lt;/strong&gt; Integrate gyroscope angular velocity to propagate the attitude estimate, then correct drift using the error between the predicted and measured gravity (and magnetic field) directions.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Error metric (vector cross-product):&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\mathbf{e} = \\hat{\\mathbf{v}} \\times \\mathbf{a}_{\\text{meas}}$$
                &lt;/div&gt;
                &lt;p&gt;where \\(\\hat{\\mathbf{v}}\\) is the estimated gravity direction (from the current attitude) and \\(\\mathbf{a}_{\\text{meas}}\\) is the normalized accelerometer reading. This cross-product is approximately proportional to the attitude error for small errors.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Corrected gyroscope rate:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\boldsymbol{\\omega}_{\\text{corr}} = \\boldsymbol{\\omega}_{\\text{gyro}} + K_p \\mathbf{e} + K_i \\int \\mathbf{e} \\, dt$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Quaternion integration:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\dot{\\mathbf{q}} = \\tfrac{1}{2} \\mathbf{q} \\otimes \\begin{bmatrix} 0 \\\\ \\boldsymbol{\\omega}_{\\text{corr}} \\end{bmatrix}$$
                &lt;/div&gt;

                &lt;p&gt;The proportional gain &lt;strong&gt;K&lt;sub&gt;p&lt;/sub&gt;&lt;/strong&gt; controls how aggressively the accelerometer corrects drift (analogous to &amp;alpha; in the linear complementary filter). The integral gain &lt;strong&gt;K&lt;sub&gt;i&lt;/sub&gt;&lt;/strong&gt; estimates and removes gyroscope bias online.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Works directly on SO(3) &amp;mdash; no gimbal lock or singularities&lt;/li&gt;
                            &lt;li&gt;Very lightweight: no matrices, no covariance propagation&lt;/li&gt;
                            &lt;li&gt;Built-in gyroscope bias estimation via the integral term&lt;/li&gt;
                            &lt;li&gt;Proven stability guarantees on the rotation manifold&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;No formal uncertainty output (unlike a Kalman filter)&lt;/li&gt;
                            &lt;li&gt;Two gains to tune (K&lt;sub&gt;p&lt;/sub&gt;, K&lt;sub&gt;i&lt;/sub&gt;) with limited systematic guidance&lt;/li&gt;
                            &lt;li&gt;Accelerometer correction assumes quasi-static conditions (degrades under sustained linear acceleration)&lt;/li&gt;
                            &lt;li&gt;Cannot easily fuse additional sensor types beyond the IMU triad&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Multirotor flight controllers:&lt;/strong&gt; Default AHRS in many open-source autopilots (ArduPilot, Betaflight, PX4)&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Wearable motion capture:&lt;/strong&gt; Real-time limb orientation from body-worn IMUs&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Handheld camera stabilization:&lt;/strong&gt; Gimbal controllers estimating camera attitude from 6-axis IMU&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Underwater vehicles:&lt;/strong&gt; Attitude estimation where GPS is unavailable and computational budget is tight&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'matched': {
            title: 'Matched Filter',
            content: `
                &lt;p&gt;The matched filter maximizes the output signal-to-noise ratio (SNR) when detecting a known signal (pulse, waveform) buried in additive white Gaussian noise. The filter's impulse response is the time-reversed, conjugated version of the signal you are looking for.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Impulse response:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$h[n] = s^*[N - 1 - n]$$
                &lt;/div&gt;
                &lt;p&gt;where s[n] is the known signal template and * denotes complex conjugation. This is equivalent to cross-correlating the input with the template.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Maximum output SNR:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$\\text{SNR}_{\\text{max}} = \\frac{2E}{N_0}$$
                &lt;/div&gt;
                &lt;p&gt;where E is the signal energy and N&lt;sub&gt;0&lt;/sub&gt;/2 is the noise power spectral density. This is the theoretical upper bound &amp;mdash; no other linear filter can do better.&lt;/p&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Maximizes output SNR (provably optimal detector)&lt;/li&gt;
                            &lt;li&gt;Equivalent to correlation &amp;mdash; simple to implement via FFT&lt;/li&gt;
                            &lt;li&gt;Foundation of optimal detection theory&lt;/li&gt;
                            &lt;li&gt;Works for any known waveform shape&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Requires exact knowledge of the signal waveform&lt;/li&gt;
                            &lt;li&gt;Optimal only for white Gaussian noise (must pre-whiten for colored noise)&lt;/li&gt;
                            &lt;li&gt;Sensitive to Doppler shift if target is moving&lt;/li&gt;
                            &lt;li&gt;Range resolution limited by signal bandwidth&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Radar:&lt;/strong&gt; Detecting returns from known transmitted pulses (pulse compression)&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Sonar:&lt;/strong&gt; Detecting echoes from underwater objects&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Digital communications:&lt;/strong&gt; Optimal receiver for PAM, QAM, and spread-spectrum signals&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Gravitational wave detection:&lt;/strong&gt; LIGO uses matched filtering to find black hole mergers in noise&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'fir': {
            title: 'FIR (Finite Impulse Response) Filters',
            content: `
                &lt;p&gt;An FIR filter computes its output as a weighted sum of the current and past N input samples. The impulse response is finite &amp;mdash; it is exactly the coefficient vector itself, and it dies to zero after N samples.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;General form:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$y[n] = \\sum_{k=0}^{N-1} b_k \\, x[n-k] = \\mathbf{b}^T \\mathbf{x}[n]$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Transfer function:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$H(z) = \\sum_{k=0}^{N-1} b_k \\, z^{-k}$$
                &lt;/div&gt;

                &lt;p&gt;All N zeros, no poles (other than at z=0). This means FIR filters are &lt;strong&gt;always stable&lt;/strong&gt; regardless of coefficient values.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Linear phase condition:&lt;/strong&gt; If the coefficients are symmetric (b&lt;sub&gt;k&lt;/sub&gt; = b&lt;sub&gt;N&amp;minus;1&amp;minus;k&lt;/sub&gt;) or antisymmetric, the filter has exactly linear phase, meaning all frequencies are delayed by the same amount. This is impossible for IIR filters.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Design methods:&lt;/strong&gt;&lt;/p&gt;
                &lt;ul style="margin: 10px 0 10px 20px;"&gt;
                    &lt;li&gt;&lt;strong&gt;Window method:&lt;/strong&gt; Start from ideal (sinc) response, multiply by a window (Hamming, Kaiser, etc.)&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Parks-McClellan (Remez):&lt;/strong&gt; Optimal equiripple design minimizing the maximum error&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Frequency sampling:&lt;/strong&gt; Specify desired values at DFT frequencies and inverse-transform&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Least-squares:&lt;/strong&gt; Minimize integrated squared error over the frequency band&lt;/li&gt;
                &lt;/ul&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Always stable (no feedback)&lt;/li&gt;
                            &lt;li&gt;Can achieve exactly linear phase&lt;/li&gt;
                            &lt;li&gt;No limit cycle oscillations or overflow issues&lt;/li&gt;
                            &lt;li&gt;Easy to implement on FPGAs and DSPs (MAC operations)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Requires many more coefficients than IIR for sharp transitions&lt;/li&gt;
                            &lt;li&gt;Higher computational cost per sample&lt;/li&gt;
                            &lt;li&gt;Longer group delay for equivalent frequency selectivity&lt;/li&gt;
                            &lt;li&gt;Cannot efficiently implement very low cutoff frequencies&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Audio/music:&lt;/strong&gt; Linear-phase EQ in mastering to avoid phase coloration&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Communications:&lt;/strong&gt; Pulse-shaping filters (raised cosine) in digital modems&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Multirate DSP:&lt;/strong&gt; Decimation and interpolation filters in sample-rate converters&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Image processing:&lt;/strong&gt; 2D convolution kernels for blurring, sharpening, edge detection&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        },
        'iir': {
            title: 'IIR (Infinite Impulse Response) Filters',
            content: `
                &lt;p&gt;An IIR filter uses feedback: the output depends on both the current/past inputs &lt;em&gt;and&lt;/em&gt; past outputs. This recursion means the impulse response is theoretically infinite in duration, decaying exponentially (when stable).&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;General form (Direct Form I):&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$y[n] = \\sum_{k=0}^{M} b_k \\, x[n-k] - \\sum_{k=1}^{N} a_k \\, y[n-k]$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Transfer function:&lt;/strong&gt;&lt;/p&gt;
                &lt;div class="formula-block"&gt;
                    $$H(z) = \\frac{\\sum_{k=0}^{M} b_k z^{-k}}{1 + \\sum_{k=1}^{N} a_k z^{-k}} = \\frac{B(z)}{A(z)}$$
                &lt;/div&gt;

                &lt;p&gt;&lt;strong&gt;Stability:&lt;/strong&gt; An IIR filter is stable if and only if all poles of H(z) lie strictly inside the unit circle. This must be verified during design and can be compromised by coefficient quantization in fixed-point implementations.&lt;/p&gt;

                &lt;p&gt;&lt;strong&gt;Common structures:&lt;/strong&gt;&lt;/p&gt;
                &lt;ul style="margin: 10px 0 10px 20px;"&gt;
                    &lt;li&gt;&lt;strong&gt;Direct Form II Transposed:&lt;/strong&gt; Minimizes delay elements, most common in practice&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Cascaded second-order sections (biquads):&lt;/strong&gt; Factors H(z) into 2nd-order stages for numerical robustness&lt;/li&gt;
                    &lt;li&gt;&lt;strong&gt;Lattice structure:&lt;/strong&gt; Better quantization properties, used in speech coding&lt;/li&gt;
                &lt;/ul&gt;

                &lt;div class="pros-cons"&gt;
                    &lt;div class="pros"&gt;
                        &lt;h4&gt;Pros&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Much fewer coefficients than FIR for equivalent selectivity&lt;/li&gt;
                            &lt;li&gt;Lower computational cost for sharp frequency transitions&lt;/li&gt;
                            &lt;li&gt;Direct analog-to-digital conversion via bilinear transform&lt;/li&gt;
                            &lt;li&gt;Low group delay relative to steepness of roll-off&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                    &lt;div class="cons"&gt;
                        &lt;h4&gt;Cons&lt;/h4&gt;
                        &lt;ul&gt;
                            &lt;li&gt;Can be unstable if poles drift outside unit circle&lt;/li&gt;
                            &lt;li&gt;Cannot achieve linear phase (always introduces phase distortion)&lt;/li&gt;
                            &lt;li&gt;Susceptible to limit cycles in fixed-point arithmetic&lt;/li&gt;
                            &lt;li&gt;Sensitive to coefficient quantization (especially high-order)&lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/div&gt;

                &lt;div class="examples"&gt;
                    &lt;h4&gt;Real-World Applications&lt;/h4&gt;
                    &lt;ul&gt;
                        &lt;li&gt;&lt;strong&gt;Audio effects:&lt;/strong&gt; Parametric EQ, wah-wah, resonant filters in synthesizers&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Control systems:&lt;/strong&gt; PID controllers are IIR filters in disguise&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Telephony:&lt;/strong&gt; DTMF tone detection using Goertzel algorithm (IIR)&lt;/li&gt;
                        &lt;li&gt;&lt;strong&gt;Biomedical:&lt;/strong&gt; Real-time ECG/EEG filtering with low latency requirements&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            `
        }
    };

    const modal = document.getElementById('modal');
    const modalTitle = document.getElementById('modal-title');
    const modalBody = document.getElementById('modal-body');
    const closeBtn = document.querySelector('.close');

    document.querySelectorAll('.filter-card').forEach(card =&gt; {
        card.addEventListener('click', function() {
            const key = this.getAttribute('data-filter');
            const info = filters[key];
            if (info) {
                modalTitle.textContent = info.title;
                modalBody.innerHTML = info.content;
                modal.style.display = 'block';
                // Re-render MathJax in the modal
                if (window.MathJax) {
                    MathJax.Hub.Queue(["Typeset", MathJax.Hub, modalBody]);
                }
            }
        });
    });

    closeBtn.addEventListener('click', function() {
        modal.style.display = 'none';
    });

    window.addEventListener('click', function(event) {
        if (event.target === modal) {
            modal.style.display = 'none';
        }
    });

    document.addEventListener('keydown', function(event) {
        if (event.key === 'Escape' &amp;&amp; modal.style.display === 'block') {
            modal.style.display = 'none';
        }
    });
&lt;/script&gt;
</code></pre>
</body>

</style></head></html><div style="break-before: page; page-break-before: always;"></div>
<h1 id="the-kalman-filter-time-varying-lqe"><a class="header" href="#the-kalman-filter-time-varying-lqe">The Kalman Filter (Time-Varying LQE)</a></h1>
<p>The Kalman Filter deals with estimating \(\hat{\boldsymbol{x}}\) for linear <em>dynamic</em> systems, which adds real-time optimality properties to the basic <a href="#the-luenberger-observer-lqe">Luenberger Observer LQE</a>.</p>
<p>You’ll probably only ever implement the discrete-time version of the Kalman filter. A nice tutorial can be found <a href="https://www.kalmanfilter.net/default.aspx">here</a>.</p>
<h2 id="discrete-time-kalman-filter"><a class="header" href="#discrete-time-kalman-filter">Discrete-Time Kalman Filter</a></h2>
<h3 id="overview"><a class="header" href="#overview">Overview</a></h3>
<p><strong>Problem Statement:</strong> Obtain the unbiased, minimum-variance linear estimate for all \(\boldsymbol{x}_k\) given the sequence of measurements \(\boldsymbol{y}_k\), subject to the dynamic and measurement models</p>
<p>$$\boldsymbol{x}_{k+1}=\boldsymbol{A}_k\boldsymbol{x}_k+\boldsymbol{B}_k\boldsymbol{u}_k+\boldsymbol{w}_k$$</p>
<p>$$\boldsymbol{y}_k=\boldsymbol{C}_k\boldsymbol{x}_k+\boldsymbol{v}_k$$</p>
<p>$$E[\boldsymbol{w}_k]=0,~E[\boldsymbol{v}_k]=0,~E[\boldsymbol{w}_j\boldsymbol{w}_k^T]=\boldsymbol{W}_k\delta_{jk},~E[\boldsymbol{v}_j\boldsymbol{v}_k^T]=\boldsymbol{V}_k\delta_{jk},~E[\boldsymbol{w}_k\boldsymbol{v}_j^T]=0$$</p>
<p>$$E[\boldsymbol{x}_0]=\bar{\boldsymbol{x}}_0,~E[(\boldsymbol{x}_0-\bar{\boldsymbol{x}}_0)(\boldsymbol{x}_0-\bar{\boldsymbol{x}}_0)^T]=\boldsymbol{P}_0$$</p>
<p>with \(\boldsymbol{w}_k\) and \(\boldsymbol{v}_k\) independent of \(\boldsymbol{x}_0\). There are many, many ways to derive the solution; <em>16.32L16</em> derives it using the optimal projection theorem (see the end of the previous section). The solution is the discrete-time Kalman Filter (which is the version you would implement on a computer, most likely).</p>
<p>This is the optimal linear filter, even if we added a positive definite matrix weighting term \(\boldsymbol{S}_k\) to the cost. It would be relatively straightforward to extend the algorithm to accommodate things like colored noise sequences and correlated measurement/process noise.</p>
<p>It should be noted that the residual sequence \(\boldsymbol{r}_k=\boldsymbol{y}_k-\boldsymbol{C}_k\hat{\boldsymbol{x}}_k\) is white, such that \(E[\boldsymbol{r}_k]=0\) and \(E[\boldsymbol{r}_k\boldsymbol{r}_j^T]=0,~j\neq k\). This is useful for verifying the optimality of an implemented filter.</p>
<h3 id="algorithm"><a class="header" href="#algorithm">Algorithm</a></h3>
<ul>
<li><em>Initialization:</em> \(\hat{\boldsymbol{x}}_0=\bar{\boldsymbol{x}}_0\), \(\boldsymbol{Q}_0=\boldsymbol{P}_0\)</li>
<li><em>State Propagation:</em> \(\hat{\boldsymbol{x}}_{k+1}^-=\boldsymbol{A}_{k}\hat{\boldsymbol{x}}_{k}^++\boldsymbol{B}_k\boldsymbol{u}_k\)</li>
<li><em>Covariance Propagation:</em> \(\boldsymbol{Q}_{k+1}^-=\boldsymbol{A}_{k}\boldsymbol{Q}_{k}^+\boldsymbol{A}_{k}^T+\boldsymbol{W}_{k}\)</li>
<li><em>Kalman Gain Calculation:</em> \(\boldsymbol{L}_k=\boldsymbol{Q}_k^-\boldsymbol{C}_k^T(\boldsymbol{C}_k\boldsymbol{Q}_k^-\boldsymbol{C}_k^T+\boldsymbol{V}_k)^{-1}\)</li>
<li><em>Measurement Update:</em> \(\hat{\boldsymbol{x}}_{k}^+=\hat{\boldsymbol{x}}_{k}^-+\boldsymbol{L}_k(\boldsymbol{y}_k-\boldsymbol{C}_k\hat{\boldsymbol{x}}_k^-)\)</li>
<li><em>Covariance Update:</em> \(\boldsymbol{Q}_{k}^+=(\boldsymbol{I}-\boldsymbol{L}_k\boldsymbol{C}_k)\boldsymbol{Q}_k^-(\boldsymbol{I}-\boldsymbol{L}_k\boldsymbol{C}_k)^T+\boldsymbol{L}_k\boldsymbol{V}_k\boldsymbol{L}_k^T\)</li>
</ul>
<p>The covariance update step above (which adds a positive definite matrix to a positive semidefinite one) is the preferable equation to use over the sometimes-cited \(\boldsymbol{Q}_{k}^+=(\boldsymbol{I}-\boldsymbol{L}_k\boldsymbol{C}_k)\boldsymbol{Q}_k^-\), which is more prone to become indefinite due to numerical rounding errors as a positive semi-definite matrix is <em>subtracted</em> from a positive definite one.</p>
<h2 id="continuous-time-kalman-filter"><a class="header" href="#continuous-time-kalman-filter">Continuous-Time Kalman Filter</a></h2>
<h3 id="overview-1"><a class="header" href="#overview-1">Overview</a></h3>
<p><strong>Problem Statement:</strong> Obtain the minimum-variance linear estimate of \(\boldsymbol{x}(t)\) given a continuous measurement function \(\boldsymbol{y}(t)\), subject to the dynamic and measurement models</p>
<p>$$\dot{\boldsymbol{x}}(t)=\boldsymbol{A}(t)\boldsymbol{x}(t)+\boldsymbol{B}_w(t)\boldsymbol{w}(t)$$</p>
<p>$$\boldsymbol{y}(t)=\boldsymbol{C}(t)\boldsymbol{x}(t)+\boldsymbol{v}(t)$$</p>
<p>$$E[\boldsymbol{w}(t)]=0,~E[\boldsymbol{v}(t)]=0,~E[\boldsymbol{w}(t)\boldsymbol{w}(\tau)^T]=\boldsymbol{W}(t)\delta(t-\tau),~E[\boldsymbol{v}(t)\boldsymbol{v}(\tau)^T]=\boldsymbol{V}(t)\delta(t-\tau),~E[\boldsymbol{w}(t)\boldsymbol{v}(\tau)^T]=0$$</p>
<p>$$E[\boldsymbol{x}(t_0)]=\bar{\boldsymbol{x}}_0,~E[(\boldsymbol{x}(t_0)-\bar{\boldsymbol{x}}_0)(\boldsymbol{x}(t_0)-\bar{\boldsymbol{x}}_0)^T]=\boldsymbol{Q}_0$$</p>
<p>with \(\boldsymbol{w}(t)\) and \(\boldsymbol{v}(t)\) independent of \(\boldsymbol{x}(t_0)\). Again, there are many ways to derive the solution, and <em>16.32L17</em> gives derivations from the optimal projection theorem, taking the limit of the discrete-time KF, solving an optimal control problem with <em>ad hoc</em> cost, and solving an optimal control problem to optimize the choice of filter gain \(\boldsymbol{L}\).</p>
<p>Note that if you were trying to <em>sample</em> from \(\boldsymbol{y}(t)\) (defined to be a white-noise process), you’d be tempted to model that as \(\boldsymbol{y}_k=\boldsymbol{y}(k\Delta t)\). BUT, because white noise varies over time with no rhyme or reason, the resulting covariance would actually be infinite! Instead, you have to time-average the white noise to get a pseudo-discrete-time measurement \(\boldsymbol{y}_k=1/\Delta t\int_{k\Delta t}^{(k+1)\Delta t}\boldsymbol{y}(t)dt\), which has a mean of \(\approx \boldsymbol{C} \boldsymbol{x}_k\) and a covariance of \(\approx 1/\Delta t \boldsymbol{V}\).</p>
<p>Another important note: the differential equation for covariance is calculated to be the <em>continuous-time differential Riccati equation for the Kalman Filter</em>:</p>
<p>$$\dot{\boldsymbol{Q}}(t)=\boldsymbol{A}(t)\boldsymbol{Q}(t)+\boldsymbol{Q}(t)\boldsymbol{A}(t)^T+\boldsymbol{B}_w(t)\boldsymbol{W}(t)\boldsymbol{B}_w(t)^T-\boldsymbol{Q}(t)\boldsymbol{C}(t)^T\boldsymbol{V}(t)^{-1}\boldsymbol{C}(t)\boldsymbol{Q}(t)$$</p>
<p>which is the dual of the LQR CARE for the costate! The conditions for this Kalman Filter are also the dual of the LQR conditions:</p>
<ul>
<li>Must be observable (detectable?) through \(\boldsymbol{C}\)</li>
<li>Must be controllable (stabilizable?) through \(\boldsymbol{B}_w\)</li>
</ul>
<p>Remember how, even with a time-varying linear system, the steady-state result of the CARE gives a nearly optimal LQR with a long time horizon? The same logic applies here. However, since the KF ARE integrates forward in time, why not just solve it normally to get the fully optimal solution?</p>
<p>As with the discrete-time case, the residual \(\boldsymbol{r}(t)=\boldsymbol{y}(t)-\boldsymbol{C}(t)\hat{\boldsymbol{x}}(t)\) is also a white noise process, demonstrating optimality.</p>
<p>FYI, the transfer-function version of the continuous-time KF is called the <em>Wiener filter</em>.</p>
<h3 id="algorithm-1"><a class="header" href="#algorithm-1">Algorithm</a></h3>
<ul>
<li>\(\dot{\hat{\boldsymbol{x}}}(t)=\boldsymbol{A}(t)\hat{\boldsymbol{x}}(t)+\boldsymbol{L}(t)(\boldsymbol{y}(t)-\boldsymbol{C}(t)\hat{\boldsymbol{x}}(t))\)</li>
<li>\(\dot{\boldsymbol{Q}}=(\boldsymbol{A}-\boldsymbol{L}\boldsymbol{C})\boldsymbol{Q}+\boldsymbol{Q}(\boldsymbol{A}-\boldsymbol{L}\boldsymbol{C})^T+\boldsymbol{L}\boldsymbol{V}\boldsymbol{L}^T+\boldsymbol{B}_w\boldsymbol{W}\boldsymbol{B}_w^T\)</li>
<li>\(\boldsymbol{L}(t)=\boldsymbol{Q}(t)\boldsymbol{C}(t)^T\boldsymbol{V}(t)^{-1}\)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="the-kinematic-filters"><a class="header" href="#the-kinematic-filters">The Kinematic Filters</a></h1>
<p><em>No need for a sophisticated dynamic model (if you can get away with it).</em></p>
<p>The filters presented here are for LTI systems that can be well-approximated as <em>kinematic</em>:</p>
<p>$$\boldsymbol{x}=\begin{bmatrix}x &amp; \dot{x} &amp; \ddot{x} &amp; \cdots\end{bmatrix}^\top ,$$</p>
<p>$$\dot{\boldsymbol{x}}=\begin{bmatrix}0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0\\0 &amp; 0 &amp; 1 &amp; \cdots &amp; 0\\ \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots\\ 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 1\\0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0\end{bmatrix}\boldsymbol{x}+\begin{bmatrix}0\\0\\ \vdots\\0\\1\end{bmatrix}\boldsymbol{u},$$</p>
<p>$$\boldsymbol{y}=\begin{bmatrix}1 &amp; 0 &amp; 0 &amp; \cdots\end{bmatrix}\boldsymbol{x}=x.$$</p>
<p>For these formulations, we’ll go one step further and set \(\boldsymbol{B}=0\). The presented filters increase in order from constant position to constant velocity to constant acceleration models. Anything beyond that probably won’t be worth it as higher-order terms empirically tend to become more significant as the system order increases. The derived filters will be of the form</p>
<p>\[ \hat{\boldsymbol{x}}_{k+1}=e^{\boldsymbol{A}\Delta t}\hat{\boldsymbol{x}}_{k}+\boldsymbol{l}r \]</p>
<p>\[r\triangleq x-\hat{x}. \]</p>
<p>Both ad hoc and covariance-based analytic methods are presented for determining the coefficients of \(\boldsymbol{l}\). To provide some intuition for these methods:</p>
<p><wrap group=""> <wrap half="" column=""> <wrap centeralign=""> <strong>Ad Hoc Coefficients</strong> </wrap></wrap></wrap></p>
<p>Coefficients are determined based on a kind of <em>discount factor</em>, \(\theta\).</p>
<p>Since the filter minimizes least-squares error of the residuals through time, \(\theta&lt;1\) weights how much influence the residuals have on the final estimate. Thus, a smaller \(\theta\) will prioritize the filter’s state memory value over individual residuals. This is an intuition that generalizes to the higher-order kinematic filters as well as the one-dimensional case.</p>
<p> <wrap half="" column=""> <wrap centeralign=""> <strong>Covariance-Based Coefficients</strong> </wrap></wrap></p>
<p>With this method of assigning coefficients, the kinematic filter turns into a Luenberger observer / steady-state Kalman Filter with a kinematic model. Thus, it could possibly be optimal! The covariances used for calculating the coefficients are</p>
<p>Process noise:</p>
<p>$$\sigma_w:\dot{\boldsymbol{x}}=\boldsymbol{A}\boldsymbol{x}+\boldsymbol{w}(t)$$</p>
<p>Measurement noise:</p>
<p>$$\sigma_v:\boldsymbol{y}=\boldsymbol{C}\boldsymbol{x}+\boldsymbol{v}(t)$$</p>
<p>You will see that, in comparing with the ad hoc method, \(\theta\sim \sigma_w/\sigma_v\), which is appropriate. If \(\sigma_w\gg \sigma_v\), then residuals should dominate the estimate, hence a large \(\theta\).</p>
<p>If you’re able to approximate your system as kinematic\(^*\), then one of these filters may end up working\(^{**}\) for your application\(^{***}\).</p>
<hr>
<p>\(^*\) Think Taylor Series expansion…either \(\Delta t\) between corrective observations should be really small, the neglected higher-order derivatives should be small, and/or their combination should be small!</p>
<p>\(^{**}\) If you’re able to obtain sufficiently high-rate corrective measurements, for instance, then the point of the filter is (1) predictive ability and (2) full-state tracking. <em>You may say that</em> those two things can be accomplished with numerical differentiation and using those derivatives to propagate kinematic models yourself. You would be right! The filters here do exactly that; in addition to propagating simple kinematic models, they can be viewed as essentially <em>fancy numerical differentiators that handle noisy data in a principled fashion</em>. They also have the advantage of automatically encoding past information for higher-order derivatives in their state vector, a la the Markov assumption for LTI observers, which keeps track of every derivative up to the desired order (mentioned in passing on <a href="http://www.holoborodko.com/pavel/numerical-methods/numerical-derivative/smooth-low-noise-differentiators/">this page</a>).</p>
<p>\(^{***}\) One notable example is in motion capture systems, where high-rate, reliable pose measurements are fused into real-time position, velocity, and acceleration estimates. It wouldn’t be a good idea to use these for tracking attitude, though, which is obviously nonlinear. These filters are also used in many tracking scenarios, such as Raytheon’s radar-based missile trackers (see <em>TRACKING AND KALMAN FILTERING MADE EASY</em> by Eli Brookner).</p>
<h2 id="constant-position-alpha--or-g--filter"><a class="header" href="#constant-position-alpha--or-g--filter">Constant Position (\(\alpha\)- or \(g\)- Filter)</a></h2>
<h3 id="filter-overview"><a class="header" href="#filter-overview">Filter Overview</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th><strong>Quantity</strong></th><th><strong>Value</strong></th></tr>
</thead>
<tbody>
<tr><td>\(\hat{\boldsymbol{x}}\)</td><td>\(\begin{bmatrix}\hat{x}\end{bmatrix}\)</td></tr>
<tr><td>\(\boldsymbol{A}\)</td><td>\(0\)</td></tr>
<tr><td>\(e^{\boldsymbol{A}\Delta t}\)</td><td>\(\boldsymbol{I}+\cdots=1\)</td></tr>
<tr><td>Prediction Step</td><td>\(\hat{\boldsymbol{x}}^-_{k+1}=\hat{\boldsymbol{x}}^+_k\)</td></tr>
<tr><td>Update Step</td><td>\(\hat{\boldsymbol{x}}^+_k=\hat{\boldsymbol{x}}^-_k+\alpha r\)</td></tr>
</tbody>
</table>
</div>
<p><strong>Ad Hoc Coefficients</strong></p>
<p>\(\alpha=\theta\).</p>
<p><strong>Analytical Coefficients</strong></p>
<p>\(\lambda=\frac{\sigma_w\Delta t^2}{\sigma_v},\)</p>
<p>\(\alpha=\frac{-\lambda^2+\sqrt{\lambda^4+16\lambda^2}}{8}.\)</p>
<h3 id="connection-to-low-pass-filtering"><a class="header" href="#connection-to-low-pass-filtering">Connection to Low-Pass Filtering</a></h3>
<p>Recall that the continuous form of the \(\alpha\)-filter:</p>
<p>$$\dot{\hat{x}}=\alpha r=\alpha(x-\hat{x})$$</p>
<p>is a first-order ODE. If you think of the measurement at each time step as a system input \(u\), and the filter estimate as the system internal state, then this describes both a first-order system and a low-pass filter! Thus, you get the namesake alpha low-pass filter and first-order system simulator, to which the math and intuition above directly applies.</p>
<h2 id="constant-velocity-alpha-beta--or-g-h--filter"><a class="header" href="#constant-velocity-alpha-beta--or-g-h--filter">Constant Velocity (\(\alpha\)-\(\beta\)- or \(g\)-\(h\)- Filter)</a></h2>
<h3 id="filter-overview-1"><a class="header" href="#filter-overview-1">Filter Overview</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th><strong>Quantity</strong></th><th><strong>Value</strong></th></tr>
</thead>
<tbody>
<tr><td>\(\hat{\boldsymbol{x}}\)</td><td>\(\begin{bmatrix}\hat{x} &amp; \hat{v}\end{bmatrix}^\top \)</td></tr>
<tr><td>\(\boldsymbol{A}\)</td><td>\(\begin{bmatrix}0 &amp; 1 \\ 0 &amp; 0\end{bmatrix}\)</td></tr>
<tr><td>\(e^{\boldsymbol{A}\Delta t}\)</td><td>\(\boldsymbol{I}+\boldsymbol{A}\Delta t + \cdots=\begin{bmatrix}1 &amp; \Delta t \\ 0 &amp; 1\end{bmatrix}\)</td></tr>
<tr><td>Prediction Step</td><td>\(\hat{\boldsymbol{x}}^-_{k+1}=\begin{bmatrix}1 &amp; \Delta t \\ 0 &amp; 1\end{bmatrix}\hat{\boldsymbol{x}}^+_k\)</td></tr>
<tr><td>Update Step</td><td>\(\hat{\boldsymbol{x}}^+_k=\hat{\boldsymbol{x}}^-_k+\begin{bmatrix}\alpha  \\  \beta/\Delta t\end{bmatrix} r\)</td></tr>
</tbody>
</table>
</div>
<p><strong>Ad Hoc Coefficients</strong></p>
<p>\(\alpha = 1-\theta^2,\)</p>
<p>\(\beta=(1-\theta)^2.\)</p>
<p><strong>Analytical Coefficients</strong></p>
<p>\(\lambda=\frac{\sigma_w\Delta t^2}{\sigma_v},\)</p>
<p>\(r=\frac{4+\lambda-\sqrt{8\lambda+\lambda^2}}{4},\)</p>
<p>\(\alpha=1-r^2,\)</p>
<p>\(\beta=2(2-\alpha)-4\sqrt{1-\alpha}.\)</p>
<h3 id="connection-to-the-dirty-derivative"><a class="header" href="#connection-to-the-dirty-derivative">Connection to the Dirty Derivative</a></h3>
<p>Writing out the full form of the \(\alpha\)-\(\beta\) filter:</p>
<p>$$\begin{bmatrix}\hat{x}_{k}^{+} \\ \dot{\hat{x}}_{k}^{+} \end{bmatrix}=\begin{bmatrix}1 &amp; \Delta t \\ 0 &amp; 1 \end{bmatrix}\begin{bmatrix}\hat{x}_{k-1}^{+} \\ \dot{\hat{x}}_{k-1}^{+} \end{bmatrix}+\begin{bmatrix}\alpha \\ \beta/\Delta t \end{bmatrix}(x_{k}-\hat{x}_{k}^{-})$$</p>
<p>The derivative term is calculated in terms of the rest of the state as</p>
<p>$$\begin{align*}\dot{\hat{x}}_{k}^{+} &amp; =\dot{\hat{x}}_{k-1}^{+}+\beta/\Delta t(x_{k}-\hat{x}_{k}^{-}) \\ &amp; =\dot{\hat{x}}_{k-1}^{+}+\beta/\Delta t(x_{k}-\hat{x}_{k-1}^{+}-\dot{\hat{x}}_{k-1}^{+}\Delta t) \\ &amp; =(1-\beta)\dot{\hat{x}}_{k-1}^{+}+\beta/\Delta t(x_{k}-\hat{x}_{k-1}^{+}).\end{align*}$$</p>
<p>Getting rid of the estimator notation and substituting \(\beta\leftarrow \frac{2\Delta t}{2\sigma + \Delta t}\), we obtain:</p>
<p>$$\dot{x}_{k}=\left(\frac{2\sigma-\Delta t}{2\sigma+\Delta t}\right)\dot{x}_{k-1}+\left(\frac{2}{2\sigma+\Delta t}\right)(x_{k}-x_{k-1}),$$</p>
<p>which is the equation for the dirty derivative! So, the dirty derivative is a special case of the \(\alpha\)-\(\beta\)-filter, where \(\alpha=0\) and \(\beta=\frac{2\Delta t}{2\sigma + \Delta t}\). This is reminiscent of how a low-pass filter implementation of the \(\alpha\) filter uses the rise time of its transfer function to set its coefficient value.</p>
<h2 id="constant-acceleration-alpha-beta-gamma--or-g-h-k--filter"><a class="header" href="#constant-acceleration-alpha-beta-gamma--or-g-h-k--filter">Constant Acceleration (\(\alpha\)-\(\beta\)-\(\gamma\)- or \(g\)-\(h\)-\(k\)- Filter)</a></h2>
<h3 id="filter-overview-2"><a class="header" href="#filter-overview-2">Filter Overview</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th><strong>Quantity</strong></th><th><strong>Value</strong></th></tr>
</thead>
<tbody>
<tr><td>\(\hat{\boldsymbol{x}}\)</td><td>\(\begin{bmatrix}\hat{x} &amp; \hat{v} &amp; \hat{a}\end{bmatrix}^\top \)</td></tr>
<tr><td>\(\boldsymbol{A}\)</td><td>\(\begin{bmatrix}0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 0\end{bmatrix} \)</td></tr>
<tr><td>\(e^{\boldsymbol{A}\Delta t}\)</td><td>\(\boldsymbol{I}+\boldsymbol{A}\Delta t + \frac{1}{2}\left(\boldsymbol{A}\Delta t\right)^2 + \cdots=\begin{bmatrix}1 &amp; \Delta t &amp; \Delta t^2/2 \\ 0 &amp; 1 &amp; \Delta t \\ 0 &amp; 0 &amp; 1\end{bmatrix}\)</td></tr>
<tr><td>Prediction Step</td><td>\(\hat{\boldsymbol{x}}^-_{k+1}=\begin{bmatrix}1 &amp; \Delta t &amp; \Delta t^2/2 \\ 0 &amp; 1 &amp; \Delta t \\ 0 &amp; 0 &amp; 1\end{bmatrix}\hat{\boldsymbol{x}}^+_k \)</td></tr>
<tr><td>Update Step</td><td>\(\hat{\boldsymbol{x}}^+_k=\hat{\boldsymbol{x}}^-_k+\begin{bmatrix}\alpha  \\  \beta/\Delta t  \  2\gamma/\Delta t^2\end{bmatrix} r \)</td></tr>
</tbody>
</table>
</div>
<p><strong>Ad Hoc Coefficients</strong></p>
<p>\(\alpha=1-\theta^3,\)</p>
<p>\(\beta = \frac{3}{2}(1-\theta^2)(1-\theta),\)</p>
<p>\(\gamma = \frac{1}{2}(1-\theta)^3.\)</p>
<p><strong>Analytical Coefficients</strong></p>
<p>\(\lambda=\frac{\sigma_{w}\Delta t^{2}}{\sigma_{v}},\)</p>
<p>\(b=\frac{\lambda}{2}-3,\)</p>
<p>\(c=\frac{\lambda}{2}+3,\)</p>
<p>\(d=-1,\)</p>
<p>\(p=c-\frac{b^{2}}{3},\)</p>
<p>\(q=\frac{2b^{3}}{27}-\frac{bc}{3}+d,\)</p>
<p>\(v=\sqrt{q^{2}+\frac{4p^{3}}{27}},\)</p>
<p>\(z=-\left(q+\frac{v}{2}\right)^{1/3},\)</p>
<p>\(s=z-\frac{p}{3z}-\frac{b}{3},\)</p>
<p>\(\alpha=1-s^{2},\)</p>
<p>\(\beta=2(1-s)^{2},\)</p>
<p>\(\gamma=\frac{\beta^{2}}{2\alpha}.\)</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="the-luenberger-observer-lqe"><a class="header" href="#the-luenberger-observer-lqe">The Luenberger Observer (LQE)</a></h1>
<p>The Luenberger Observer deals with estimating \(\hat{\boldsymbol{x}}\) for linear <em>dynamic</em> systems, which adds a prediction step and linear constraints to the <a href="#least-squares-optimization">linear static estimation problem</a>.</p>
<p>You’ll probably only ever implement the discrete-time version of the filter…</p>
<h2 id="discrete-time-luenberger-observer"><a class="header" href="#discrete-time-luenberger-observer">Discrete-Time Luenberger Observer</a></h2>
<h3 id="overview-2"><a class="header" href="#overview-2">Overview</a></h3>
<p><strong>Problem Statement:</strong> Obtain the unbiased, minimum-variance linear estimate for \(\boldsymbol{x}_k\) <em>in the steady-state limit</em> (or, in the case of pole-placement, simply satisfy some dynamic response specifications) given the sequence of measurements \(\boldsymbol{y}_k\), subject to the dynamic and measurement models</p>
<p>$$\boldsymbol{x}_{k+1}=\boldsymbol{A}\boldsymbol{x}_k+\boldsymbol{B}\boldsymbol{u}_k + \boldsymbol{w}_k$$</p>
<p>$$\boldsymbol{y}_k=\boldsymbol{C}\boldsymbol{x}_k+\boldsymbol{v}_k$$</p>
<p>$$E[\boldsymbol{w}_k]=0,~E[\boldsymbol{v}_k]=0,~E[\boldsymbol{w}_j\boldsymbol{w}_k^\top ]=\boldsymbol{W}\delta_{jk},~E[\boldsymbol{v}_j\boldsymbol{v}_k^\top ]=\boldsymbol{V}\delta_{jk},~E[\boldsymbol{w}_k\boldsymbol{v}_j^\top ]=0$$</p>
<p>The solution filter takes the form</p>
<p>$$\hat{\boldsymbol{x}}_{k+1}=\boldsymbol{A}\hat{\boldsymbol{x}}_k+\boldsymbol{B}\boldsymbol{u}_k+\boldsymbol{L}(\boldsymbol{y}_k-\boldsymbol{C}\hat{\boldsymbol{x}}_k)$$</p>
<p>where \(\boldsymbol{L}\) is constant throughout the estimation process. More on how to pick coefficient values later.</p>
<h3 id="algorithm-2"><a class="header" href="#algorithm-2">Algorithm</a></h3>
<ul>
<li><em>Initialization:</em> \(\hat{\boldsymbol{x}}_0=\bar{\boldsymbol{x}}_0\), pre-compute \(\boldsymbol{L}\)</li>
<li><em>State Propagation:</em> \(\hat{\boldsymbol{x}}_{k+1}^-=\boldsymbol{A}\hat{\boldsymbol{x}}_{k}^++\boldsymbol{B}\boldsymbol{u}_k\)</li>
<li><em>Measurement Update:</em> \(\hat{\boldsymbol{x}}_{k}^+=\hat{\boldsymbol{x}}_{k}^-+\boldsymbol{L}(\boldsymbol{y}_k-\boldsymbol{C}\hat{\boldsymbol{x}}_k^-)\)</li>
</ul>
<h2 id="picking-coefficients-for-boldsymboll"><a class="header" href="#picking-coefficients-for-boldsymboll">Picking Coefficients for \(\boldsymbol{L}\)</a></h2>
<h3 id="pole-placement"><a class="header" href="#pole-placement">Pole Placement</a></h3>
<p>Say we would like our closed-loop estimator \((\boldsymbol{A}-\boldsymbol{L}\boldsymbol{C})(\boldsymbol{x}(t)-\tilde{\boldsymbol{x}}(t))\) eigenvalues to be at</p>
<p>$$\lambda_1,\lambda_2,\cdots,\lambda_n$$</p>
<p>Giving a desired characteristic polynomial of</p>
<p>$$\phi_d(\lambda)=(\lambda-\lambda_1)(\lambda-\lambda_2)\cdots(\lambda-\lambda_n)$$</p>
<p>Then:</p>
<p>$$\boldsymbol{L}=\phi_d(\boldsymbol{A})\boldsymbol{\mathcal{M}}_O^{-1}\begin{bmatrix}0 \\ \vdots \\ 0 \\ 1\end{bmatrix},$$</p>
<p>where we have the observability matrix:</p>
<p>$$\boldsymbol{\mathcal{M}}_O=\begin{bmatrix}\boldsymbol{C}\\ \boldsymbol{C}\boldsymbol{A}\\ \boldsymbol{C}\boldsymbol{A}^2\\ \vdots\\ \boldsymbol{C}\boldsymbol{A}^{n-1}\end{bmatrix}$$</p>
<h3 id="optimal-pole-placement-lqe"><a class="header" href="#optimal-pole-placement-lqe">Optimal Pole Placement: LQE</a></h3>
<p>If the goal is indeed to minimize the variance of \(\hat{\boldsymbol{x}}\) <em>in the limit</em>, then \(\boldsymbol{L}\) comes from the solution to the Algebraic Ricatti Equation for observers:</p>
<p>$$\boldsymbol{A}\boldsymbol{Q}+\boldsymbol{Q}\boldsymbol{A}^\top -\boldsymbol{Q}\boldsymbol{C}^\top \boldsymbol{V}^{-1}\boldsymbol{C}\boldsymbol{Q}+\boldsymbol{W}=0$$</p>
<p>$$\boldsymbol{L}=\boldsymbol{Q}\boldsymbol{C}^\top \boldsymbol{V}^{-1}$$</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="math-fundamentals"><a class="header" href="#math-fundamentals">Math Fundamentals</a></h1>
<ul>
<li><a href="#3d-geometry">3D Geometry</a>
<ul>
<li><a href="#implementing-rotations-a-robotics-field-guide">Rotations Robotics Field Guide</a></li>
</ul>
</li>
<li><a href="#linear-algebra">Linear Algebra</a>
<ul>
<li><a href="#visualizing-matrices">Visualizing Matrices</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="3d-geometry"><a class="header" href="#3d-geometry">3D Geometry</a></h1>
<ul>
<li><a href="#implementing-rotations-a-robotics-field-guide">Rotations Robotics Field Guide</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="implementing-rotations-a-robotics-field-guide"><a class="header" href="#implementing-rotations-a-robotics-field-guide">Implementing Rotations: A Robotics Field Guide</a></h1>
<p><em><strong>Why?</strong></em></p>
<p>My aim here is to elucidate the complex machinery that constitutes the hard part of working with transforms and frames in robotics: rotations and rotational representations.</p>
<p>Even when working with a pre-existing software library that provides rotational representations for you, there are so many different conventions (and the implications of those conventions, often mixed together, so ingrained in the math) that without thorough documentation on the part of the library (good luck), you’re bound to be banging your head against the wall at some point. Sometimes, even understanding exactly what the functions are giving you can give you pause.</p>
<p><em>This guide is meant to be a one-stop-shop for concisely clarifying the possibilities and helping you recognize which ones you’re working with and their implications. Some convenient calculators that conform to your chosen conventions are also provided.</em></p>
<p>I’ve implemented many of these concepts in a <a href="https://github.com/goromal/manif-geom-cpp">C++ library</a> with corresponding <a href="https://github.com/goromal/geometry">Python bindings</a>. There’s also a <a href="https://gist.github.com/goromal/fb15f44150ca4e0951acaee443f72d3e">Python script</a> that implements the checks laid out in this guide for deducing the rotational conventions used by a particular library.</p>
<h2 id="introduction-conventions"><a class="header" href="#introduction-conventions">Introduction: Conventions</a></h2>
<p>Often ignored or omitted from documentation are the hidden conventions associated with a rotation representation implementation–particularly implementations that allow for converting between different representations. But conventions are very important to get right in order to ensure consistency and correctness, as well as prevent needless hours of debugging. This guide attempts to aggregate most, if not all, possible conventions for the various representations in one place. Here are the types of conventions relevant to rotational representations:</p>
<ul>
<li><strong>Ordering:</strong> Pure semantics–in what order are the components stored in memory and notationally?</li>
<li><strong>Handedness:</strong> This convention is a catch-all for intrinsic properties that determine the geometry of compositions.</li>
<li><strong>Function:</strong> Does the rotation serve to change the reference frame of a vector (Passive) or <em>move</em> the vector (Active) by its action? Note that in computer graphics, active functions are more common, whereas in robotics rotations almost always are meant to be passive. The one nuance is when library definitions associate quaternions with rotation matrices in such a way that it looks like the quaternion is acting as an active counterpart to its corresponding passive rotation matrix–more on that later.</li>
<li><strong>Directionality:</strong> A rotation is relative–the rotation of frame \(A\) relative to frame \(B\). Directionality determines which of \(A\) or \(B\) is the frame being rotated <em>from</em> and <em>to</em>. In robotics, the canonical \(A\) and \(B\) frames are often labeled as \(W\) (the “World” frame) and \(B\) (the “Body” frame). The “World” and “Body” frames are only semi-arbitrary. Regardless of conventions, it is natural to think of a rotation intuitively as going from some “static (World)” frame to some “transformed (Body)” frame.</li>
<li><strong>Perturbation:</strong> Only relevant for representations that have defined addition \(\oplus\) and subtraction \(\ominus\) operators and thus tangent-space vector aliases. Perturbation convention determines which tangent space (or “frame”) the vector belongs to. The convention is largely up to your preference, and isn’t specifically tied to the other conventions used–you just have to be consistent within your algorithm!</li>
</ul>
<p>The table below gives most, if not all, of the possible convention combinations for the rotational representations used in this guide.</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th></th><th>Ordering (<strong>O</strong>)</th><th>Handedness (<strong>H</strong>)</th><th>Function (<strong>F</strong>)</th><th>Directionality (<strong>D</strong>)</th><th>Perturbation (<strong>P</strong>)</th></tr>
</thead>
<tbody>
<tr><td>Rotation Matrix</td><td></td><td></td><td>Active / Passive</td><td>B2W / W2B</td><td>Local / Global</td></tr>
<tr><td>Euler Angles</td><td>3-2-1 / 3-2-3 / 3-1-3\(^{*}\)</td><td>Successive / Fixed Axes</td><td>Active / Passive</td><td>B2W / W2B</td><td></td></tr>
<tr><td>Rodrigues / Axis-Angle</td><td></td><td></td><td>Active / Passive</td><td>B2W / W2B</td><td></td></tr>
<tr><td>Quaternion</td><td>\(q_w\) first / \(q_w\) last</td><td>Right / Left</td><td>Active / Passive</td><td>B2W / W2B</td><td>Local / Global</td></tr>
</tbody>
</table>
</div>
<p>\(^{*}\) There are really \(3^3\) possible orderings of Euler Angles, though a good portion of those are redundant. The three chosen conventions in the table were chosen as (1) NASA standard airplane, (2) NASA standard aerospace, and (3) historically significant.</p>
<p>Two very popular convention groups for quaternions are called the <strong>Hamilton</strong> and <strong>Shuster/JPL</strong> conventions. This table will also include the conventions used by some members of my lab:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th></th><th>Ordering (<strong>O</strong>)</th><th>Handedness (<strong>H</strong>)</th><th>Function (<strong>F</strong>)</th><th>Directionality (<strong>D</strong>)</th></tr>
</thead>
<tbody>
<tr><td>Hamilton</td><td>\(q_w\) first / last</td><td>Right</td><td>Passive</td><td>B2W</td></tr>
<tr><td>Shuster / JPL</td><td>\(q_w\) last</td><td>Left</td><td>Passive</td><td>W2B</td></tr>
<tr><td>My Lab</td><td>\(q_w\) first</td><td>Right</td><td>Active</td><td>W2B</td></tr>
</tbody>
</table>
</div>
<p>See Table 1 of the <a href="https://arxiv.org/abs/1801.07478">Flipped Quaternion Paper</a> for an overview of literature and software that use the Hamilton and Shuster / JPL conventions.</p>
<h2 id="introduction-notions-of-distance"><a class="header" href="#introduction-notions-of-distance">Introduction: Notions of Distance</a></h2>
<p>A distance metric \(\text{dist}(a,b)\) must satisfy the following properties:</p>
<ul>
<li><em>non-negativity</em>: \(\text{dist}(a,b) \geq 0\)</li>
<li><em>identity</em>: \(\text{dist}(a,b)=0 \iff a=b\)</li>
<li><em>symmetry</em>: \(\text{dist}(a,b) \geq \text{dist}(b,a)\)</li>
<li><em>triangle inequality</em>: \(\text{dist}(a,c) \leq \text{dist}(a,b) + \text{dist}(b,c)\)</li>
</ul>
<p>There are many possible choices depending on analytical/computational convenience, particularly for rotations. A good review of metrics can be found in <em>R. Hartley, J. Trumpf, Y. Dai, and H. Li. Rotation averaging. IJCV, 103(3):267-305, 2013.</em>.</p>
<h2 id="rotation-matrix"><a class="header" href="#rotation-matrix">Rotation Matrix</a></h2>
<h3 id="construction-techniques"><a class="header" href="#construction-techniques">Construction Techniques</a></h3>
<p><strong>From Frame Axes \(A\) &amp; \(B\)</strong></p>
<blockquote>
<p>F = Passive:</p>
</blockquote>
<p>$$\mathbf{R}_A^B=\begin{bmatrix}^B\mathbf{x}_A &amp; ^B\mathbf{y}_A &amp; ^B\mathbf{z}_A\end{bmatrix}$$</p>
<blockquote>
<p>F = Active:</p>
</blockquote>
<p>See <em>F = passive</em>, where \(A\) is the source frame and \(B\) is the destination frame.</p>
<p><strong>From Rotation \(\theta\) about n-Axis from World to Body</strong></p>
<ul>
<li>1 and 0’s on the n-dimension</li>
<li>Cosines on the diagonal</li>
<li>Sines everywhere else…</li>
</ul>
<blockquote>
<p>D = B2W:</p>
</blockquote>
<ul>
<li>…Negative sine <strong>underneath</strong> the 1</li>
</ul>
<blockquote>
<p>D = W2B, F = Passive:</p>
</blockquote>
<ul>
<li>…Negative sine <strong>above</strong> the 1</li>
</ul>
<blockquote>
<p>D = W2B, F = Active:</p>
</blockquote>
<ul>
<li>…Negative sine <strong>underneath</strong> the 1</li>
</ul>
<h3 id="conversions-to"><a class="header" href="#conversions-to">Conversions (To…)</a></h3>
<p><strong>Euler Angles</strong></p>
<p><em>Assuming 3-2-1 ordering, H = Successive.</em></p>
<blockquote>
<p>D = B2W:</p>
</blockquote>
<p>$$\phi=\text{atan2}(R_{32},R_{33}),\quad\theta=-\arcsin(R_{31}),\quad\psi=\text{atan2}(R_{21},R_{11})$$</p>
<blockquote>
<p>D = W2B, F = Passive:</p>
</blockquote>
<p>$$\phi=\text{atan2}(R_{23},R_{33}),\quad\theta=-\arcsin(R_{13}),\quad\psi=\text{atan2}(R_{12},R_{11})$$</p>
<blockquote>
<p>D = W2B, F = Active:</p>
</blockquote>
<p>Same matrix form as D = B2W, so:</p>
<p>$$\phi=\text{atan2}(R_{32},R_{33}),\quad\theta=-\arcsin(R_{31}),\quad\psi=\text{atan2}(R_{21},R_{11})$$</p>
<p>Singularity at \(\theta=\pm\pi/2\) (gimbal lock). For H = Fixed, reverse the multiplication order in the underlying matrix construction; extraction then proceeds from the transposed matrix structure.</p>
<p><strong>Rodrigues</strong></p>
<p><em>i.e., the SO(3) logarithmic map</em>.</p>
<blockquote>
<p>D = B2W:</p>
</blockquote>
<p>$$\theta=\cos^{-1}\left(\frac{\text{trace}(\mathbf{R})-1}{2}\right)$$</p>
<p>if \(\theta\neq 0\):</p>
<p>$$\theta\mathbf{u} = Log(\mathbf{R}) = \frac{\theta(\mathbf{R}-\mathbf{R}^T)^\vee}{2\sin(\theta)}$$</p>
<p>else:</p>
<p>$$\theta\mathbf{u} = Log(\mathbf{R}) = \mathbf{0}$$</p>
<p>Alternatively, \(\mathbf{u}\) can be thought of as the eigenvector of \(\mathbf{R}\) that corresponds to the eigenvalue \(1\).</p>
<blockquote>
<p>D = W2B, F = Passive:</p>
</blockquote>
<p>Same formula applied to \(\mathbf{R}_W^B\):</p>
<p>$$\theta\mathbf{u} = Log(\mathbf{R}) = \frac{\theta(\mathbf{R}-\mathbf{R}^T)^\vee}{2\sin(\theta)}$$</p>
<p>Since \(\mathbf{R}_W^B=(\mathbf{R}_B^W)^T\), the result is the negation of the B2W Rodrigues vector: \(Log(\mathbf{R}_W^B)=-Log(\mathbf{R}_B^W)\).</p>
<blockquote>
<p>D = W2B, F = Active:</p>
</blockquote>
<p>Same formula and result as D = B2W, since the W2B active rotation matrix is identical to the B2W passive rotation matrix.</p>
<p><strong>Quaternion</strong></p>
<blockquote>
<p>D = B2W:</p>
</blockquote>
<p>\(\delta=\text{trace}(\boldsymbol{R})\)</p>
<p>if \(\delta&gt;0\) then</p>
<p>\(s=2\sqrt{\delta+1}\)</p>
<p>\(q_w=\frac{s}{4}\)</p>
<p>\(q_x=\frac{1}{s}(R_{32}-R_{23})\)</p>
<p>\(q_y=\frac{1}{s}(R_{13}-R_{31})\)</p>
<p>\(q_z=\frac{1}{s}(R_{21}-R_{12})\)</p>
<p>else if \(R_{11}&gt;R_{22}\) and \(R_{11}&gt;R_{33}\) then</p>
<p>\(s=2\sqrt{1+R_{11}-R_{22}-R_{33}}\)</p>
<p>\(q_w=\frac{1}{s}(R_{32}-R_{23})\)</p>
<p>\(q_x=\frac{s}{4}\)</p>
<p>\(q_y=\frac{1}{s}(R_{21}+R_{12})\)</p>
<p>\(q_z=\frac{1}{s}(R_{31}+R_{13})\)</p>
<p>else if \(R_{22}&gt;R_{33}\) then</p>
<p>\(s=2\sqrt{1+R_{22}-R_{11}-R_{33}}\)</p>
<p>\(q_w=\frac{1}{s}(R_{13}-R_{31})\)</p>
<p>\(q_x=\frac{1}{s}(R_{21}+R_{12})\)</p>
<p>\(q_y=\frac{s}{4}\)</p>
<p>\(q_z=\frac{1}{s}(R_{32}+R_{23})\)</p>
<p>else</p>
<p>\(s=2\sqrt{1+R_{33}-R_{11}-R_{22}}\)</p>
<p>\(q_w=\frac{1}{s}(R_{21}-R_{12})\)</p>
<p>\(q_x=\frac{1}{s}(R_{31}+R_{13})\)</p>
<p>\(q_y=\frac{1}{s}(R_{32}+R_{23})\)</p>
<p>\(q_z=\frac{s}{4}\)</p>
<blockquote>
<p>D = W2B, F = Passive:</p>
</blockquote>
<p>Same Shepperd extraction as D = B2W, applied to \(\mathbf{R}_W^B\). Since \(\mathbf{R}_W^B=(\mathbf{R}_B^W)^T\), this yields \(\mathbf{q}_W^B=(\mathbf{q}_B^W)^{-1}\). Equivalently, using the B2W quaternion components directly:</p>
<p>\(\delta=\text{trace}(\boldsymbol{R})\)</p>
<p>if \(\delta&gt;0\) then</p>
<p>\(s=2\sqrt{\delta+1}\)</p>
<p>\(q_w=\frac{s}{4}\)</p>
<p>\(q_x=\frac{1}{s}(R_{32}-R_{23})\)</p>
<p>\(q_y=\frac{1}{s}(R_{13}-R_{31})\)</p>
<p>\(q_z=\frac{1}{s}(R_{21}-R_{12})\)</p>
<p>else if \(R_{11}&gt;R_{22}\) and \(R_{11}&gt;R_{33}\) then</p>
<p>\(s=2\sqrt{1+R_{11}-R_{22}-R_{33}}\)</p>
<p>\(q_w=\frac{1}{s}(R_{32}-R_{23})\)</p>
<p>\(q_x=\frac{s}{4}\)</p>
<p>\(q_y=\frac{1}{s}(R_{21}+R_{12})\)</p>
<p>\(q_z=\frac{1}{s}(R_{31}+R_{13})\)</p>
<p>else if \(R_{22}&gt;R_{33}\) then</p>
<p>\(s=2\sqrt{1+R_{22}-R_{11}-R_{33}}\)</p>
<p>\(q_w=\frac{1}{s}(R_{13}-R_{31})\)</p>
<p>\(q_x=\frac{1}{s}(R_{21}+R_{12})\)</p>
<p>\(q_y=\frac{s}{4}\)</p>
<p>\(q_z=\frac{1}{s}(R_{32}+R_{23})\)</p>
<p>else</p>
<p>\(s=2\sqrt{1+R_{33}-R_{11}-R_{22}}\)</p>
<p>\(q_w=\frac{1}{s}(R_{21}-R_{12})\)</p>
<p>\(q_x=\frac{1}{s}(R_{31}+R_{13})\)</p>
<p>\(q_y=\frac{1}{s}(R_{32}+R_{23})\)</p>
<p>\(q_z=\frac{s}{4}\)</p>
<p>The formulas are structurally identical to B2W, but plugging in \(\mathbf{R}_W^B\) entries (which are the transpose of \(\mathbf{R}_B^W\)) naturally produces the conjugate quaternion.</p>
<blockquote>
<p>D = W2B, F = Active:</p>
</blockquote>
<p>\(\delta=\text{trace}(\boldsymbol{R})\)</p>
<p>if \(\delta&gt;0\) then</p>
<p>\(s=2\sqrt{\delta+1}\)</p>
<p>\(q_w=\frac{s}{4}\)</p>
<p>\(q_x=\frac{1}{s}(R_{23}-R_{32})\)</p>
<p>\(q_y=\frac{1}{s}(R_{31}-R_{13})\)</p>
<p>\(q_z=\frac{1}{s}(R_{12}-R_{21})\)</p>
<p>else if \(R_{11}&gt;R_{22}\) and \(R_{11}&gt;R_{33}\) then</p>
<p>\(s=2\sqrt{1+R_{11}-R_{22}-R_{33}}\)</p>
<p>\(q_w=\frac{1}{s}(R_{23}-R_{32})\)</p>
<p>\(q_x=\frac{s}{4}\)</p>
<p>\(q_y=\frac{1}{s}(R_{21}+R_{12})\)</p>
<p>\(q_z=\frac{1}{s}(R_{31}+R_{13})\)</p>
<p>else if \(R_{22}&gt;R_{33}\) then</p>
<p>\(s=2\sqrt{1+R_{22}-R_{11}-R_{33}}\)</p>
<p>\(q_w=\frac{1}{s}(R_{31}-R_{13})\)</p>
<p>\(q_x=\frac{1}{s}(R_{21}+R_{12})\)</p>
<p>\(q_y=\frac{s}{4}\)</p>
<p>\(q_z=\frac{1}{s}(R_{32}+R_{23})\)</p>
<p>else</p>
<p>\(s=2\sqrt{1+R_{33}-R_{11}-R_{22}}\)</p>
<p>\(q_w=\frac{1}{s}(R_{12}-R_{21})\)</p>
<p>\(q_x=\frac{1}{s}(R_{31}+R_{13})\)</p>
<p>\(q_y=\frac{1}{s}(R_{32}+R_{23})\)</p>
<p>\(q_z=\frac{s}{4}\)</p>
<h3 id="action"><a class="header" href="#action">Action</a></h3>
<blockquote>
<p>F = passive</p>
</blockquote>
<p>$$\mathbf{R}_A^B~^A\mathbf{v}=^B\mathbf{v}$$</p>
<blockquote>
<p>F = active</p>
</blockquote>
<p>$$\mathbf{R}~^A\mathbf{v}=^A\mathbf{v}’$$</p>
<h3 id="composition-and-inversion"><a class="header" href="#composition-and-inversion">Composition and Inversion</a></h3>
<p><strong>Composition</strong></p>
<p>$$\mathbf{R}_B^C\mathbf{R}_A^B=\mathbf{R}_A^C$$</p>
<p><strong>Inversion</strong></p>
<p>$$\left(\mathbf{R}_A^B\right)^{-1}=\left(\mathbf{R}_A^B\right)^T=\mathbf{R}_B^A$$</p>
<h3 id="addition-and-subtraction"><a class="header" href="#addition-and-subtraction">Addition and Subtraction</a></h3>
<p>Perturbations are represented by \(\boldsymbol{\theta}\in \mathbb{R}^3\), where local perturbations are expressed in the body frame and global perturbations are expressed in the world frame.</p>
<p><strong>Addition</strong></p>
<blockquote>
<p>F = Passive, D = B2W, P = Local</p>
</blockquote>
<p>$$\boldsymbol{R}_{B+}^{W}=\boldsymbol{R}_{B}^{W} \text{Exp}\left(\boldsymbol{\theta}_{B+}^{B}\right)$$</p>
<blockquote>
<p>F = Passive, D = B2W, P = Global</p>
</blockquote>
<p>$$\boldsymbol{R}_{B}^{W+}=\text{Exp}\left(\boldsymbol{\theta}_{W}^{W+}\right)\boldsymbol{R}_{B}^{W}$$</p>
<blockquote>
<p>F = Passive, D = W2B, P = Local</p>
</blockquote>
<p>$$\boldsymbol{R}_{W}^{B+}=\text{Exp}\left(\boldsymbol{\theta}_{B}^{B+}\right)\boldsymbol{R}_{W}^{B}$$</p>
<p><strong>Subtraction</strong></p>
<blockquote>
<p>F = Passive, D = B2W, P = Local</p>
</blockquote>
<p>$$\boldsymbol{\theta}_{B+}^{B}=\text{Log}\left((\boldsymbol{R}_{B}^{W})^T\boldsymbol{R}_{B+}^{W}\right)$$</p>
<blockquote>
<p>F = Passive, D = B2W, P = Global</p>
</blockquote>
<p>$$\boldsymbol{\theta}_{W}^{W+}=\text{Log}\left(\boldsymbol{R}_{B}^{W+}(\boldsymbol{R}_{B}^{W})^T\right)$$</p>
<blockquote>
<p>F = Passive, D = W2B, P = Local</p>
</blockquote>
<p>$$\boldsymbol{\theta}_{B}^{B+}=\text{Log}\left(\boldsymbol{R}_{W}^{B+}(\boldsymbol{R}_{W}^{B})^T\right)$$</p>
<h3 id="notions-of-distance"><a class="header" href="#notions-of-distance">Notions of Distance</a></h3>
<p><strong>Angular/Geodesic</strong></p>
<p>Gives the effective rotation angle about the correct axis:</p>
<p>$$||Log(\mathbf{R}_A^T\mathbf{R}_B)||=||Log(\mathbf{R}_B^T\mathbf{R}_A)||$$</p>
<p><strong>Chordal</strong></p>
<p>A computational, straight-line shortcut utilizing the Frobenius norm:</p>
<p>$$||\mathbf{R}_A-\mathbf{R}_B||_F=||\mathbf{R}_B-\mathbf{R}_A||_F$$</p>
<h3 id="derivatives-and-numeric-integration"><a class="header" href="#derivatives-and-numeric-integration">Derivatives and (Numeric) Integration</a></h3>
<blockquote>
<p>D = B2W:</p>
</blockquote>
<p>$$\dot{\mathbf{R}}_B^W=\mathbf{R}_B^W[\boldsymbol{\omega}^B]_\times=[\boldsymbol{\omega}^W]_\times\mathbf{R}_B^W$$</p>
<p>where \(\boldsymbol{\omega}^B\) and \(\boldsymbol{\omega}^W\) are the angular velocity expressed in the body and world frames, respectively.</p>
<blockquote>
<p>D = W2B, F = Passive:</p>
</blockquote>
<p>$$\dot{\mathbf{R}}_W^B=-[\boldsymbol{\omega}^B]_\times\mathbf{R}_W^B=-\mathbf{R}_W^B[\boldsymbol{\omega}^W]_\times$$</p>
<p><strong>Numeric Integration (first-order):</strong></p>
<blockquote>
<p>D = B2W:</p>
</blockquote>
<p>$$\mathbf{R}_B^W(t+\Delta t)\approx\mathbf{R}_B^W(t)\cdot Exp(\boldsymbol{\omega}^B\Delta t)$$</p>
<blockquote>
<p>D = W2B, F = Passive:</p>
</blockquote>
<p>$$\mathbf{R}_W^B(t+\Delta t)\approx Exp(-\boldsymbol{\omega}^B\Delta t)\cdot\mathbf{R}_W^B(t)$$</p>
<h3 id="representational-strengths-and-shortcomings"><a class="header" href="#representational-strengths-and-shortcomings">Representational Strengths and Shortcomings</a></h3>
<p><strong>Strengths</strong></p>
<ul>
<li>Excellent for calculations</li>
</ul>
<p><strong>Shortcomings</strong></p>
<ul>
<li>Not very human-readable</li>
<li>Clearly redundant with 9 numbers for a 3-DOF quantity</li>
</ul>
<h3 id="unit-tests-to-determine-conventions"><a class="header" href="#unit-tests-to-determine-conventions">Unit Tests to Determine Conventions</a></h3>
<ol>
<li>Verify \(\mathbf{R}^T\mathbf{R}=\mathbf{I}\) and \(\det(\mathbf{R})=1\).</li>
<li>Construct a rotation of \(\theta=90°\) about the z-axis.</li>
<li>Apply \(\mathbf{R}\) to \(\mathbf{v}=[1,0,0]^T\):
<ul>
<li>Result \([0,1,0]^T\): <strong>F = Active</strong> or <strong>(F = Passive, D = B2W)</strong>.</li>
<li>Result \([0,-1,0]^T\): <strong>F = Passive, D = W2B</strong>.</li>
</ul>
</li>
<li>To distinguish Active from Passive B2W: compose two 90° rotations about z, then about x. Check whether frame subscripts cancel (Passive) or the operation moves the vector (Active).</li>
<li>Identity check: \(\mathbf{R}(0)=\mathbf{I}\) for any axis.</li>
</ol>
<h2 id="euler-angles"><a class="header" href="#euler-angles">Euler Angles</a></h2>
<p><em>Assuming 3-2-1 ordering.</em></p>
<h3 id="construction-techniques-1"><a class="header" href="#construction-techniques-1">Construction Techniques</a></h3>
<p><strong>From visualizing rotations from World to Body axes</strong></p>
<p>First consideration: Order. Follow the exact order in a straightforward fashion.</p>
<p>Second, handedness must be considered:</p>
<blockquote>
<p>H = Successive</p>
</blockquote>
<p>Each rotation is visualized to be with respect to the transformed axes of the previous rotation.</p>
<blockquote>
<p>H = Fixed</p>
</blockquote>
<p>Each rotation is visualized to be with respect to the world axes.</p>
<p>Handedness must be noted for all future operations with the numbers you just generated.</p>
<h3 id="conversions-to-1"><a class="header" href="#conversions-to-1">Conversions (To…)</a></h3>
<p><em>This is the computational bedrock of the usefulness of Euler Angles.</em> In fact, the Function and Directionality conventions only matter for conversions, and are dictated by the destination forms.</p>
<p><strong>Rotation Matrix</strong></p>
<p>See Rotation Matrix construction techniques for building the component \(\mathbf{R}_i\) matrices here.</p>
<p>First consideration is directionality of the matrices <em>(must be consistent)</em>:</p>
<blockquote>
<p>D = B2W</p>
</blockquote>
<p>$$\mathbf{R}_B^W=\mathbf{R}_3\mathbf{R}_2\mathbf{R}_1$$</p>
<blockquote>
<p>D = W2B, F = Passive</p>
</blockquote>
<p>$$\mathbf{R}_W^B=\mathbf{R}_1\mathbf{R}_2\mathbf{R}_3$$</p>
<blockquote>
<p>D = W2B, F = Active</p>
</blockquote>
<p>$$\mathbf{R}=\mathbf{R}_3\mathbf{R}_2\mathbf{R}_1$$</p>
<p>Then, take into account handedness:</p>
<blockquote>
<p>H = Successive</p>
</blockquote>
<p>Keep the above, which was derived assuming successive axes.</p>
<blockquote>
<p>H = Fixed</p>
</blockquote>
<p>Reverse the above, whatever it is:</p>
<p>$$\mathbf{R}_a\mathbf{R}_b\mathbf{R}_c \rightarrow \mathbf{R}_c\mathbf{R}_b\mathbf{R}_a$$</p>
<p>And the reversed rotations must be with respect to the chosen fixed frame. See below.</p>
<p>The aim is to prove that intrinsic and extrinsic rotation compositions are applied in reverse order from each other. To prove this, consider three frames 0,1,2, where 0 is the fixed “world” frame. Suppose that \(\mathbf{R}_2^0\) represents the rotation of the 2-frame relative to the 0-frame. To encode that rotation relative to the 1-frame requires a <strong>similarity transform</strong>, granted that the frames no longer appear to cancel out nicely:</p>
<p>$$\mathbf{R}_2^1=(\mathbf{R}_1^0)^{-1}\mathbf{R}_2^0\mathbf{R}_1^0$$</p>
<p>Placing this within the context of rotation composition to get from frame 2 to 0, the composition looks like</p>
<p>$$\mathbf{R}_2^0=\mathbf{R}_1^0\mathbf{R}_2^1=\mathbf{R}_1^0((\mathbf{R}_1^0)^{-1}\mathbf{R}_2^0\mathbf{R}_1^0)=\mathbf{R}_2^0\mathbf{R}_1^0$$</p>
<p>Note the reversed directionality between the <strong>intrinsic</strong> composition \(\mathbf{R}_1^0\mathbf{R}_2^1\) and the <em>equivalent</em> <strong>extrinsic</strong> composition \(\mathbf{R}_2^0\mathbf{R}_1^0\). Generic rotations were used here, demonstrating generalizability.</p>
<p><strong>Rodrigues</strong></p>
<p>Convert to a rotation matrix first (using the Euler Angles \(\rightarrow\) Rotation Matrix formulas above), then extract the Rodrigues vector using the \(SO(3)\) logarithmic map.</p>
<p><strong>Quaternion</strong></p>
<p><em>Direct method for 3-2-1 ordering, H = Successive:</em></p>
<p>Compose the elemental quaternions for each axis rotation:</p>
<p>$$\mathbf{q}=\mathbf{q}_3(\psi)\otimes\mathbf{q}_2(\theta)\otimes\mathbf{q}_1(\phi)$$</p>
<p>where (assuming O = \(q_w\) first):</p>
<p>$$\mathbf{q}_1(\phi)=\begin{bmatrix}\cos(\phi/2)\\ \sin(\phi/2)\\ 0\\ 0\end{bmatrix},\quad \mathbf{q}_2(\theta)=\begin{bmatrix}\cos(\theta/2)\\ 0\\ \sin(\theta/2)\\ 0\end{bmatrix},\quad \mathbf{q}_3(\psi)=\begin{bmatrix}\cos(\psi/2)\\ 0\\ 0\\ \sin(\psi/2)\end{bmatrix}$$</p>
<p>Composition order follows the same directionality/handedness rules as the Euler Angles \(\rightarrow\) Rotation Matrix conversion. Alternatively, convert to a rotation matrix first and then extract the quaternion.</p>
<h3 id="composition-and-inversion-1"><a class="header" href="#composition-and-inversion-1">Composition and Inversion</a></h3>
<p><em>Not applicable for Euler angles.</em> Composition and inversion are typically performed by first converting the Euler angles to a rotation matrix.</p>
<h3 id="derivatives-and-numeric-integration-1"><a class="header" href="#derivatives-and-numeric-integration-1">Derivatives and (Numeric) Integration</a></h3>
<p>Unlike with composition and inversion, there are methods of numeric differentiation and integration with Euler angles that are mathematically valid over infinitesimally small delta angles.</p>
<p><em>Assuming 3-2-1 ordering (\(\psi\) yaw, \(\theta\) pitch, \(\phi\) roll), H = Successive, D = B2W.</em></p>
<p><strong>Euler angle rates from body-frame angular velocity:</strong></p>
<p>$$\boldsymbol{\omega}^B=\begin{bmatrix}p\\ q\\ r\end{bmatrix}=\begin{bmatrix}1 &amp; 0 &amp; -\sin\theta\\ 0 &amp; \cos\phi &amp; \sin\phi\cos\theta\\ 0 &amp; -\sin\phi &amp; \cos\phi\cos\theta\end{bmatrix}\begin{bmatrix}\dot{\phi}\\ \dot{\theta}\\ \dot{\psi}\end{bmatrix}$$</p>
<p><strong>Inverse (for integration):</strong></p>
<p>$$\begin{bmatrix}\dot{\phi}\\ \dot{\theta}\\ \dot{\psi}\end{bmatrix}=\begin{bmatrix}1 &amp; \sin\phi\tan\theta &amp; \cos\phi\tan\theta\\ 0 &amp; \cos\phi &amp; -\sin\phi\\ 0 &amp; \sin\phi\sec\theta &amp; \cos\phi\sec\theta\end{bmatrix}\begin{bmatrix}p\\ q\\ r\end{bmatrix}$$</p>
<p>Note the singularity at \(\theta=\pm\pi/2\) in the inverse mapping (gimbal lock).</p>
<p><strong>Numeric Integration (first-order):</strong></p>
<p>$$\boldsymbol{\Theta}(t+\Delta t)\approx\boldsymbol{\Theta}(t)+\dot{\boldsymbol{\Theta}}(t)\Delta t$$</p>
<h3 id="representational-strengths-and-shortcomings-1"><a class="header" href="#representational-strengths-and-shortcomings-1">Representational Strengths and Shortcomings</a></h3>
<p><strong>Strengths</strong></p>
<ul>
<li>Can be very intuitive</li>
<li>Minimal representation</li>
</ul>
<p><strong>Shortcomings</strong></p>
<ul>
<li>There are many different orders and conventions that people don’t always specify</li>
<li>Operations with Euler angles involve trigonometric functions, and are thus slower to compute and more difficult to analyze</li>
<li><em>Singularities/Gimbal Lock</em>: For example, \(\mathbf{R}=\mathbf{R}_z(\delta)\mathbf{R}_y(\pi/2)\mathbf{R}_x(\alpha+\delta)\) for <em>any</em> choice of \(\delta\). Singularities will occur for any 3-parameter representation (J. Stuelpnagel. On the Parametrization of the Three-Dimensional Rotation Group. SIAM Review, 6(4):422-430, 1964.).</li>
</ul>
<h3 id="unit-tests-to-determine-conventions-1"><a class="header" href="#unit-tests-to-determine-conventions-1">Unit Tests to Determine Conventions</a></h3>
<ol>
<li>Set \((\psi,\theta,\phi)=(90°,0,0)\) (pure yaw) and convert to a rotation matrix.</li>
<li><strong>Ordering</strong>: Check which axis the rotation occurred about (the first number in the ordering label corresponds to the outermost rotation axis).</li>
<li><strong>Handedness</strong>: Set \((\psi,\theta,\phi)=(90°,45°,0)\). Convert to a matrix and compare against constructing the same rotations about the successive (body) axes vs. the fixed (world) axes. The one that matches determines H.</li>
<li><strong>F and D</strong>: Apply the resulting rotation matrix to a known vector and use the rotation matrix unit tests above to determine function and directionality.</li>
</ol>
<h2 id="eulerrodrigues"><a class="header" href="#eulerrodrigues">Euler/Rodrigues</a></h2>
<h3 id="construction-techniques-2"><a class="header" href="#construction-techniques-2">Construction Techniques</a></h3>
<p><em>Remember</em>, \(\mathbf{u}\) is expressed in the World frame, just as you would intuitively think.</p>
<p><strong>From Axis-Angle Representation: \(\theta\), \(\mathbf{u}\)</strong></p>
<p>Normalize \(\mathbf{u}\) and multiply by \(\theta\).</p>
<h3 id="conversions-to-2"><a class="header" href="#conversions-to-2">Conversions (To…)</a></h3>
<p>Besides tangent-space operations, this is the computational bedrock of the usefulness of Euler/Rodrigues.* In fact, as with Euler Angles, the Function and Directionality conventions only matter for conversions, and are dictated by the destination forms.</p>
<p><strong>Rotation Matrix</strong></p>
<p><em>i.e., the SO(3) exponential map</em>.</p>
<p>*i.e., Rodrigues’ rotation formula.</p>
<blockquote>
<p>D = B2W</p>
</blockquote>
<p>$$\mathbf{R}_B^W=\cos\theta\mathbf{I}+\sin\theta[\mathbf{u}]_\times+(1-\cos\theta)\mathbf{u} \mathbf{u}^T$$</p>
<p>$$=\mathbf{I}+[\mathbf{u}]_\times\sin\theta+[\mathbf{u}]_\times^2(1-\cos\theta)$$</p>
<p>$$=exp([\theta\mathbf{u}]_\times)=Exp(\theta\mathbf{u})$$</p>
<p>$$\approx \boldsymbol{I}+\lfloor \boldsymbol{\theta} \rfloor_{\times}$$</p>
<blockquote>
<p>D = W2B, F = Passive</p>
</blockquote>
<p>$$\mathbf{R}_W^B=\cos\theta\mathbf{I}-\sin\theta[\mathbf{u}]_\times+(1-\cos\theta)\mathbf{u}\mathbf{u}^T$$</p>
<p>$$=\mathbf{I}-[\mathbf{u}]_\times\sin\theta+[\mathbf{u}]_\times^2(1-\cos\theta)$$</p>
<p>$$=exp(-[\theta\mathbf{u}]_\times)=Exp(-\theta\mathbf{u})$$</p>
<p>$$\approx\boldsymbol{I}-\lfloor\boldsymbol{\theta}\rfloor_{\times}$$</p>
<blockquote>
<p>D = W2B, F = Active</p>
</blockquote>
<p>Same matrix form as D = B2W:</p>
<p>$$\mathbf{R}=\cos\theta\mathbf{I}+\sin\theta[\mathbf{u}]_\times+(1-\cos\theta)\mathbf{u}\mathbf{u}^T=Exp(\theta\mathbf{u})$$</p>
<p>$$\approx\boldsymbol{I}+\lfloor\boldsymbol{\theta}\rfloor_{\times}$$</p>
<p><strong>Euler Angles</strong></p>
<p>Convert to a rotation matrix first using the \(SO(3)\) exponential map (Rodrigues’ rotation formula above), then extract Euler angles using the Rotation Matrix \(\rightarrow\) Euler Angles formulas.</p>
<p><strong>Quaternion</strong></p>
<p><em>i.e., the Quaternion exponential map</em>.</p>
<p>Assuming O = \(q_w\) <em>first</em>.</p>
<blockquote>
<p>D = B2W</p>
</blockquote>
<p>$$\mathbf{q}=\begin{bmatrix}\cos(\theta/2) \\ \sin(\theta/2)\mathbf{u}\end{bmatrix}$$</p>
<blockquote>
<p>D = W2B, F = Passive</p>
</blockquote>
<p>$$\mathbf{q}=\begin{bmatrix}\cos(\theta/2) \\ -\sin(\theta/2)\mathbf{u}\end{bmatrix}$$</p>
<p>i.e., the conjugate of the B2W quaternion: \(\mathbf{q}_W^B=(\mathbf{q}_B^W)^{-1}\).</p>
<blockquote>
<p>D = W2B, F = Active</p>
</blockquote>
<p>$$\mathbf{q}=\begin{bmatrix}\cos(\theta/2) \\ -\sin(\theta/2)\mathbf{u}\end{bmatrix}$$</p>
<p>Same values as W2B Passive. The quaternion uses \(C_S\) instead of \(C_H\) to map to the rotation matrix, but the quaternion components are identical.</p>
<h3 id="composition-and-inversion-2"><a class="header" href="#composition-and-inversion-2">Composition and Inversion</a></h3>
<p><strong>Composition</strong></p>
<p>Rodrigues vector composition does not have a clean closed-form expression. The standard approach is to convert to rotation matrices or quaternions, compose, and convert back:</p>
<p>$$(\theta_1\mathbf{u}_1)\circ(\theta_2\mathbf{u}_2)=Log\left(Exp(\theta_1\mathbf{u}_1)\cdot Exp(\theta_2\mathbf{u}_2)\right)$$</p>
<p>For small angles, the Baker-Campbell-Hausdorff (BCH) formula provides an approximation:</p>
<p>$$Log(Exp(\mathbf{a})\cdot Exp(\mathbf{b}))\approx\mathbf{a}+\mathbf{b}+\frac{1}{2}[\mathbf{a}]_\times\mathbf{b}+\frac{1}{12}\left([\mathbf{a}]_\times^2\mathbf{b}+[\mathbf{b}]_\times^2\mathbf{a}\right)+\ldots$$</p>
<p><strong>Inversion</strong></p>
<p>$$(\theta\mathbf{u})^{-1}=-\theta\mathbf{u}$$</p>
<h3 id="derivatives-and-numeric-integration-2"><a class="header" href="#derivatives-and-numeric-integration-2">Derivatives and (Numeric) Integration</a></h3>
<p>The relationship between the Rodrigues vector rate and angular velocity involves the left and right Jacobians of \(SO(3)\):</p>
<p>$$\dot{\boldsymbol{\theta}}=\mathbf{J}_l^{-1}(\boldsymbol{\theta})\boldsymbol{\omega}^W=\mathbf{J}_r^{-1}(\boldsymbol{\theta})\boldsymbol{\omega}^B$$</p>
<p>where:</p>
<p>$$\mathbf{J}_l(\boldsymbol{\theta})=\frac{\sin\theta}{\theta}\mathbf{I}+\left(1-\frac{\sin\theta}{\theta}\right)\mathbf{u}\mathbf{u}^T+\frac{1-\cos\theta}{\theta}[\mathbf{u}]_\times$$</p>
<p>$$\mathbf{J}_r(\boldsymbol{\theta})=\mathbf{J}_l(-\boldsymbol{\theta})=\frac{\sin\theta}{\theta}\mathbf{I}+\left(1-\frac{\sin\theta}{\theta}\right)\mathbf{u}\mathbf{u}^T-\frac{1-\cos\theta}{\theta}[\mathbf{u}]_\times$$</p>
<p>The inverse left Jacobian:</p>
<p>$$\mathbf{J}_l^{-1}(\boldsymbol{\theta})=\frac{\theta/2}{\tan(\theta/2)}\mathbf{I}+\left(1-\frac{\theta/2}{\tan(\theta/2)}\right)\mathbf{u}\mathbf{u}^T-\frac{\theta}{2}[\mathbf{u}]_\times$$</p>
<p><strong>Numeric Integration:</strong></p>
<p>$$\boldsymbol{\theta}(t+\Delta t)=Log\left(Exp(\boldsymbol{\theta}(t))\cdot Exp(\boldsymbol{\omega}^B\Delta t)\right)$$</p>
<h3 id="representational-strengths-and-shortcomings-2"><a class="header" href="#representational-strengths-and-shortcomings-2">Representational Strengths and Shortcomings</a></h3>
<p><strong>Strengths</strong></p>
<ul>
<li>Constitutes the Lie Group of \(SO(3)\).</li>
<li>Easily visualized and understood</li>
<li>Minimal representation</li>
</ul>
<p><strong>Shortcomings</strong></p>
<ul>
<li>Similar to Euler Angles, operations are with trig functions, and thus slower to compute and harder to analyze (though the inverse is trivial to compute)</li>
<li>Non-unique!</li>
</ul>
<h3 id="unit-tests-to-determine-conventions-2"><a class="header" href="#unit-tests-to-determine-conventions-2">Unit Tests to Determine Conventions</a></h3>
<ol>
<li>Construct \(\boldsymbol{\theta}=(\pi/2)\hat{\mathbf{z}}\) (90° about z-axis) and convert to a rotation matrix.</li>
<li>Apply the rotation matrix unit tests to determine F and D.</li>
<li>Verify \(Exp(\mathbf{0})=\mathbf{I}\).</li>
<li>Verify \(Exp(\boldsymbol{\theta})\cdot Exp(-\boldsymbol{\theta})=\mathbf{I}\).</li>
</ol>
<h2 id="quaternions"><a class="header" href="#quaternions">Quaternions</a></h2>
<h3 id="construction-techniques-3"><a class="header" href="#construction-techniques-3">Construction Techniques</a></h3>
<p>Because quaternions are so non-intuitive, it is generally best to construct a quaternion at the outset either as the identity rotation or converted from a different representation.</p>
<h3 id="conversions-to-3"><a class="header" href="#conversions-to-3">Conversions (To…)</a></h3>
<p><strong>Rotation Matrix</strong></p>
<blockquote>
<p>D = B2W</p>
</blockquote>
<p>Hamiltonian cosine matrix:</p>
<p>$$\mathbf{R}=\mathbf{C}_H=(q_w^2-1)\boldsymbol{I}+2q_w\lfloor\boldsymbol{q}_v\rfloor_{\times}+2\boldsymbol{q}_v\boldsymbol{q}_v^{\top}=\begin{bmatrix}1-2q_y^2-2q_z^2 &amp; 2q_xq_y-2q_wq_z &amp; 2q_xq_z+2q_wq_y \\ 2q_xq_y+2q_wq_z &amp; 1-2q_x^2-2q_z^2 &amp; 2q_yq_z-2q_wq_x \\ 2q_xq_z-2q_wq_y &amp; 2q_yq_z+2q_wq_x &amp; 1-2q_x^2-2q_y^2\end{bmatrix}$$</p>
<blockquote>
<p>D = W2B, F = Passive</p>
</blockquote>
<p>$$\mathbf{R}=\mathbf{C}_H=(q_w^2-1)\boldsymbol{I}+2q_w\lfloor\boldsymbol{q}_v\rfloor_{\times}+2\boldsymbol{q}_v\boldsymbol{q}_v^{\top}=\begin{bmatrix}1-2q_y^2-2q_z^2 &amp; 2q_xq_y-2q_wq_z &amp; 2q_xq_z+2q_wq_y \\ 2q_xq_y+2q_wq_z &amp; 1-2q_x^2-2q_z^2 &amp; 2q_yq_z-2q_wq_x \\ 2q_xq_z-2q_wq_y &amp; 2q_yq_z+2q_wq_x &amp; 1-2q_x^2-2q_y^2\end{bmatrix}$$</p>
<p>Same \(C_H\) formula as B2W. The W2B passive quaternion \(\mathbf{q}_W^B=(\mathbf{q}_B^W)^{-1}\) produces \(\mathbf{R}_W^B=(\mathbf{R}_B^W)^T\) when plugged in. Note that \(C_H(\mathbf{q}_W^B)=C_S(\mathbf{q}_B^W)\).</p>
<blockquote>
<p>D = W2B, F = Active</p>
</blockquote>
<p>Shuster cosine matrix:</p>
<p>$$\mathbf{R}=\mathbf{C}_S=(q_w^2-1)\boldsymbol{I}-2q_w\lfloor\boldsymbol{q}_v\rfloor_{\times}+2\boldsymbol{q}_v\boldsymbol{q}_v^{\top}=\begin{bmatrix}1-2q_y^2-2q_z^2 &amp; 2q_xq_y+2q_wq_z &amp; 2q_xq_z-2q_wq_y \\ 2q_xq_y-2q_wq_z &amp; 1-2q_x^2-2q_z^2 &amp; 2q_yq_z+2q_wq_x \\ 2q_xq_z+2q_wq_y &amp; 2q_yq_z-2q_wq_x &amp; 1-2q_x^2-2q_y^2\end{bmatrix}$$</p>
<p>$$\mathbf{R}(\mathbf{q})=\mathbf{R}(-\mathbf{q}).$$</p>
<p>The use of \(C_H\) means that \(\text{Exp}(\tilde{q}) \approx I + [\tilde{q}]_\times \) for small \(\tilde{q}\). For \(C_S\), the approximation becomes \(I - [\tilde{q}]_\times\). A transposed matrix flips the sign again. The sign change for the active + passive world-to-body convention is important because the <em>values</em> in the actual quaternion correspond to the <em>inverse</em> of the underlying passive quaternion. Thus, all Jacobians \(\partial \cdot / \partial \tilde{q}\)  must have that negated sign to send the linearizing derivatives in the correct direction given the apparent error-state value.</p>
<p><strong>Euler Angles</strong></p>
<p><em>Assuming 3-2-1 ordering, O = \(q_w\) first, D = B2W:</em></p>
<p>$$\phi=\text{atan2}\left(2(q_wq_x+q_yq_z),1-2(q_x^2+q_y^2)\right)$$</p>
<p>$$\theta=\arcsin\left(2(q_wq_y-q_xq_z)\right)$$</p>
<p>$$\psi=\text{atan2}\left(2(q_wq_z+q_xq_y),1-2(q_y^2+q_z^2)\right)$$</p>
<p>For other conventions, convert to the rotation matrix first using the appropriate cosine matrix formula, then extract Euler angles from the matrix.</p>
<p><strong>Rodrigues</strong></p>
<p><em>i.e., the Quaternion logarithmic map.</em></p>
<p>Assuming O = \(q_w\) first:</p>
<p>if \(\lVert\mathbf{q}_v\rVert&gt;\epsilon\):</p>
<p>$$\theta\mathbf{u}=Log(\mathbf{q})=2\text{atan2}(\lVert\mathbf{q}_v\rVert,q_w)\frac{\mathbf{q}_v}{\lVert\mathbf{q}_v\rVert}$$</p>
<p>else:</p>
<p>$$\theta\mathbf{u}=Log(\mathbf{q})\approx 2\frac{\mathbf{q}_v}{q_w}$$</p>
<p>To avoid \(\theta&gt;\pi\), negate \(\mathbf{q}\) if \(q_w&lt;0\) before applying the map.</p>
<h3 id="action-1"><a class="header" href="#action-1">Action</a></h3>
<p><em>Assuming O = \(q_w\) last. Flip for \(q_w\) first.</em></p>
<blockquote>
<p>F = passive</p>
</blockquote>
<p>$$\mathbf{q}_A^B \otimes \begin{bmatrix}^A\mathbf{v} \\ 0\end{bmatrix} \otimes \left(\mathbf{q}_A^B\right)^{-1}=^B\mathbf{v}$$</p>
<p><strong>Homogeneous Coordinates:</strong></p>
<p>$$\mathbf{q}_A^B \otimes \begin{bmatrix}^A\mathbf{v} \\ 1\end{bmatrix} \otimes \left(\mathbf{q}_A^B\right)^{-1}=^B\mathbf{v}$$</p>
<blockquote>
<p>F = active</p>
</blockquote>
<p>$$\left(\mathbf{q}\right)^{-1} \otimes \begin{bmatrix}^A\mathbf{v} \\ 0\end{bmatrix} \otimes \mathbf{q}=\begin{bmatrix}^A\mathbf{v}’ \\ 0\end{bmatrix}$$</p>
<p><strong>Homogeneous Coordinates:</strong></p>
<p>$$\left(\mathbf{q}\right)^{-1} \otimes \begin{bmatrix}^A\mathbf{v} \\ 1\end{bmatrix} \otimes \mathbf{q}=\begin{bmatrix}^A\mathbf{v}’ \\ 1\end{bmatrix}$$</p>
<h3 id="composition-and-inversion-3"><a class="header" href="#composition-and-inversion-3">Composition and Inversion</a></h3>
<p><strong>Composition</strong></p>
<p>$$\mathbf{q}_1 \otimes \mathbf{q}_2=[\mathbf{q}_1]_L\mathbf{q}_2=[\mathbf{q}_2]_R\mathbf{q}_1$$</p>
<blockquote>
<p>H = Right, O = qw-first</p>
</blockquote>
<p>$$[\mathbf{q}]_L=\begin{bmatrix}q_w &amp; -\mathbf{q}_v^T \\ \mathbf{q}_v &amp; q_w\mathbf{I}+[\mathbf{q}_v]_\times\end{bmatrix}=\begin{bmatrix}q_w &amp; -q_x &amp; -q_y &amp; -q_z \\ q_x &amp; q_w &amp; -q_z &amp; q_y \\ q_y &amp; q_z &amp; q_w &amp; -q_x \\ q_z &amp; -q_y &amp; q_x &amp; q_w\end{bmatrix}$$</p>
<p>$$[\mathbf{q}]_R=\begin{bmatrix}q_w &amp; -\mathbf{q}_v^T \\ \mathbf{q}_v &amp; q_w\mathbf{I}-[\mathbf{q}_v]_\times\end{bmatrix}=\begin{bmatrix}q_w &amp; -q_x &amp; -q_y &amp; -q_z \\ q_x &amp; q_w &amp; q_z &amp; -q_y \\ q_y &amp; -q_z &amp; q_w &amp; q_x \\ q_z &amp; q_y &amp; -q_x &amp; q_w \end{bmatrix}$$</p>
<blockquote>
<p>H = Right, O = qw-last</p>
</blockquote>
<p>$$[\mathbf{q}]_L=\begin{bmatrix}q_w\mathbf{I}+[\mathbf{q}_v]_\times &amp; \mathbf{q}_v\\ -\mathbf{q}_v^T &amp; q_w\end{bmatrix}=\begin{bmatrix}q_w &amp; -q_z &amp; q_y &amp; q_x\\ q_z &amp; q_w &amp; -q_x &amp; q_y\\ -q_y &amp; q_x &amp; q_w &amp; q_z \\ -q_x &amp; -q_y &amp; -q_z &amp; q_w\end{bmatrix}$$</p>
<p>$$[\mathbf{q}]_R=\begin{bmatrix}q_w\mathbf{I}-[\mathbf{q}_v]_\times &amp; \mathbf{q}_v\\ -\mathbf{q}_v^T &amp; q_w\end{bmatrix}=\begin{bmatrix}q_w &amp; q_z &amp; -q_y &amp; q_x\\ -q_z &amp; q_w &amp; q_x &amp; q_y\\q_y &amp; -q_x &amp; q_w &amp; q_z \\ -q_x &amp; -q_y &amp; -q_z &amp; q_w\end{bmatrix}$$</p>
<blockquote>
<p>H = Left, O = qw-first</p>
</blockquote>
<p>$$[\mathbf{q}]_L=\begin{bmatrix}q_w &amp; -\mathbf{q}_v^T \\ \mathbf{q}_v &amp; q_w\mathbf{I}-[\mathbf{q}_v]_\times\end{bmatrix}=\begin{bmatrix}q_w &amp; -q_x &amp; -q_y &amp; -q_z \\ q_x &amp; q_w &amp; q_z &amp; -q_y \\ q_y &amp; -q_z &amp; q_w &amp; q_x \\ q_z &amp; q_y &amp; -q_x &amp; q_w \end{bmatrix}$$</p>
<p>$$[\mathbf{q}]_R=\begin{bmatrix}q_w &amp; -\mathbf{q}_v^T \\ \mathbf{q}_v &amp; q_w\mathbf{I}+[\mathbf{q}_v]_\times\end{bmatrix}=\begin{bmatrix}q_w &amp; -q_x &amp; -q_y &amp; -q_z \\ q_x &amp; q_w &amp; -q_z &amp; q_y \\ q_y &amp; q_z &amp; q_w &amp; -q_x \\ q_z &amp; -q_y &amp; q_x &amp; q_w\end{bmatrix}$$</p>
<blockquote>
<p>H = Left, O = qw-last</p>
</blockquote>
<p>$$[\mathbf{q}]_L=\begin{bmatrix}q_w\mathbf{I}-[\mathbf{q}_v]_\times &amp; \mathbf{q}_v \\ -\mathbf{q}_v^T &amp; q_w\end{bmatrix}=\begin{bmatrix}q_w &amp; q_z &amp; -q_y &amp; q_x \\ -q_z &amp; q_w &amp; q_x &amp; q_y\\q_y &amp; -q_x &amp; q_w &amp; q_z \\ -q_x &amp; -q_y &amp; -q_z &amp; q_w\end{bmatrix}$$</p>
<p>$$[\mathbf{q}]_R=\begin{bmatrix}q_w\mathbf{I}+[\mathbf{q}_v]_\times &amp; \mathbf{q}_v\\ -\mathbf{q}_v^T &amp; q_w\end{bmatrix}=\begin{bmatrix}q_w &amp; -q_z &amp; q_y &amp; q_x \\ q_z &amp; q_w &amp; -q_x &amp; q_y\\ -q_y &amp; q_x &amp; q_w &amp; q_z \\ -q_x &amp; -q_y &amp; -q_z &amp; q_w\end{bmatrix}$$</p>
<p>When attaching frames to the quaternions, composition has the potential for nuance due to the fact that, in certain implementations, a quaternion can be specified to represent a certain type of SO(3) rotation that actually uses different conventions from the quaternion. This seems unwise, but it happens, <em>as with certain manifestations of the JPL convention</em>. For that reason, one cannot simply exclusively pair Passive B2W behavior with active behavior, as other combinations are also fair game.</p>
<blockquote>
<p>D = B2W</p>
</blockquote>
<p>$$\mathbf{q}_A^C=\mathbf{q}_B^C\otimes \mathbf{q}_A^B$$</p>
<blockquote>
<p>D = W2B, F = Passive</p>
</blockquote>
<p>$$\mathbf{q}_A^C=\mathbf{q}_B^C\otimes \mathbf{q}_A^B$$</p>
<blockquote>
<p>D = W2B, F = Active</p>
</blockquote>
<p>$$\mathbf{q}_A^C=\mathbf{q}_A^B\otimes \mathbf{q}_B^C$$</p>
<p><strong>Inversion</strong></p>
<p>$$\mathbf{q}^{-1}=\begin{bmatrix}q_w\\ \mathbf{q}_v\end{bmatrix}^{-1}=\begin{bmatrix}q_w\\ -\mathbf{q}_v\end{bmatrix}$$</p>
<p>$$\left(\mathbf{q}_a \otimes \mathbf{q}_b \otimes \dots \otimes \mathbf{q}_N\right)^{-1}=\mathbf{q}_N^{-1}\otimes \dots \otimes \mathbf{q}_b^{-1} \otimes \mathbf{q}_a^{-1}$$</p>
<h3 id="addition-and-subtraction-1"><a class="header" href="#addition-and-subtraction-1">Addition and Subtraction</a></h3>
<p>Perturbations are represented by \(\boldsymbol{\theta}\in\mathbb{R}^3\), where local perturbations are expressed in the body frame and global perturbations are expressed in the world frame.</p>
<p><strong>Addition</strong></p>
<blockquote>
<p>D = B2W, P = Local</p>
</blockquote>
<p>$$\mathbf{q}_{B+}^{W}=\mathbf{q}_{B}^{W}\otimes\text{Exp}(\boldsymbol{\theta}_{B+}^{B})$$</p>
<blockquote>
<p>D = B2W, P = Global</p>
</blockquote>
<p>$$\mathbf{q}_{B}^{W+}=\text{Exp}(\boldsymbol{\theta}_{W}^{W+})\otimes\mathbf{q}_{B}^{W}$$</p>
<blockquote>
<p>D = W2B, F = Passive, P = Local</p>
</blockquote>
<p>$$\mathbf{q}_{W}^{B+}=\text{Exp}(\boldsymbol{\theta}_{B}^{B+})\otimes\mathbf{q}_{W}^{B}$$</p>
<p><strong>Subtraction</strong></p>
<blockquote>
<p>D = B2W, P = Local</p>
</blockquote>
<p>$$\boldsymbol{\theta}_{B+}^{B}=\text{Log}\left((\mathbf{q}_{B}^{W})^{-1}\otimes\mathbf{q}_{B+}^{W}\right)$$</p>
<blockquote>
<p>D = B2W, P = Global</p>
</blockquote>
<p>$$\boldsymbol{\theta}_{W}^{W+}=\text{Log}\left(\mathbf{q}_{B}^{W+}\otimes(\mathbf{q}_{B}^{W})^{-1}\right)$$</p>
<blockquote>
<p>D = W2B, F = Passive, P = Local</p>
</blockquote>
<p>$$\boldsymbol{\theta}_{B}^{B+}=\text{Log}\left(\mathbf{q}_{W}^{B+}\otimes(\mathbf{q}_{W}^{B})^{-1}\right)$$</p>
<h3 id="notions-of-distance-1"><a class="header" href="#notions-of-distance-1">Notions of Distance</a></h3>
<p><strong>Quaternion distance</strong></p>
<p>$$||\mathbf{q}_A-\mathbf{q}_B||=||\mathbf{q}_B-\mathbf{q}_A||$$</p>
<p>A modification to account for the negative sign ambiguity:</p>
<p>$$\min_{b\in{-1;+1}}||\mathbf{q}_A-b\mathbf{q}_B||$$</p>
<h3 id="derivatives-and-numeric-integration-3"><a class="header" href="#derivatives-and-numeric-integration-3">Derivatives and (Numeric) Integration</a></h3>
<p><em>Assuming O = \(q_w\) first, H = Right.</em></p>
<blockquote>
<p>D = B2W:</p>
</blockquote>
<p>$$\dot{\mathbf{q}}_B^W=\frac{1}{2}\mathbf{q}_B^W\otimes\begin{bmatrix}0\\ \boldsymbol{\omega}^B\end{bmatrix}=\frac{1}{2}\begin{bmatrix}0\\ \boldsymbol{\omega}^W\end{bmatrix}\otimes\mathbf{q}_B^W$$</p>
<blockquote>
<p>D = W2B, F = Passive:</p>
</blockquote>
<p>$$\dot{\mathbf{q}}_W^B=-\frac{1}{2}\begin{bmatrix}0\\ \boldsymbol{\omega}^B\end{bmatrix}\otimes\mathbf{q}_W^B=-\frac{1}{2}\mathbf{q}_W^B\otimes\begin{bmatrix}0\\ \boldsymbol{\omega}^W\end{bmatrix}$$</p>
<p><strong>Numeric Integration (first-order):</strong></p>
<blockquote>
<p>D = B2W:</p>
</blockquote>
<p>$$\mathbf{q}_B^W(t+\Delta t)=\mathbf{q}_B^W(t)\otimes Exp(\boldsymbol{\omega}^B\Delta t)$$</p>
<blockquote>
<p>D = W2B, F = Passive:</p>
</blockquote>
<p>$$\mathbf{q}_W^B(t+\Delta t)=Exp(-\boldsymbol{\omega}^B\Delta t)\otimes\mathbf{q}_W^B(t)$$</p>
<p>Always renormalize after integration to maintain unit norm: \(\mathbf{q}\leftarrow\mathbf{q}/\lVert\mathbf{q}\rVert\).</p>
<h3 id="representational-strengths-and-shortcomings-3"><a class="header" href="#representational-strengths-and-shortcomings-3">Representational Strengths and Shortcomings</a></h3>
<p><strong>Strengths</strong></p>
<ul>
<li>Minimal representation with <em>no singularities</em>!</li>
<li>Fast computation without resorting to trigonometry</li>
<li>Composition has 16 products instead of 27 for rotation matrices</li>
</ul>
<p><strong>Shortcomings</strong></p>
<ul>
<li>Not as intuitive as Euler Angles</li>
<li><em>Sign ambiguity</em> poses challenges that must be circumvented in control and estimation problems</li>
</ul>
<h3 id="unit-tests-to-determine-correctness"><a class="header" href="#unit-tests-to-determine-correctness">Unit Tests to Determine Correctness</a></h3>
<ol>
<li><strong>Identity</strong>: \(\mathbf{q}=[1,0,0,0]^T\) (or \([0,0,0,1]^T\) for O = \(q_w\) last) should yield \(\mathbf{R}=\mathbf{I}\).</li>
<li><strong>Inverse</strong>: \(\mathbf{q}\otimes\mathbf{q}^{-1}=\mathbf{q}_{id}\).</li>
<li><strong>Ordering</strong>: Check whether the scalar is stored first or last in the library’s data structure.</li>
<li><strong>Handedness</strong>: Compute \(\mathbf{q}_i\otimes\mathbf{q}_j\) where \(\mathbf{q}_i=[0,1,0,0]^T\) and \(\mathbf{q}_j=[0,0,1,0]^T\) (O = \(q_w\) first). Result \([0,0,0,1]^T\) implies <strong>H = Right</strong>; result \([0,0,0,-1]^T\) implies <strong>H = Left</strong>.</li>
<li><strong>Function and Directionality</strong>: Construct a quaternion for 90° about z. Convert to a rotation matrix and apply the rotation matrix convention tests.</li>
<li><strong>Double cover</strong>: Verify \(\mathbf{R}(\mathbf{q})=\mathbf{R}(-\mathbf{q})\).</li>
<li><strong>Norm preservation</strong>: \(\lVert\mathbf{q}_1\otimes\mathbf{q}_2\rVert=\lVert\mathbf{q}_1\rVert\cdot\lVert\mathbf{q}_2\rVert\).</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="linear-algebra"><a class="header" href="#linear-algebra">Linear Algebra</a></h1>
<ul>
<li><a href="#visualizing-matrices">Visualizing Matrices</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="visualizing-matrices"><a class="header" href="#visualizing-matrices">Visualizing Matrices</a></h1>
<p>There are various scenarios (e.g., covariance matrices, inertia matrices, quadratic forms) in which you’d want to represent a (square) matrix visually, and ultimately it comes down to Eigen decompositions.</p>
<p>In graphics, it’s generally preferable to draw an “unrotated” version of your graphic, and then apply a rotation. Thus, the methods below will focus on extracting <strong>semi-major axis lengths</strong> and a <strong>rotation</strong> from the Eigen decomposition. Example code will be given in <strong>Matlab</strong>.</p>
<p>For testing, here’s some Matlab code for generating a random \(n\times n\) positive-definite matrix:</p>
<pre><code class="language-matlab">function A = generateSPDmatrix(n)
% Generate a dense n x n symmetric, positive definite matrix

A = rand(n,n); % generate a random n x n matrix

% construct a symmetric matrix using either
A = 0.5*(A+A'); OR
A = A*A';
% The first is significantly faster: O(n^2) compared to O(n^3)

% since A(i,j) &lt; 1 by construction and a symmetric diagonally dominant matrix
%   is symmetric positive definite, which can be ensured by adding nI
A = A + n*eye(n);

end
</code></pre>
<h2 id="twothree-dimensional-positive-definite-matrix-ellipseellipsoid"><a class="header" href="#twothree-dimensional-positive-definite-matrix-ellipseellipsoid">Two/Three-Dimensional Positive Definite Matrix (Ellipse/Ellipsoid)</a></h2>
<p><strong>Matrix:</strong> \(\boldsymbol A\in \mathbb{R}^{2\times 2}\) or \(\boldsymbol A\in \mathbb{R}^{3\times 3}\), \(\boldsymbol A &gt; 0\)</p>
<p><strong>Get the principal axis lengths:</strong></p>
<ul>
<li>Find eigenvalues of \(\boldsymbol A\). These are the (ordered) semi-major axis lengths.
<ul>
<li>Let’s say that by convention, \(\boldsymbol A\) is expressed in frame \(W\), and when it’s expressed in frame \(F\), it’s diagonal (\(\boldsymbol D\)) with the eigenvalues on the diagonal.</li>
</ul>
</li>
</ul>
<p><strong>Get the rotation matrix:</strong></p>
<ul>
<li>Find the (ordered) eigenvectors of \(\boldsymbol A\). These form the column vectors of \(\boldsymbol R_F^W\).</li>
<li>Check the determinant of \(\boldsymbol R_F^W\); if it’s -1, then flip the sign of the last column to make the determinant +1.</li>
<li>From matrix basis change rules, you can check your work by making sure that \(\boldsymbol D=\left(\boldsymbol R_F^W\right)^{-1}\boldsymbol A\boldsymbol R_F^W\).</li>
</ul>
<p><strong>Matlab code:</strong></p>
<pre><code class="language-matlab">% Get random positive definite matrix
A = generateRandom2x2PDMatrix();

% Extract axis lengths and rotation
[R,D] = eig(A);
x_axis_len = D(1,1);
y_axis_len = D(2,2);
if det(R) &lt; 0
    R(:,2) = -1 * R(:,2);
end

% Draw unrotated ellipse
theta = linspace(0,2*pi,100);
coords = [x_axis_len * cos(theta); y_axis_len * sin(theta)];
plot(coords(1,:),coords(2,:),'k--')
hold on; grid on

% Draw rotated ellipse (R acts like active rotation
% since it's B2W convention)
rotated_coords = R * coords;
plot(rotated_coords(1,:),rotated_coords(2,:),'k-','Linewidth',2.0)
hold off

A

function A = generateRandom2x2PDMatrix()
A = rand(2,2);
A = A*A';
A = A + 2*eye(2);
end
</code></pre>
<p>$$\boldsymbol A=\begin{bmatrix}3.0114 &amp; 0.9353 \\ 0.9353 &amp; 2.9723\end{bmatrix}$$</p>
<img src="img/math/avis.svg" style="display: block; margin-left: auto; margin-right: auto;">
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="perception"><a class="header" href="#perception">Perception</a></h1>
<ul>
<li><a href="#computer-vision">Computer Vision</a>
<ul>
<li><a href="#the-pinhole-camera-model-fundamentals-for-geometric-computer-vision">The Pinhole Camera Model</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="computer-vision"><a class="header" href="#computer-vision">Computer Vision</a></h1>
<ul>
<li><a href="#the-pinhole-camera-model-fundamentals-for-geometric-computer-vision">The Pinhole Camera Model</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="the-pinhole-camera-model-fundamentals-for-geometric-computer-vision"><a class="header" href="#the-pinhole-camera-model-fundamentals-for-geometric-computer-vision">The Pinhole Camera Model: Fundamentals for Geometric Computer Vision</a></h1>
<p>Based on some very useful readings: <a href="http://rpg.ifi.uzh.ch/visual_odometry_tutorial.html">VO - Scaramuzza and Fraundorfer</a>, <a href="http://asrl.utias.utoronto.ca/~tdb/bib/barfoot_ser17.pdf">State Estimation for Robotics - Barfoot</a>.</p>
<h2 id="the-pinhole-camera-model"><a class="header" href="#the-pinhole-camera-model">The Pinhole Camera Model</a></h2>
<img src="img/perception/pinhole.svg" width="400" style="display: block; margin-left: auto; margin-right: auto;">
<p>In essence, the camera model (utilizing the virtual image plane, and not the “true,” flipped image plane <em>behind</em> the camera optical center) uses similar triangles in the camera \(x\) and \(y\) axes (normalized by \(z\)) to project a 3D point onto the image plane, losing depth information in the process:</p>
<p>$$p_{z}^{c}\begin{bmatrix}u_{m}^{c}\\ v_{m}^{c}\\ 1 \end{bmatrix}=\begin{bmatrix}f &amp; 0 &amp; 0\\ 0 &amp; f &amp; 0\\ 0 &amp; 0 &amp; 1 \end{bmatrix}\begin{bmatrix}p_{x}^{c}\\ p_{y}^{c}\\ p_{z}^{c} \end{bmatrix}=\begin{bmatrix}f &amp; 0 &amp; 0\\ 0 &amp; f &amp; 0\\ 0 &amp; 0 &amp; 1 \end{bmatrix}\boldsymbol{p}^{c}.$$</p>
<p>To convert the point to pixels, consider the following pixel model (accommodating skew):</p>
<p>$$u^{I}=s_{x}u_{m}^{c}+o_{x},$$</p>
<p>$$v^{I}=s_{y}v_{m}^{c}+o_{y},$$</p>
<p>which, once we add the possibility of cross-skew (i.e., non-rectangular pixels), gives the point-to-pixels projection model:</p>
<p>$$p_{z}^{c}\begin{bmatrix}u^{I}\\ v^{I}\\ 1 \end{bmatrix}=\begin{bmatrix}s_{x}f &amp; s_{\theta}f &amp; o_{x}\\ 0 &amp; s_{y}f &amp; o_{y}\\ 0 &amp; 0 &amp; 1 \end{bmatrix}\boldsymbol{p}^{c}=\boldsymbol{K}\boldsymbol{p}^{c}.$$</p>
<p>\(\boldsymbol{K}\) is called the <strong>intrinsic (calibration) matrix</strong>.</p>
<p>Say that the 3D point is expressed in a different frame, \(W\), than the camera frame. We need to augment the point with homogeneous coordinates \(\tilde{\boldsymbol{p}}^{W}=\begin{bmatrix}\left(\boldsymbol{p}^{W}\right)^{T} &amp; 1\end{bmatrix}^{T} \) and apply the <strong>extrinsic (calibration) matrix</strong> \(\begin{bmatrix}\boldsymbol{R}_W^c &amp;\boldsymbol{t}_W^c\end{bmatrix}\):</p>
<p>$$p_z^c\begin{bmatrix}u^I\\ v^I\\ 1 \end{bmatrix}=\boldsymbol{K}\begin{bmatrix}\boldsymbol{R}_W^c &amp; \boldsymbol{t}_W^c\end{bmatrix}\tilde{\boldsymbol{p}}^W=\boldsymbol{\Pi}\tilde{\boldsymbol{p}}^W,$$</p>
<p>where \(\boldsymbol{\Pi}\) is the <strong>projection matrix</strong>. If the point is already expressed in the camera frame, as before:</p>
<p>$$p_{z}^{c}\begin{bmatrix}u^{I}\\ v^{I}\\ 1 \end{bmatrix}=\boldsymbol{K}\begin{bmatrix}\boldsymbol{I} &amp; \boldsymbol{0}\end{bmatrix}\tilde{\boldsymbol{p}}^{c}=\boldsymbol{\Pi}_{0}\tilde{\boldsymbol{p}}^{c},$$</p>
<p>where \(\boldsymbol{\Pi}_{0}\) is called the <strong>canonical projection</strong>. Some more terminology:</p>
<ul>
<li>\(\begin{bmatrix}o_x &amp; o_y\end{bmatrix}\) is the <strong>principal point</strong>.</li>
<li>\(s_xf=f_x\) is the <strong>focal length in horizontal pixels</strong> (\(s_x\) pixels per meter)</li>
<li>\(s_yf=f_y\) is the <strong>focal length in vertical pixels</strong></li>
<li>\(s_x/s_y\) is the <strong>aspect ratio</strong></li>
<li>\(s_\theta f\) is the pixel <strong>skew</strong></li>
</ul>
<p>Aside from 3D-to-2D projection, a normal camera will probably impose some sort of distortion on the points, which will not preserve straight lines in the projection. See <a href="https://docs.opencv.org/3.4/d4/d94/tutorial_camera_calibration.html">this OpenCV link</a> for an example distortion model (e.g., barrel, radial, pincushion) and how to correct for it.</p>
<p>Consider the qualitative effects of modifying the intrinsic parameters of a camera on how a 3D scene “looks” when projected onto the image plane. For example, the figures below help visualize what happens when the focal length is changed. A shorter focal length <em>widens</em> the field of view, appearing to push back further objects on the periphery when your view window is constrained to be the same size:</p>
<img src="img/perception/small_fl_optimized.gif" style="display: inline-block; width: 49%;">
<img src="img/perception/medium_fl_optimized.gif" style="display: inline-block; width: 49%;">
<img src="img/perception/10poundsfeat.jpg" width="400" style="display: block; margin-left: auto; margin-right: auto;">
<h3 id="alternative-parameterizations"><a class="header" href="#alternative-parameterizations">Alternative Parameterizations</a></h3>
<p><strong>Focal Length: Pixels vs. Millimeters</strong></p>
<p>To convert between pixels and millimeters, you need the “sensor width/height” (both are needed if \(f_x\) and \(f_y\) are different) information. Call it \(\sigma\). Then,</p>
<p>$$f_\text{pixels}=L_\text{pixels}\frac{f_\text{mm}}{\sigma_\text{mm}},$$</p>
<p>where \(L\) is either image plane width or height. This is a matter of canceling out units and using the image vs. sensor dimensions to scale things.</p>
<p><strong>FOV vs. Focal Length</strong></p>
<p>$$\theta=2\tan^{-1}\left(\frac{L}{2f}\right) \iff f=\frac{L}{2\tan(\theta/2)},$$</p>
<p>where \(\theta\) is horizontal/vertical FOV and \(L\) is image plane width/height, respectively. Note that \(L\) and \(f\) must have the same units (e.g., pixels, millimeters, etc.).</p>
<h2 id="vanishing-points"><a class="header" href="#vanishing-points">Vanishing Points</a></h2>
<p><em>All parallel lines</em> in 3D space eventually intersect <em>at a vanishing point</em>, whether or not that point is within the camera field of view (with some notable exceptions).</p>
<img src="img/perception/vanishing_point.svg" width="400" style="display: block; margin-left: auto; margin-right: auto;">
<p>With \(o_{x}=o_{y}=s_{\theta}=0\) and \(f=s_{x}=s_{y}=1\), the intrinsic matrix becomes the identity. Thus, with any 3D point in the camera frame \(\boldsymbol{p}=\begin{bmatrix}x &amp; y &amp; z\end{bmatrix}^{T} \), the projection relationship becomes</p>
<p>$$\begin{bmatrix}u^{I}\\ v^{I} \end{bmatrix}=\begin{bmatrix}x/z\\ y/z \end{bmatrix}.$$</p>
<p>Consider the generalized equation for a line in 3D space, parameterized by \(\lambda\) and oriented by unit vector \(\hat{\boldsymbol{r}}^{c}\), expressed in the camera frame:</p>
<p>$$\boldsymbol{p}^{c}(\lambda)=\boldsymbol{p}_{0}^{c}+\lambda\hat{\boldsymbol{r}}^{c}.$$</p>
<p>Substituting the projection equation into the line equation gives the following pixel coordinates (also parameterized by \(\lambda\)) for \(\boldsymbol{p}\) in the image plane:</p>
<p>$$u_{p}(\lambda) =\frac{\alpha +\lambda\hat{r}_x^c}{\gamma+\lambda\hat{r}_z^c},$$</p>
<p>$$v_{p}(\lambda) =\frac{\beta+\lambda\hat{r}_{y}^{c}}{\gamma+\lambda\hat{r}_z^c},$$</p>
<p>where \(\alpha \triangleq p_{0,x}^c\), \(\beta \triangleq p_{0,y}^c\), \(\gamma \triangleq p_{0,z}^c\). The vanishing point can be found in the limit as \(\lambda\rightarrow\infty\):</p>
<p>$$\lim_{\lambda\rightarrow\infty}u_p(\lambda) =\frac{\hat{r}_x^c}{\hat{r}_z^c},$$</p>
<p>$$\lim_{\lambda\rightarrow\infty}v_p(\lambda) =\frac{\hat{r}_y^c}{\hat{r}_z^c}.$$</p>
<p>These equations indicate that the vanishing point depends only on \(\hat{\boldsymbol{r}}^{c}\), so <em>any set of</em> parallel lines in 3D space will share the same vanishing point in the image plane.</p>
<p>To find a condition in which no vanishing point exists, consider setting \(\hat{r}_{z}^{c}\) equal to zero. In that case, the limits above don’t exist, suggesting that no vanishing point exists. In other words, if two parallel lines are confined to a plane parallel to the image plane, then they will never appear to intersect when projected onto the image plane.</p>
<h2 id="camera-based-relative-pose-calculation"><a class="header" href="#camera-based-relative-pose-calculation">Camera-Based Relative Pose Calculation</a></h2>
<p>A central problem in geometric computer vision is recovering the relative pose (rotation and translation) between two camera viewpoints from feature correspondences observed in both images. Given matched feature points between two images, there are three main approaches depending on the type of information available. All three methods commonly employ <a href="https://en.wikipedia.org/wiki/Random_sample_consensus">RANSAC</a> for outlier rejection, since each requires only a small number of point correspondences to compute a solution–making them well-suited to the hypothesize-and-verify loop that RANSAC provides.</p>
<h3 id="the-essential-and-fundamental-matrices"><a class="header" href="#the-essential-and-fundamental-matrices">The Essential and Fundamental Matrices</a></h3>
<p>Before diving into the specific methods, it helps to understand the <strong>essential matrix</strong> \(\boldsymbol{E}\), which encodes the geometric relationship between two calibrated camera views. Given a point \(\boldsymbol{p}\) observed in both camera frames as normalized image coordinates \(\boldsymbol{q}_1\) and \(\boldsymbol{q}_2\) (i.e., with intrinsics removed: \(\boldsymbol{q}=\boldsymbol{K}^{-1}\tilde{\boldsymbol{u}}\)), the essential matrix satisfies the <strong>epipolar constraint</strong>:</p>
<p>$$\boldsymbol{q}_2^T \boldsymbol{E} , \boldsymbol{q}_1 = 0.$$</p>
<p>The essential matrix is defined as</p>
<p>$$\boldsymbol{E} = \boldsymbol{t}^{\wedge} \boldsymbol{R},$$</p>
<p>where \(\boldsymbol{R}\) and \(\boldsymbol{t}\) are the relative rotation and translation between the two camera frames, and \(\boldsymbol{t}^{\wedge}\) denotes the skew-symmetric matrix form of \(\boldsymbol{t}\). Because \(\boldsymbol{E}\) is constructed from a unit-norm translation direction and a rotation, it has exactly five degrees of freedom (three for rotation, two for translation direction–the magnitude of translation is unrecoverable from image correspondences alone).</p>
<p>When the camera intrinsics are not known, the <strong>fundamental matrix</strong> \(\boldsymbol{F}\) is used instead. It relates pixel coordinates directly:</p>
<p>$$\tilde{\boldsymbol{u}}_2^T \boldsymbol{F} , \tilde{\boldsymbol{u}}_1 = 0,$$</p>
<p>and is related to the essential matrix by \(\boldsymbol{F} = \boldsymbol{K}_2^{-T} \boldsymbol{E} , \boldsymbol{K}_1^{-1}\). The fundamental matrix has seven degrees of freedom (nine entries minus one for scale, minus one from the \(\det(\boldsymbol{F})=0\) constraint).</p>
<h3 id="2d-2d-correspondences"><a class="header" href="#2d-2d-correspondences">2D-2D Correspondences</a></h3>
<p><em>Input: feature points from image A, feature points from image B.</em></p>
<p>When only 2D feature correspondences are available (the most common case for a monocular camera), the relative pose is recovered through the essential matrix:</p>
<ol>
<li>The <strong>five-point algorithm</strong> estimates \(\boldsymbol{E}\) from at least five point correspondences. Each correspondence provides one equation via the epipolar constraint, and the five degrees of freedom of \(\boldsymbol{E}\) require a minimum of five points. In practice, the algorithm solves a system that enforces both the epipolar constraints and the algebraic properties of essential matrices (i.e., that its singular values are \(\{\sigma, \sigma, 0\}\)).</li>
<li>The relative rotation \(\boldsymbol{R}\) and translation direction \(\hat{\boldsymbol{t}}\) are extracted from \(\boldsymbol{E}\) via SVD. The decomposition yields four possible solutions (two rotations times two translation directions); the physically correct one is selected by checking that triangulated points land in front of both cameras (positive depth, or “cheirality” check).</li>
</ol>
<p>When intrinsics are unknown, the <strong>eight-point algorithm</strong> can be used to estimate the fundamental matrix \(\boldsymbol{F}\) instead, requiring at least eight correspondences (since \(\boldsymbol{F}\) has seven DOF plus one equation fixes the scale).</p>
<p>Translation is only determined up to a scale factor–this is a fundamental ambiguity of monocular geometry, since a scene and its camera motion can be uniformly scaled without changing the images.</p>
<h3 id="2d-3d-correspondences"><a class="header" href="#2d-3d-correspondences">2D-3D Correspondences</a></h3>
<p><em>Input: 2D feature points from the current image, 3D points triangulated from previous images (or from a known map).</em></p>
<p>When 3D structure is already available (e.g., from prior triangulation or a pre-built map), the camera pose can be recovered directly using <strong>Perspective-n-Point (PnP)</strong> algorithms. Given \(n\) correspondences between known 3D points \(\boldsymbol{p}_i\) and their observed 2D projections \(\boldsymbol{u}_i\), PnP finds the camera pose \((\boldsymbol{R}, \boldsymbol{t})\) such that</p>
<p>$$\boldsymbol{u}_i \sim \boldsymbol{K} \begin{bmatrix} \boldsymbol{R} &amp; \boldsymbol{t} \end{bmatrix} \tilde{\boldsymbol{p}}_i$$</p>
<p>for all \(i\). A minimum of three correspondences is required (the P3P case), which yields up to four possible solutions that can be disambiguated with a fourth point. The pose recovered by PnP is <strong>fully determined</strong>–including the scale of translation–because the 3D point positions provide an absolute reference.</p>
<h3 id="3d-3d-correspondences"><a class="header" href="#3d-3d-correspondences">3D-3D Correspondences</a></h3>
<p><em>Input: 3D point clouds from image A and image B. Usually available with RGB-D sensors or stereo cameras.</em></p>
<p>When both views produce 3D point clouds (e.g., from depth sensors), the relative transform can be computed directly from matched 3D-3D correspondences. Given corresponding point sets \(\{\boldsymbol{p}_i\}\) and \(\{\boldsymbol{p}_i’\}\), we seek the transform that minimizes</p>
<p>$$\sum_i \left| \boldsymbol{p}_i’ - (\boldsymbol{R}\boldsymbol{p}_i + \boldsymbol{t}) \right|^2.$$</p>
<p>This can be solved in closed form using SVD on the cross-covariance matrix of the centered point sets. When scale drift is a concern (as can happen over long trajectories), a <strong>similarity transform</strong> \((\boldsymbol{R}, \boldsymbol{t}, s)\) can be estimated instead of a rigid-body transform, adding a scale factor that absorbs accumulated drift. The <a href="https://en.wikipedia.org/wiki/Iterative_closest_point">Iterative Closest Point (ICP)</a> algorithm generalizes this approach to handle cases where explicit point correspondences are not known, iteratively alternating between establishing nearest-neighbor correspondences and solving for the transform.</p>
<h2 id="the-homography-matrix"><a class="header" href="#the-homography-matrix">The Homography Matrix</a></h2>
<p>A <strong>homography</strong> is an invertible mapping between two images of the same planar surface (or, equivalently, between any two images related by a pure camera rotation with no translation). It is represented by a \(3\times 3\) matrix \(\boldsymbol{H}\) that maps homogeneous pixel coordinates from one image to another:</p>
<p>$$\tilde{\boldsymbol{u}}_2 \sim \boldsymbol{H} , \tilde{\boldsymbol{u}}_1,$$</p>
<p>where \(\sim\) denotes equality up to scale. The matrix \(\boldsymbol{H}\) has eight degrees of freedom (nine entries minus one for the overall scale ambiguity) and can be estimated from a minimum of four point correspondences (each providing two equations).</p>
<p>For a planar scene with surface normal \(\hat{\boldsymbol{n}}\) at distance \(d\) from the first camera, the homography between two calibrated views is given by</p>
<p>$$\boldsymbol{H} = \boldsymbol{K}_2 \left( \boldsymbol{R} + \frac{\boldsymbol{t}\hat{\boldsymbol{n}}^T}{d} \right) \boldsymbol{K}_1^{-1},$$</p>
<p>where \(\boldsymbol{R}\) and \(\boldsymbol{t}\) are the relative rotation and translation between cameras. In the special case of pure rotation (\(\boldsymbol{t}=\boldsymbol{0}\)), this simplifies to \(\boldsymbol{H} = \boldsymbol{K}_2 \boldsymbol{R} \boldsymbol{K}_1^{-1}\), which holds regardless of scene geometry.</p>
<p>Common applications of the homography include:</p>
<ul>
<li><strong>Image stitching / panoramas:</strong> When the camera rotates but does not translate, the homography maps the entire scene between views, enabling seamless panoramic mosaics.</li>
<li><strong>Planar rectification:</strong> A homography can warp a perspective view of a planar surface into a fronto-parallel (top-down) view, useful in applications like document scanning or sports field analysis.</li>
<li><strong>Projector calibration:</strong> The mapping between a projector’s output and the surface it illuminates is a homography when the surface is planar.</li>
<li><strong>Augmented reality:</strong> Overlaying virtual content onto a detected planar surface (e.g., a marker or tabletop) requires estimating and applying a homography.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="search-and-optimization"><a class="header" href="#search-and-optimization">Search and Optimization</a></h1>
<ul>
<li><a href="#least-squares-optimization">Least-Squares Optimization</a></li>
<li><a href="#nonlinear-optimization">Nonlinear Optimization</a></li>
<li><a href="#optimization-over-lie-groups">Optimization Over Lie Groups</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="least-squares-optimization"><a class="header" href="#least-squares-optimization">Least-Squares Optimization</a></h1>
<h2 id="why-the-2-norm"><a class="header" href="#why-the-2-norm">Why The 2-Norm?</a></h2>
<p>The 2-norm, or \(\lvert\lvert\cdot\rvert\rvert_2\), is advantageous as a cost function for a number of reasons, including the following:</p>
<ul>
<li>It often coincides with a useful physical interpretation (e.g., energy, power).</li>
<li>It is induced by the inner product \(\langle\cdot,\cdot\rangle\) operator((Inner product-induced norms expand outwards like n-dimensional spheres which, as they expand, come to touch vector spaces (i.e., “flat” spaces) at exactly <em>one</em> location, implying exactly <em>one</em> optimal solution. Hence their <strong>convexity</strong> when bounded by linear constraints (since the linear constraints provide the “flat” space).)).</li>
</ul>
<p>A least-squares problem is, by definition, any optimization problem whose cost function is a 2-norm of some generalized <strong>residual</strong> function, \(r(x)\). Whether \(r(x)\) is linear or not (The residual equation is sometimes expressed as a constraint instead of in the cost function (rendering the cost function somewhat trivial), but usually not; both linear and nonlinear least-squares problems are generally considered to be a special case of <a href="#nonlinear-optimization">unconstrained nonlinear optimization problems</a>, for example.) will completely affect how the problem is approached and solved.</p>
<h2 id="linear"><a class="header" href="#linear">Linear</a></h2>
<p>Despite their name, linear least-squares problems are a subset of general unconstrained nonlinear optimization problems because of the nonlinear 2-norm operator. They’re also referred to as <strong>quadratic programs</strong>. Their general form is</p>
<p>$$\min_x||r(x)||_2=\min_x||Ax-b||_2^2$$</p>
<p>with \(A\in \mathbb{R}^{m\times n}\). Optionally, a weighting matrix \(Q\) can be used:</p>
<p>$$\min_xr^\top Qr=\min_x||Q^{1/2}(Ax-b)||_2^2.$$</p>
<h3 id="solution-methods"><a class="header" href="#solution-methods">Solution Methods</a></h3>
<p>Because this is an unconstrained nonlinear problem, we could just use some greedy search method like steepest descent, where \(F(x)=&lt;r(x),r(x)&gt;=(Ax-b)^\top(Ax-b)\) and \(g(x)=2A^\top(Ax-b)\). However, we can and should take advantage of the fact that the cost function is induced by the inner product and that the residual function is describable using vector spaces in order to derive an analytical solution. After all, what linear least squares is really asking is what is the best \(x^{*}\) such that \(Ax^{*}\) is as close to \(b\) as possible, even if \(b\) is outside of the span of \(A\). The general solution to this problem utilizes the Moore-Penrose pseudoinverse of \(A\) (assuming full row rank):</p>
<p>$$x^*=A^\dagger b,$$</p>
<p>where the pseudoinverse is defined as</p>
<ul>
<li>\(m&gt;n\): \(A^\dagger=(A^\top A)^{-1}A^\top\)
<ul>
<li>Known as the <em>left inverse</em> (\(A^\dagger A=I\)), and exists when \(A\) is “tall,” which will <em>most likely</em> be the case in learning problems, where you have linearly independent columns due to having more data points than variables. In this case, \(A^\top A&gt;0\) is positive definite.</li>
</ul>
</li>
<li>\(m=n\): \(A^\dagger=A^{-1}\)
<ul>
<li>The trivial case–doesn’t happen very often</li>
</ul>
</li>
<li>\(m &lt; n\): \(A^\dagger=A^\top(AA^\top)^{-1}\)
<ul>
<li>Known as the <em>right inverse</em> (\(AA^\dagger=I\)), and exists when \(A\) is “fat,” which usually shows up in high- or infinite-dimensional least-squares minimization problems (like optimal control) where you have far more variables than data points. In this case, \(x^{*}\) is simply the \(x\) with the shortest 2-norm that satisfies \(Ax=b\).</li>
</ul>
</li>
</ul>
<p>Assuming that we want to calculate \(x^{*}\) with the <em>left inverse</em>, how to do so efficiently? Here are two methods:</p>
<h4 id="cholesky-decomposition-method"><a class="header" href="#cholesky-decomposition-method">Cholesky Decomposition Method</a></h4>
<p>Assuming \(A^\top A&gt;0\) (again, given with the left inverse),</p>
<ul>
<li>Find lower triangular \(L\) such that \(A^\top A=LL^\top\) (Cholesky decomposition)</li>
<li>Use \(Ly=A^\top b\) to obtain \(y\)</li>
<li>Use \(L^\top x^*=y\) to obtain \(x^{*}\).</li>
</ul>
<p>Faster than QR.</p>
<h4 id="qr-decomposition-method"><a class="header" href="#qr-decomposition-method">QR Decomposition Method</a></h4>
<ul>
<li>Find \(Q\in \mathbb{R}^{n\times n},~Q^\top Q=I\) and upper triangular \(R\in\mathbb{R}^{n\times n}\) such that \(A^\top A=QR\) (QR decomposition)</li>
<li>Solve \(Rx^*=Q^\top A^\top b\) via back substitution.</li>
</ul>
<p>More numerically stable than Cholesky.</p>
<h3 id="application-to-estimation"><a class="header" href="#application-to-estimation">Application to Estimation</a></h3>
<p>Here, we focus on estimating quantities that don’t evolve according to some modeled dynamics (unlike the Kalman Filter), so either a lot of measurements are going to help you estimate one static quantity or you are going to be trying to estimate a changing quantity at repeated snapshots, unable to take advantage of previous knowledge((There are least-squares-based estimation algorithms that also take advantage of previous solutions by using clever numerical tricks like exploiting the sparsity that shows up in SLAM problems as with <a href="https://www.cs.cmu.edu/~kaess/pub/Kaess08tro.pdf">incremental smoothing</a>.)).</p>
<p><strong>Problem Statement:</strong> Estimate \(\hat{x}\) (with a prior estimate \(x_0\) covariance \(Q_0\)) when the differentiable, <em>linear</em> measurement model is</p>
<p>$$y=Hx+v,~~v\sim \mathcal{N}(0,R)$$</p>
<p>Consider that the conditional probability density of a measurement given the state is expressed as</p>
<p>$$f(y|x)=\frac{1}{\alpha}e^{-\frac{1}{2}(y-Hx)^\top R^{-1}(y-Hx)}$$</p>
<p>Thus, to get the <em>maximum likelihood</em> estimation of \(x\), we need to <em>minimize the measurement error term</em> in the exponential:</p>
<p>$$J=\frac{1}{2}(y-Hx)^\top R^{-1}(y-Hx)$$</p>
<p>Or, if we’re adding a measurement update to a prior belief \(x_0\) with covariance \(Q_0\) to obtain the posterior with mean \(\hat{x}\) and covariance \(Q_1\):</p>
<p>$$J=\frac{1}{2}(\hat{x}-x_0)^\top Q_0^{-1}(\hat{x}-x_0)+\frac{1}{2}(y-H\hat{x})^\top R^{-1}(y-H\hat{x})$$</p>
<p>We can analytically minimize this cost function because of the linear measurement model by setting \(\frac{\partial J}{\partial \hat{x}}=0\):</p>
<p>$$\hat{x}=x_0+Q_1H^\top R^{-1}(y-Hx_0),~Q_1=(Q_0^{-1}+H^\top R^{-1}H)^{-1}$$</p>
<p>Note that if there were just the measurement without the prior in the cost function, differentiating and setting to zero like before would yield</p>
<p>$$\hat{x}=(H^\top R^{-1}H)^{-1}H^\top R^{-1}y=(R^{-1/2}H)^{-L}R^{-1/2}y$$</p>
<p>which, of course, is the <em>weighted</em> (by information/certainty, or inverse covariance) least squares solution to minimizing \(R^{-1/2}(y-H\hat{x})\). This makes sense, since the least squares cost function of the residual that’s linear in \(x\) (whether it’s a linear measurement model or matching the values of a polynomial that’s linear in the coefficient or parameter vector) is always minimized by projecting the observed measurement vector (or stack of measurement vectors) \(y\) (or, in this case, the scaled measurement vector \(R^{-1/2}y\)) from somewhere in the left null space onto the column space of whatever the (tall) linear operator \(H\) (or, in this weighted case, \(R^{-1/2}H\)) represents as an operator on \(x\) via the left Moore-Penrose pseudoinverse as expressed above.</p>
<p>So, the optimal \(\hat{x}\) is the one that makes the residual \(y-H\hat{x}=y-\hat{y}\) <em>orthogonal</em> to the column space or span of \(H\). Intuitively, when the goal is to minimize the variance of \(\hat{x}\), this occurs when all possible estimate information has been extracted from the measurements:</p>
<p>$$\tilde{x}\perp y \iff \tilde{x} \perp \hat{x} \iff E[\tilde{x}y^\top]=0$$</p>
<p>where the equivalence comes from the fact that with linear estimators, the estimate is a linear combination of the measurements. The intuition makes sense when you think about the orthogonal projection theorem applied to regular vectors. Thus, <em>an optimal linear estimator must satisfy the above relations</em>.</p>
<h2 id="nonlinear"><a class="header" href="#nonlinear">Nonlinear</a></h2>
<p>Nonlinear least-squares problems make no assumptions about the structure of the residual function, so they are not necessarily convex and are afforded none of the inner-product magic of linear least-squares for deriving an analytical solution. Their general form is</p>
<p>$$\min_x||r(x)||_2^2,$$</p>
<p>where \(r\) is any nonlinear vector-valued function of \(x\). As with the linear case, a weighting matrix \(Q\) can be used.</p>
<h3 id="solution-methods-1"><a class="header" href="#solution-methods-1">Solution Methods</a></h3>
<p>The non-convexity of nonlinear least-squares problems demands an iterative solution, as with general unconstrained nonlinear optimization. Second-order Newton-based methods are again adopted here, where the Hessian needs to at least be approximated. Except for this time, the 2-norm does at least afford methods that are more efficient than BFGS and other general quasi-Newton algorithms. Two of the best known Newton-based methods tailored specifically to the nonlinear least-squares problem (in order of increasing effectiveness) are Gauss-Newton and Levenberg-Marquardt. More information can be found in Chapter 10 of <a href="http://www.apmath.spbu.ru/cnsa/pdf/monograf/Numerical_Optimization2006.pdf">this reference</a> and <a href="http://ceres-solver.org/nnls_solving.html">the Ceres Solver documentation</a>.</p>
<h4 id="gauss-newton"><a class="header" href="#gauss-newton">Gauss-Newton</a></h4>
<p>At a high level, Gauss-Newton repeatedly linearizes the vector-valued \(r(x)\) by computing the Jacobian \(J(x)\), and uses the magic analytical solution to linear least-squares to solve the miniature problem again and again. Using the same pseudoinverse operator defined with linear least squares, the recursive relation is</p>
<p>$$x_{k+1}=x_k-\alpha_kJ^\dagger r(x_k)$$</p>
<p>where the step size \(\alpha_k\) is determined via a line search (see <a href="#nonlinear-optimization">brief discussion on line searching for BFGS</a>) to help with convergence. Alternatively, if \(r(x)\triangleq y-f(x)\) and \(J\) is the Jacobian of \(f(x)\), then the recursive relation is</p>
<p>$$x_{k+1}=x_k+\alpha_kJ^\dagger r(x_k).$$</p>
<h4 id="levenberg-marquardt"><a class="header" href="#levenberg-marquardt">Levenberg-Marquardt</a></h4>
<p>Think about the case where the right inverse of \(J\) is needed for a Gauss-Newton iteration. This will happen in regions where the “local” Hessian is not positive definite, and thus \(J^\top J\) is not invertible. While \(J^\dagger\) will return <em>a</em> solution, that solution will not be unique. The Levenberg-Marquardt algorithm deals with this possibility using an <em>adaptive term</em>, \(\lambda\), to prevent instability:</p>
<p>$$x_{k+1}=x_k-\alpha_k(J^\top J+\lambda I)^{-1}J^\top R(x_k)$$</p>
<p>where \(\lambda&gt;0\), evidently, can keep \(J^\top J\) positive definite. This term (also referred to as a “damping” term) allows for the dynamic transitioning between steepest-descent-like behavior (when far from an optimum) and Gauss-Newton behavior (when close to the optimum). Thus, at each iteration, \(\lambda\) can be shrunk as the cost reduction per iteration becomes larger.</p>
<h3 id="application-to-estimation-1"><a class="header" href="#application-to-estimation-1">Application to Estimation</a></h3>
<p><strong>Problem Statement:</strong> (Iteratively) estimate \(\hat{x}\) (with a prior estimate \(x_0\) covariance \(Q_0\)) when the differentiable measurement model is</p>
<p>$$y=h(x)+v,~~v\sim \mathcal{N}(0,R)$$</p>
<p>The only difference from the linear case is that we are acknowledging that \(h\) is nonlinear (with zero-mean Gaussian noise on the measurement). The objective function is then</p>
<p>$$J=(\hat{x}-x_0)^\top Q_0^{-1}(\hat{x}-x_0)+(y-h(\hat{x}))^\top R^{-1}(y-h(\hat{x}))$$</p>
<p>Note that the iterative/time construction isn’t of necessity; we could be doing a single optimization with no \(x_0\), \(Q_0\), or a batch optimization with a bunch of stacked \(y\)’s (re-writable as a cost function adding many individual \(y\) costs). The following analysis generalizes to those cases, as well.</p>
<p>\(J\) can be minimized numerically by solvers like <a href="http://ceres-solver.org/">Ceres</a> or <a href="https://gtsam.org/">GTSAM</a>, which will use a solver like Levenberg-Marquardt. If we wanted to solve it analytically, setting its derivative with respect to \(\hat{x}\) equal to zero yields the <em>necessary condition</em>:</p>
<p>$$2Q_0^{-1}(\hat{x}-x_0)-2H_\hat{x}^\top R^{-1}(y-h(\hat{x}))=0$$</p>
<p>where \(H_\hat{x}=\frac{\partial h}{\partial x}|_\hat{x}\) is the Jacobian of the measurement model at the optimum, implying a multi-dimensional linearization at \(\hat{x}\). Note that if your cost function just has a single measurement with no \(x_0\), then obviously the optimum is where \(y=h(\hat{x})\).</p>
<p>The equation above usually can’t be solved analytically, but one option for iteratively solving is to first assume that \(x_0\) is close to \(\hat{x}\) such that \(H_{x_0}\approx H_{\hat{x}}\), yielding the analytical expression:</p>
<p>$$\hat{x}=x_0+Q_1H_{x_0}^\top R_{-1}(y-h(x_0)),~Q_1=(Q_0^{-1}+H_{x_0}^\top R^{-1}H_{x_0})^{-1}$$</p>
<p>and then, repeatedly relinearizing about \(\hat{x}\), simplifying, and solving the necessary condition, the iteration equation is</p>
<p>$$\hat{x}_{k+1}=\hat{x}_k+Q_{k+1}H_{\hat{x}_k}^\top R^{-1}(y-h(\hat{x}_k))+Q_{k+1}Q_0^{-1}(x_0-\hat{x}_k),~Q_{k+1}=(Q_0^{-1}+H_{\hat{x}_k}^\top R^{-1}H_{\hat{x}_k})^{-1}$$</p>
<p>You’ll know it’s converged when the necessary condition holds true. But watch out! High levels of nonlinearity might lead to poor convergence properties since, for instance, the Jacobian could be iteratively calculated at non-optimal states such that it just keeps bouncing around and either doesn’t converge or converges not at the minimum. Note, by the way, that this is the source of Ceres’ <a href="http://ceres-solver.org/nnls_covariance.html">discussion of covariance estimation</a>. Relating the term for the covariance to the residual from the math above, a residual for Ceres is written as</p>
<p>$$r=Q^{-1/2}(y-h(\hat{x}))$$</p>
<p>since the cost function is formulated as \(J=\sum_i r_i^\top R_i\).</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="nonlinear-optimization"><a class="header" href="#nonlinear-optimization">Nonlinear Optimization</a></h1>
<p><em>When the cost function or constraints are not linear.</em></p>
<h2 id="unconstrained-form"><a class="header" href="#unconstrained-form">Unconstrained Form</a></h2>
<h3 id="background"><a class="header" href="#background">Background</a></h3>
<p>Our optimization tools tend to be <strong>convex</strong> solvers, in which case they’re only good at finding local minima.</p>
<p>With continuous derivatives (i.e., smooth functions), we use Taylor series expansions (with gradient \(g(x)\) and Hessian \(H(x)\)) for function approximation:</p>
<p>$$ F(x+\delta x)\approx F(x)+\Delta x^Tg(x)+\frac{1}{2}\Delta x^TH(x)\Delta x + \cdots $$</p>
<ul>
<li>Necessary and Sufficient Conditions:
<ul>
<li>Necessary (for stationary point): \(g(x^*)=0\)</li>
<li>Sufficient (for strong minimum): \(H(x^*)&gt;0\)</li>
<li>Sufficient (for weak minimum): \(H(x^*)\geq0\) (or Necessary for strong minimum)</li>
</ul>
</li>
<li>Checking for positive definiteness:
<ul>
<li>Eigenvalue criteria</li>
<li>Gaussian elimination (\(O(n^3)\)): every pivot positive after elimination</li>
<li>Sylvester criterion (\(O(n!)\))</li>
</ul>
</li>
</ul>
<h3 id="methods"><a class="header" href="#methods">Methods</a></h3>
<h4 id="newtons-method"><a class="header" href="#newtons-method">Newton’s Method</a></h4>
<p>Using a second-order Taylor expansion, with \(\Delta x=x-x_k\), and getting an approximate value for \(\nabla F(x)\approx g_k+H_k(x-x_k)\), we solve for the point where \(\nabla F(x)=0\) and move there:</p>
<p>$$x_{k+1}=x_k-H_k^{-1}g_k$$</p>
<p>Obviously, if \(F\) is only a quadratic function, then this will solve for <strong>a stationary point</strong> in <strong>one step</strong>, and can converge <strong>super-linearly</strong> (error reduced by increasing factors) for non-quadratic \(F\). Sometimes isn’t ideal in the neighborhood of the minimum, and requires the costly computation of the Hessian.</p>
<p>Regardless of the weaknesses, the <em>best</em> descent direction is always \(d=-H^{-1}\nabla\).</p>
<p><a href="http://www2.lawrence.edu/fast/GREGGJ/Math420/Sections_2_3_to_2_5.pdf">Some external notes</a> on Newton’s Method.</p>
<h4 id="steepest-descent-gradient-only"><a class="header" href="#steepest-descent-gradient-only">Steepest Descent (Gradient-Only)</a></h4>
<p>Hessian ignored (i.e., set to \(I\)):</p>
<p>$$d=-\nabla$$</p>
<p>A line search method is used to see just how far to go in the descent direction. Doesn’t do well with \(F\) with poorly-conditioned Hessians. Convergence rate can be as bad as</p>
<p>$$\mu\approx 1-\frac{2}{\text{cond}(H)}$$</p>
<h4 id="quasi-newton-methods-approximate-the-hessian"><a class="header" href="#quasi-newton-methods-approximate-the-hessian">Quasi-Newton Methods (Approximate the Hessian)</a></h4>
<p>Uses Newton Method update, but approximates either the Hessian or its inverse at each time step. If \(F\) is quadratic, then Hessian is exact after \(\text{dim}(x)\) steps! <strong>BFGS</strong> the most popular method nowadays. Estimating inverse Hessian \(B_k=H_k^{-1}\) directly:</p>
<p>$$B_0=I$$
$$d_k=-B_kg_k$$
$$x_{k+1}=x_k+\alpha_kd_k$$
$$s_k=\alpha_kd_k$$
$$y_k=g_{k+1}-g_k$$
$$B_{k+1}=B_k-\frac{(B_ky_k)s_k^T+s_k(B_ky_k)^T}{y_k^Ts_k}+\frac{y_k^Ts_k+y_k^T(B_ky_k)}{(y_k^Ts_k)^2}s_ks_k^T$$</p>
<p>Line search also used to find step size \(\alpha_k\), but doesn’t even have to be all that good. Just has to satisfy <strong>Wolfe</strong> conditions (Armijo rule + curvature condition) for BFGS to maintain a \(B_k&gt;0\):</p>
<p>$$f(x_k+\alpha_kd_k)\leq f(x_k)+c_1\alpha_kd_k^T\nabla f(x_k)$$
$$-d_k^T\nabla f(x_k+\alpha_kd_k)\leq -c_2d_k^T\nabla f(x_k)$$
$$0&lt;c_1&lt;c_2&lt;1~(c_2=0.9~\text{for quasi-Newton})$$
$$c_1&lt;0.5~(c_1=10^{-4})$$</p>
<h2 id="constrained-form"><a class="header" href="#constrained-form">Constrained Form</a></h2>
<h3 id="background-1"><a class="header" href="#background-1">Background</a></h3>
<ul>
<li>Builds off of unconstrained methods, which solve for the vanilla necessary conditions in a Newton (or Newton-like) step
<ul>
<li>These do the same, but solve for the <strong>KKT</strong> necessary conditions, which provide machinery for both active and inactive constraints using Lagrange multipliers</li>
<li>Quadratic programming for quadratic cost functions</li>
<li>SQP or IP for nonlinear applications, in which we make a quadratic approximation of the problem, Newton step to solve KKT, repeat.</li>
</ul>
</li>
<li>General form:</li>
</ul>
<p>$$\text{minimize:}~~f(x)$$
$$\text{subject to:}~c_i(x)=0,~i\in \mathcal{E}$$
$$c_i(x)\leq 0,~i\in \mathcal{I}$$</p>
<h3 id="lagrange-multipliers"><a class="header" href="#lagrange-multipliers">Lagrange Multipliers</a></h3>
<h4 id="equality-constraints-only"><a class="header" href="#equality-constraints-only">Equality Constraints Only</a></h4>
<p>At the optimum, your “engine” \(\nabla f\) can only take you into “forbidden” space, which is a linear combination of the gradients of \(c_i\):</p>
<p>$$\nabla f=-\sum_{i=1}^{m}\lambda_i\nabla c_i$$</p>
<p>with this fact, we can augment our cost to make the <strong>Lagrangian</strong> and derive a new set of necessary conditions surrounding it:</p>
<p>$$L(x,\lambda)=f+\sum_{i=1}^{m}\lambda_ic_i(x)=f(x)+\lambda^Tc(x)$$</p>
<p>First (necessary) condition, equivalent to two equations ago:</p>
<p>$$\frac{\partial L}{\partial x} = \nabla_xL=\nabla f+\lambda^T\nabla c=0$$</p>
<p>Second (necessary) condition, equivalent to equality constraints’ being satisfied:</p>
<p>$$\frac{\partial L}{\partial \lambda}=c(x)=0$$</p>
<p>Those two conditions give \(n+m\) equations and \(n+m\) unknowns. <strong>If you’re solving these equations by hand, without a search method attached (better be a quadratic Lagrangian!),</strong> you’ll need to ensure that the following <em>sufficient</em> condition holds:</p>
<p>$$L_{xx}=\frac{\partial^2f}{\partial x^2}+\lambda^T\frac{\partial^2c}{\partial x^2}&gt;0$$</p>
<h4 id="adding-inequality-constraints"><a class="header" href="#adding-inequality-constraints">Adding Inequality Constraints</a></h4>
<p>Same principle, but now we can have <em>inactive</em> constraints whose gradients <em>don’t contribute</em> to the space that the cost function’s gradient is stuck in. This is accounted for with a clever “mixed-integer-like” math trick, giving the <strong>KKT necessary conditions</strong>:</p>
<p>$$\frac{\partial L}{\partial x}=0~\text{(Stationarity)}$$</p>
<p>$$c_i(x)=0, c_j(x)\leq 0~\text{(Primal Feasibility)}$$</p>
<p>$$\lambda_i\geq 0~\text{(Dual Feasibility)}$$</p>
<p>$$\lambda_jc_j(x)=0~\text{(Complementary Slackness)}$$</p>
<p>Redundant constraints make Lagrange multipliers not unique, causing some issues possibly (which \(c\) gradient basis vector to use to describe the gradient of \(f\)?).</p>
<p>Expected (absolute) objective gain can be calculated as \(\Delta c_i(\lambda_i)\).</p>
<h2 id="scaling"><a class="header" href="#scaling">Scaling</a></h2>
<p>The closer your variables’ scales are to each other, the more well-conditioned your systems (like the KKT conditions arranged in a matrix) are going to be for solving.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="optimization-over-lie-groups"><a class="header" href="#optimization-over-lie-groups">Optimization Over Lie Groups</a></h1>
<h3 id="birds-eye-view"><a class="header" href="#birds-eye-view">Birds-Eye View</a></h3>
<p>Optimization methods incorporating Lie Groups are, by definition, nonlinear. Thus, the focus here is on nonlinear “local search” methods and adapting them to accommodate state vectors \(\boldsymbol{x}\) containing at least one Lie group component:</p>
<p>$$\boldsymbol x\in \mathbb{R}^n\times \mathcal{M} \times \cdots.$$</p>
<p>Acknowledging that a state vector can contain both vector and group components, define the following composite addition and subtraction operators:</p>
<p>$$\boldsymbol{a}\boxplus\boldsymbol{b}=\begin{cases}
(\boldsymbol{a}+\boldsymbol{b})\in \mathbb{R}^n &amp; \boldsymbol{a},\boldsymbol{b}\in\mathbb{R}^{n}\
(\boldsymbol{a}\oplus\boldsymbol{b})\in \mathcal{M} &amp; \boldsymbol{a}\in\mathcal{M},\boldsymbol{b}\in \mathbb{R}^m \cong \mathfrak{m}
\end{cases}$$</p>
<p>$$\boldsymbol{a}\boxminus\boldsymbol{b}=\begin{cases}
(\boldsymbol{a}-\boldsymbol{b})\in \mathbb{R}^n &amp; \boldsymbol{a},\boldsymbol{b}\in\mathbb{R}^{n}\
(\boldsymbol{a}\ominus\boldsymbol{b})\in \mathbb{R}^m\cong \mathfrak{m} &amp; \boldsymbol{a},\boldsymbol{b}\in\mathbb{\mathcal{M}}
\end{cases}$$</p>
<p>Local search, as the name suggests, utilizes the <em>local, right-</em> versions of the \(\oplus\) and \(\ominus\) operators, as well as <em>right-Jacobians</em>.</p>
<h3 id="lie-ify-your-optimization-algorithm"><a class="header" href="#lie-ify-your-optimization-algorithm">Lie-ify Your Optimization Algorithm</a></h3>
<p>Local, iterative search algorithms (as with <a href="#nonlinear-optimization">nonlinear least squares</a>) take the following form when \(\boldsymbol x\) belongs to a vector space:</p>
<p>$$\boldsymbol x_{k+1}=\boldsymbol x_k+\boldsymbol{\Delta x},~\boldsymbol{\Delta x}=f(\boldsymbol{x}_k,\boldsymbol J(\boldsymbol x_k))\in \mathbb{R}^n,$$</p>
<p>where \(\boldsymbol J(\boldsymbol x_k)\) is the Jacobian of the residual function, \(r(\boldsymbol{x}_k)\).</p>
<p>Acknowledging that the state can contain Lie group components, the above must be modified to:</p>
<p>$$\boldsymbol x_{k+1}=\boldsymbol x_k\boxplus\boldsymbol{\Delta x},~\boldsymbol{\Delta x}=f(\boldsymbol{x}_k,\boldsymbol J(\boldsymbol x_k))\in \mathbb{R}^n\times \mathbb{R}^m\cong \mathfrak{m}\times \cdots.$$</p>
<p>In essence, to perform local search with a state that evolves on the manifold, the following three steps must be taken:</p>
<ul>
<li>Ensure that \(r(\boldsymbol x)\) returns a vector (doesn’t necessarily <em>have</em> to be this way, but it makes things much more straightforward).</li>
<li>Be able to calculate \(\boldsymbol J(\boldsymbol x_k)\), which may contain both Jacobian terms over vector spaces as well as Jacobian terms on the manifold. An example below.</li>
<li>Ensure that, for your formulation, \(f(\boldsymbol{x}_k,\boldsymbol J(\boldsymbol x_k))\) also returns a vector, but <em>with components that are isomorphic to a Lie algebra</em> (i.e., \(\mathbb{R}^m\cong \mathfrak{m}\)) where appropriate so that the \(\boxplus\) operation makes sense.</li>
</ul>
<p>If you can do those three things, then your optimization will behave as any other local search over vector spaces.</p>
<h3 id="examples"><a class="header" href="#examples">Examples</a></h3>
<h4 id="simple-mixed-jacobian-example"><a class="header" href="#simple-mixed-jacobian-example">Simple “Mixed” Jacobian Example</a></h4>
<p>Say that your state vector looks like</p>
<p>$$\boldsymbol x=\begin{bmatrix}\boldsymbol p\\ \boldsymbol{R}\end{bmatrix}\in \mathbb{R}^3 \times SO(3),$$</p>
<p>and your residual function is</p>
<p>$$r(\boldsymbol x)=\begin{bmatrix}\boldsymbol p_\text{measured}-\boldsymbol p\\ \boldsymbol R_\text{measured}\boldsymbol R^{-1}\end{bmatrix}\triangleq \begin{bmatrix}r_1(\boldsymbol x)\\r_2(\boldsymbol x)\end{bmatrix}.$$</p>
<p>The Jacobian matrix will then look like</p>
<p>$$\boldsymbol J=\begin{bmatrix}\frac{\partial r_1}{\partial \boldsymbol p} &amp; \frac{\partial r_1}{\partial \boldsymbol R} \\ \frac{\partial r_2}{\partial \boldsymbol p} &amp; \frac{\partial r_2}{\partial \boldsymbol R}\end{bmatrix}\in \mathbb{R}^{6\times 6},$$</p>
<p>where the Jacobians \(\partial r_1/\partial \boldsymbol R\) and \(\partial r_2/\partial \boldsymbol R\) are the (nontrivial) right-Jacobians on the manifold, which must be calculated as explained in the <a href="autonomy:math:manifold-calculus:lie-fundamentals#jacobians">Jacobians</a> section and demonstrated in the next example.</p>
<h4 id="gauss-newton-for-a-nonlinear-least-squares-problem"><a class="header" href="#gauss-newton-for-a-nonlinear-least-squares-problem">Gauss-Newton for a Nonlinear Least-Squares Problem</a></h4>
<p>Suppose we want to derive the Gauss-Newton recursive update step for the nonlinear least-squares problem</p>
<p>$$\min_{\boldsymbol T\in SE(3)}\frac{1}{n}\sum_{i=1}^n\text{Tr}((\boldsymbol T-\boldsymbol T_i)^T(\boldsymbol T-\boldsymbol T_i)),$$</p>
<p>where \(\boldsymbol T_i\) are a series of \(n\) pose measurements. Let’s go through the three steps for formulating local search on the manifold:</p>
<p><em><strong>1:</strong> Ensure that the residual function returns a vector.</em></p>
<p>Defining \(\boldsymbol x\triangleq \boldsymbol T\in SE(3)\), we want the optimization above to look like:</p>
<p>$$\min_{\boldsymbol x}r(\boldsymbol x)^Tr(\boldsymbol x)$$</p>
<p>where \(r(\boldsymbol x)\) returns a vector. We’ll do that now:</p>
<p>$$\frac{1}{n}\sum_{i=1}^n\text{Tr}((\boldsymbol T-\boldsymbol T_i)^T(\boldsymbol T-\boldsymbol T_i))=\text{vec}\left(\frac{1}{n}\sum_{i=1}^n(\boldsymbol T-\boldsymbol T_i)\right)^T\text{vec}\left(\frac{1}{n}\sum_{i=1}^n(\boldsymbol T-\boldsymbol T_i)\right)$$</p>
<p>$$=\text{vec}\left(\boldsymbol T-\bar{\boldsymbol{T}} \right)^T\text{vec}\left( \boldsymbol T-\bar{\boldsymbol{T}}\right)=\text{vec}\left(\begin{bmatrix}\boldsymbol{R}-\bar{\boldsymbol{R}} &amp; \boldsymbol{p}-\bar{\boldsymbol{p}}\\ \boldsymbol{0} &amp; \boldsymbol{1}\end{bmatrix} \right)^T\text{vec}\left(\begin{bmatrix}\boldsymbol{R}-\bar{\boldsymbol{R}} &amp; \boldsymbol{p}-\bar{\boldsymbol{p}}\\ \boldsymbol{0} &amp; \boldsymbol{1}\end{bmatrix} \right),$$</p>
<p>where \(\bar{\cdot}\) indicates the average value over \(n\) samples. Throw out the constants (which don’t affect the optimization) to save some space, and you have a concise definition for an equivalent vector-valued residual function:</p>
<p>$$r(\boldsymbol x)\triangleq \begin{bmatrix}\boldsymbol{p}-\bar{\boldsymbol{p}} \\ \boldsymbol R-\bar{\boldsymbol{R}})\boldsymbol e_1 \\ (\boldsymbol R-\bar{\boldsymbol{R}})\boldsymbol e_2 \\ (\boldsymbol R-\bar{\boldsymbol{R}})\boldsymbol e_3\end{bmatrix}~:~SE(3)\rightarrow \mathbb{R}^{12}.$$</p>
<p><em><strong>2:</strong> Calculate the Jacobian matrix of the residual function.</em></p>
<p>Most Jacobian elements can be trivially calculated as</p>
<p>$$\boldsymbol J=\begin{bmatrix} \partial r_1/\partial \boldsymbol p &amp; \partial r_1/\partial \boldsymbol \theta \\ \partial r_2/\partial \boldsymbol p &amp; \partial r_2/\partial \boldsymbol \theta \\ \partial r_3/\partial \boldsymbol p &amp; \partial r_3/\partial \boldsymbol \theta \\ \partial r_4/\partial \boldsymbol p &amp; \partial r_4/\partial \boldsymbol \theta \end{bmatrix}=\begin{bmatrix}\boldsymbol I &amp; \boldsymbol 0\\ \boldsymbol 0 &amp; \partial r_2/\partial \boldsymbol \theta\\ \boldsymbol 0 &amp; \partial r_3/\partial \boldsymbol \theta \\ \boldsymbol 0 &amp; \partial r_4/\partial \boldsymbol \theta\end{bmatrix}.$$</p>
<p>The remaining Jacobian blocks must be calculated on the manifold:</p>
<p>$$\frac{\partial r_2}{\partial \boldsymbol\theta}=\lim_{\boldsymbol \theta\rightarrow \boldsymbol{0}}\frac{r_2(\boldsymbol R \oplus \boldsymbol \theta)-r_2(\boldsymbol R)}{\boldsymbol \theta}$$</p>
<p>(…note the regular minus \(-\) sign in the numerator, since \(r\) returns a vector and thus \(\ominus\) is not necessary…)</p>
<p>$$=\lim_{\boldsymbol{\theta}\rightarrow \boldsymbol{0}}\frac{(\boldsymbol R \text{Exp}\boldsymbol \theta-\bar{\boldsymbol{R}})\boldsymbol e_1-(\boldsymbol{R}-\bar{\boldsymbol{R}})\boldsymbol e_1}{\boldsymbol \theta}=\lim_{\boldsymbol \theta\rightarrow \boldsymbol{0}}\frac{\boldsymbol R(\text{Exp}\boldsymbol \theta-\boldsymbol I)\boldsymbol e_1}{\boldsymbol \theta}$$</p>
<p>$$\approx\lim_{\boldsymbol{\theta}\rightarrow \boldsymbol{0}}\frac{\boldsymbol{R}[\boldsymbol{\theta}]_\times\boldsymbol e_1}{\boldsymbol \theta}$$</p>
<p>$$=\lim_{\boldsymbol{\theta}\rightarrow \boldsymbol{0}}\frac{-\boldsymbol{R}[\boldsymbol e_1]_{\times}\boldsymbol{\theta}}{\boldsymbol{\theta}}$$</p>
<p>$$=-\boldsymbol{R}[\boldsymbol e_1]_\times.$$</p>
<p>$$\vdots$$</p>
<p>$$\boldsymbol{J} = \begin{bmatrix} \boldsymbol{I} &amp; \boldsymbol{0} \\ \boldsymbol{0} &amp; -\boldsymbol{R}[\boldsymbol e_1]_\times \\ \boldsymbol{0} &amp; -\boldsymbol{R}[\boldsymbol e_2]_\times \\ \boldsymbol{0} &amp; -\boldsymbol{R}[\boldsymbol e_3]_\times \end{bmatrix} \in \mathbb{R}^{12 \times 6}.$$</p>
<p><em><strong>3:</strong> Check that the \(\boxplus\) operation makes sense.</em></p>
<p>For a Gauss-Newton update step, the recursive relation is</p>
<p>$$\boldsymbol x_{k+1}=\boldsymbol x_k \boxplus \alpha_k \boldsymbol J^\dagger r(\boldsymbol{x}_k),$$</p>
<p>so that means that we have the requirement</p>
<p>$$\boldsymbol J^\dagger r(\boldsymbol{x}_k)\in \mathbb{R}^6 \cong \mathfrak{se}(3).$$</p>
<p>Carrying out the pseudoinverse expansion of \(\boldsymbol J^\dagger\) and multiplying with \(r\) will indeed verify that the dimensions are all correct.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="systems-implementation"><a class="header" href="#systems-implementation">Systems Implementation</a></h1>
<ul>
<li><a href="#computer-science">Computer Science</a>
<ul>
<li><a href="#algorithms">Algorithms</a></li>
<li><a href="#data-structures">Data Structures</a></li>
</ul>
</li>
<li><a href="#computer-simulations">Computer Simulations</a>
<ul>
<li><a href="#event-based-collision-detection">Event-Based Collision Detection</a></li>
<li><a href="#the-inertial-measurement-unit-imu-sensor">The Inertial Measurement Unit (IMU) Sensor</a></li>
<li><a href="#the-rotor-blade-flapping-effect">The Rotor Blade Flapping Effect</a></li>
</ul>
</li>
<li><a href="#operating-systems">Operating Systems</a>
<ul>
<li><a href="#a-key-press">A Key Press</a></li>
<li><a href="#multithreaded-executable">Multithreaded Executable</a></li>
<li><a href="#networking-layers">Networking Layers</a></li>
</ul>
</li>
<li><a href="#optimization-libraries">Optimization Libraries</a>
<ul>
<li><a href="#2d-range-bearing-landmark-resolution-with-ceres">2D Range-Bearing Landmark Resolution with Ceres</a></li>
<li><a href="#ceres-solver-python-tutorial">Ceres Solver Python Tutorial</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="computer-science"><a class="header" href="#computer-science">Computer Science</a></h1>
<ul>
<li><a href="#algorithms">Algorithms</a></li>
<li><a href="#data-structures">Data Structures</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="algorithms"><a href="#algorithms" class="header">Algorithms</a></h1>

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fundamental Algorithms — Sorting &amp; Search</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
<pre><code>    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background: linear-gradient(135deg, #4a1942 0%, #8b2fc9 100%);
        padding: 40px 20px;
        min-height: 100vh;
    }

    .container {
        max-width: 1200px;
        margin: 0 auto;
        background: white;
        border-radius: 20px;
        padding: 40px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
    }

    h1 {
        text-align: center;
        color: #2d3748;
        margin-bottom: 10px;
        font-size: 2.5em;
    }

    .subtitle {
        text-align: center;
        color: #718096;
        margin-bottom: 50px;
        font-size: 1.1em;
    }

    /* Section heading */
    .section-heading {
        font-size: 0.75em;
        font-weight: 700;
        text-transform: uppercase;
        letter-spacing: 0.12em;
        color: #a0aec0;
        margin: 40px 0 16px 0;
        padding-bottom: 8px;
        border-bottom: 1px solid #e2e8f0;
    }
    .section-heading:first-of-type {
        margin-top: 0;
    }

    /* Card grid */
    .ds-grid {
        display: grid;
        grid-template-columns: repeat(auto-fill, minmax(260px, 1fr));
        gap: 18px;
        margin-bottom: 8px;
    }

    .ds-card {
        border-radius: 14px;
        padding: 22px 20px 18px;
        cursor: pointer;
        transition: transform 0.22s ease, box-shadow 0.22s ease;
        position: relative;
        overflow: hidden;
    }

    .ds-card:hover {
        transform: translateY(-4px);
    }

    /* Complexity badge in top-right */
    .complexity-badge {
        position: absolute;
        top: 14px;
        right: 14px;
        font-size: 0.68em;
        font-weight: 700;
        padding: 3px 9px;
        border-radius: 20px;
        letter-spacing: 0.03em;
        background: rgba(255,255,255,0.25);
        color: rgba(255,255,255,0.95);
    }

    .ds-card-icon {
        font-size: 1.9em;
        margin-bottom: 10px;
        line-height: 1;
    }

    .ds-card-name {
        font-size: 1.15em;
        font-weight: 700;
        color: white;
        margin-bottom: 6px;
    }

    .ds-card-tagline {
        font-size: 0.82em;
        color: rgba(255,255,255,0.85);
        line-height: 1.45;
        margin-bottom: 12px;
    }

    .ds-card-ops {
        display: flex;
        flex-wrap: wrap;
        gap: 5px;
    }

    .op-tag {
        font-size: 0.68em;
        font-weight: 700;
        padding: 2px 8px;
        border-radius: 20px;
        background: rgba(255,255,255,0.22);
        color: rgba(255,255,255,0.95);
        letter-spacing: 0.02em;
    }

    /* Card colour themes */
    .card-insertion  { background: linear-gradient(135deg, #2b6cb0, #3182ce); box-shadow: 0 4px 18px rgba(49,130,206,0.35); }
    .card-insertion:hover { box-shadow: 0 8px 28px rgba(49,130,206,0.5); }

    .card-selection  { background: linear-gradient(135deg, #0369a1, #0284c7); box-shadow: 0 4px 18px rgba(2,132,199,0.35); }
    .card-selection:hover { box-shadow: 0 8px 28px rgba(2,132,199,0.5); }

    .card-merge      { background: linear-gradient(135deg, #276749, #38a169); box-shadow: 0 4px 18px rgba(56,161,105,0.35); }
    .card-merge:hover { box-shadow: 0 8px 28px rgba(56,161,105,0.5); }

    .card-quick      { background: linear-gradient(135deg, #881337, #e11d48); box-shadow: 0 4px 18px rgba(225,29,72,0.35); }
    .card-quick:hover { box-shadow: 0 8px 28px rgba(225,29,72,0.5); }

    .card-heap       { background: linear-gradient(135deg, #92400e, #d97706); box-shadow: 0 4px 18px rgba(217,119,6,0.35); }
    .card-heap:hover { box-shadow: 0 8px 28px rgba(217,119,6,0.5); }

    .card-counting   { background: linear-gradient(135deg, #6b21a8, #9333ea); box-shadow: 0 4px 18px rgba(147,51,234,0.35); }
    .card-counting:hover { box-shadow: 0 8px 28px rgba(147,51,234,0.5); }

    .card-radix      { background: linear-gradient(135deg, #7e22ce, #a855f7); box-shadow: 0 4px 18px rgba(168,85,247,0.35); }
    .card-radix:hover { box-shadow: 0 8px 28px rgba(168,85,247,0.5); }

    .card-linear     { background: linear-gradient(135deg, #4a5568, #718096); box-shadow: 0 4px 18px rgba(113,128,150,0.35); }
    .card-linear:hover { box-shadow: 0 8px 28px rgba(113,128,150,0.5); }

    .card-binary     { background: linear-gradient(135deg, #065f46, #059669); box-shadow: 0 4px 18px rgba(5,150,105,0.35); }
    .card-binary:hover { box-shadow: 0 8px 28px rgba(5,150,105,0.5); }

    .card-interp     { background: linear-gradient(135deg, #0f766e, #14b8a6); box-shadow: 0 4px 18px rgba(20,184,166,0.35); }
    .card-interp:hover { box-shadow: 0 8px 28px rgba(20,184,166,0.5); }

    .card-expo       { background: linear-gradient(135deg, #1d4ed8, #2563eb); box-shadow: 0 4px 18px rgba(37,99,235,0.35); }
    .card-expo:hover { box-shadow: 0 8px 28px rgba(37,99,235,0.5); }

    /* Summary bar */
    .summary-bar {
        background: #edf2f7;
        padding: 16px 20px;
        border-radius: 10px;
        text-align: center;
        margin-top: 36px;
        color: #2d3748;
        font-weight: 600;
        font-size: 0.95em;
        line-height: 1.6;
    }

    /* Modal */
    .modal {
        display: none;
        position: fixed;
        z-index: 1000;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(0, 0, 0, 0.6);
        animation: fadeIn 0.25s;
    }

    @keyframes fadeIn {
        from { opacity: 0; }
        to   { opacity: 1; }
    }

    .modal-content {
        background-color: white;
        margin: 6% auto;
        padding: 40px;
        border-radius: 16px;
        width: 84%;
        max-width: 720px;
        max-height: 85vh;
        overflow-y: auto;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        position: relative;
        animation: slideIn 0.25s;
    }

    @keyframes slideIn {
        from { transform: translateY(-36px); opacity: 0; }
        to   { transform: translateY(0);     opacity: 1; }
    }

    .close {
        color: #a0aec0;
        position: absolute;
        right: 20px;
        top: 18px;
        font-size: 34px;
        font-weight: bold;
        cursor: pointer;
        transition: color 0.2s;
        line-height: 1;
    }

    .close:hover { color: #2d3748; }

    .modal-title {
        color: #7c3aed;
        font-size: 1.6em;
        margin-bottom: 18px;
        padding-bottom: 14px;
        border-bottom: 3px solid #8b2fc9;
        padding-right: 40px;
        line-height: 1.3;
    }

    .modal-body {
        color: #2d3748;
        line-height: 1.82;
        font-size: 1.01em;
    }

    .modal-body p   { margin-bottom: 14px; }
    .modal-body strong { color: #7c3aed; }
    .modal-body ul  { margin: 0 0 14px 22px; }
    .modal-body li  { margin-bottom: 5px; }
    .modal-body code {
        background: #edf2f7;
        border-radius: 4px;
        padding: 1px 5px;
        font-family: 'Cascadia Code', 'Fira Code', Consolas, monospace;
        font-size: 0.91em;
        color: #2d3748;
    }
    .modal-body h3 {
        color: #2d3748;
        font-size: 1.05em;
        margin: 18px 0 6px;
    }

    /* Responsive */
    @media screen and (max-width: 700px) {
        body { padding: 20px 10px; }
        .container { padding: 22px 14px; border-radius: 12px; }
        h1 { font-size: 1.6em; }
        .ds-grid { grid-template-columns: 1fr; }
        .modal-content { margin: 4% auto; padding: 24px 18px; width: 96%; max-width: 96%; max-height: 90vh; }
        .modal-title { font-size: 1.25em; }
    }

    @media (hover: none) and (pointer: coarse) {
        .ds-card:active { transform: scale(0.97); }
    }
&lt;/style&gt;
</code></pre>

<body>
    
<div id="modal-2" class="modal">
        
<div class="modal-content">
            <span class="close">×</span>
            
<h2 class="modal-title" id="modal-title-2"></h2>

            
<div class="modal-body" id="modal-body-2"></div>

        </div>

    </div>

<pre><code>&lt;div class="container"&gt;
    &lt;h1&gt;Fundamental Algorithms&lt;/h1&gt;
    &lt;p class="subtitle"&gt;Sorting and search — the algorithmic building blocks of computer science, ordered by increasing sophistication&lt;/p&gt;

    &lt;!-- ── SECTION 1: ELEMENTARY SORTS ── --&gt;
    &lt;div class="section-heading"&gt;Elementary Sorts&lt;/div&gt;
    &lt;div class="ds-grid"&gt;

        &lt;div class="ds-card card-insertion" data-info="insertion-sort"&gt;
            &lt;div class="complexity-badge"&gt;O(n&amp;sup2;) worst&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;&amp;#x25B7;&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Insertion Sort&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Builds the sorted array one element at a time by inserting each into its correct position. Adaptive, stable, and optimal for small or nearly-sorted inputs.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Best O(n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Avg O(n&amp;sup2;)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Space O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Stable&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-selection" data-info="selection-sort"&gt;
            &lt;div class="complexity-badge"&gt;O(n&amp;sup2;) always&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;&amp;#x25CB;&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Selection Sort&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Repeatedly finds the minimum from the unsorted portion and swaps it into place. Simple, but always quadratic — no adaptivity.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Best O(n&amp;sup2;)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Avg O(n&amp;sup2;)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Space O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Not Stable&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

    &lt;/div&gt;

    &lt;!-- ── SECTION 2: EFFICIENT COMPARISON SORTS ── --&gt;
    &lt;div class="section-heading"&gt;Efficient Comparison Sorts&lt;/div&gt;
    &lt;div class="ds-grid"&gt;

        &lt;div class="ds-card card-merge" data-info="merge-sort"&gt;
            &lt;div class="complexity-badge"&gt;O(n log n)&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;&amp;#x2194;&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Merge Sort&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Divide-and-conquer: split in half, sort each recursively, merge the sorted halves. Guaranteed O(n log n) and stable — the gold standard when stability matters.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Best O(n log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Worst O(n log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Space O(n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Stable&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-quick" data-info="quick-sort"&gt;
            &lt;div class="complexity-badge"&gt;O(n log n) avg&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;&amp;#x26A1;&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Quick Sort&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Pick a pivot, partition around it, recurse on each side. The fastest comparison sort in practice thanks to cache locality and small constants.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Best O(n log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Worst O(n&amp;sup2;)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Space O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Not Stable&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-heap" data-info="heap-sort"&gt;
            &lt;div class="complexity-badge"&gt;O(n log n)&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;&amp;#x25B3;&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Heap Sort&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Build a max-heap, then repeatedly extract the maximum. Guaranteed O(n log n) and in-place — the worst-case optimal comparison sort for memory-constrained systems.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Best O(n log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Worst O(n log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Space O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Not Stable&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

    &lt;/div&gt;

    &lt;!-- ── SECTION 3: NON-COMPARISON SORTS ── --&gt;
    &lt;div class="section-heading"&gt;Non-Comparison Sorts&lt;/div&gt;
    &lt;div class="ds-grid"&gt;

        &lt;div class="ds-card card-counting" data-info="counting-sort"&gt;
            &lt;div class="complexity-badge"&gt;O(n + k)&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;&amp;#x2116;&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Counting Sort&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Counts occurrences of each value, then reconstructs the sorted output. Beats the O(n log n) comparison lower bound when the key range k is small.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Time O(n + k)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Space O(n + k)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Stable&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-radix" data-info="radix-sort"&gt;
            &lt;div class="complexity-badge"&gt;O(d(n + k))&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;&amp;#x2261;&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Radix Sort&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Sort digit by digit from least significant to most, using a stable sub-sort (counting sort) at each level. Linear time for fixed-width keys.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Time O(d(n+k))&lt;/span&gt;
                &lt;span class="op-tag"&gt;Space O(n + k)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Stable&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

    &lt;/div&gt;

    &lt;!-- ── SECTION 4: SEARCH ALGORITHMS ── --&gt;
    &lt;div class="section-heading"&gt;Search Algorithms&lt;/div&gt;
    &lt;div class="ds-grid"&gt;

        &lt;div class="ds-card card-linear" data-info="linear-search"&gt;
            &lt;div class="complexity-badge"&gt;O(n)&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;&amp;#x2192;&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Linear Search&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Scan every element from start to end until the target is found or the array is exhausted. No preconditions — works on any collection.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Best O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Avg O(n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Worst O(n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Unsorted OK&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-binary" data-info="binary-search"&gt;
            &lt;div class="complexity-badge"&gt;O(log n)&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;&amp;#x00BD;&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Binary Search&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Halve the search space at each step by comparing the target to the middle element. The fundamental algorithm for sorted data and monotonic decision problems.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Best O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Avg O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Worst O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Sorted Only&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-interp" data-info="interpolation-search"&gt;
            &lt;div class="complexity-badge"&gt;O(log log n) avg&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;&amp;#x223F;&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Interpolation Search&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Estimates the target's position using value distribution rather than always probing the midpoint. Sub-logarithmic on uniformly distributed data.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Best O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Avg O(log log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Worst O(n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Uniform Data&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-expo" data-info="exponential-search"&gt;
            &lt;div class="complexity-badge"&gt;O(log n)&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;&amp;#x00D7;2&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Exponential Search&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Double the search range until the target is bracketed, then binary search within that range. Optimal when the target is near the beginning of an unbounded or very large sorted sequence.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Best O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Worst O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Unbounded OK&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

    &lt;/div&gt;

    &lt;div class="summary-bar"&gt;
        Click any card to explore the full algorithm, motivation, and real-world application examples.
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
const explanations = {

    /* ══════════════════════════════════════════
       ELEMENTARY SORTS
       ══════════════════════════════════════════ */

    'insertion-sort': {
        title: 'Insertion Sort',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; Insertion sort maintains a sorted prefix and grows it by one element at each step. It takes the next unsorted element, scans backward through the sorted prefix, shifts larger elements right, and inserts the new element in its correct position.&lt;/p&gt;

            &lt;h3&gt;The Algorithm&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;Start with the first element (trivially sorted).&lt;/li&gt;
                &lt;li&gt;For each subsequent element &lt;code&gt;key = a[i]&lt;/code&gt;:&lt;/li&gt;
                &lt;li&gt;Compare &lt;code&gt;key&lt;/code&gt; with elements &lt;code&gt;a[i-1], a[i-2], …&lt;/code&gt; moving right until the correct position is found.&lt;/li&gt;
                &lt;li&gt;Insert &lt;code&gt;key&lt;/code&gt; there. One pass through the array; inner loop does the shifting.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Best case O(n):&lt;/strong&gt; The array is already sorted — the inner loop never executes. This makes insertion sort &lt;em&gt;adaptive&lt;/em&gt;: it runs in O(n + d) where d is the number of inversions.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Average and worst case O(n&amp;sup2;):&lt;/strong&gt; Random data has O(n&amp;sup2;) inversions; reverse-sorted data is the worst case.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; O(1) — in-place.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Stability:&lt;/strong&gt; Stable — equal elements maintain their original order because we only shift strictly greater elements.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Why It Matters&lt;/h3&gt;
            &lt;p&gt;Insertion sort has the lowest overhead of any sorting algorithm. For small arrays (n &amp;lt; 20–50), its simplicity and cache-friendly sequential access pattern make it faster than quicksort or merge sort despite the quadratic asymptotic bound. This is why every serious sorting library (glibc's &lt;code&gt;qsort&lt;/code&gt;, Python's Timsort, Java's dual-pivot sort) switches to insertion sort for small subarrays.&lt;/p&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Timsort's inner loop (Python, Java):&lt;/strong&gt; Timsort — the default sort in Python and Java — identifies naturally sorted "runs" in the data and merges them. Within each small run, it uses binary insertion sort. Nearly-sorted data hits the O(n) best case.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Small-array base case in quicksort/mergesort:&lt;/strong&gt; GCC's &lt;code&gt;std::sort&lt;/code&gt; switches to insertion sort when the partition size drops below ~16 elements. This eliminates recursive call overhead and exploits the nearly-sorted state of small partitions.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Online sorting (streaming data):&lt;/strong&gt; Insertion sort naturally handles data arriving one element at a time — each insertion is O(n) worst case, but maintaining a sorted buffer of recent items is practical for small windows.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Card sorting (the human analogy):&lt;/strong&gt; The way most people sort a hand of playing cards — pick up one card, slide it into the right place among the cards already held — is exactly insertion sort.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Embedded systems with tiny arrays:&lt;/strong&gt; Microcontrollers sorting 8–16 sensor readings use insertion sort because it compiles to minimal code, uses no extra memory, and beats asymptotically faster algorithms at these sizes.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'selection-sort': {
        title: 'Selection Sort',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; Selection sort divides the array into a sorted prefix and an unsorted suffix. On each pass, it scans the unsorted suffix to find the minimum element and swaps it into the first unsorted position. After n−1 passes, the array is sorted.&lt;/p&gt;

            &lt;h3&gt;The Algorithm&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;For &lt;code&gt;i = 0&lt;/code&gt; to &lt;code&gt;n-2&lt;/code&gt;:&lt;/li&gt;
                &lt;li&gt;Find the index &lt;code&gt;min_idx&lt;/code&gt; of the minimum element in &lt;code&gt;a[i..n-1]&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;Swap &lt;code&gt;a[i]&lt;/code&gt; and &lt;code&gt;a[min_idx]&lt;/code&gt;.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;All cases O(n&amp;sup2;):&lt;/strong&gt; Always performs exactly n(n−1)/2 comparisons regardless of input order. Not adaptive.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Swaps:&lt;/strong&gt; At most n−1 swaps — the minimum number possible. This is selection sort's only advantage: it minimises data movement.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; O(1) — in-place.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Stability:&lt;/strong&gt; Not stable in the standard swap-based form (swapping can jump equal elements over each other). A stable variant exists using shifts instead of swaps, but then it becomes insertion sort.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Why It Matters&lt;/h3&gt;
            &lt;p&gt;Selection sort is primarily a teaching algorithm. Its value lies in demonstrating the &lt;em&gt;selection&lt;/em&gt; paradigm (finding the extremum) and in its O(n) swap count, which matters when writes are much more expensive than reads — for example, when sorting large records on flash memory with limited write cycles.&lt;/p&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Minimising writes to flash/EEPROM:&lt;/strong&gt; On flash memory with limited write endurance (~10,000 cycles), selection sort's O(n) swaps versus insertion sort's O(n&amp;sup2;) shifts can extend the memory's usable life — relevant in IoT sensor logging.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Sorting very large records by small keys:&lt;/strong&gt; When each element is a multi-megabyte blob and copying is expensive, selection sort's minimal swap count reduces I/O. (In practice, you'd sort an index array instead.)&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Pedagogical foundation:&lt;/strong&gt; Selection sort is the canonical algorithm for teaching loop invariants: "after iteration i, the first i elements are the i smallest in sorted order." Every algorithms textbook begins here.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Tournament selection in evolutionary algorithms:&lt;/strong&gt; Genetic algorithms use tournament selection — repeatedly picking the fittest from a small random subset — which is the selection sort principle applied to one position at a time.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    /* ══════════════════════════════════════════
       EFFICIENT COMPARISON SORTS
       ══════════════════════════════════════════ */

    'merge-sort': {
        title: 'Merge Sort',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; Merge sort is a divide-and-conquer algorithm. Split the array in half, recursively sort each half, then merge the two sorted halves into a single sorted array. The merge step does all the work: it scans both halves with two pointers, always copying the smaller element into the output.&lt;/p&gt;

            &lt;h3&gt;The Algorithm&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Divide:&lt;/strong&gt; Split the array at the midpoint into left and right halves.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Conquer:&lt;/strong&gt; Recursively sort each half. Base case: a single element is already sorted.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Merge:&lt;/strong&gt; Two-pointer merge of two sorted arrays into one. Compare the front elements of each half; copy the smaller; advance that pointer. O(n) per merge level, O(log n) levels → O(n log n) total.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;All cases O(n log n):&lt;/strong&gt; The recursion tree always has log n levels, each doing O(n) work. No degradation on any input.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; O(n) for the auxiliary merge buffer. This is the primary downside compared to quicksort. In-place merge sort exists but is complex and slower in practice.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Stability:&lt;/strong&gt; Stable — the merge step preserves the order of equal elements by always taking from the left half first on ties.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;The Comparison Sort Lower Bound&lt;/h3&gt;
            &lt;p&gt;Any comparison-based sort must make at least &lt;code&gt;&amp;lceil;log&amp;sub2;(n!)&amp;rceil; &amp;asymp; n log n&lt;/code&gt; comparisons in the worst case — because there are n! possible orderings and each comparison eliminates at most half. Merge sort matches this lower bound: it is &lt;em&gt;asymptotically optimal&lt;/em&gt; among comparison sorts.&lt;/p&gt;

            &lt;h3&gt;Variants&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Bottom-up merge sort:&lt;/strong&gt; Iterative. Merge pairs of size 1 into sorted pairs, then merge pairs of size 2 into sorted runs of 4, and so on. No recursion overhead; same O(n log n).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Natural merge sort / Timsort:&lt;/strong&gt; Detect existing sorted runs in the data and merge them. Timsort is the dominant modern variant — O(n) on nearly-sorted data.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Merge sort on linked lists:&lt;/strong&gt; O(n log n) with O(log n) stack space and no extra array — splitting is O(n) with slow/fast pointers, merging is pointer rewiring. The preferred sort for linked lists.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;External merge sort:&lt;/strong&gt; For data too large to fit in RAM. Sort chunks that fit in memory, write sorted runs to disk, then k-way merge the runs using a priority queue. The basis of all large-scale sorting (databases, MapReduce).&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Python's sort / Java's Arrays.sort for objects:&lt;/strong&gt; Timsort (a natural merge sort) is the default sort in CPython and OpenJDK for objects. It exploits pre-existing order, achieving O(n) on nearly-sorted data and worst-case O(n log n).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Database external sort:&lt;/strong&gt; When &lt;code&gt;ORDER BY&lt;/code&gt; operates on more data than fits in memory, PostgreSQL and MySQL perform external merge sort: sort in-memory chunks, flush to temp files, then multi-way merge.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;MapReduce shuffle phase:&lt;/strong&gt; Hadoop and Spark sort mapper output by key using external merge sort before feeding it to reducers. This is the largest-scale sorting in the world — petabytes of data sorted across thousands of machines.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Inversion counting:&lt;/strong&gt; The number of inversions (out-of-order pairs) in an array can be counted in O(n log n) by modifying merge sort's merge step to count splits. Used in ranking correlation (Kendall tau distance).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Git diff and merge:&lt;/strong&gt; Git's merge algorithm (recursive three-way merge) uses patience sorting and merge-like operations to align file content. The underlying merge logic is structurally the same as merge sort's merge step.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'quick-sort': {
        title: 'Quick Sort',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; Quick sort selects a &lt;em&gt;pivot&lt;/em&gt; element, partitions the array so that all elements less than the pivot come before it and all greater elements come after, then recursively sorts the two partitions. The key insight: the pivot is in its final sorted position after partitioning — no merge step needed.&lt;/p&gt;

            &lt;h3&gt;The Algorithm (Lomuto Partition)&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;Choose a pivot (last element, random, or median-of-three).&lt;/li&gt;
                &lt;li&gt;Maintain index &lt;code&gt;i&lt;/code&gt; = boundary of "less than pivot" region.&lt;/li&gt;
                &lt;li&gt;Scan &lt;code&gt;j&lt;/code&gt; from left to right: if &lt;code&gt;a[j] &amp;lt; pivot&lt;/code&gt;, swap &lt;code&gt;a[j]&lt;/code&gt; with &lt;code&gt;a[i]&lt;/code&gt; and increment &lt;code&gt;i&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;Swap pivot into position &lt;code&gt;i&lt;/code&gt;. Now &lt;code&gt;a[0..i-1] &amp;lt; pivot &amp;le; a[i+1..n-1]&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;Recurse on both sides.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Hoare Partition&lt;/h3&gt;
            &lt;p&gt;Hoare's original scheme uses two pointers that converge from both ends. It performs fewer swaps on average than Lomuto and handles repeated elements more gracefully. Most production implementations use Hoare or a dual-pivot variant.&lt;/p&gt;

            &lt;h3&gt;Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Average case O(n log n):&lt;/strong&gt; A random pivot splits the array into roughly equal halves with high probability. The expected number of comparisons is ~1.39 n log n — about 39% more than merge sort, but the constant factor is lower due to cache locality.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Worst case O(n&amp;sup2;):&lt;/strong&gt; Occurs when the pivot is always the smallest or largest element (already-sorted input with naive pivot choice). Randomised pivot selection or median-of-three makes this astronomically unlikely.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; O(log n) for the recursion stack (tail-call optimise the larger partition). Worst case O(n) without tail-call optimisation.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Stability:&lt;/strong&gt; Not stable — the partition swaps can reorder equal elements.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Variants &amp;amp; Improvements&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Introsort (C++ std::sort):&lt;/strong&gt; Start with quicksort; if recursion depth exceeds 2 log n, switch to heapsort to guarantee O(n log n) worst case. Use insertion sort for small partitions. This is the standard in GCC and MSVC.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Dual-pivot quicksort (Java):&lt;/strong&gt; Java's &lt;code&gt;Arrays.sort&lt;/code&gt; for primitives uses Yaroslavskiy's dual-pivot quicksort: two pivots create three partitions, reducing the number of comparisons and improving cache performance.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Three-way partition (Dutch National Flag):&lt;/strong&gt; Partition into &amp;lt; pivot, = pivot, &amp;gt; pivot. Essential for arrays with many duplicates — reduces the problem size by excluding all copies of the pivot from recursion.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Quickselect (selection):&lt;/strong&gt; Quicksort's partition step alone finds the k-th smallest element in O(n) average time — only recurse into the partition containing position k.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;C++ &lt;code&gt;std::sort&lt;/code&gt; (Introsort):&lt;/strong&gt; GCC's libstdc++ and LLVM's libc++ both implement &lt;code&gt;std::sort&lt;/code&gt; as introsort — quicksort with heapsort fallback and insertion sort for small ranges. The fastest general-purpose sort for primitive types.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Java &lt;code&gt;Arrays.sort&lt;/code&gt; for primitives:&lt;/strong&gt; Uses dual-pivot quicksort. Benchmarks show 10–20% fewer comparisons and better cache utilisation than classic single-pivot quicksort.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;qsort in C standard library:&lt;/strong&gt; glibc's &lt;code&gt;qsort()&lt;/code&gt; is a quicksort with median-of-three pivot and insertion sort fallback. The workhorse sort for C programs.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Database in-memory sort:&lt;/strong&gt; When the data fits in memory, database engines (PostgreSQL, DuckDB) use quicksort variants for &lt;code&gt;ORDER BY&lt;/code&gt; because the cache-friendly access pattern outperforms merge sort at these scales.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Quickselect in percentile computation:&lt;/strong&gt; Computing the median, p95 latency, or any order statistic of a dataset uses quickselect — quicksort's partition without full sorting. NumPy's &lt;code&gt;np.percentile&lt;/code&gt; uses this internally.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'heap-sort': {
        title: 'Heap Sort',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; Heap sort leverages the binary heap data structure. First, build a max-heap from the array in O(n). Then, repeatedly extract the maximum (swap root with the last element, reduce heap size by one, sift down the new root). After n−1 extractions, the array is sorted in ascending order.&lt;/p&gt;

            &lt;h3&gt;The Algorithm&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Build max-heap:&lt;/strong&gt; Call sift-down on nodes from &lt;code&gt;n/2&lt;/code&gt; down to &lt;code&gt;1&lt;/code&gt;. Each sift-down is O(log n), but the total work is O(n) because most nodes are near the leaves. (A subtle but important result — proved via a geometric series on the heights.)&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Extract-max loop:&lt;/strong&gt; For &lt;code&gt;i = n-1&lt;/code&gt; down to &lt;code&gt;1&lt;/code&gt;: swap &lt;code&gt;a[0]&lt;/code&gt; with &lt;code&gt;a[i]&lt;/code&gt; (placing the max at the end), then sift down &lt;code&gt;a[0]&lt;/code&gt; in the reduced heap &lt;code&gt;a[0..i-1]&lt;/code&gt;. Each extraction is O(log n); n−1 extractions → O(n log n).&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;All cases O(n log n):&lt;/strong&gt; No input can cause degradation. The build phase is O(n) and the extraction phase is always O(n log n).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; O(1) — fully in-place. The heap is built within the array itself. This makes heapsort the only O(n log n) comparison sort with O(1) auxiliary space.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Stability:&lt;/strong&gt; Not stable — the initial heap construction and root-to-end swaps disrupt the order of equal elements.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Cache performance:&lt;/strong&gt; Worse than quicksort. Sift-down jumps to child indices &lt;code&gt;2i&lt;/code&gt; and &lt;code&gt;2i+1&lt;/code&gt;, causing non-sequential memory access patterns that thrash CPU caches. This is why heapsort is ~2–3× slower than quicksort in practice despite the same asymptotic bound.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Why It Matters&lt;/h3&gt;
            &lt;p&gt;Heapsort provides the &lt;em&gt;tightest guarantees&lt;/em&gt; of any comparison sort: O(n log n) worst case, O(1) space, no recursion needed. It is the fallback sort when guarantees matter more than average-case speed. Introsort (used in C++ &lt;code&gt;std::sort&lt;/code&gt;) switches to heapsort precisely when quicksort's recursion depth signals potential O(n&amp;sup2;) behaviour.&lt;/p&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Introsort fallback (C++ std::sort):&lt;/strong&gt; When quicksort's recursion depth exceeds 2 log n, introsort switches to heapsort to guarantee O(n log n). This is the safety net that makes &lt;code&gt;std::sort&lt;/code&gt; both fast and worst-case safe.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Embedded real-time systems:&lt;/strong&gt; Systems with strict worst-case timing requirements (avionics, medical devices) use heapsort because its execution time is deterministic — no pathological inputs can cause a slowdown.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Linux kernel (partial sort):&lt;/strong&gt; The kernel uses heap-based operations for priority scheduling and timer management where the heap structure's O(log n) insert/extract is the primary operation, not full sorting.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Selection of top-k elements:&lt;/strong&gt; Build a min-heap of size k, then scan the remaining n−k elements: replace the root whenever a larger element is found. O(n log k) time, O(k) space. Used in search engine ranking (retrieve the top 10 results from millions of candidates).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Memory-constrained environments:&lt;/strong&gt; When the auxiliary O(n) buffer needed by merge sort is unacceptable (deeply embedded systems, bootloaders), heapsort is the only option that guarantees O(n log n) with O(1) extra memory.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    /* ══════════════════════════════════════════
       NON-COMPARISON SORTS
       ══════════════════════════════════════════ */

    'counting-sort': {
        title: 'Counting Sort',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; Counting sort is a non-comparison sorting algorithm. Instead of comparing pairs of elements, it counts the number of occurrences of each distinct key value, then uses these counts to place each element directly into its sorted position. It requires that keys are integers (or can be mapped to integers) within a known range [0, k).&lt;/p&gt;

            &lt;h3&gt;The Algorithm&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Count:&lt;/strong&gt; Allocate an array &lt;code&gt;count[0..k-1]&lt;/code&gt;, initialised to zero. For each element &lt;code&gt;a[i]&lt;/code&gt;, increment &lt;code&gt;count[a[i]]&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Prefix sums:&lt;/strong&gt; Compute cumulative sums: &lt;code&gt;count[j] += count[j-1]&lt;/code&gt; for &lt;code&gt;j = 1..k-1&lt;/code&gt;. Now &lt;code&gt;count[v]&lt;/code&gt; tells you the index where the last copy of value &lt;code&gt;v&lt;/code&gt; should be placed.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Place:&lt;/strong&gt; Traverse the input in reverse (for stability). For each element &lt;code&gt;a[i]&lt;/code&gt;: decrement &lt;code&gt;count[a[i]]&lt;/code&gt;, and place &lt;code&gt;a[i]&lt;/code&gt; at &lt;code&gt;output[count[a[i]]]&lt;/code&gt;.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Time:&lt;/strong&gt; O(n + k) — one pass to count, one pass for prefix sums, one pass to place. Linear in input size plus key range.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; O(n + k) — output array of size n plus count array of size k.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Stability:&lt;/strong&gt; Stable — the reverse-order placement pass ensures equal keys retain their original order. This stability is what makes counting sort useful as a subroutine in radix sort.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Breaking the Comparison Lower Bound&lt;/h3&gt;
            &lt;p&gt;The O(n log n) lower bound applies only to comparison-based sorts. Counting sort avoids comparisons entirely — it exploits the structure of integer keys. When k = O(n), counting sort runs in O(n), beating the comparison bound. The tradeoff: it only works for discrete keys with a bounded range.&lt;/p&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Radix sort subroutine:&lt;/strong&gt; Radix sort calls counting sort once per digit. This is the most important use — counting sort's stability ensures that sorting by digit &lt;em&gt;d&lt;/em&gt; does not disturb the order established by digit &lt;em&gt;d−1&lt;/em&gt;.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Histogram computation:&lt;/strong&gt; The "count" phase of counting sort is exactly a histogram. Image processing computes pixel intensity histograms (256 bins for 8-bit images) in O(n) as the first step of histogram equalisation, Otsu's thresholding, and colour analysis.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Suffix array construction:&lt;/strong&gt; The SA-IS and DC3 algorithms for building suffix arrays in O(n) use counting sort on character values at each stage. This underlies full-text indexing in bioinformatics and search engines.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Sorting exam scores or ages:&lt;/strong&gt; When keys come from a small, known domain (exam scores 0–100, ages 0–150), counting sort is the natural O(n) solution. Grade distribution reports at universities use exactly this.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Network packet classification:&lt;/strong&gt; Sorting packets by 8-bit Type of Service (ToS) or DSCP fields uses counting sort — 256 or 64 buckets, one O(n) pass. Routers use this for QoS classification at line rate.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'radix-sort': {
        title: 'Radix Sort',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; Radix sort processes integer keys one digit at a time, from the least significant digit (LSD) to the most significant. At each digit position, it uses a stable sort (typically counting sort) to reorder elements by that digit alone. After processing all &lt;em&gt;d&lt;/em&gt; digits, the array is fully sorted.&lt;/p&gt;

            &lt;h3&gt;The Algorithm (LSD Radix Sort)&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;Choose a radix (base) &lt;em&gt;b&lt;/em&gt;. Common choices: b = 10 (decimal digits), b = 256 (bytes), b = 65536 (16-bit chunks).&lt;/li&gt;
                &lt;li&gt;For each digit position &lt;code&gt;d = 0, 1, …, D-1&lt;/code&gt; (from least to most significant):&lt;/li&gt;
                &lt;li&gt;Extract digit &lt;code&gt;d&lt;/code&gt; of each key: &lt;code&gt;digit = (key / b^d) mod b&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;Apply counting sort on the extracted digits. The stability of counting sort preserves the order established by previous (less significant) digits.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Time:&lt;/strong&gt; O(d(n + k)) where d is the number of digit positions and k is the radix (number of possible digit values). For 32-bit integers with radix 256: d = 4, k = 256, giving O(4(n + 256)) = O(n). Linear!&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; O(n + k) — same as counting sort.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Stability:&lt;/strong&gt; Stable — inherits from the stable counting sort subroutine.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;LSD vs. MSD Radix Sort&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;LSD (Least Significant Digit first):&lt;/strong&gt; Process digits right to left. Simpler; always examines all d digits. Works well for fixed-width keys.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;MSD (Most Significant Digit first):&lt;/strong&gt; Process digits left to right, recursively sorting each bucket. Can short-circuit for variable-length keys (e.g. strings). Essentially a trie-based sort. Used in string sorting.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Sorting large integer datasets:&lt;/strong&gt; When sorting millions of 32-bit or 64-bit integers, radix sort (with radix 256, processing 1 byte at a time) outperforms quicksort by 2–5×. It makes 4 or 8 linear passes instead of O(n log n) comparisons with branch mispredictions.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Database integer column sorting:&lt;/strong&gt; Columnar databases (DuckDB, ClickHouse) use radix sort for integer and fixed-width columns because the predictable memory access pattern and linear time dominate comparison sorts at scale.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;GPU sorting (CUB/Thrust):&lt;/strong&gt; NVIDIA's CUB library implements radix sort as the primary GPU sort. Radix sort's regular, data-independent access pattern maps perfectly to GPU parallelism — each digit pass is a massively parallel scatter. It is the fastest known GPU sort.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Suffix array construction:&lt;/strong&gt; The DC3/Skew algorithm builds suffix arrays in O(n) using radix sort to sort triples of characters. This is foundational to bioinformatics (genome alignment) and full-text search indexes.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Network packet sorting by IP address:&lt;/strong&gt; Sorting IPv4 packets by 32-bit source or destination address is a natural fit for radix sort with radix 256 — four passes over the four octets, O(n) total.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    /* ══════════════════════════════════════════
       SEARCH ALGORITHMS
       ══════════════════════════════════════════ */

    'linear-search': {
        title: 'Linear Search',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; Linear search (sequential search) examines each element of a collection one by one, from first to last, until the target is found or the collection is exhausted. It is the simplest possible search algorithm and the only option when the data has no exploitable structure.&lt;/p&gt;

            &lt;h3&gt;The Algorithm&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;For &lt;code&gt;i = 0&lt;/code&gt; to &lt;code&gt;n-1&lt;/code&gt;:&lt;/li&gt;
                &lt;li&gt;If &lt;code&gt;a[i] == target&lt;/code&gt;, return &lt;code&gt;i&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;If the loop completes without a match, return "not found."&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Best case O(1):&lt;/strong&gt; Target is the first element.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Average case O(n):&lt;/strong&gt; On average, examine n/2 elements (assuming the target is equally likely to be at any position, or absent).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Worst case O(n):&lt;/strong&gt; Target is the last element or absent.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; O(1).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Preconditions:&lt;/strong&gt; None. Works on unsorted data, linked lists, streams — anything iterable.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Sentinel Optimisation&lt;/h3&gt;
            &lt;p&gt;Place the target value at the end of the array as a &lt;em&gt;sentinel&lt;/em&gt;. This eliminates the bounds check (&lt;code&gt;i &amp;lt; n&lt;/code&gt;) from the inner loop — the search is guaranteed to terminate at the sentinel. After the loop, check whether the found index is the sentinel position. This halves the number of comparisons per iteration, improving real-world performance by ~30% despite the same asymptotic bound.&lt;/p&gt;

            &lt;h3&gt;Why It Matters&lt;/h3&gt;
            &lt;p&gt;Linear search is the baseline. Every other search algorithm is an optimisation that trades some precondition (sorted order, hash function, tree structure) for sub-linear time. Understanding linear search precisely — its simplicity, its universality, and its limitations — is the foundation for understanding &lt;em&gt;why&lt;/em&gt; we need sorted data or index structures at all.&lt;/p&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Small collections (n &amp;lt; ~64):&lt;/strong&gt; For tiny arrays, linear search is faster than binary search because it avoids the overhead of computing midpoints and has perfect sequential cache access. Standard library &lt;code&gt;find()&lt;/code&gt; implementations use linear search for small containers.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Unsorted / streaming data:&lt;/strong&gt; Searching a network packet stream for a specific pattern, scanning log lines for an error message, or finding a value in an unindexed JSON array — all linear search. You cannot sort a stream.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Linked list traversal:&lt;/strong&gt; Linked lists do not support random access, so binary search is impossible. Linear search is the only option: &lt;code&gt;std::find&lt;/code&gt; on a &lt;code&gt;std::list&lt;/code&gt;, walking a linked hash bucket, or traversing a DOM tree.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;grep / string matching inner loop:&lt;/strong&gt; At the lowest level, &lt;code&gt;grep&lt;/code&gt; scans each line byte by byte (with SIMD acceleration) looking for a pattern match. The outer loop over lines is a linear search for matching lines.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Brute-force nearest neighbour:&lt;/strong&gt; Without a spatial index (k-d tree, ball tree), finding the closest point in a point cloud requires scanning all n points and tracking the minimum distance. This O(n) per query is acceptable for small datasets or as a correctness baseline.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'binary-search': {
        title: 'Binary Search',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; Binary search halves the search space at each step. Given a sorted array and a target value, compare the target to the middle element. If equal, found. If less, recurse on the left half. If greater, recurse on the right half. Each comparison eliminates half the remaining elements.&lt;/p&gt;

            &lt;h3&gt;The Algorithm&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;Maintain two pointers: &lt;code&gt;lo = 0&lt;/code&gt;, &lt;code&gt;hi = n - 1&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;While &lt;code&gt;lo &amp;le; hi&lt;/code&gt;:&lt;/li&gt;
                &lt;li&gt;Compute &lt;code&gt;mid = lo + (hi - lo) / 2&lt;/code&gt; (avoids integer overflow vs. &lt;code&gt;(lo + hi) / 2&lt;/code&gt;).&lt;/li&gt;
                &lt;li&gt;If &lt;code&gt;a[mid] == target&lt;/code&gt;, return &lt;code&gt;mid&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;If &lt;code&gt;a[mid] &amp;lt; target&lt;/code&gt;, set &lt;code&gt;lo = mid + 1&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;If &lt;code&gt;a[mid] &amp;gt; target&lt;/code&gt;, set &lt;code&gt;hi = mid - 1&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;If the loop exits, the target is not present. &lt;code&gt;lo&lt;/code&gt; is the insertion point.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Time:&lt;/strong&gt; O(log n). Each comparison halves the search space: n → n/2 → n/4 → … → 1, taking log&amp;sub2;(n) steps.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; O(1) iterative; O(log n) recursive.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Precondition:&lt;/strong&gt; The array must be sorted (or more generally, the search predicate must be monotonic).&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Variants &amp;amp; Generalisations&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Lower bound (leftmost):&lt;/strong&gt; Find the first index where &lt;code&gt;a[i] &amp;ge; target&lt;/code&gt;. When there are duplicates, this gives the leftmost occurrence. C++ &lt;code&gt;std::lower_bound&lt;/code&gt;, Python &lt;code&gt;bisect.bisect_left&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Upper bound (rightmost):&lt;/strong&gt; Find the first index where &lt;code&gt;a[i] &amp;gt; target&lt;/code&gt;. Together with lower bound, gives the range of equal elements.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Binary search on the answer:&lt;/strong&gt; When the answer space is monotonic (e.g. "can we achieve throughput X?"), binary search over possible answers rather than array indices. A powerful technique in optimisation and competitive programming.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Bisection method (numerical analysis):&lt;/strong&gt; Find a root of a continuous function f(x) by binary searching on the interval where f changes sign. Converges linearly; used as a robust fallback in root-finding libraries.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;The Off-by-One Trap&lt;/h3&gt;
            &lt;p&gt;Binary search is notoriously easy to get wrong. Knuth noted that the first correct published binary search appeared in 1946, but the first bug-free implementation didn't appear until 1962 — 16 years of off-by-one errors. Java's &lt;code&gt;Arrays.binarySearch&lt;/code&gt; had an integer overflow bug (&lt;code&gt;(lo + hi) / 2&lt;/code&gt;) that went undetected for 9 years. Always use &lt;code&gt;lo + (hi - lo) / 2&lt;/code&gt;.&lt;/p&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Database index lookup (B-tree search):&lt;/strong&gt; B-tree nodes are sorted arrays. At each node, binary search finds the correct child pointer. This is the inner loop of every database query that uses an index — billions of binary searches per second globally.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Standard library search functions:&lt;/strong&gt; C's &lt;code&gt;bsearch()&lt;/code&gt;, Python's &lt;code&gt;bisect&lt;/code&gt; module, Java's &lt;code&gt;Arrays.binarySearch&lt;/code&gt;, C++'s &lt;code&gt;std::lower_bound&lt;/code&gt; — all binary search.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Git bisect:&lt;/strong&gt; &lt;code&gt;git bisect&lt;/code&gt; uses binary search over the commit history to find the exact commit that introduced a bug. If there are 1024 commits, it takes at most 10 tests instead of 1024.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;IP routing table lookup:&lt;/strong&gt; Longest-prefix match on sorted prefix tables uses binary search variants. DPDK and kernel routing stacks use this for fast forwarding decisions.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Binary search on the answer (optimisation):&lt;/strong&gt; "What is the minimum cable length such that we can connect k cities?" — binary search over possible lengths, checking feasibility at each candidate. This pattern appears throughout operations research and competitive programming.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Machine learning hyperparameter tuning:&lt;/strong&gt; When a metric is monotonic in a parameter (e.g. regularisation strength), binary search on the parameter finds the optimal value in O(log n) evaluations instead of grid search's O(n).&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'interpolation-search': {
        title: 'Interpolation Search',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; Interpolation search improves on binary search by estimating where the target is likely to be, based on the distribution of values. Instead of always probing the midpoint, it probes at a position proportional to the target's value relative to the current bounds. If the data is uniformly distributed, this converges much faster than binary search.&lt;/p&gt;

            &lt;h3&gt;The Algorithm&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;Maintain bounds &lt;code&gt;lo&lt;/code&gt; and &lt;code&gt;hi&lt;/code&gt; as in binary search.&lt;/li&gt;
                &lt;li&gt;Estimate the probe position using linear interpolation:&lt;/li&gt;
                &lt;li&gt;&lt;code&gt;pos = lo + ((target - a[lo]) / (a[hi] - a[lo])) &amp;times; (hi - lo)&lt;/code&gt;&lt;/li&gt;
                &lt;li&gt;Compare &lt;code&gt;a[pos]&lt;/code&gt; with the target and adjust bounds, exactly as in binary search.&lt;/li&gt;
                &lt;li&gt;Guard against &lt;code&gt;a[hi] == a[lo]&lt;/code&gt; (division by zero) and &lt;code&gt;pos&lt;/code&gt; falling outside &lt;code&gt;[lo, hi]&lt;/code&gt;.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Average case O(log log n):&lt;/strong&gt; On uniformly distributed data, each probe eliminates a &lt;em&gt;multiplicative&lt;/em&gt; fraction of the search space proportional to &lt;code&gt;1/&amp;radic;n&lt;/code&gt;, yielding doubly-logarithmic convergence. This is provably optimal for uniform data.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Worst case O(n):&lt;/strong&gt; If the data is highly non-uniform (e.g. exponentially distributed), the interpolation estimate can be wildly wrong, and the algorithm degenerates to linear search. In the worst case, every probe reduces the search space by only 1.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; O(1).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Precondition:&lt;/strong&gt; The array must be sorted, and the algorithm assumes roughly uniform distribution of values for its speed advantage.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Interpolation vs. Binary Search&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Uniform data:&lt;/strong&gt; Interpolation search makes ~log log n probes vs. binary search's log n. For n = 10&amp;sup6;, that's ~4 probes vs. ~20 — a 5× reduction.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Non-uniform data:&lt;/strong&gt; Binary search is always O(log n) regardless of distribution. Interpolation search has no such guarantee. In practice, a hybrid approach works best: use interpolation for the first few probes, then fall back to binary search.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Cache and branch prediction:&lt;/strong&gt; Binary search's predictable access pattern is friendlier to modern CPUs. Interpolation search's arithmetic (division, multiplication) and less predictable access can offset its theoretical advantage for smaller n.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Large sorted databases with uniform keys:&lt;/strong&gt; Auto-incrementing primary keys (user IDs, order IDs) are naturally uniform. Interpolation search on a sorted array of 100 million IDs finds the target in ~5 probes instead of ~27. Used in high-performance in-memory databases.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Learned indexes (ML for systems):&lt;/strong&gt; Google's "Learned Index" paper (Kraska et al., 2018) generalises interpolation search: train a model to predict the position of a key in a sorted array. A simple linear model is exactly interpolation search; neural models can handle non-uniform distributions. Achieves 1.5–3× speedup over B-trees.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Searching time-series data:&lt;/strong&gt; Timestamps are roughly uniformly spaced. Searching a sorted log file by timestamp (e.g. finding the log entry nearest to 14:30:00) benefits from interpolation: the estimated position is usually very close.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Telephone directory analogy:&lt;/strong&gt; When looking up "Smith" in a phone book, you don't open to the middle — you open near 80% of the way through, because "S" is late in the alphabet. This is interpolation search. Binary search would always open to the middle.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Numerical root-finding (regula falsi):&lt;/strong&gt; The false position method for finding roots of continuous functions uses linear interpolation between two bracketing points — the same principle as interpolation search applied to continuous functions instead of discrete arrays.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'exponential-search': {
        title: 'Exponential Search',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; Exponential search (also called galloping search or doubling search) finds the range containing the target by repeatedly doubling an index — 1, 2, 4, 8, 16, … — until the element at that index exceeds the target. Then it performs binary search within the identified range. It is optimal when the target is near the beginning of a sorted collection or when the collection's size is unknown.&lt;/p&gt;

            &lt;h3&gt;The Algorithm&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;If &lt;code&gt;a[0] == target&lt;/code&gt;, return 0.&lt;/li&gt;
                &lt;li&gt;Set &lt;code&gt;bound = 1&lt;/code&gt;. While &lt;code&gt;bound &amp;lt; n&lt;/code&gt; and &lt;code&gt;a[bound] &amp;lt; target&lt;/code&gt;: double &lt;code&gt;bound&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;Now the target lies in &lt;code&gt;[bound/2, min(bound, n-1)]&lt;/code&gt;.&lt;/li&gt;
                &lt;li&gt;Binary search within this range.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Time:&lt;/strong&gt; O(log i) where i is the index of the target element. The doubling phase takes O(log i) steps to bracket the target, and the binary search within the range of size i also takes O(log i). If the target is at position 8, only ~6 comparisons are needed, regardless of whether the array has 100 or 100 million elements.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Worst case:&lt;/strong&gt; O(log n) when the target is near the end — same as binary search.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; O(1).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Precondition:&lt;/strong&gt; Sorted data. The collection can be unbounded (infinite stream or unknown size).&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Why O(log i) Matters&lt;/h3&gt;
            &lt;p&gt;Binary search always takes O(log n) regardless of where the target is. Exponential search is &lt;em&gt;output-sensitive&lt;/em&gt;: its cost depends on the target's position, not the collection's size. This is an important distinction for:&lt;/p&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Unbounded search:&lt;/strong&gt; You have a sorted stream or function and don't know n. Binary search requires knowing both endpoints; exponential search does not.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Skewed access patterns:&lt;/strong&gt; If most queries target elements near the start, exponential search outperforms binary search on average.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Timsort's galloping mode:&lt;/strong&gt; Python's Timsort (and Java's) uses exponential search ("galloping") during the merge phase. When one run is consistently winning (i.e. its elements are smaller), Timsort gallops through it with doubling steps to find the break point, reducing comparisons from O(n) to O(log n) for merging skewed runs.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Search engine posting list intersection:&lt;/strong&gt; When intersecting two sorted posting lists of vastly different lengths (e.g. "the" with 10M entries vs. "quasar" with 100), gallop through the longer list using exponential search for each element of the shorter list. O(m log(n/m)) total, much better than linear merge for skewed sizes.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Unbounded binary search in algorithms:&lt;/strong&gt; Finding the first index where a monotone predicate becomes true on an unbounded domain (e.g. "the smallest k such that f(k) &gt; threshold") requires exponential search to first find a bound, then binary search. Used in competitive programming and theoretical CS.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Auto-tuning loop unrolling:&lt;/strong&gt; Compilers and runtime systems that need to find the optimal iteration count for a loop (where performance is monotonically increasing then decreasing) use exponential search to bracket the peak before refining.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Finger search on sorted arrays:&lt;/strong&gt; When you know the approximate position of the target from a previous query (a "finger"), exponential search from that position finds the new target in O(log d) where d is the distance from the finger. Skip lists and splay trees offer similar finger search guarantees.&lt;/li&gt;
            &lt;/ul&gt;
        `
    }
};

const modal = document.getElementById('modal');
const modalTitle = document.getElementById('modal-title');
const modalBody = document.getElementById('modal-body');
const closeBtn = document.querySelector('.close');

document.querySelectorAll('.ds-card').forEach(card =&gt; {
    card.addEventListener('click', function () {
        const key = this.getAttribute('data-info');
        const info = explanations[key];
        if (info) {
            modalTitle.textContent = info.title;
            modalBody.innerHTML = info.content;
            modal.style.display = 'block';
            document.body.style.overflow = 'hidden';
        }
    });
});

closeBtn.addEventListener('click', () =&gt; {
    modal.style.display = 'none';
    document.body.style.overflow = '';
});
window.addEventListener('click', e =&gt; {
    if (e.target === modal) {
        modal.style.display = 'none';
        document.body.style.overflow = '';
    }
});
document.addEventListener('keydown', e =&gt; {
    if (e.key === 'Escape' &amp;&amp; modal.style.display === 'block') {
        modal.style.display = 'none';
        document.body.style.overflow = '';
    }
});
&lt;/script&gt;
</code></pre>
</body>

</style></head></html><div style="break-before: page; page-break-before: always;"></div>
<h1 id="data-structures"><a href="#data-structures" class="header">Data Structures</a></h1>

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fundamental Data Structures</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
<pre><code>    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background: linear-gradient(135deg, #1a3a6b 0%, #2563a8 100%);
        padding: 40px 20px;
        min-height: 100vh;
    }

    .container {
        max-width: 1200px;
        margin: 0 auto;
        background: white;
        border-radius: 20px;
        padding: 40px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
    }

    h1 {
        text-align: center;
        color: #2d3748;
        margin-bottom: 10px;
        font-size: 2.5em;
    }

    .subtitle {
        text-align: center;
        color: #718096;
        margin-bottom: 50px;
        font-size: 1.1em;
    }

    /* Section heading */
    .section-heading {
        font-size: 0.75em;
        font-weight: 700;
        text-transform: uppercase;
        letter-spacing: 0.12em;
        color: #a0aec0;
        margin: 40px 0 16px 0;
        padding-bottom: 8px;
        border-bottom: 1px solid #e2e8f0;
    }
    .section-heading:first-of-type {
        margin-top: 0;
    }

    /* DS card grid */
    .ds-grid {
        display: grid;
        grid-template-columns: repeat(auto-fill, minmax(260px, 1fr));
        gap: 18px;
        margin-bottom: 8px;
    }

    .ds-card {
        border-radius: 14px;
        padding: 22px 20px 18px;
        cursor: pointer;
        transition: transform 0.22s ease, box-shadow 0.22s ease;
        position: relative;
        overflow: hidden;
    }

    .ds-card:hover {
        transform: translateY(-4px);
    }

    /* Complexity badge in top-right */
    .complexity-badge {
        position: absolute;
        top: 14px;
        right: 14px;
        font-size: 0.68em;
        font-weight: 700;
        padding: 3px 9px;
        border-radius: 20px;
        letter-spacing: 0.03em;
        background: rgba(255,255,255,0.25);
        color: rgba(255,255,255,0.95);
    }

    .ds-card-icon {
        font-size: 1.9em;
        margin-bottom: 10px;
        line-height: 1;
    }

    .ds-card-name {
        font-size: 1.15em;
        font-weight: 700;
        color: white;
        margin-bottom: 6px;
    }

    .ds-card-tagline {
        font-size: 0.82em;
        color: rgba(255,255,255,0.85);
        line-height: 1.45;
        margin-bottom: 12px;
    }

    .ds-card-ops {
        display: flex;
        flex-wrap: wrap;
        gap: 5px;
    }

    .op-tag {
        font-size: 0.68em;
        font-weight: 700;
        padding: 2px 8px;
        border-radius: 20px;
        background: rgba(255,255,255,0.22);
        color: rgba(255,255,255,0.95);
        letter-spacing: 0.02em;
    }

    /* Card colour themes */
    .card-array    { background: linear-gradient(135deg, #2b6cb0, #3182ce); box-shadow: 0 4px 18px rgba(49,130,206,0.35); }
    .card-array:hover { box-shadow: 0 8px 28px rgba(49,130,206,0.5); }

    .card-linked   { background: linear-gradient(135deg, #276749, #38a169); box-shadow: 0 4px 18px rgba(56,161,105,0.35); }
    .card-linked:hover { box-shadow: 0 8px 28px rgba(56,161,105,0.5); }

    .card-stack    { background: linear-gradient(135deg, #6b21a8, #9333ea); box-shadow: 0 4px 18px rgba(147,51,234,0.35); }
    .card-stack:hover { box-shadow: 0 8px 28px rgba(147,51,234,0.5); }

    .card-queue    { background: linear-gradient(135deg, #9a3412, #ea580c); box-shadow: 0 4px 18px rgba(234,88,12,0.35); }
    .card-queue:hover { box-shadow: 0 8px 28px rgba(234,88,12,0.5); }

    .card-bst      { background: linear-gradient(135deg, #065f46, #059669); box-shadow: 0 4px 18px rgba(5,150,105,0.35); }
    .card-bst:hover { box-shadow: 0 8px 28px rgba(5,150,105,0.5); }

    .card-heap     { background: linear-gradient(135deg, #92400e, #d97706); box-shadow: 0 4px 18px rgba(217,119,6,0.35); }
    .card-heap:hover { box-shadow: 0 8px 28px rgba(217,119,6,0.5); }

    .card-trie     { background: linear-gradient(135deg, #0369a1, #0284c7); box-shadow: 0 4px 18px rgba(2,132,199,0.35); }
    .card-trie:hover { box-shadow: 0 8px 28px rgba(2,132,199,0.5); }

    .card-avl      { background: linear-gradient(135deg, #1d4ed8, #2563eb); box-shadow: 0 4px 18px rgba(37,99,235,0.35); }
    .card-avl:hover { box-shadow: 0 8px 28px rgba(37,99,235,0.5); }

    .card-hash     { background: linear-gradient(135deg, #881337, #e11d48); box-shadow: 0 4px 18px rgba(225,29,72,0.35); }
    .card-hash:hover { box-shadow: 0 8px 28px rgba(225,29,72,0.5); }

    .card-graph    { background: linear-gradient(135deg, #4a5568, #718096); box-shadow: 0 4px 18px rgba(113,128,150,0.35); }
    .card-graph:hover { box-shadow: 0 8px 28px rgba(113,128,150,0.5); }

    .card-disjoint { background: linear-gradient(135deg, #7e22ce, #a855f7); box-shadow: 0 4px 18px rgba(168,85,247,0.35); }
    .card-disjoint:hover { box-shadow: 0 8px 28px rgba(168,85,247,0.5); }

    .card-bloom    { background: linear-gradient(135deg, #0f766e, #14b8a6); box-shadow: 0 4px 18px rgba(20,184,166,0.35); }
    .card-bloom:hover { box-shadow: 0 8px 28px rgba(20,184,166,0.5); }

    .card-skiplist { background: linear-gradient(135deg, #c2410c, #f97316); box-shadow: 0 4px 18px rgba(249,115,22,0.35); }
    .card-skiplist:hover { box-shadow: 0 8px 28px rgba(249,115,22,0.5); }

    /* Summary bar */
    .summary-bar {
        background: #edf2f7;
        padding: 16px 20px;
        border-radius: 10px;
        text-align: center;
        margin-top: 36px;
        color: #2d3748;
        font-weight: 600;
        font-size: 0.95em;
        line-height: 1.6;
    }

    /* Modal */
    .modal {
        display: none;
        position: fixed;
        z-index: 1000;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(0, 0, 0, 0.6);
        animation: fadeIn 0.25s;
    }

    @keyframes fadeIn {
        from { opacity: 0; }
        to   { opacity: 1; }
    }

    .modal-content {
        background-color: white;
        margin: 6% auto;
        padding: 40px;
        border-radius: 16px;
        width: 84%;
        max-width: 720px;
        max-height: 85vh;
        overflow-y: auto;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        position: relative;
        animation: slideIn 0.25s;
    }

    @keyframes slideIn {
        from { transform: translateY(-36px); opacity: 0; }
        to   { transform: translateY(0);     opacity: 1; }
    }

    .close {
        color: #a0aec0;
        position: absolute;
        right: 20px;
        top: 18px;
        font-size: 34px;
        font-weight: bold;
        cursor: pointer;
        transition: color 0.2s;
        line-height: 1;
    }

    .close:hover { color: #2d3748; }

    .modal-title {
        color: #1e56b0;
        font-size: 1.6em;
        margin-bottom: 18px;
        padding-bottom: 14px;
        border-bottom: 3px solid #2563a8;
        padding-right: 40px;
        line-height: 1.3;
    }

    .modal-body {
        color: #2d3748;
        line-height: 1.82;
        font-size: 1.01em;
    }

    .modal-body p   { margin-bottom: 14px; }
    .modal-body strong { color: #1e56b0; }
    .modal-body ul  { margin: 0 0 14px 22px; }
    .modal-body li  { margin-bottom: 5px; }
    .modal-body code {
        background: #edf2f7;
        border-radius: 4px;
        padding: 1px 5px;
        font-family: 'Cascadia Code', 'Fira Code', Consolas, monospace;
        font-size: 0.91em;
        color: #2d3748;
    }
    .modal-body h3 {
        color: #2d3748;
        font-size: 1.05em;
        margin: 18px 0 6px;
    }

    /* Responsive */
    @media screen and (max-width: 700px) {
        body { padding: 20px 10px; }
        .container { padding: 22px 14px; border-radius: 12px; }
        h1 { font-size: 1.6em; }
        .ds-grid { grid-template-columns: 1fr; }
        .modal-content { margin: 4% auto; padding: 24px 18px; width: 96%; max-width: 96%; max-height: 90vh; }
        .modal-title { font-size: 1.25em; }
    }

    @media (hover: none) and (pointer: coarse) {
        .ds-card:active { transform: scale(0.97); }
    }
&lt;/style&gt;
</code></pre>

<body>
    
<div id="modal-3" class="modal">
        
<div class="modal-content">
            <span class="close">×</span>
            
<h2 class="modal-title" id="modal-title-3"></h2>

            
<div class="modal-body" id="modal-body-3"></div>

        </div>

    </div>

<pre><code>&lt;div class="container"&gt;
    &lt;h1&gt;Fundamental Data Structures&lt;/h1&gt;
    &lt;p class="subtitle"&gt;Core abstractions of computer science — algorithms, motivations, and real-world applications, ordered by increasing complexity&lt;/p&gt;

    &lt;!-- ── SECTION 1: LINEAR ── --&gt;
    &lt;div class="section-heading"&gt;Linear Structures&lt;/div&gt;
    &lt;div class="ds-grid"&gt;

        &lt;div class="ds-card card-array" data-info="array"&gt;
            &lt;div class="complexity-badge"&gt;O(1) access&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;▦&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Array&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Contiguous block of elements addressable by index. The foundation of nearly all other structures.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Access O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Search O(n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Insert O(n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Delete O(n)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-linked" data-info="linked-list"&gt;
            &lt;div class="complexity-badge"&gt;O(1) insert&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;⬡&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Linked List&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Nodes connected by pointers. Constant-time insertion/deletion at known positions without shifting.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Access O(n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Search O(n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Insert O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Delete O(1)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-stack" data-info="stack"&gt;
            &lt;div class="complexity-badge"&gt;LIFO&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;⬆&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Stack&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Last-in, first-out discipline. Push and pop from one end only. Models function call frames and undo history.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Push O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Pop O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Peek O(1)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-queue" data-info="queue"&gt;
            &lt;div class="complexity-badge"&gt;FIFO&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;⇒&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Queue&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;First-in, first-out discipline. Enqueue at the back, dequeue from the front. Natural model for waiting lines and BFS.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Enqueue O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Dequeue O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Peek O(1)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

    &lt;/div&gt;

    &lt;!-- ── SECTION 2: TREES ── --&gt;
    &lt;div class="section-heading"&gt;Tree Structures&lt;/div&gt;
    &lt;div class="ds-grid"&gt;

        &lt;div class="ds-card card-bst" data-info="bst"&gt;
            &lt;div class="complexity-badge"&gt;O(log n) avg&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;🌲&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Binary Search Tree&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Ordered binary tree where left &amp;lt; parent &amp;lt; right. Fast search, insert, and delete on average-case data.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Search O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Insert O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Delete O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Worst O(n)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-avl" data-info="avl"&gt;
            &lt;div class="complexity-badge"&gt;O(log n) worst&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;⚖&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Balanced BST (AVL / Red-Black)&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Self-balancing trees that guarantee O(log n) in the worst case by maintaining height invariants via rotations.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Search O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Insert O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Delete O(log n)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-heap" data-info="heap"&gt;
            &lt;div class="complexity-badge"&gt;O(log n) push/pop&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;△&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Heap (Priority Queue)&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Complete binary tree satisfying the heap property. O(1) access to the min or max element; O(log n) insertion.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Peek O(1)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Push O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Pop O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Build O(n)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-trie" data-info="trie"&gt;
            &lt;div class="complexity-badge"&gt;O(k) per op&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;✦&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Trie (Prefix Tree)&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Tree where each edge is a character. Lookup time is proportional to key length, not corpus size. Ideal for autocomplete.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Insert O(k)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Search O(k)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Prefix O(k)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

    &lt;/div&gt;

    &lt;!-- ── SECTION 3: HASH &amp; GRAPHS ── --&gt;
    &lt;div class="section-heading"&gt;Hash Tables &amp;amp; Graphs&lt;/div&gt;
    &lt;div class="ds-grid"&gt;

        &lt;div class="ds-card card-hash" data-info="hash-table"&gt;
            &lt;div class="complexity-badge"&gt;O(1) avg&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;#&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Hash Table&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Maps keys to array indices via a hash function. Expected O(1) insert, lookup, and delete — the workhorse of fast lookup.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Insert O(1) avg&lt;/span&gt;
                &lt;span class="op-tag"&gt;Lookup O(1) avg&lt;/span&gt;
                &lt;span class="op-tag"&gt;Delete O(1) avg&lt;/span&gt;
                &lt;span class="op-tag"&gt;Worst O(n)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-graph" data-info="graph"&gt;
            &lt;div class="complexity-badge"&gt;V + E&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;◎&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Graph&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Vertices connected by edges. Directed or undirected, weighted or unweighted. Models relationships, networks, and dependencies.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;BFS O(V+E)&lt;/span&gt;
                &lt;span class="op-tag"&gt;DFS O(V+E)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Dijkstra O((V+E)log V)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

    &lt;/div&gt;

    &lt;!-- ── SECTION 4: ADVANCED ── --&gt;
    &lt;div class="section-heading"&gt;Advanced &amp;amp; Probabilistic Structures&lt;/div&gt;
    &lt;div class="ds-grid"&gt;

        &lt;div class="ds-card card-disjoint" data-info="disjoint-set"&gt;
            &lt;div class="complexity-badge"&gt;≈ O(α(n))&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;∪&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Disjoint Set (Union-Find)&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Tracks a partition of elements into disjoint groups. Near-constant amortised time with union-by-rank and path compression.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Find O(α(n))&lt;/span&gt;
                &lt;span class="op-tag"&gt;Union O(α(n))&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-bloom" data-info="bloom-filter"&gt;
            &lt;div class="complexity-badge"&gt;O(k) · no FN&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;~&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Bloom Filter&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Probabilistic set membership test. Space-efficient: no false negatives; small, tunable false-positive rate.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Insert O(k)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Query O(k)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Space O(m bits)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class="ds-card card-skiplist" data-info="skip-list"&gt;
            &lt;div class="complexity-badge"&gt;O(log n) expected&lt;/div&gt;
            &lt;div class="ds-card-icon"&gt;≡&lt;/div&gt;
            &lt;div class="ds-card-name"&gt;Skip List&lt;/div&gt;
            &lt;div class="ds-card-tagline"&gt;Randomised multi-level linked list. Provides sorted access with O(log n) expected operations — no rotations needed.&lt;/div&gt;
            &lt;div class="ds-card-ops"&gt;
                &lt;span class="op-tag"&gt;Search O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Insert O(log n)&lt;/span&gt;
                &lt;span class="op-tag"&gt;Delete O(log n)&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;

    &lt;/div&gt;

    &lt;div class="summary-bar"&gt;
        Click any card to explore the full algorithm, motivation, and real-world application examples.
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
const explanations = {

    /* ══════════════════════════════════════════
       LINEAR STRUCTURES
       ══════════════════════════════════════════ */

    'array': {
        title: 'Array',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; An array is a contiguous block of memory that stores elements of the same type, each addressable by an integer index in O(1) time. It is the most primitive aggregate data structure and underpins virtually all others.&lt;/p&gt;

            &lt;h3&gt;Core Operations &amp;amp; Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Random access&lt;/strong&gt; — &lt;code&gt;a[i]&lt;/code&gt; in O(1): the address of element &lt;em&gt;i&lt;/em&gt; is simply &lt;code&gt;base + i × element_size&lt;/code&gt;, a single multiply-and-add.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Search (unsorted)&lt;/strong&gt; — O(n) linear scan; O(log n) with binary search on a sorted array.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Insert/Delete at arbitrary index&lt;/strong&gt; — O(n) because all subsequent elements must be shifted.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Append to end (dynamic array)&lt;/strong&gt; — O(1) amortised: a dynamic array (e.g. Python list, C++ vector) doubles capacity when full, so the average cost per push is constant despite occasional O(n) resizes.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Key Algorithms&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Binary Search:&lt;/strong&gt; On a sorted array, repeatedly halve the search space. Compare the middle element; go left if target is smaller, right if larger. T = O(log n).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Prefix Sums:&lt;/strong&gt; Precompute &lt;code&gt;P[i] = a[0] + … + a[i]&lt;/code&gt; in O(n). Then any range sum &lt;code&gt;a[l..r] = P[r] − P[l−1]&lt;/code&gt; is O(1) — used heavily in competitive programming and signal processing.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Two-Pointer / Sliding Window:&lt;/strong&gt; Maintain two indices into the array to find subarrays satisfying a property in O(n) instead of O(n²).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Kadane's Algorithm:&lt;/strong&gt; Maximum subarray sum in O(n): track the best sum ending at each position.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Motivation&lt;/h3&gt;
            &lt;p&gt;Arrays are optimal when you know the size up front, need fast indexed access, and want excellent cache locality — elements sit adjacent in memory, so sequential access benefits from hardware prefetching. No other structure matches O(1) random read.&lt;/p&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Image buffers:&lt;/strong&gt; A bitmap image is a 2D array of pixel values (RGB triplets). GPU memory, OpenCV &lt;code&gt;Mat&lt;/code&gt;, and NumPy arrays all exploit contiguous layout for SIMD vectorisation.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Sensor time-series:&lt;/strong&gt; An IMU at 1 kHz produces a flat array of float64 samples; FFT, convolution, and filters rely on random-access arithmetic.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Database column stores:&lt;/strong&gt; Columnar databases (DuckDB, Apache Parquet) store each column as a contiguous array, enabling vectorised SIMD aggregations over millions of rows.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Ring/Circular buffers:&lt;/strong&gt; Embedded systems use fixed-length arrays with head/tail indices modulo capacity to implement lock-free FIFO queues between ISR and main loop.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Hash table backing store:&lt;/strong&gt; Every hash table implementation uses an underlying array of buckets.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'linked-list': {
        title: 'Linked List',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A linked list is a sequence of nodes, each holding a value and a pointer (reference) to the next node. A doubly-linked list adds a pointer to the previous node. There is no contiguous memory requirement.&lt;/p&gt;

            &lt;h3&gt;Core Operations &amp;amp; Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Access by index&lt;/strong&gt; — O(n): must traverse from the head.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Insert/Delete at a known pointer&lt;/strong&gt; — O(1): just rewire two or three pointers. No shifting.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Search&lt;/strong&gt; — O(n) linear scan.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Prepend to head&lt;/strong&gt; — O(1), the canonical fast operation.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Key Algorithms&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Floyd's Cycle Detection (Tortoise &amp;amp; Hare):&lt;/strong&gt; Two pointers advance at different speeds; if they meet, a cycle exists. Detects and locates cycles in O(n) time, O(1) space.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Reversal:&lt;/strong&gt; Iterate once, pointing each node's &lt;code&gt;next&lt;/code&gt; to its predecessor. O(n), O(1) space.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Merge Sort on a Linked List:&lt;/strong&gt; Find the midpoint with slow/fast pointers, recursively sort each half, merge. O(n log n) with O(log n) stack depth — preferred over arrays here since there's no copying cost for splitting.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;XOR Linked List:&lt;/strong&gt; Store &lt;code&gt;prev XOR next&lt;/code&gt; in each node to halve the pointer storage. A curiosity demonstrating the value of bit tricks.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Motivation&lt;/h3&gt;
            &lt;p&gt;Linked lists shine when the number of elements is unpredictable, frequent mid-sequence insertions/deletions are needed at already-known positions, and random access is rare. They avoid the O(n) shift cost of arrays and never need to over-allocate like dynamic arrays.&lt;/p&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;OS kernel memory allocator (free lists):&lt;/strong&gt; The Linux kernel's slab allocator links free memory blocks with embedded &lt;code&gt;list_head&lt;/code&gt; structs — no extra allocation needed for the list node itself.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;LRU Cache:&lt;/strong&gt; A doubly-linked list + hash map implements O(1) eviction of the least-recently-used item. Used by CPU caches, database buffer pools, and web caches like Varnish.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Undo/Redo history:&lt;/strong&gt; A doubly-linked list of state snapshots allows O(1) stepping forward and backward.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Adjacency lists for graphs:&lt;/strong&gt; Each vertex stores a linked list of its neighbours — efficient for sparse graphs where adjacency matrices would waste O(V²) space.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Chained hash table buckets:&lt;/strong&gt; Hash collisions are handled by prepending to a linked list at the collision bucket.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'stack': {
        title: 'Stack',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A stack is an abstract data type that enforces a Last-In, First-Out (LIFO) access discipline. Only the top element is accessible. Implemented either over a dynamic array or a linked list.&lt;/p&gt;

            &lt;h3&gt;Core Operations &amp;amp; Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Push&lt;/strong&gt; — O(1): add element to the top.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Pop&lt;/strong&gt; — O(1): remove and return the top element.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Peek/Top&lt;/strong&gt; — O(1): read the top without removing.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;isEmpty&lt;/strong&gt; — O(1).&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Key Algorithms&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Balanced Parentheses:&lt;/strong&gt; Push each opening bracket; on a closing bracket, pop and check for a match. O(n). Used by every compiler and linter.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Infix → Postfix (Shunting-Yard):&lt;/strong&gt; Dijkstra's algorithm converts &lt;code&gt;3 + 4 × 2&lt;/code&gt; to &lt;code&gt;3 4 2 × +&lt;/code&gt; using an operator stack, respecting precedence and associativity. Parsers use this to build ASTs.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Monotonic Stack:&lt;/strong&gt; Maintain a stack where elements are monotonically increasing or decreasing. Solves "next greater element", stock span, and largest rectangle in histogram in O(n).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Iterative DFS:&lt;/strong&gt; Replace recursion with an explicit stack to traverse trees/graphs without call-stack overflow on deep inputs.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Backtracking:&lt;/strong&gt; Push choices onto the stack; pop to undo when a path fails (maze solving, Sudoku, N-Queens).&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Motivation&lt;/h3&gt;
            &lt;p&gt;The LIFO invariant captures the fundamental structure of nested scopes and recursive subproblems. Whenever a problem requires "remember where I came from and undo in reverse order," a stack is the natural tool.&lt;/p&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;CPU call stack:&lt;/strong&gt; Every function call pushes a stack frame (return address, local variables, saved registers). Return pops it. Stack overflow = exhausting this memory region.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Expression evaluation:&lt;/strong&gt; Spreadsheet formula engines, calculators, and shader compilers evaluate RPN expressions with an operand stack.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Browser history / forward-back navigation:&lt;/strong&gt; Two stacks — one for back history, one for forward — implement O(1) navigation. (Though modern browsers optimise further.)&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Undo in editors:&lt;/strong&gt; VS Code, Vim, Photoshop push operations onto a stack; Ctrl+Z pops and inverts them.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Robotics path planning (backtracking search):&lt;/strong&gt; A robot exploring an unknown maze pushes candidate moves and pops to backtrack when a dead end is reached.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'queue': {
        title: 'Queue',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A queue is an abstract data type enforcing First-In, First-Out (FIFO) order. Elements enqueue at the rear and dequeue from the front. Implemented over a ring buffer (circular array) for O(1) amortised ops, or a doubly-linked list for strict O(1).&lt;/p&gt;

            &lt;h3&gt;Core Operations &amp;amp; Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Enqueue&lt;/strong&gt; — O(1): append to the rear.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Dequeue&lt;/strong&gt; — O(1): remove from the front.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Peek/Front&lt;/strong&gt; — O(1): read the front element.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;isEmpty&lt;/strong&gt; — O(1).&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Variants&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Deque (double-ended queue):&lt;/strong&gt; O(1) insert/remove at both ends. Python's &lt;code&gt;collections.deque&lt;/code&gt;. Useful for sliding window problems.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Priority Queue:&lt;/strong&gt; Dequeue returns the minimum (or maximum) element, not FIFO. Implemented with a heap (see Heap card). Used for Dijkstra's shortest path.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Circular Buffer:&lt;/strong&gt; Fixed-size queue with head/tail indices mod capacity. Lock-free variants used in real-time systems.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Key Algorithms&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Breadth-First Search (BFS):&lt;/strong&gt; Enqueue the root; while the queue is non-empty, dequeue a node, process it, enqueue its unvisited neighbours. Guarantees shortest path in unweighted graphs.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Level-order Tree Traversal:&lt;/strong&gt; BFS on a tree visits nodes level by level — used to serialise/deserialise binary trees.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Sliding Window Maximum (Monotonic Deque):&lt;/strong&gt; Maintain a deque of candidate maximum indices; pop from the back when a larger element arrives, pop from the front when out of the window. O(n) for all windows.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Topological Sort (Kahn's algorithm):&lt;/strong&gt; Enqueue all nodes with in-degree zero; process and reduce in-degrees, enqueueing new zero-degree nodes. Detects cycles.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;OS task/process scheduler:&lt;/strong&gt; The Linux Completely Fair Scheduler maintains run queues of ready tasks per CPU core. Round-robin time slices are managed with a queue.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Network packet buffers:&lt;/strong&gt; A router's output queue holds packets waiting to be forwarded. Active Queue Management (AQM) algorithms (CoDel, FQ-CoDel) keep latency low by actively dropping from the queue tail.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Message brokers (Kafka, RabbitMQ):&lt;/strong&gt; Producers enqueue messages; consumers dequeue in order. Kafka persists queues to disk for durability and replay.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Print spoolers &amp;amp; job queues:&lt;/strong&gt; Print jobs enqueue in FIFO order. GPU compute job queues (CUDA streams) work the same way.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;BFS robot navigation:&lt;/strong&gt; A robot computing shortest path on a grid with BFS expands wave-fronts using a queue, visiting cells in order of increasing distance from the start.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    /* ══════════════════════════════════════════
       TREE STRUCTURES
       ══════════════════════════════════════════ */

    'bst': {
        title: 'Binary Search Tree (BST)',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A binary tree where every node satisfies: all values in its left subtree are strictly less than the node's value, and all values in its right subtree are strictly greater. This ordering invariant enables efficient search.&lt;/p&gt;

            &lt;h3&gt;Core Operations &amp;amp; Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Search, Insert, Delete&lt;/strong&gt; — O(h) where &lt;em&gt;h&lt;/em&gt; is the tree height. Average case (random data): O(log n). Worst case (sorted insertions): O(n) — a degenerate chain.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;In-order traversal&lt;/strong&gt; — O(n): visits nodes in sorted ascending order. "Free" sorted output.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Min/Max&lt;/strong&gt; — O(h): traverse leftmost/rightmost path.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Successor/Predecessor&lt;/strong&gt; — O(h): used to implement range queries.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Key Algorithms&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Search:&lt;/strong&gt; Compare target with current node; recurse left if smaller, right if larger; return when found or null.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Insert:&lt;/strong&gt; Search for the position where the key would be; attach a new leaf node there.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Delete:&lt;/strong&gt; Three cases — leaf (just remove), one child (splice out), two children (replace with in-order successor, then delete the successor).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Range Query:&lt;/strong&gt; In-order traversal with early termination collects all keys in [lo, hi] in O(h + k) where k is the number of results.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Motivation&lt;/h3&gt;
            &lt;p&gt;BSTs combine the fast insertion of a linked structure with the ordered lookup of sorted arrays. The BST invariant gives a binary decision at every node, halving the search space (when balanced). They are the foundation for self-balancing trees and database index structures like B-trees.&lt;/p&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Sorted sets and maps in standard libraries:&lt;/strong&gt; C++ &lt;code&gt;std::map&lt;/code&gt; / &lt;code&gt;std::set&lt;/code&gt; and Java's &lt;code&gt;TreeMap&lt;/code&gt; / &lt;code&gt;TreeSet&lt;/code&gt; use red-black trees (balanced BSTs) internally, providing O(log n) ordered operations.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Database indexes (B-trees):&lt;/strong&gt; B-trees — a generalisation of BSTs where each node can have many children — are the universal index structure in relational databases (PostgreSQL, MySQL). They allow efficient range scans on disk.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Symbol tables in compilers:&lt;/strong&gt; An ordered symbol table backed by a BST enables fast lookup of identifiers while preserving lexicographic order for efficient scoping.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Event-driven simulation (event queue):&lt;/strong&gt; Events sorted by timestamp are stored in a BST (or heap) for O(log n) next-event extraction.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;File system directory trees:&lt;/strong&gt; Some file systems (ext4's HTree, NTFS) use B-tree variants for directory entries to support fast name lookup in large directories.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'avl': {
        title: 'Balanced BST — AVL Tree &amp; Red-Black Tree',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A self-balancing binary search tree that maintains a height invariant ensuring O(log n) worst-case operations by performing &lt;em&gt;rotations&lt;/em&gt; after insertions and deletions.&lt;/p&gt;

            &lt;h3&gt;AVL Tree&lt;/h3&gt;
            &lt;p&gt;An &lt;strong&gt;AVL tree&lt;/strong&gt; (Adelson-Velsky and Landis, 1962) stores a &lt;em&gt;balance factor&lt;/em&gt; at each node: &lt;code&gt;height(left) − height(right) ∈ {−1, 0, +1}&lt;/code&gt;. If an insertion violates this, one of four rotation cases restores balance:&lt;/p&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Right rotation&lt;/strong&gt; (LL case)&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Left rotation&lt;/strong&gt; (RR case)&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Left-Right rotation&lt;/strong&gt; (LR case)&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Right-Left rotation&lt;/strong&gt; (RL case)&lt;/li&gt;
            &lt;/ul&gt;
            &lt;p&gt;AVL trees are height-optimal: height ≤ 1.44 log₂(n). They are slightly more rigidly balanced than red-black trees, making lookups marginally faster, but insertions slightly slower (more rotations).&lt;/p&gt;

            &lt;h3&gt;Red-Black Tree&lt;/h3&gt;
            &lt;p&gt;A &lt;strong&gt;red-black tree&lt;/strong&gt; colours each node red or black and enforces five invariants (e.g. no two consecutive red nodes; all root-to-leaf paths have the same number of black nodes). This guarantees height ≤ 2 log₂(n+1). Fewer rotations than AVL on insert/delete, making it preferred in practice.&lt;/p&gt;

            &lt;h3&gt;Key Algorithms&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Rotation:&lt;/strong&gt; A local restructuring of three nodes that preserves the BST invariant but changes the height. O(1) pointer rewiring.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Rebalance after insert/delete:&lt;/strong&gt; Walk back up the tree from the modified leaf, checking and fixing balance. At most O(log n) rotations (AVL insert: ≤ 2; AVL delete: O(log n); RB tree: ≤ 3 rotations ever).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Order statistics:&lt;/strong&gt; Augment each node with subtree size → O(log n) rank(x) and select(k) queries. Linux's CFS scheduler uses this for fair scheduling.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;C++ STL &lt;code&gt;std::map&lt;/code&gt; / &lt;code&gt;std::set&lt;/code&gt;:&lt;/strong&gt; Every conforming C++ standard library implementation (libstdc++, libc++) uses a red-black tree, giving O(log n) insertion and iteration in sorted order.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Java &lt;code&gt;TreeMap&lt;/code&gt; / &lt;code&gt;TreeSet&lt;/code&gt;:&lt;/strong&gt; Same guarantee; Java's implementation is also a red-black tree.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Linux kernel CFS scheduler:&lt;/strong&gt; The Completely Fair Scheduler organises runnable tasks in a red-black tree keyed by virtual runtime. The leftmost node (minimum vruntime) is always the next task to run — O(log n) insert/delete, O(1) find-min.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Interval trees &amp;amp; segment trees (augmented RB):&lt;/strong&gt; Computational geometry libraries augment red-black trees to answer "which intervals overlap point x?" in O(log n + k).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Database query optimiser:&lt;/strong&gt; PostgreSQL uses red-black trees internally for in-memory work tables and plan-cache structures.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'heap': {
        title: 'Heap (Binary Heap / Priority Queue)',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A &lt;em&gt;complete&lt;/em&gt; binary tree stored as a flat array where the heap property holds: in a min-heap, every node's value is ≤ its children's values; in a max-heap, ≥. This guarantees O(1) access to the minimum (or maximum) element at the root.&lt;/p&gt;

            &lt;h3&gt;Array Representation&lt;/h3&gt;
            &lt;p&gt;For a node at index &lt;code&gt;i&lt;/code&gt; (1-indexed): left child = &lt;code&gt;2i&lt;/code&gt;, right child = &lt;code&gt;2i+1&lt;/code&gt;, parent = &lt;code&gt;⌊i/2⌋&lt;/code&gt;. No pointers needed — perfect cache locality.&lt;/p&gt;

            &lt;h3&gt;Core Operations &amp;amp; Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Peek (min/max)&lt;/strong&gt; — O(1): read index 1.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Push/Insert&lt;/strong&gt; — O(log n): append to the end and &lt;em&gt;sift up&lt;/em&gt; (swap with parent while heap property violated).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Pop (extract-min/max)&lt;/strong&gt; — O(log n): swap root with the last element, remove last, &lt;em&gt;sift down&lt;/em&gt; (swap with the smaller child while violated).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Build heap from array (heapify)&lt;/strong&gt; — O(n): surprisingly, calling sift-down from n/2 down to 1 is O(n), not O(n log n).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Decrease-key&lt;/strong&gt; — O(log n): used in Dijkstra's and Prim's. Requires a handle/index. Fibonacci heaps offer O(1) amortised decrease-key.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Key Algorithms&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Heap Sort:&lt;/strong&gt; Build a max-heap (O(n)), then repeatedly extract-max and place at the end. O(n log n) in-place, O(1) extra space. Not stable, but optimal worst-case.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Dijkstra's Algorithm:&lt;/strong&gt; Min-heap of (distance, vertex) pairs. Pop the closest unvisited vertex; relax edges; push updated neighbours. O((V + E) log V).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Prim's MST:&lt;/strong&gt; Same structure as Dijkstra but using edge weight to the growing MST as the key. O((V + E) log V).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Merge k sorted lists:&lt;/strong&gt; Push the head of each list into a min-heap; pop the smallest, push its successor. O(n log k).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;k-th Largest Element:&lt;/strong&gt; Maintain a min-heap of size k; replace the root whenever a larger element arrives. O(n log k).&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Operating system process scheduling:&lt;/strong&gt; Priority queues determine which process or interrupt handler runs next. Linux's timer wheel uses heap-like structures for time-ordered event delivery.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Network routing (Dijkstra / A*):&lt;/strong&gt; Every GPS navigation app and OSPF routing protocol computes shortest paths with a priority queue over the graph of road segments or network links.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Compression (Huffman coding):&lt;/strong&gt; Build a Huffman tree by repeatedly merging the two lowest-frequency symbols from a min-heap. Produces optimal prefix-free codes for lossless compression (ZIP, PNG, gzip).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Real-time task schedulers:&lt;/strong&gt; Embedded RTOS kernels (FreeRTOS, Zephyr) schedule tasks by priority using a priority queue; the highest-priority ready task always runs.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Stream median:&lt;/strong&gt; Two heaps — a max-heap for the lower half and a min-heap for the upper half — give the running median in O(log n) per insertion. Used in statistics dashboards and signal processing.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'trie': {
        title: 'Trie (Prefix Tree)',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A tree where each edge represents a character (or bit), and a path from the root to a marked node spells a complete key. Every node is implicitly labelled by the prefix of keys that pass through it. The lookup time is O(k) in the key length — independent of how many keys are stored.&lt;/p&gt;

            &lt;h3&gt;Core Operations &amp;amp; Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Insert&lt;/strong&gt; — O(k): traverse or create one node per character.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Search (exact)&lt;/strong&gt; — O(k): follow edges; return true if the terminal node is marked.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Prefix search&lt;/strong&gt; — O(k): traverse to the node representing the prefix, then enumerate all descendants. Fundamental to autocomplete.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Delete&lt;/strong&gt; — O(k): unmark the terminal and prune any now-childless nodes back toward the root.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Variants&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Compressed Trie (Radix / Patricia Tree):&lt;/strong&gt; Merge chains of single-child nodes into one edge labelled by the entire substring. Reduces memory from O(n·k) to O(n) nodes — used in IP routing tables.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Ternary Search Tree (TST):&lt;/strong&gt; Each node has three children (less, equal, greater). More memory-efficient than a full alphabet-branching trie.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Binary Trie:&lt;/strong&gt; One bit per level. Used in XOR-based problems and IP longest-prefix-match lookups (CIDR routing).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Suffix Trie / Suffix Array:&lt;/strong&gt; Insert all suffixes of a string. Enables O(k) substring search in a text of length n. Suffix arrays are the compressed, practical alternative.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Autocomplete &amp;amp; spell-check:&lt;/strong&gt; Google Search, IDE code completion, and smartphone keyboards store the lexicon in a trie. Depth-first enumeration of all words under a prefix node yields candidates ranked by frequency.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;IP routing (LPM):&lt;/strong&gt; A binary trie (or compressed PATRICIA trie) stores CIDR prefixes. Routers perform Longest Prefix Match in O(32) or O(128) bit comparisons — constant time regardless of routing table size.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;DNS resolver:&lt;/strong&gt; Domain labels are traversed in reverse (root → TLD → domain) in a trie-like structure to find the authoritative nameserver.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Genome sequence search (suffix array/trie):&lt;/strong&gt; Bioinformatics tools (BWA, Bowtie) align short reads to a reference genome using compressed suffix tries (FM-index), enabling O(k) pattern matching across 3-billion-base references.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;XOR maximum pair:&lt;/strong&gt; Insert integers into a binary trie; for each new integer, greedily pick the opposite bit at each level to maximise XOR. O(32n) — used in competitive programming and network bitmask optimisation.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    /* ══════════════════════════════════════════
       HASH TABLES &amp; GRAPHS
       ══════════════════════════════════════════ */

    'hash-table': {
        title: 'Hash Table',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A hash table stores key–value pairs in an array of &lt;em&gt;buckets&lt;/em&gt;. A &lt;em&gt;hash function&lt;/em&gt; maps each key to a bucket index. Collisions — when two keys map to the same index — are resolved either by chaining (linked list at each bucket) or open addressing (probe for the next empty slot).&lt;/p&gt;

            &lt;h3&gt;Core Operations &amp;amp; Complexity&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Insert, Lookup, Delete&lt;/strong&gt; — O(1) average, O(n) worst (all keys collide). With a good hash function and load factor α &amp;lt; 0.75, worst case is extremely rare.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Load factor α = n / m&lt;/strong&gt; (n keys, m buckets): as α rises, collision probability rises. Dynamic resizing (doubling when α exceeds threshold) keeps α bounded, giving O(1) amortised.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Iteration&lt;/strong&gt; — O(m + n): must scan all buckets. Hash tables do not support ordered iteration.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Hash Functions&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Division method:&lt;/strong&gt; &lt;code&gt;h(k) = k mod m&lt;/code&gt;. Simple but sensitive to m choice.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Multiplication method:&lt;/strong&gt; &lt;code&gt;h(k) = ⌊m · (kA mod 1)⌋&lt;/code&gt;, A ≈ 0.618. Less sensitive to m.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Universal hashing:&lt;/strong&gt; Pick a random hash function from a family; guarantees O(1) expected collisions for any input, including adversarial.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Cryptographic hashes (SHA-256, MurmurHash3):&lt;/strong&gt; Used when the hash must be unpredictable to an attacker (hash flooding defence).&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Collision Resolution&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Separate chaining:&lt;/strong&gt; Each bucket is a linked list (or small dynamic array). Simple; handles high load factors gracefully.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Open addressing (linear probing):&lt;/strong&gt; On collision, probe bucket + 1, +2, … until empty. Better cache performance but sensitive to clustering.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Robin Hood hashing:&lt;/strong&gt; Steal slots from "rich" entries (low probe distance) for "poor" ones (high probe distance). Equalises probe distances; used in Rust's &lt;code&gt;HashMap&lt;/code&gt;.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Language built-in maps/dicts:&lt;/strong&gt; Python's &lt;code&gt;dict&lt;/code&gt;, JavaScript's &lt;code&gt;Map&lt;/code&gt;, Java's &lt;code&gt;HashMap&lt;/code&gt;, and Go's &lt;code&gt;map&lt;/code&gt; are all hash tables. The single most-used data structure in most programs.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Database hash joins:&lt;/strong&gt; Build a hash table on the smaller relation; probe with each row of the larger. O(n) vs. O(n log n) for sort-merge join when data fits in memory.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Caching (memcached, Redis):&lt;/strong&gt; An in-memory hash table maps string keys to arbitrary byte values. Sub-millisecond lookup latency allows databases to serve millions of requests per second.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Compiler symbol tables:&lt;/strong&gt; Identifier → (type, scope, offset) lookup in O(1) during parsing and code generation.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Counting and frequency analysis:&lt;/strong&gt; Count word frequencies in a document, detect duplicate packets in a network stream, or track unique visitors — all done with &lt;code&gt;table[key]++&lt;/code&gt; in O(n).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Blockchain / Merkle trees:&lt;/strong&gt; SHA-256 hashes chain blocks, creating an append-only ledger where tampering with any block invalidates all subsequent hashes.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'graph': {
        title: 'Graph',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A graph G = (V, E) consists of a set of &lt;em&gt;vertices&lt;/em&gt; (nodes) and &lt;em&gt;edges&lt;/em&gt; (connections). Edges may be directed (digraph) or undirected, weighted or unweighted. Graphs are the most general relational data structure — almost any system of relationships can be modelled as a graph.&lt;/p&gt;

            &lt;h3&gt;Representations&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Adjacency list:&lt;/strong&gt; Array of V lists; list[u] contains all neighbours of u. Space O(V + E). Preferred for sparse graphs (most real-world graphs).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Adjacency matrix:&lt;/strong&gt; V×V boolean or weight matrix; M[u][v] = 1 iff edge (u,v) exists. Space O(V²). O(1) edge query; O(V) neighbour enumeration. Good for dense graphs or when O(1) edge lookup is critical.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Edge list:&lt;/strong&gt; Simple list of (u, v) pairs. Used in Kruskal's MST and when iterating all edges.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Fundamental Algorithms&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;BFS (Breadth-First Search):&lt;/strong&gt; O(V+E). Explores level by level using a queue. Finds shortest path in unweighted graphs. Used in web crawlers, social network distance, puzzle solvers (15-puzzle, Rubik's cube).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;DFS (Depth-First Search):&lt;/strong&gt; O(V+E). Explores as deep as possible using a stack (or recursion). Used for cycle detection, topological sort, strongly connected components, maze generation.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Dijkstra's Shortest Path:&lt;/strong&gt; O((V+E) log V) with a binary heap. Finds shortest paths from a source to all vertices in non-negatively-weighted graphs.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Bellman-Ford:&lt;/strong&gt; O(VE). Handles negative-weight edges; detects negative cycles. Used in BGP routing protocol's distance-vector computation.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;A* Search:&lt;/strong&gt; Dijkstra + heuristic; focuses search toward the goal. Used in GPS navigation, game AI pathfinding (NPC movement).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Kruskal's / Prim's MST:&lt;/strong&gt; Find the minimum spanning tree — the subset of edges connecting all vertices with minimum total weight. Used in network design, cluster analysis.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Topological Sort (Kahn's / DFS-based):&lt;/strong&gt; Linear ordering of a DAG's vertices such that every edge points forward. Used in build systems, dependency resolution, course scheduling.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Tarjan's SCC / Kosaraju's:&lt;/strong&gt; Find strongly connected components of a digraph in O(V+E). Used in compiler dead-code elimination, feedback loop analysis.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Maps and navigation (A*, Dijkstra):&lt;/strong&gt; Google Maps, Apple Maps, and OpenStreetMap model roads as weighted directed graphs. Dijkstra or bidirectional A* finds the shortest or fastest route.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Social networks:&lt;/strong&gt; Facebook's friendship graph, Twitter's follower digraph. Algorithms compute friend-of-a-friend suggestions (BFS), influence spread (PageRank), and community detection.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Dependency resolution (build systems):&lt;/strong&gt; Bazel, Make, and npm model target/package dependencies as a DAG. Topological sort gives the valid build order; cycles are build errors.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Network routing protocols:&lt;/strong&gt; OSPF uses Dijkstra's algorithm on a graph of routers to compute shortest paths. BGP uses path-vector (Bellman-Ford variant) across autonomous systems.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Knowledge graphs (AI/ML):&lt;/strong&gt; Google's Knowledge Graph, Wikidata, and embedding models like TransE represent entities and relations as directed graphs used for semantic search and recommendation.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Autonomy &amp;amp; robotics:&lt;/strong&gt; Occupancy grids become graphs for A* motion planning. Factor graphs model SLAM (Simultaneous Localisation and Mapping) as a sparse graph of pose and landmark nodes optimised by message passing.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    /* ══════════════════════════════════════════
       ADVANCED STRUCTURES
       ══════════════════════════════════════════ */

    'disjoint-set': {
        title: 'Disjoint Set (Union-Find)',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A disjoint-set forest maintains a collection of non-overlapping (disjoint) sets and supports two operations: &lt;strong&gt;Find&lt;/strong&gt; (which set does element x belong to?) and &lt;strong&gt;Union&lt;/strong&gt; (merge two sets). With two optimisations — &lt;em&gt;union by rank&lt;/em&gt; and &lt;em&gt;path compression&lt;/em&gt; — both operations run in O(α(n)) amortised time, where α is the inverse Ackermann function, practically constant (≤ 4) for all realistic n.&lt;/p&gt;

            &lt;h3&gt;Structure&lt;/h3&gt;
            &lt;p&gt;Each element is a node in a forest of trees. Each tree represents one set; the root is the set's canonical representative. Initially, each element is its own tree (n singleton sets).&lt;/p&gt;

            &lt;h3&gt;Optimisations&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Union by Rank (or Size):&lt;/strong&gt; Always attach the smaller tree under the root of the larger. This keeps tree heights O(log n) in the worst case.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Path Compression:&lt;/strong&gt; During Find, make every node on the path point directly to the root. Subsequent Finds on the same path are O(1). Together with union by rank, amortised cost is O(α(n)).&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Key Algorithms&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Kruskal's Minimum Spanning Tree:&lt;/strong&gt; Sort all edges by weight. For each edge (u, v), if Find(u) ≠ Find(v), add it to the MST and Union(u, v). O(E log E). Union-Find decides cycle detection in near-constant time per edge.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Connected Components:&lt;/strong&gt; Process edges one by one. After all edges, nodes in the same tree share a connected component.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Online connectivity queries:&lt;/strong&gt; As edges arrive in a stream, maintain connectivity without recomputing from scratch.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Percolation (physics simulation):&lt;/strong&gt; Model a grid where sites open randomly; union adjacent open sites. Ask whether the top and bottom are connected — the phase transition occurs near a critical threshold.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Network connectivity:&lt;/strong&gt; Has a network partition occurred? Are nodes A and B in the same connected component? Union-Find answers in near-constant time as topology changes arrive.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Image segmentation:&lt;/strong&gt; Computer vision algorithms union adjacent pixels of similar colour into regions (connected components labelling). Union-Find makes a single-pass O(n) algorithm possible.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Kruskal's MST in practice:&lt;/strong&gt; Used in geographic cluster analysis, minimum-cost network design, and approximation algorithms for the Travelling Salesman Problem (Christofides).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Least Common Ancestor (offline Tarjan's LCA):&lt;/strong&gt; Tarjan's offline LCA algorithm processes queries in DFS order using Union-Find, answering all LCA queries in O(n α(n)).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Version control merge:&lt;/strong&gt; Git's three-way merge and rebase operations conceptually compute connected components of modified hunks — Union-Find-like reasoning underlies conflict detection.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'bloom-filter': {
        title: 'Bloom Filter',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A Bloom filter is a probabilistic, space-efficient data structure that answers the question "has element x been inserted?" with:&lt;/p&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;No false negatives:&lt;/strong&gt; If the filter says "no," x is definitely not present.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Possible false positives:&lt;/strong&gt; If the filter says "yes," x is &lt;em&gt;probably&lt;/em&gt; present — with a tunable false-positive rate (FPR) ε.&lt;/li&gt;
            &lt;/ul&gt;
            &lt;p&gt;The filter is a bit array of length &lt;em&gt;m&lt;/em&gt;, initially all zeros, and uses &lt;em&gt;k&lt;/em&gt; independent hash functions.&lt;/p&gt;

            &lt;h3&gt;Core Operations&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Insert(x):&lt;/strong&gt; Compute h₁(x), h₂(x), …, hₖ(x) and set those k bits to 1.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Query(x):&lt;/strong&gt; Check all k bits. If any is 0, return "definitely not present." If all are 1, return "probably present."&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Delete:&lt;/strong&gt; Not supported in a basic Bloom filter (bits are shared). &lt;em&gt;Counting Bloom filters&lt;/em&gt; replace each bit with a counter to allow deletion.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Optimal Parameters&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Number of hash functions:&lt;/strong&gt; &lt;code&gt;k = (m/n) ln 2&lt;/code&gt;, where n is the number of inserted elements.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Bit array size:&lt;/strong&gt; &lt;code&gt;m = −(n ln ε) / (ln 2)²&lt;/code&gt; for a target false-positive rate ε.&lt;/li&gt;
                &lt;li&gt;A Bloom filter for 1 million elements with 1% FPR requires only ~9.6 bits per element (~1.2 MB) — compared to ~20+ bytes per element in a hash set.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Database query optimisation:&lt;/strong&gt; Apache Cassandra, HBase, and RocksDB use Bloom filters per SSTable. Before reading a slow disk file, query the Bloom filter. If "definitely not present," skip the file entirely. Reduces unnecessary I/O by ~10×.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Web cache (CDN):&lt;/strong&gt; Akamai and Cloudflare use Bloom filters to decide whether a URL is "one-hit wonder" content that should not be cached (saving cache space for popular URLs).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Chrome Safe Browsing:&lt;/strong&gt; Google Chrome ships a Bloom filter of known malicious URLs. Suspicious URLs are checked locally in microseconds without a round-trip to Google's servers.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Distributed systems (deduplication):&lt;/strong&gt; Apache Kafka and stream processors use Bloom filters to detect and discard duplicate messages with near-zero memory overhead.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Cryptocurrency (Bitcoin SPV):&lt;/strong&gt; Simplified Payment Verification clients send a Bloom filter of addresses they care about to full nodes, which filter transactions before sending — preserving bandwidth and partial privacy.&lt;/li&gt;
            &lt;/ul&gt;
        `
    },

    'skip-list': {
        title: 'Skip List',
        content: `
            &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt; A skip list is a randomised data structure — a hierarchy of sorted linked lists where higher levels "skip" over many elements, acting as express lanes. It provides the same O(log n) expected operations as a balanced BST without the complexity of rotations, using only randomisation.&lt;/p&gt;

            &lt;h3&gt;Structure&lt;/h3&gt;
            &lt;p&gt;Level 0 is a standard sorted linked list containing all elements. Each higher level is a sublist of the level below — each node independently promoted to the next level with probability p (typically 0.5). The expected height of the structure is O(log_{1/p} n) ≈ O(log n).&lt;/p&gt;

            &lt;h3&gt;Core Operations &amp;amp; Complexity (Expected)&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Search:&lt;/strong&gt; Start at the highest level; advance forward if the next node's key ≤ target; drop down a level when the next key exceeds target. Expected O(log n) steps.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Insert:&lt;/strong&gt; Find the position at each level; coin-flip to determine height; insert new node with forward pointers. O(log n).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Delete:&lt;/strong&gt; Find and splice out the node at every level it appears. O(log n).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Range query:&lt;/strong&gt; Search for the lower bound, then scan level-0 list forward. O(log n + k).&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Skip List vs. Balanced BST&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Advantages:&lt;/strong&gt; Simpler to implement; lock-free concurrent versions are practical; naturally supports range queries; no rebalancing.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt; O(log n) only in expectation (BST with rotations is deterministic); higher constant factors due to pointer chasing; slightly worse cache performance than array-backed heaps.&lt;/li&gt;
            &lt;/ul&gt;

            &lt;h3&gt;Real-World Applications&lt;/h3&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Redis Sorted Sets (&lt;code&gt;ZSET&lt;/code&gt;):&lt;/strong&gt; Redis's sorted set data type is implemented with a skip list + hash table. Skip list provides O(log n) rank queries and range scans; hash table provides O(1) score lookup. Powers real-time leaderboards in games and live ranking boards.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;LevelDB / RocksDB MemTable:&lt;/strong&gt; Writes are buffered in an in-memory skip list (MemTable) before being flushed to SSTable files. Skip list provides ordered iteration for efficient SSTable generation and supports concurrent reads with a single writer.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Java &lt;code&gt;ConcurrentSkipListMap&lt;/code&gt;:&lt;/strong&gt; Java's standard library provides a lock-free concurrent sorted map backed by a skip list — used in high-throughput concurrent applications where multiple threads read/write without blocking.&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Time-ordered event logs:&lt;/strong&gt; Skip lists efficiently support inserting events with arbitrary timestamps and querying all events in a time range — useful for distributed tracing systems (Jaeger, Zipkin).&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Lucene (Elasticsearch / Solr):&lt;/strong&gt; Apache Lucene uses skip lists within its inverted index to accelerate the intersection of large posting lists, enabling fast boolean query evaluation over millions of documents.&lt;/li&gt;
            &lt;/ul&gt;
        `
    }
};

const modal = document.getElementById('modal');
const modalTitle = document.getElementById('modal-title');
const modalBody = document.getElementById('modal-body');
const closeBtn = document.querySelector('.close');

document.querySelectorAll('.ds-card').forEach(card =&gt; {
    card.addEventListener('click', function () {
        const key = this.getAttribute('data-info');
        const info = explanations[key];
        if (info) {
            modalTitle.textContent = info.title;
            modalBody.innerHTML = info.content;
            modal.style.display = 'block';
            document.body.style.overflow = 'hidden';
        }
    });
});

closeBtn.addEventListener('click', () =&gt; {
    modal.style.display = 'none';
    document.body.style.overflow = '';
});
window.addEventListener('click', e =&gt; {
    if (e.target === modal) {
        modal.style.display = 'none';
        document.body.style.overflow = '';
    }
});
document.addEventListener('keydown', e =&gt; {
    if (e.key === 'Escape' &amp;&amp; modal.style.display === 'block') {
        modal.style.display = 'none';
        document.body.style.overflow = '';
    }
});
&lt;/script&gt;
</code></pre>
</body>

</style></head></html><div style="break-before: page; page-break-before: always;"></div>
<h1 id="computer-simulations"><a class="header" href="#computer-simulations">Computer Simulations</a></h1>
<ul>
<li><a href="#event-based-collision-detection">Event-Based Collision Detection</a></li>
<li><a href="#the-inertial-measurement-unit-imu-sensor">The Inertial Measurement Unit (IMU) Sensor</a></li>
<li><a href="#the-rotor-blade-flapping-effect">The Rotor Blade Flapping Effect</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="event-based-collision-detection"><a class="header" href="#event-based-collision-detection">Event-Based Collision Detection</a></h1>
<p><em>Predict and simulate a collision before it happens rather than make state adjustments after object overlap.</em></p>
<p>I used these notes to create the backend C++ simulator for the <a href="https://andrewtorgesen.com/projects/Planning_and_Control/Multi-Agent_Air_Hockey.html">Multi-Agent Air Hockey</a> project.</p>
<h2 id="planar-case"><a class="header" href="#planar-case">Planar Case</a></h2>
<p><strong>Sources</strong></p>
<ul>
<li>[1] <a href="https://algs4.cs.princeton.edu/61event/">https://algs4.cs.princeton.edu/61event/</a></li>
</ul>
<p>[1] assumes all disks move in straight lines without any external forces or anything other than single-integrator dynamics. Then, you can form your global priority queue with impending collisions. This assumption can be circumvented by (assuming your simulation has a time step \(\Delta t\)) doing the same logic but limiting your sense of time to the <strong>time window</strong> \(t=0\rightarrow \Delta t\) and resetting your priority queue at every time step. In fact, you can chop your normal simulation time step into a bunch of smaller \(\Delta t\)’s if the straight-line trajectory assumption holds up better over those smaller time steps.</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Symbol</th><th>Meaning</th></tr>
</thead>
<tbody>
<tr><td>\(p=\begin{bmatrix}p_x &amp; p_y\end{bmatrix}^T\)</td><td>Agent position at start of time window.</td></tr>
<tr><td>\(v=\begin{bmatrix}v_x &amp; v_y\end{bmatrix}^T\)</td><td>Agent velocity at start of time window.</td></tr>
<tr><td>\(r\)</td><td>Agent radius.</td></tr>
<tr><td>\(\pm h\)</td><td>y-limits where wall is located.</td></tr>
<tr><td>\(\pm w\)</td><td>x-limits where wall is located.</td></tr>
</tbody>
</table>
</div>
<p><strong>For each time window:</strong></p>
<ul>
<li><em>Initialize discard list</em> \(\mathcal{D}={(\text{time},\text{agent index})}\) to empty.</li>
<li><em>Form priority queue</em> \(\mathcal{P}={[\tau](\text{time-of-insertion},\text{agent(s)},\text{collision TYPE})}\), which sorts by time-to-collision \(\tau\). Queue items can take the form of a special <em>collision</em> class.</li>
<li>For each agent \(i\):
<ul>
<li>If \(v_y &gt; 0\):
<ul>
<li>\(\tau=(h-r-p_y)/v_y\)</li>
<li>If \(\tau \leq \Delta t\): Append [\(\tau\)](0,\(i\), <strong>WALL-UP</strong>) to \(\mathcal{P}\)</li>
</ul>
</li>
<li>Else If \(v_y &lt; 0\):
<ul>
<li>\(\tau=(-h+r-p_y)/v_y\)</li>
<li>If \(\tau \leq \Delta t\): Append [\(\tau\)](0,\(i\), <strong>WALL-DOWN</strong>) to \(\mathcal{P}\)</li>
</ul>
</li>
<li>If \(v_x &gt; 0\):
<ul>
<li>\(\tau=(w-r-p_x)/v_x\)</li>
<li>If \(\tau \leq \Delta t\): Append [\(\tau\)](0,\(i\), <strong>WALL-RIGHT</strong>) to \(\mathcal{P}\)</li>
</ul>
</li>
<li>Else If \(v_x\) &lt; 0:
<ul>
<li>\(\tau=(-w+r-p_x)/v_x\)</li>
<li>If \(\tau \leq \Delta t\): Append [\(\tau\)](0,\(i\), <strong>WALL-LEFT</strong>) to \(\mathcal{P}\)</li>
</ul>
</li>
</ul>
</li>
<li>For each pairwise combination (order doesn’t matter) \((i,j)\) of agents:
<ul>
<li>\(\Delta p = p_j-p_i\)</li>
<li>\(\Delta v = v_j-v_i\)</li>
<li>\(\sigma = r_i + r_j\)</li>
<li>\(d=(\Delta v \cdot \Delta p)^2-(\Delta v \cdot \Delta v)(\Delta p \cdot \Delta p - \sigma^2)\)</li>
<li>If \(\Delta v \cdot \Delta p &lt; 0\) and \(d \geq 0\):
<ul>
<li>\(\tau = -\frac{\Delta v \cdot \Delta p + \sqrt{d}}{\Delta v \cdot \Delta v}\)</li>
<li>If \(\tau \leq \Delta t\): Append [\(\tau\)](0,\((i,j)\), <strong>INTER-AGENT</strong>) to \(\mathcal{P}\)</li>
</ul>
</li>
</ul>
</li>
<li><em>Work through priority queue</em>:</li>
<li>While \(\mathcal{P}\) not empty:
<ul>
<li>Grab collision from top of queue.</li>
<li>If time-of-insertion &lt; an item in \(\mathcal{D}\) with a matching agent ID, then simply discard and delete (also the item in \(\mathcal{D}\)).</li>
<li>Else:
<ul>
<li>Simulate all agents in the simulation and advance global time up to \(t=\text{time-of-insertion}+\tau\).</li>
<li>Remove all items in \(\mathcal{D}\) with time &lt; \(t\).</li>
<li>Carry out collision type and remove from \(\mathcal{P}\).</li>
<li>Append to \(\mathcal{D}\) tuples of \(t\) and the agents involved.</li>
<li>For each agent involved, repeat all of the \(\mathcal{P}\) append logic, replacing the insertion time with \(t\).</li>
</ul>
</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="the-inertial-measurement-unit-imu-sensor"><a class="header" href="#the-inertial-measurement-unit-imu-sensor">The Inertial Measurement Unit (IMU) Sensor</a></h1>
<h2 id="a-quick-note-on-notation"><a class="header" href="#a-quick-note-on-notation">A Quick Note on Notation</a></h2>
<p>The only perhaps non-standard notation used in this article is explained in this quick note. The symbol</p>
<p>$$\boldsymbol{v}_{B/C}^A$$</p>
<p>refers to vector (bolded, lower) quantity \(\boldsymbol{v}\) expressed in the reference frame (non-bolded, capitalized) \(A\). This vector is describing something related to the evolution of the reference frame \(B\) with respect to the origin of reference frame \(C\). In order to prevent the notation from getting too unnecessarily cluttered, these latter two reference frames will only be explicitly specified if they are neither obvious nor non-applicable.</p>
<h2 id="measurement-model"><a class="header" href="#measurement-model">Measurement Model</a></h2>
<p>An IMU outputs body-frame accelerometer \(\bar{\boldsymbol{a}}^B\) and rate gyro \(\bar{\boldsymbol{\omega}}^B\) measurements at 100-1000 Hz. The following measurement models assume that the IMU lies at the inertial center of the translating/rotating rigid body (which we’ll call the <em>vehicle</em>). See the subsequent section on applying \(SE(3)\) transforms for handling other cases.</p>
<h3 id="accelerometer-model"><a class="header" href="#accelerometer-model">Accelerometer Model</a></h3>
<p>An accelerometer, contrary to some belief, does <em>not</em> measure gravity. Instead, it measures the <em>specific force</em> (i.e., \(\boldsymbol{F}/m\)) that is currently preventing free fall. Thus, an accelerometer falling in a vacuum would measure \(\boldsymbol{0}\), whereas an accelerometer sitting on a table would measure the specific normal force from the table, and an accelerometer onboard a hovering UAV would measure the specific thrust of the vehicle. The measurement equation is</p>
<p>$$\bar{\boldsymbol{a}}^B=\left(\boldsymbol{R}_B^W\right)^\top\left(\boldsymbol{a}^W-\boldsymbol{g}^W\right)+\boldsymbol{\eta}_a^B+\boldsymbol{\beta}_a^B,$$</p>
<p>where \(\boldsymbol{a}^W\) is the inertial acceleration of the vehicle, \(\boldsymbol{g}^W\) is the inertial gravity vector, and \(\boldsymbol{\eta}_a^B\), \(\boldsymbol{\beta}_a^B\) represent zero-mean Gaussian noise and non-zero bias. We can express acceleration as the (inertial) derivative of vehicle velocity, which gives</p>
<p><strong>(A.1)</strong></p>
<p>$$\bar{\boldsymbol{a}}^B=\left(\boldsymbol{R}_B^W\right)^\top\left(\frac{d \boldsymbol{v}_{B/W}^W}{dt^W}-\boldsymbol{g}^W\right)+\boldsymbol{\eta}_a^B+\boldsymbol{\beta}_a^B.$$</p>
<p>It’s often the case, however, where we would like to express or are given velocity in the body frame. In that case, numerically differentiating velocity will yield</p>
<p>$$\frac{d\boldsymbol{v}_{B/W}^B}{dt^B},$$</p>
<p>which is a derivative taken from the perspective of a rotating reference frame, and thus is not valid in a Newtonian-mechanics-sense on its own. Instead, we require the application of the transport theorem,</p>
<p>$$\frac{d\cdot^\circ}{dt^W}=\frac{d\cdot^\circ}{dt^\circ}+\boldsymbol{\omega}_{\circ/W}^\circ\times\cdot^\circ,$$</p>
<p>to yield the body-frame velocity version of the accelerometer measurement model:</p>
<p><strong>(A.2)</strong></p>
<p>$$\bar{\boldsymbol{a}}^B=\frac{d\boldsymbol{v}_{B/W}^B}{dt^B}+\boldsymbol{\omega}_{B/W}^B\times\boldsymbol{v}_{B/W}^B-\left(\boldsymbol{R}_B^W\right)^\top\boldsymbol{g}^W+\boldsymbol{\eta}_a^B+\boldsymbol{\beta}_a^B.$$</p>
<h3 id="rate-gyro-model"><a class="header" href="#rate-gyro-model">Rate Gyro Model</a></h3>
<p>The rate gyro measurement model is much more straightforward, as it’s just the true angular velocity (which is pretty much always expressed/given in the body frame) with added noise and bias:</p>
<p><strong>(B)</strong></p>
<p>$$\bar{\boldsymbol{\omega}}^B=\boldsymbol{\omega}_{B/W}^B+\boldsymbol{\eta}_\omega^B+\boldsymbol{\beta}_\omega^B.$$</p>
<h2 id="synthesizing-measurements"><a class="header" href="#synthesizing-measurements">Synthesizing Measurements</a></h2>
<h3 id="uncorrupted-measurements"><a class="header" href="#uncorrupted-measurements">Uncorrupted Measurements</a></h3>
<p>Noise- and bias-less IMU measurements can be synthesized from simulation
truth data using the measurement equations <strong>(A.1-2)</strong>, <strong>(B)</strong>, themselves.
While most of the required state terms are straightforward to extract,
care must be taken to ensure that the correct velocity term is being
used for the chosen accelerometer model. Here are some likely cases:</p>
<ul>
<li>A rigid body dynamics simulation is yielding a differential velocity term \(\delta\boldsymbol{v}_k^B\) such that \(\boldsymbol{v}_{k+1}^B=f(\boldsymbol{v}_k^B,\delta\boldsymbol{v}_k^B)\) where \(f\) is some numerical integration technique (e.g., RK4). In this case, \(\delta\boldsymbol{v}_k^B\) should be substituted in for the \(d\boldsymbol{v}_{B/W}^B/dt^B\) term in Eq. <strong>(A.2)</strong>.</li>
<li>A rigid body dynamics simulation is yielding a differential velocity term \(\delta\boldsymbol{v}_k^W\) such that \(\boldsymbol{v}_{k+1}^W=f(\boldsymbol{v}_k^W,\delta\boldsymbol{v}_k^W)\). In this case, \(\delta\boldsymbol{v}_{k}^{W}\) should be substituted in for the \(d\boldsymbol{v}_{B/W}^{W}/dt^{W}\) term in Eq. <strong>(A.1)</strong>.</li>
<li>Access to the underlying dynamics simulation is not given, and instead one has a series of time-stamped body-frame velocity vectors \(\boldsymbol{v}_{k}^{B}\). In this case, \(\boldsymbol{v}_{k}^{B}\) must be numerically differentiated to obtain the \(\delta\boldsymbol{v}_{k}^{B}\) terms from Case 1.</li>
<li>One has a series of time-stamped inertial velocity vectors \(\boldsymbol{v}_{k}^{W}\). In this case, \(\boldsymbol{v}_{k}^{W}\) must be numerically differentiated to obtain the \(\delta\boldsymbol{v}_{k}^{W}\) terms from Case 2.</li>
</ul>
<p>Similarly for angular velocity, if \(\boldsymbol{\omega}_{k}^{B}\)
isn’t provided directly, then the orientation data, whether in matrix
or quaternion form, can be numerically differentiated on the manifold,
provided that the resulting tangent-space vectors are expressed as
local perturbations.</p>
<h3 id="simulated-noise-and-bias"><a class="header" href="#simulated-noise-and-bias">Simulated Noise and Bias</a></h3>
<p>The accelerometer and gyro each have their own noise and bias levels,
defined by a set of three numbers for each:</p>
<ul>
<li>Noise standard deviation, \(\sigma_{\eta}\)</li>
<li>Initial bias range, \(\kappa_{\beta_{0}}\)</li>
<li>Bias walk standard deviation, \(\sigma_{\beta}\)</li>
</ul>
<p>Noise and bias are then simulated at each time step according to the
recursive relationship:</p>
<p>$$\boldsymbol{\beta}_{0}=\mathcal{U}(-\kappa_{\beta_{0}},\kappa_{\beta_{0}}),$$</p>
<p>$$\boldsymbol{\beta}_{k}=\boldsymbol{\beta}_{k-1}+\mathcal{N}(0,\sigma_{\beta})\Delta t,$$</p>
<p>$$\boldsymbol{\eta}_{\boldsymbol{k}}=\mathcal{N}(0,\sigma_{\eta}),$$</p>
<p>where \(\mathcal{U}\) and \(\mathcal{N}\) are the uniform and normal
distributions, respectively.</p>
<h2 id="shifting-measurements-in-se3"><a class="header" href="#shifting-measurements-in-se3">Shifting Measurements in \(SE(3)\)</a></h2>
<p>Suppose we want an IMU measurement model for when the IMU is mounted
away from the inertially-centered body frame, still rigidly attached
to the vehicle. We have an \(SE(3)\) transform description of the relationship
between the body frame and this “shifted” frame, which we’ll refer
to as \(U\):</p>
<p>$$\boldsymbol{T}_{U}^{B}=\begin{bmatrix}\boldsymbol{R}_{U}^{B} &amp; \boldsymbol{t}_{U/B}^{B}\\ \boldsymbol{0} &amp; 1\end{bmatrix}.$$</p>
<p>We will now derive the shifted accelerometer measurement \(\bar{\boldsymbol{a}}^{U}\) in terms of the body-frame measurement \(\bar{\boldsymbol{a}}^{B}\). Applying Eq. <strong>(A.1)</strong>, the shifted measurement would be</p>
<p>$$\bar{\boldsymbol{a}}^{U}=\left(\boldsymbol{R}_{U}^{W}\right)^{\top}\left(\frac{d\boldsymbol{v}_{U/W}^{W}}{dt^{W}}-\boldsymbol{g}^{W}\right)+\boldsymbol{\eta}^{U}+\boldsymbol{\beta}^{U}.$$</p>
<p>Before proceeding, there are two key things to note from basic kinematics:</p>
<ul>
<li>Because both \(B\) and \(U\) are rigidly attached to the same vehicle, \(\boldsymbol{\omega}_{U/W}=\boldsymbol{\omega}_{B/W}.\)</li>
<li>A frame with a non-zero offset away from the vehicle center of mass will experience additional velocity under vehicle rotation: \(\boldsymbol{v}_{U/W}=\boldsymbol{v}_{B/W}+\boldsymbol{\omega}_{B/W}\times\boldsymbol{t}_{U/B}.\)</li>
</ul>
<p>Applying these two facts, the shifted measurement can be re-written
as</p>
<p>$$\bar{\boldsymbol{a}}^{U} =\left(\boldsymbol{R}_{U}^{B}\right)^{\top}\left(\bar{\boldsymbol{a}}^{B}+\frac{d}{dt^{W}}\left(\boldsymbol{\omega}_{B/W}^{B}\times\boldsymbol{t}_{U/B}^{B}\right)\right)$$</p>
<p>$$=\left(\boldsymbol{R}_{U}^{B}\right)^{\top}\left(\bar{\boldsymbol{a}}^{B}+\frac{d}{dt^{B}}\left(\boldsymbol{\omega}_{B/W}^{B}\times\boldsymbol{t}_{U/B}^{B}\right)+\boldsymbol{\omega}_{B/W}^{B}\times\left(\boldsymbol{\omega}_{B/W}^{B}\times\boldsymbol{t}_{U/B}^{B}\right)\right).$$</p>
<p>Expanding the derivative and triple product terms, the concise shifted
accelerometer measurement equation is</p>
<p>$$\bar{\boldsymbol{a}}^{U}=\left(\boldsymbol{R}_{U}^{B}\right)^{\top}\left(\bar{\boldsymbol{a}}^{B}+\left(\lfloor\dot{\boldsymbol{\omega}}\rfloor_{\times}+\boldsymbol{\omega}\boldsymbol{\omega}^{\top}-\boldsymbol{\omega}^{\top}\boldsymbol{\omega}\boldsymbol{I}\right)\boldsymbol{t}_{U/B}^{B}\right),$$</p>
<p>$$\boldsymbol{\omega}\triangleq\boldsymbol{\omega}_{B/W}^{B}.$$</p>
<p>The shifted rate gyro equation involves only a frame change:</p>
<p>$$\bar{\boldsymbol{\omega}}^{U}=\left(\boldsymbol{R}_{U}^{B}\right)^{\top}\bar{\boldsymbol{\omega}}^{B}.$$</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="the-rotor-blade-flapping-effect"><a class="header" href="#the-rotor-blade-flapping-effect">The Rotor Blade Flapping Effect</a></h1>
<h2 id="source-papers"><a class="header" href="#source-papers">Source Papers</a></h2>
<ul>
<li><a href="https://pdfs.semanticscholar.org/a3dd/e9f67353f7f000011351e757a0aaaf3ec941.pdf">[LIT] Quadrotor Helicopter Flight Dynamics and Control: Theory and Experiment</a>
<ul>
<li>Considers <strong>four aerodynamic effects</strong> which arise when deviating significantly from hover flight regime</li>
<li>Taking them into account allows for improved tracking at higher speeds and in gusting winds</li>
</ul>
</li>
<li><a href="https://flyingmachinearena.org/wp-content/publications/2017/gilIEEE17.pdf">[LIT] Propeller Thrust and Drag in Forward Flight</a></li>
<li><a href="http://ai.stanford.edu/~gabeh/papers/ICRA09_AeroEffects.pdf">[LIT] Aerodynamics and Control of Autonomous Quadrotor Helicopters in Aggressive Maneuvering</a></li>
<li><a href="https://arxiv.org/pdf/1509.03388.pdf">[LIT] Improved State Estimation in Quadrotor MAVs: A Novel Drift-Free Velocity Estimator</a>
<ul>
<li>focuses on the translational force that opposes quadrotor motion</li>
<li>actually uses it to get more accurate velocity estimation</li>
</ul>
</li>
</ul>
<h2 id="consolidated-model"><a class="header" href="#consolidated-model">Consolidated Model</a></h2>
<h3 id="core-equations"><a class="header" href="#core-equations">Core Equations</a></h3>
<p>A rotor in translational flight undergoes an effect known as blade flapping. The advancing blade of the rotor has a higher velocity relative to the free-stream, while the retreating blade sees a lower effective airspeed. This causes an imbalance in lift, inducing an up and down oscillation of the rotor blades. In steady state, this causes the effective rotor plane to tilt at some angle off of vertical, causing a deflection of the thrust vector (see Figure 2). If the rotor plane is not aligned with the vehicle’s center of gravity, this will create a moment about the center of gravity (\(M_{b,lon}\)) that can degrade attitude controller performance. For stiff rotors without hinges at the hub, there is also a moment generated directly at the rotor hub from the deflection of the blades (\(M_{b,s}\)).</p>
<p>The total moment on the UAV about the body pitch and roll axes comes from the contribution of each rotor \(i\):</p>
<p>$$M_{flap,\phi}=\sum_i (M_{b,lon,\phi,i}+ M_{b,s,\phi,i})$$</p>
<p>$$M_{b,lon,\phi,i}=T_ih\sin{a_{1s,\phi}}$$</p>
<p>$$M_{b,s,\phi,i}=k_\beta a_{1s,\phi}$$</p>
<p>$$a_{1s,\phi}=-k_f~^bv_y$$</p>
<p>$$M_{flap,\theta}=\sum_i (M_{b,lon,\theta,i}+ M_{b,s,\theta,i})$$</p>
<p>$$M_{b,lon,\theta,i}=T_ih\sin{a_{1s,\theta}}$$</p>
<p>$$M_{b,s,\theta,i}=k_\beta a_{1s,\theta}$$</p>
<p>$$a_{1s,\theta}=k_f~^bv_x$$</p>
<p>Where</p>
<p>\(h\) is the vertical distance from rotor plane to origin of the body frame ($m$),</p>
<p>\(k_\beta\) is the stiffness of the rotor blade (\(N~m/rad\)),</p>
<p>\(k_f\) is a constant providing a linear approximation to Eq. 8 on page 7 of [1]. The linear approximation is explained preceding Eq. 14 on page 4 of [3].</p>
<p>Additionally, the total force on the quadrotor is</p>
<p>$$^\mathcal{I}F_{flap}=-\lambda_1\sum_i\omega_i\tilde{V}$$</p>
<p>Where</p>
<p>\(\omega_i\) is the rotational speed of each rotor,</p>
<p>\(\tilde{V}\) is the projection of \(^\mathcal{I}V\) on to the propeller plane,</p>
<p>\(\lambda_1\) is a “critical parameter” which is the rotor drag coefficient, and probably entails an experimental estimation method (introduced on page 37 of [4])</p>
<p>Manipulating the relations from the top left of page 35 of [4], there is an easier-to-estimate parameter (again, see page 37) called \(k_1\) (which is assumed to be constant throughout stable flight) such that</p>
<p>$$ k_1=\lambda_1\sum_i\omega_i. $$</p>
<p>The authors of [4] found their \(k_1\) value to be equal to 0.57.</p>
<p>Motor thrust related to total angular rotation rate by the following relation (from page 33 of [4]):</p>
<p>$$T=k_T\sum_i\omega_i^2$$</p>
<p>where \(k_T\) is the “thrust coefficient” of the propellers.</p>
<h3 id="how-to-simulate-effect"><a class="header" href="#how-to-simulate-effect">How to simulate effect</a></h3>
<p>Currently, we are using a Force-Torque polynomial model fit to go directly from PWM motor commands to output thrusts and torques. This gives us no information about the individual rotor speed without an estimate of \(k_T\). <strong>If all the rotor planes were parallel with each other</strong>, this would not be a big deal if we had a reasonable estimate of \(k_1\). However, since our rotor planes are not guaranteed to be parallel, we need to use the following process to compute the blade flapping effect forces and torques on the UAV:</p>
<p>This is roughly what I’m doing in C++:</p>
<pre><code class="language-cpp">double omega_Total = 0.0;
for (int i = 0; i &lt; num_rotors_; i++)
{
    ...
    motor_speeds_(i, 0) = sqrt(abs(actual_forces_(i) / motor_kT_));
    omega_Total += motor_speeds_(i, 0);
}

* Blade flapping effect
for (int i = 0; i &lt; num_rotors_; i++)
{
    * determine allocation of k_1 to each motor and calculate force and torques
    double k1i = motor_k1_ * motor_speeds_(i, 0) / omega_Total;

    * Calculate forces
    Force_ -= k1i * (Matrix3d::Identity() - motors_[i].normal*motors_[i].normal.transpose()) * airspeed_UAV;

    * Calculate torque about roll axis
    double as1phi = -motor_kf_ * airspeed_UAV(1);
    Torque_(0) -= actual_forces_(i) * motors_[i].position(2) * sin(as1phi);
    Torque_(0) += motor_kB_ * as1phi;

    // Calcualte torque about pitch axis
    double as1theta = motor_kf_ * airspeed_UAV(0);
    Torque_(1) -= actual_forces_(i) * motors_[i].position(2) * sin(as1theta);
    Torque_(1) += motor_kB_ * as1theta;
}
</code></pre>
<h2 id="parameter-estimation-attempts"><a class="header" href="#parameter-estimation-attempts">Parameter Estimation Attempts</a></h2>
<h3 id="rotor-blade-stiffness-k_beta"><a class="header" href="#rotor-blade-stiffness-k_beta">Rotor Blade Stiffness \(k_\beta\)</a></h3>
<p>Page 15 of <a href="http://www.diva-portal.org/smash/get/diva2:1070420/FULLTEXT01.pdf">this thesis</a> gives a static bending test table for a nylon 6 rotor blade, Under a load of 0.9 N, the measured deflection at the tip of the blade (with a length of 6 in = 0.1524 m) was 0.0305 m. Numerous other load and deflection values were tabulated. The calculated elastic modulus from the table was 9.5 GPa.</p>
<p>Given the above numbers, \(k_\beta\) can be calculated as</p>
<p>$$k_\beta=\frac{(0.9N)(0.1524m)}{\tan^{-1}(0.0305m/0.1524m)}\approx 0.7 \frac{Nm}{rad}.$$</p>
<h3 id="rotor-thrust-coefficient-k_t"><a class="header" href="#rotor-thrust-coefficient-k_t">Rotor Thrust Coefficient \(k_T\)</a></h3>
<p>From <a href="https://arxiv.org/pdf/1601.00733.pdf">this paper</a>, it is noted that quadrotors tend to have very low thrust coefficients compared to helicopters (on the order of zero from looking at the figure on page 20). As a ballpark estimate, the paper explains that the quadrotors studied require motor speeds around 5000 RPM to keep the vehicle in the air. Assuming that a quadrotor’s mass is somewhere around 2 kilograms and distributed evenly among four rotors, that would give a thrust coefficient of</p>
<p>$$k_T=\frac{F_{rotor}}{\omega^2}\approx 2.0 \times 10^{-5} \frac{N s^2}{rad^2}$$</p>
<p>which is in line with the figure.</p>
<h3 id="the-enigmatic-k_1-parameter"><a class="header" href="#the-enigmatic-k_1-parameter">The Enigmatic \(k_1\) Parameter</a></h3>
<p>I’m just copying the empirical value from [4] here, though it might be interesting in the future to replicate their parameter estimation process for our own platform if deemed necessary.</p>
<p>$$k_1 \approx 0.57 \frac{kg~rad}{s}$$</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="operating-systems"><a class="header" href="#operating-systems">Operating Systems</a></h1>
<ul>
<li><a href="#a-key-press">A Key Press</a></li>
<li><a href="#multithreaded-executable">Multithreaded Executable</a></li>
<li><a href="#networking-layers">Networking Layers</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="a-key-press"><a href="#a-key-press" class="header">A Key Press</a></h1>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Keystroke to Screen Rendering Pipeline</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
<pre><code>    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background: linear-gradient(135deg, #1a3a6b 0%, #2563a8 100%);
        padding: 40px 20px;
        min-height: 100vh;
    }

    .container {
        max-width: 1400px;
        margin: 0 auto;
        background: white;
        border-radius: 20px;
        padding: 40px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
    }

    h1 {
        text-align: center;
        color: #2d3748;
        margin-bottom: 20px;
        font-size: 2.5em;
    }

    .subtitle {
        text-align: center;
        color: #718096;
        margin-bottom: 50px;
        font-size: 1.1em;
    }

    .layer {
        display: grid;
        grid-template-columns: 200px 1fr 350px;
        gap: 30px;
        margin-bottom: 40px;
        align-items: start;
    }

    .layer-label {
        background: linear-gradient(135deg, #1e56b0 0%, #3b82d4 100%);
        color: white;
        padding: 20px;
        border-radius: 12px;
        font-weight: bold;
        font-size: 1.1em;
        text-align: center;
        display: flex;
        align-items: center;
        justify-content: center;
        min-height: 100px;
        box-shadow: 0 4px 15px rgba(30, 86, 176, 0.4);
    }

    .layer-components {
        display: flex;
        flex-direction: column;
        gap: 15px;
    }

    .component {
        background: #f7fafc;
        border: 2px solid #e2e8f0;
        border-radius: 10px;
        padding: 15px 20px;
        position: relative;
        transition: all 0.3s ease;
    }

    .component:hover {
        transform: translateX(5px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        border-color: #2563a8;
    }

    .component-title {
        font-weight: bold;
        color: #2d3748;
        margin-bottom: 5px;
    }

    .component-detail {
        font-size: 0.9em;
        color: #718096;
    }

    .explanation {
        background: #eff6ff;
        border-left: 4px solid #2563a8;
        padding: 20px;
        border-radius: 8px;
        line-height: 1.6;
        color: #2d3748;
    }

    .explanation h3 {
        color: #1e56b0;
        margin-bottom: 10px;
        font-size: 1.1em;
    }

    .arrow {
        text-align: center;
        margin: 0;
        line-height: 0;
        padding: 4px 0;
    }

    .arrow svg {
        display: inline-block;
        vertical-align: middle;
    }

    /* Color coding for different layers */
    .layer:nth-child(2) .layer-label {
        background: linear-gradient(135deg, #1565c0 0%, #42a5f5 100%);
        box-shadow: 0 4px 15px rgba(21, 101, 192, 0.4);
    }

    .layer:nth-child(4) .layer-label {
        background: linear-gradient(135deg, #0d47a1 0%, #1976d2 100%);
        box-shadow: 0 4px 15px rgba(13, 71, 161, 0.4);
    }

    .layer:nth-child(6) .layer-label {
        background: linear-gradient(135deg, #1e56b0 0%, #64b5f6 100%);
        box-shadow: 0 4px 15px rgba(30, 86, 176, 0.4);
    }

    .layer:nth-child(8) .layer-label {
        background: linear-gradient(135deg, #0277bd 0%, #4fc3f7 100%);
        box-shadow: 0 4px 15px rgba(2, 119, 189, 0.4);
    }

    .layer:nth-child(10) .layer-label {
        background: linear-gradient(135deg, #01579b 0%, #29b6f6 100%);
        box-shadow: 0 4px 15px rgba(1, 87, 155, 0.4);
    }

    .layer:nth-child(12) .layer-label {
        background: linear-gradient(135deg, #1a3a6b 0%, #90caf9 100%);
        box-shadow: 0 4px 15px rgba(26, 58, 107, 0.4);
    }

    .timeline {
        background: #edf2f7;
        padding: 15px;
        border-radius: 8px;
        text-align: center;
        margin-top: 40px;
        font-weight: bold;
        color: #2d3748;
    }

    .component {
        cursor: pointer;
    }

    .modal {
        display: none;
        position: fixed;
        z-index: 1000;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(0, 0, 0, 0.6);
        animation: fadeIn 0.3s;
    }

    @keyframes fadeIn {
        from {
            opacity: 0;
        }

        to {
            opacity: 1;
        }
    }

    .modal-content {
        background-color: white;
        margin: 10% auto;
        padding: 40px;
        border-radius: 15px;
        width: 80%;
        max-width: 700px;
        max-height: 80vh;
        overflow-y: auto;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        position: relative;
        animation: slideIn 0.3s;
    }

    @keyframes slideIn {
        from {
            transform: translateY(-50px);
            opacity: 0;
        }

        to {
            transform: translateY(0);
            opacity: 1;
        }
    }

    .close {
        color: #a0aec0;
        position: absolute;
        right: 20px;
        top: 20px;
        font-size: 35px;
        font-weight: bold;
        cursor: pointer;
        transition: color 0.3s;
    }

    .close:hover {
        color: #2d3748;
    }

    .modal-title {
        color: #1e56b0;
        font-size: 1.8em;
        margin-bottom: 20px;
        padding-bottom: 15px;
        border-bottom: 3px solid #2563a8;
    }

    .modal-body {
        color: #2d3748;
        line-height: 1.8;
        font-size: 1.05em;
    }

    .modal-body p {
        margin-bottom: 15px;
    }

    .modal-body strong {
        color: #1e56b0;
    }

    /* Responsive Design for Mobile */
    @media screen and (max-width: 768px) {
        body {
            padding: 20px 10px;
        }

        .container {
            padding: 20px 15px;
            border-radius: 12px;
        }

        h1 {
            font-size: 1.5em;
            margin-bottom: 15px;
        }

        .subtitle {
            font-size: 0.95em;
            margin-bottom: 30px;
        }

        .layer {
            grid-template-columns: 1fr;
            gap: 15px;
            margin-bottom: 30px;
        }

        .layer-label {
            padding: 15px;
            font-size: 1em;
            min-height: auto;
        }

        .component {
            padding: 12px 15px;
        }

        .component-title {
            font-size: 0.95em;
        }

        .component-detail {
            font-size: 0.85em;
        }

        .explanation {
            padding: 15px;
            font-size: 0.9em;
        }

        .explanation h3 {
            font-size: 1em;
        }

        .arrow {
            font-size: 1.5em;
            margin: -5px 0;
        }

        .timeline {
            padding: 12px;
            font-size: 0.9em;
            margin-top: 30px;
        }

        .modal-content {
            margin: 5% auto;
            padding: 25px;
            padding-bottom: 30px;
            width: 95%;
            max-width: 95%;
            max-height: 90vh;
        }

        .modal-title {
            font-size: 1.3em;
            padding-bottom: 10px;
        }

        .modal-body {
            font-size: 0.95em;
            line-height: 1.6;
        }

        .close {
            right: 15px;
            top: 15px;
            font-size: 28px;
        }
    }

    /* Tablet adjustments */
    @media screen and (min-width: 769px) and (max-width: 1024px) {
        .container {
            padding: 30px;
        }

        h1 {
            font-size: 2em;
        }

        .layer {
            grid-template-columns: 150px 1fr 280px;
            gap: 20px;
        }

        .layer-label {
            padding: 15px;
            font-size: 1em;
        }

        .explanation {
            font-size: 0.9em;
        }
    }

    /* Improved touch targets for mobile */
    @media (hover: none) and (pointer: coarse) {
        .component {
            padding: 15px 18px;
            margin: 5px 0;
        }

        .component:active {
            transform: scale(0.98);
            background: #edf2f7;
        }
    }
&lt;/style&gt;
</code></pre>

<body>
    
<div id="modal-4" class="modal">
        
<div class="modal-content">
            <span class="close">×</span>
            
<h2 class="modal-title" id="modal-title-4"></h2>

            
<div class="modal-body" id="modal-body-4"></div>

        </div>

    </div>

    
<div class="container">
        
<h1>Keystroke to Screen Rendering Pipeline</h1>

        
<p class="subtitle">The complete journey from physical key press to visible character</p>

<pre><code>    &lt;!-- Hardware Layer --&gt;
    &lt;div class="layer"&gt;
        &lt;div class="layer-label"&gt;HARDWARE&lt;br&gt;LAYER&lt;/div&gt;
        &lt;div class="layer-components"&gt;
            &lt;div class="component" data-info="key-press"&gt;
                &lt;div class="component-title"&gt;Key Press&lt;/div&gt;
                &lt;div class="component-detail"&gt;Physical switch closure&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="keyboard-controller"&gt;
                &lt;div class="component-title"&gt;Keyboard Controller&lt;/div&gt;
                &lt;div class="component-detail"&gt;Microcontroller/ASIC&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="physical-connection"&gt;
                &lt;div class="component-title"&gt;Physical Connection&lt;/div&gt;
                &lt;div class="component-detail"&gt;USB/PS2/Bluetooth interface&lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;What Happens Here&lt;/h3&gt;
            When you press a key, you physically close an electrical switch. The keyboard's microcontroller detects
            this change in the circuit. This is pure electrical and mechanical interaction—the foundation of all
            digital input.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Firmware Layer --&gt;
    &lt;div class="layer"&gt;
        &lt;div class="layer-label"&gt;FIRMWARE&lt;br&gt;LAYER&lt;/div&gt;
        &lt;div class="layer-components"&gt;
            &lt;div class="component" data-info="keyboard-firmware"&gt;
                &lt;div class="component-title"&gt;Keyboard Firmware&lt;/div&gt;
                &lt;div class="component-detail"&gt;Scans key matrix&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="debouncing"&gt;
                &lt;div class="component-title"&gt;Debouncing Logic&lt;/div&gt;
                &lt;div class="component-detail"&gt;Filters electrical noise&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="scan-code"&gt;
                &lt;div class="component-title"&gt;Scan Code Generation&lt;/div&gt;
                &lt;div class="component-detail"&gt;Creates unique key identifier&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="hid-protocol"&gt;
                &lt;div class="component-title"&gt;HID Protocol Encoding&lt;/div&gt;
                &lt;div class="component-detail"&gt;Packages data for transmission&lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;What Happens Here&lt;/h3&gt;
            The firmware continuously scans the keyboard matrix to detect which key was pressed. It filters out
            electrical "bounce" (rapid on/off signals) and generates a scan code—a unique number for that key. This
            code is then packaged using the HID (Human Interface Device) protocol for transmission to the computer.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- OS Kernel Layer --&gt;
    &lt;div class="layer"&gt;
        &lt;div class="layer-label"&gt;OS KERNEL&lt;br&gt;LAYER&lt;/div&gt;
        &lt;div class="layer-components"&gt;
            &lt;div class="component" data-info="device-driver"&gt;
                &lt;div class="component-title"&gt;Device Driver&lt;/div&gt;
                &lt;div class="component-detail"&gt;USB/HID driver receives data&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="interrupt-handler"&gt;
                &lt;div class="component-title"&gt;Interrupt Handler&lt;/div&gt;
                &lt;div class="component-detail"&gt;IRQ processing&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="input-subsystem"&gt;
                &lt;div class="component-title"&gt;Input Subsystem&lt;/div&gt;
                &lt;div class="component-detail"&gt;Event processing and queuing&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="keyboard-layout"&gt;
                &lt;div class="component-title"&gt;Keyboard Layout Mapping&lt;/div&gt;
                &lt;div class="component-detail"&gt;Scan code → Key code conversion&lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;What Happens Here&lt;/h3&gt;
            The operating system kernel's device driver receives the signal via hardware interrupt. The interrupt
            handler processes this high-priority event, and the input subsystem converts the hardware-specific scan
            code into a standardized key code based on your keyboard layout (QWERTY, DVORAK, etc.).
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- OS Userspace Layer --&gt;
    &lt;div class="layer"&gt;
        &lt;div class="layer-label"&gt;OS USERSPACE&lt;br&gt;LAYER&lt;/div&gt;
        &lt;div class="layer-components"&gt;
            &lt;div class="component" data-info="window-manager"&gt;
                &lt;div class="component-title"&gt;Window Manager/Display Server&lt;/div&gt;
                &lt;div class="component-detail"&gt;X11, Wayland, Windows DWM, macOS Quartz&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="ime"&gt;
                &lt;div class="component-title"&gt;Input Method Editor&lt;/div&gt;
                &lt;div class="component-detail"&gt;Character composition (IME)&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="active-app"&gt;
                &lt;div class="component-title"&gt;Active Application&lt;/div&gt;
                &lt;div class="component-detail"&gt;Event queue and focus management&lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;What Happens Here&lt;/h3&gt;
            The window manager determines which application has focus and routes the keypress event to it. The Input
            Method Editor may compose multiple keypresses into a single character (important for languages like
            Chinese, Japanese, or when typing accented characters). The event is placed in the application's event
            queue.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Application Layer --&gt;
    &lt;div class="layer"&gt;
        &lt;div class="layer-label"&gt;APPLICATION&lt;br&gt;LAYER&lt;/div&gt;
        &lt;div class="layer-components"&gt;
            &lt;div class="component" data-info="event-handler"&gt;
                &lt;div class="component-title"&gt;Event Handler&lt;/div&gt;
                &lt;div class="component-detail"&gt;Processes keypress event&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="text-buffer"&gt;
                &lt;div class="component-title"&gt;Text Buffer&lt;/div&gt;
                &lt;div class="component-detail"&gt;Inserts character at cursor position&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="rendering-engine"&gt;
                &lt;div class="component-title"&gt;Text Rendering Engine&lt;/div&gt;
                &lt;div class="component-detail"&gt;Font rasterization and layout&lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;What Happens Here&lt;/h3&gt;
            Your application (text editor, browser, etc.) receives the event and its event handler processes it. The
            character is inserted into the text buffer at the cursor position. The rendering engine then determines
            how to visually represent this character using the selected font, including kerning, anti-aliasing, and
            layout calculations.
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="48" viewBox="0 0 36 48" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="36" stroke="#2563a8" stroke-width="3" stroke-linecap="round"/&gt;
            &lt;polyline points="6,26 18,40 30,26" fill="none" stroke="#2563a8" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Display Layer --&gt;
    &lt;div class="layer"&gt;
        &lt;div class="layer-label"&gt;DISPLAY&lt;br&gt;LAYER&lt;/div&gt;
        &lt;div class="layer-components"&gt;
            &lt;div class="component" data-info="graphics-api"&gt;
                &lt;div class="component-title"&gt;Graphics API&lt;/div&gt;
                &lt;div class="component-detail"&gt;OpenGL, DirectX, Metal, Vulkan&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="gpu"&gt;
                &lt;div class="component-title"&gt;GPU Processing&lt;/div&gt;
                &lt;div class="component-detail"&gt;Vertex &amp; fragment shaders&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="frame-buffer"&gt;
                &lt;div class="component-title"&gt;Frame Buffer&lt;/div&gt;
                &lt;div class="component-detail"&gt;Pixel data storage&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="display-controller"&gt;
                &lt;div class="component-title"&gt;Display Controller&lt;/div&gt;
                &lt;div class="component-detail"&gt;HDMI/DisplayPort signal generation&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class="component" data-info="monitor"&gt;
                &lt;div class="component-title"&gt;Monitor&lt;/div&gt;
                &lt;div class="component-detail"&gt;Character visible on screen!&lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="explanation"&gt;
            &lt;h3&gt;What Happens Here&lt;/h3&gt;
            The graphics API sends rendering commands to the GPU, which processes them through shader programs to
            create the final pixels. These pixels are stored in the frame buffer, then sent by the display
            controller through HDMI/DisplayPort to your monitor, where liquid crystals or LEDs illuminate to show
            the character. Success!
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="timeline"&gt;
        Total Time: Typically 10-50 milliseconds from keypress to visible character
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
    // Component explanations database
    const explanations = {
        'key-press': {
            title: 'Key Press - Physical Switch Closure',
            content: `
                &lt;p&gt;When you press a key on your keyboard, you're physically closing an electrical circuit. Most modern keyboards use one of several switch technologies:&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Mechanical switches:&lt;/strong&gt; These use physical metal contacts that close when pressed. They're popular among enthusiasts for their tactile feedback and durability (rated for 50-100 million keypresses).&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Membrane switches:&lt;/strong&gt; These use a rubber dome that presses a conductive trace onto a circuit board. They're quieter and cheaper but less durable.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Scissor switches:&lt;/strong&gt; Common in laptops, these use a scissor-like mechanism to stabilize the key and provide even pressure distribution.&lt;/p&gt;
                
                &lt;p&gt;When the circuit closes, it changes the electrical resistance at that point in the keyboard's matrix, which the controller can detect.&lt;/p&gt;
            `
        },
        'keyboard-controller': {
            title: 'Keyboard Controller - The Brain of Your Keyboard',
            content: `
                &lt;p&gt;The keyboard controller is a small microcontroller or ASIC (Application-Specific Integrated Circuit) embedded in your keyboard. It's essentially a tiny computer dedicated to one job: monitoring key presses.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Key Matrix Scanning:&lt;/strong&gt; To save on wiring, keyboards arrange keys in a matrix (typically 8x16 or similar). The controller continuously scans this matrix by energizing one row at a time and checking which columns show a connection.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Scan Rate:&lt;/strong&gt; Modern keyboards scan at 125-1000 Hz, meaning they check for key presses 125 to 1000 times per second. Gaming keyboards often feature higher scan rates (1000 Hz = 1ms polling rate).&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Intelligent Processing:&lt;/strong&gt; Some advanced keyboards have programmable controllers that can handle macros, key remapping, or RGB lighting effects directly in firmware.&lt;/p&gt;
            `
        },
        'physical-connection': {
            title: 'Physical Connection - Getting Data to Your Computer',
            content: `
                &lt;p&gt;Once the keyboard controller has detected and processed a keypress, it needs to transmit this information to your computer. Several connection methods exist:&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;USB (Universal Serial Bus):&lt;/strong&gt; The most common modern connection. USB keyboards typically operate at "Low Speed" (1.5 Mbps) or "Full Speed" (12 Mbps) - more than enough for keyboard data. USB also provides power to the keyboard.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;PS/2:&lt;/strong&gt; An older connector (introduced in 1987) that's still preferred by some gamers because it supports true N-key rollover and doesn't share bandwidth with other devices. However, it's largely obsolete.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Bluetooth:&lt;/strong&gt; Wireless keyboards use Bluetooth Low Energy to transmit keypresses. This introduces slightly more latency (typically 5-15ms additional) but offers the convenience of wireless operation. The keyboard must manage power consumption to maximize battery life.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;2.4 GHz Wireless:&lt;/strong&gt; Some wireless keyboards use proprietary 2.4 GHz protocols instead of Bluetooth, offering lower latency closer to wired performance.&lt;/p&gt;
            `
        },
        'keyboard-firmware': {
            title: 'Keyboard Firmware - Software on Your Keyboard',
            content: `
                &lt;p&gt;Firmware is permanent software programmed into the keyboard's controller chip. Unlike regular software, it stays in the device even when powered off and controls the keyboard's fundamental operation.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Matrix Scanning Algorithm:&lt;/strong&gt; The firmware contains the logic for scanning the key matrix. It activates one row at a time and reads which columns are connected, building a map of which keys are currently pressed.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Key Mapping:&lt;/strong&gt; The firmware knows the physical layout of keys and can map physical positions to logical key identifiers before sending data to the computer.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Programmable Firmware:&lt;/strong&gt; Some keyboards (like those using QMK or VIA firmware) allow users to reprogram the firmware to customize key behavior, create macros, or modify the keyboard layout without involving the operating system.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Performance Optimization:&lt;/strong&gt; Well-written firmware minimizes latency between physical keypress detection and data transmission to achieve sub-millisecond response times.&lt;/p&gt;
            `
        },
        'debouncing': {
            title: 'Debouncing Logic - Filtering Electrical Noise',
            content: `
                &lt;p&gt;When a mechanical switch closes, it doesn't make a clean electrical connection immediately. The metal contacts actually "bounce" against each other for a few milliseconds, creating multiple rapid on-off signals.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;The Problem:&lt;/strong&gt; Without debouncing, a single keypress could register as multiple keypresses (you'd see "hhhhhello" instead of "hello").&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Software Debouncing:&lt;/strong&gt; The firmware implements a debounce algorithm, typically waiting 5-10 milliseconds after detecting a state change before confirming it as a real keypress. During this window, any additional state changes are ignored.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Hardware Debouncing:&lt;/strong&gt; Some keyboards also include capacitors or other components that smooth out the electrical signal physically, though software debouncing is still usually necessary.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Trade-offs:&lt;/strong&gt; Longer debounce times are more reliable but add latency. Gaming keyboards often use shorter debounce times (2-5ms) to minimize input lag, accepting a slightly higher risk of bounce-related errors.&lt;/p&gt;
            `
        },
        'scan-code': {
            title: 'Scan Code Generation - Creating a Unique Identifier',
            content: `
                &lt;p&gt;After debouncing, the firmware generates a scan code - a unique number that identifies which key was pressed and whether it was pressed or released.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;What is a Scan Code?&lt;/strong&gt; A scan code is a hardware-level identifier specific to the physical position of a key on the keyboard. For example, the physical key in the top-left corner (usually Esc) always generates the same scan code, regardless of keyboard layout.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Make and Break Codes:&lt;/strong&gt; Most systems use separate codes for key-down (make) and key-up (break) events. This allows the operating system to track which keys are currently held down - essential for modifier keys like Shift, Ctrl, and Alt.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Scan Code Sets:&lt;/strong&gt; Historically, there have been different scan code sets (Set 1, Set 2, Set 3). Modern USB keyboards use HID scan codes, which are standardized across all manufacturers.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Extended Scan Codes:&lt;/strong&gt; Some keys (like multimedia keys or the Windows key) require extended scan codes that use multiple bytes to represent keys that weren't in the original PC keyboard specification.&lt;/p&gt;
            `
        },
        'hid-protocol': {
            title: 'HID Protocol Encoding - Packaging for Transmission',
            content: `
                &lt;p&gt;The Human Interface Device (HID) protocol is a USB standard specifically designed for devices like keyboards, mice, and game controllers.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Standardization:&lt;/strong&gt; HID provides a standard way for input devices to communicate with computers without requiring custom drivers. This is why you can plug any USB keyboard into any computer and it "just works."&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Report Structure:&lt;/strong&gt; The keyboard packages scan codes into HID reports - small data packets (typically 8 bytes for keyboards) that describe the current state of the keyboard. A typical report includes:
                - Modifier keys status (Ctrl, Shift, Alt, etc.) - 1 byte
                - Reserved byte - 1 byte  
                - Up to 6 simultaneously pressed keys - 6 bytes&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Polling vs Interrupt:&lt;/strong&gt; USB keyboards typically use interrupt transfers, where the keyboard only sends data when a change occurs. The computer polls the keyboard at regular intervals (every 1-8ms typically) asking "anything new?"&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Boot Protocol:&lt;/strong&gt; HID keyboards also support a simplified "boot protocol" that works even before the full OS loads, allowing you to use your keyboard in BIOS or boot menus.&lt;/p&gt;
            `
        },
        'device-driver': {
            title: 'Device Driver - OS Gateway to Hardware',
            content: `
                &lt;p&gt;A device driver is specialized software that allows the operating system to communicate with hardware devices. For keyboards, this is typically the USB HID driver or a keyboard-specific driver.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Built-in Drivers:&lt;/strong&gt; Modern operating systems include generic HID drivers that work with standard keyboards out of the box. This is why you don't need to install drivers for most keyboards.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Driver Responsibilities:&lt;/strong&gt; The keyboard driver handles low-level communication over the USB bus, processes HID reports from the keyboard, and translates them into a format the operating system can understand.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Custom Drivers:&lt;/strong&gt; Gaming keyboards or keyboards with special features (programmable keys, RGB lighting, macro keys) may include custom drivers that provide enhanced functionality beyond what the standard HID driver supports.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Kernel Space Operation:&lt;/strong&gt; Drivers run in kernel space (privileged mode) with direct hardware access, which is why poorly written drivers can crash your entire system rather than just one application.&lt;/p&gt;
            `
        },
        'interrupt-handler': {
            title: 'Interrupt Handler - High-Priority Event Processing',
            content: `
                &lt;p&gt;When a keyboard sends data to the computer, it triggers a hardware interrupt - a signal that immediately gets the processor's attention, even interrupting whatever else it was doing.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;IRQ (Interrupt Request):&lt;/strong&gt; Each device has an IRQ line. When the keyboard has data, it asserts its IRQ, causing the CPU to save its current state and jump to the interrupt handler code.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Why Interrupts?&lt;/strong&gt; Interrupts ensure keyboard input is processed with minimal delay. Without interrupts, the OS would have to constantly poll the keyboard ("anything new? anything new?"), wasting CPU cycles and adding latency.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Interrupt Service Routine (ISR):&lt;/strong&gt; The interrupt handler is a small, fast piece of code that runs with interrupts disabled. It quickly reads the data from the keyboard, stores it in a buffer, and acknowledges the interrupt so the CPU can resume what it was doing.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Deferred Processing:&lt;/strong&gt; To minimize time spent in the ISR, complex processing is deferred to a later stage (the input subsystem), where it can run with interrupts enabled and be properly scheduled.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Interrupt Priority:&lt;/strong&gt; Keyboard interrupts typically have high priority to ensure responsive input, though not as high as critical system interrupts like timer or disk controller interrupts.&lt;/p&gt;
            `
        },
        'input-subsystem': {
            title: 'Input Subsystem - Event Processing and Queuing',
            content: `
                &lt;p&gt;The input subsystem is the OS component responsible for managing all input events from various devices and making them available to applications in a consistent way.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Event Abstraction:&lt;/strong&gt; The input subsystem converts low-level hardware signals into standardized input events. This abstraction means applications don't need to know whether input came from USB, PS/2, or Bluetooth - they all look the same.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Event Queue:&lt;/strong&gt; Input events are placed in queues where they wait to be processed. This buffering prevents event loss if the system is temporarily busy. However, if events arrive faster than they can be processed, older events may be dropped.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Event Types:&lt;/strong&gt; The subsystem tracks different event types:
                - Key press/release events
                - Repeat events (when a key is held down)
                - Modifier state changes
                - Special key combinations&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Filtering and Translation:&lt;/strong&gt; The input subsystem may filter events (like ignoring very rapid repeated presses) or translate them (handling key repeat timing, processing dead keys for accent marks).&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Security:&lt;/strong&gt; The input subsystem also enforces security policies - for example, preventing applications from capturing keystrokes from other applications without permission (preventing keyloggers).&lt;/p&gt;
            `
        },
        'keyboard-layout': {
            title: 'Keyboard Layout Mapping - From Scan Codes to Characters',
            content: `
                &lt;p&gt;Scan codes identify physical key positions, but users type in different languages and layouts. The keyboard layout mapping translates physical keys to logical characters.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Layout Types:&lt;/strong&gt; Common layouts include QWERTY, DVORAK, AZERTY (French), QWERTZ (German), and many others. The same physical key produces different characters depending on the active layout.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Two-Stage Mapping:&lt;/strong&gt; First, scan codes are mapped to virtual key codes (abstract key identifiers like VK_A, VK_SHIFT). Then, virtual key codes plus modifier state (Shift, Alt, etc.) are mapped to actual characters.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Dead Keys:&lt;/strong&gt; Some layouts use "dead keys" that don't immediately produce a character but modify the next character typed. For example, pressing ´ then e produces é. The keyboard layout mapping must track this state.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Multi-Language Support:&lt;/strong&gt; Users can switch between keyboard layouts (often with Alt+Shift or Windows+Space), allowing them to type in multiple languages on the same physical keyboard.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Custom Layouts:&lt;/strong&gt; Power users can create custom keyboard layouts using tools like Microsoft Keyboard Layout Creator or third-party utilities to optimize for specific use cases (programming, stenography, etc.).&lt;/p&gt;
            `
        },
        'window-manager': {
            title: 'Window Manager / Display Server - Routing Input to Applications',
            content: `
                &lt;p&gt;The window manager or display server is responsible for determining which application should receive input events and coordinating what appears on screen.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Focus Management:&lt;/strong&gt; The window manager tracks which window currently has "focus" - the active window that should receive keyboard input. Only one window can have keyboard focus at a time (though some systems support focus-follows-mouse).&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;X11 (Linux/Unix):&lt;/strong&gt; X Window System uses a client-server model where the X server manages display and input, while applications (X clients) request to draw and receive input events. X has been the standard for decades but has design limitations.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Wayland (Modern Linux):&lt;/strong&gt; A newer protocol that eliminates the X client-server split, giving applications (called Wayland clients) more direct control over their windows while the compositor handles display coordination.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Windows DWM (Desktop Window Manager):&lt;/strong&gt; Introduced in Windows Vista, DWM uses GPU acceleration to composite all windows into the final display, handling effects like transparency and animations.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;macOS Quartz:&lt;/strong&gt; Apple's window manager combines display management with PDF-based rendering, providing smooth graphics and window compositing.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Security:&lt;/strong&gt; The window manager enforces security boundaries - applications can't spy on other applications' windows or capture their input without explicit permission.&lt;/p&gt;
            `
        },
        'ime': {
            title: 'Input Method Editor - Complex Character Composition',
            content: `
                &lt;p&gt;Input Method Editors (IMEs) allow users to type characters that don't have direct keys on the keyboard - crucial for languages like Chinese, Japanese, Korean, and for typing accented characters.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Why IMEs Exist:&lt;/strong&gt; Languages like Chinese have thousands of characters - far too many for a keyboard. IMEs let users type phonetically or using other input methods, then select the intended character from candidates.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Chinese Input:&lt;/strong&gt; Users can type using Pinyin (romanization) or other systems. For example, typing "ni" might show candidates: 你 (you), 尼 (Buddhist nun), 泥 (mud), etc. The user selects the intended character.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Japanese Input:&lt;/strong&gt; Users type in Romaji (Latin alphabet) which is converted to Hiragana, then can convert to Kanji. For example, "konnnichiwa" → "こんにちは" → "今日は"&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Predictive Input:&lt;/strong&gt; Modern IMEs use machine learning to predict which character the user intends based on context, dramatically speeding up input.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Accented Characters:&lt;/strong&gt; Even for European languages, IMEs help type accented characters. You might type ' + e to get é, or use a picker to select from various accent marks.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Composition Window:&lt;/strong&gt; IMEs typically show a small window near the cursor displaying the current input state and candidate characters, providing real-time feedback.&lt;/p&gt;
            `
        },
        'active-app': {
            title: 'Active Application - Event Queue and Focus',
            content: `
                &lt;p&gt;The active application is the program that currently has focus and will receive keyboard input. It manages its own event queue and determines how to respond to input.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Event Queue:&lt;/strong&gt; Each application has an event queue (or message queue) where input events, window events, timer events, and other messages wait to be processed. The application's main event loop continuously processes events from this queue.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Event Loop:&lt;/strong&gt; A typical event loop looks like:
                1. Wait for next event
                2. Dispatch event to appropriate handler
                3. Execute handler code
                4. Return to step 1
                This continues for the entire lifetime of the application.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Focus Tracking:&lt;/strong&gt; Applications receive focus events (WM_SETFOCUS, FocusIn) when they become active and lose-focus events when they become inactive. This allows apps to provide visual feedback (like highlighting the title bar) and control behavior.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Event Filtering:&lt;/strong&gt; Applications can filter which events they care about. A game might only care about certain keys, while a text editor needs to process all character input.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Blocked Event Loop:&lt;/strong&gt; If an application's event loop is blocked (doing intensive processing), it can't process new events, leading to the "not responding" state where the app appears frozen and doesn't respond to input.&lt;/p&gt;
            `
        },
        'event-handler': {
            title: 'Event Handler - Processing Keypress Events',
            content: `
                &lt;p&gt;Event handlers are functions within an application that respond to specific events - in this case, keyboard input events.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Event-Driven Programming:&lt;/strong&gt; Modern applications are event-driven - instead of running in a straight line, they wait for events (user input, network data, timer ticks) and respond to each event with the appropriate handler.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Handler Registration:&lt;/strong&gt; Applications register handlers for events they care about. For example, a text box widget registers a keypress handler to insert typed characters.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Event Object:&lt;/strong&gt; Handlers receive an event object containing detailed information:
                - Which key was pressed (key code)
                - Character value (after layout mapping)
                - Modifier state (Shift, Ctrl, Alt)
                - Timestamp
                - Repeat count (if key is held)&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Event Propagation:&lt;/strong&gt; Events often "bubble" through a hierarchy. A keypress might first go to a text field, then to the containing form, then to the window. Handlers can stop propagation if they've handled the event.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Shortcuts and Hotkeys:&lt;/strong&gt; Handlers can implement keyboard shortcuts by checking for specific key combinations (Ctrl+S for save, Ctrl+C for copy, etc.) and executing the corresponding action.&lt;/p&gt;
            `
        },
        'text-buffer': {
            title: 'Text Buffer - Managing Document Content',
            content: `
                &lt;p&gt;The text buffer is the in-memory data structure that holds the actual content of your document - all the characters you've typed.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Buffer Data Structures:&lt;/strong&gt; Text buffers use sophisticated data structures optimized for editing operations:
                - Gap buffers: Keep a "gap" at the cursor position for fast insertion
                - Rope data structure: Tree of strings for efficient editing of large documents
                - Piece tables: Track changes as a list of pieces from original and added text&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Cursor Management:&lt;/strong&gt; The buffer tracks cursor position(s) - where new characters will be inserted. Advanced editors support multiple cursors for simultaneous editing at different locations.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Undo/Redo:&lt;/strong&gt; Text buffers maintain history of changes to support undo/redo functionality. This is often implemented as a stack of operations or using the Command pattern.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Text Encoding:&lt;/strong&gt; The buffer stores text in a specific encoding (usually UTF-8 or UTF-16). This determines how characters are represented in memory - a single character might be 1, 2, 3, or even 4 bytes depending on the character and encoding.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Syntax Highlighting:&lt;/strong&gt; In code editors, the text buffer is often paired with a parser that tokenizes the text to enable syntax highlighting, showing keywords, strings, and comments in different colors.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Performance:&lt;/strong&gt; For large documents, efficient buffer implementation is crucial. Operations like insertion, deletion, and searching need to be fast even for documents with millions of characters.&lt;/p&gt;
            `
        },
        'rendering-engine': {
            title: 'Text Rendering Engine - Making Text Visible',
            content: `
                &lt;p&gt;The text rendering engine takes characters from the text buffer and determines how to draw them visually on screen with proper fonts, spacing, and styling.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Font Rasterization:&lt;/strong&gt; Fonts are stored as vector outlines (TrueType, OpenType). The rendering engine converts these outlines into pixel patterns at the appropriate size - a process called rasterization. Modern systems cache rasterized glyphs for performance.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Anti-aliasing:&lt;/strong&gt; To make text look smooth rather than jagged, rendering engines use anti-aliasing - adding semi-transparent pixels at the edges of glyphs. Techniques include grayscale anti-aliasing and subpixel rendering (ClearType on Windows, which uses the RGB subpixels of LCD screens).&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Text Layout:&lt;/strong&gt; The engine must:
                - Calculate glyph positions (with proper kerning - spacing between specific letter pairs)
                - Handle line breaking and word wrapping
                - Apply text formatting (bold, italic, underline, color)
                - Handle bidirectional text (mixing left-to-right and right-to-left languages)
                - Position combining characters (accents) correctly&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Font Fallback:&lt;/strong&gt; If a character isn't in the current font, the engine searches fallback fonts. This is how you can display emoji or Chinese characters even when using a Western font.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Performance Optimization:&lt;/strong&gt; Text rendering is expensive, so engines use caching extensively:
                - Glyph caching (rasterized characters)
                - Layout caching (already-calculated line breaks and positions)
                - Only re-render changed portions when editing&lt;/p&gt;
            `
        },
        'graphics-api': {
            title: 'Graphics API - Standardized Interface to GPU',
            content: `
                &lt;p&gt;Graphics APIs provide a standardized way for applications to communicate with the GPU (Graphics Processing Unit) and draw graphics on screen.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;OpenGL:&lt;/strong&gt; Cross-platform graphics API developed in the early 1990s. It's widely supported but has accumulated legacy cruft over decades. Still popular for portable applications and Linux.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;DirectX (Direct3D):&lt;/strong&gt; Microsoft's graphics API for Windows and Xbox. Direct3D 11 is mature and stable; Direct3D 12 offers lower-level control for better performance but is harder to use. Industry standard for Windows gaming.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Metal:&lt;/strong&gt; Apple's modern graphics API for macOS, iOS, and other Apple platforms. Designed from scratch for modern GPUs with low overhead and tight integration with Apple hardware.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Vulkan:&lt;/strong&gt; Modern cross-platform API designed as OpenGL's successor. Offers low-level control similar to DirectX 12 and Metal, enabling maximum performance but requiring more complex code.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Abstraction Layers:&lt;/strong&gt; Many applications use higher-level frameworks (like Qt, SDL, or game engines) that abstract away the specific graphics API, letting developers write once and run on any platform.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Command Buffers:&lt;/strong&gt; Modern APIs work by building lists of commands (draw this triangle, use this texture, etc.) that are submitted to the GPU in batches for efficiency rather than sending commands one at a time.&lt;/p&gt;
            `
        },
        'gpu': {
            title: 'GPU Processing - Parallel Graphics Computation',
            content: `
                &lt;p&gt;The GPU (Graphics Processing Unit) is a specialized processor designed for parallel processing of graphics operations, with thousands of small cores instead of a few powerful cores like a CPU.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Vertex Shaders:&lt;/strong&gt; The first stage processes vertices (corner points) of geometry. For text rendering, each glyph (character) is typically represented as a rectangular quad (two triangles). The vertex shader transforms these from text-buffer coordinates to screen coordinates.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Fragment Shaders (Pixel Shaders):&lt;/strong&gt; For each pixel that might be covered by the geometry, the fragment shader runs to determine the final pixel color. For text, this involves:
                - Sampling the font texture (rasterized glyph image)
                - Applying the text color
                - Handling anti-aliasing (smooth edges)
                - Applying effects (shadows, outlines, etc.)&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Massive Parallelism:&lt;/strong&gt; GPUs can process millions of pixels simultaneously. A modern GPU might have 2,000+ shader cores, each processing different pixels at the same time. This is why they're so fast at graphics despite having slower individual cores than CPUs.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Texture Sampling:&lt;/strong&gt; Font glyphs are stored as textures (images) in GPU memory. The GPU has specialized hardware for efficiently looking up pixel values from textures, with filtering for smooth scaling.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;GPU Pipeline:&lt;/strong&gt; The graphics pipeline includes many stages between vertex and fragment shaders (clipping, rasterization, depth testing, blending). The GPU executes this entire pipeline for every frame rendered.&lt;/p&gt;
            `
        },
        'frame-buffer': {
            title: 'Frame Buffer - Temporary Image Storage',
            content: `
                &lt;p&gt;The frame buffer is a region of memory (usually in the GPU's VRAM) that holds the complete pixel data for what will be displayed on screen.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Pixel Format:&lt;/strong&gt; Each pixel in the frame buffer typically stores:
                - Red, Green, Blue color values (8 bits each = 24 bits total for ~16.7 million colors)
                - Alpha (transparency) channel (8 bits)
                - Total: 32 bits (4 bytes) per pixel
                For a 1920x1080 screen, that's about 8 MB of data per frame.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Double Buffering:&lt;/strong&gt; To prevent visual tearing (where part of the screen shows the old frame and part shows the new), systems use double buffering:
                - Front buffer: Currently being displayed
                - Back buffer: Being drawn to
                When drawing is complete, buffers are swapped instantly.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Triple Buffering:&lt;/strong&gt; Some systems use three buffers to improve performance and reduce latency, especially at high refresh rates.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Compositing:&lt;/strong&gt; Modern systems don't draw directly to the final frame buffer. Each window has its own buffer, and the compositor combines them into the final frame buffer, enabling effects like transparency, shadows, and smooth window animations.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Frame Rate:&lt;/strong&gt; The frame buffer is typically refreshed at your monitor's refresh rate (60, 120, 144, or 240 Hz). For smooth typing, you want the character to appear in the next frame after input, giving 16.7ms latency at 60 Hz or 8.3ms at 120 Hz.&lt;/p&gt;
            `
        },
        'display-controller': {
            title: 'Display Controller - Generating Video Signals',
            content: `
                &lt;p&gt;The display controller (also called display driver or timing controller) is hardware that reads pixel data from the frame buffer and generates the exact electrical signals needed to drive the monitor.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Scan-out:&lt;/strong&gt; The controller systematically reads the frame buffer from left-to-right, top-to-bottom, sending pixel data to the monitor. This must happen continuously at the monitor's refresh rate to maintain a stable image.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Display Interfaces:&lt;/strong&gt;
                - HDMI: Consumer standard supporting audio + video, common on TVs and monitors
                - DisplayPort: More advanced standard with higher bandwidth, supports daisy-chaining
                - USB-C (with DisplayPort Alt Mode): Carries DisplayPort signals over USB-C cables
                - DVI: Older digital standard, still seen on some monitors
                - VGA: Ancient analog standard, largely obsolete&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Timings and Modes:&lt;/strong&gt; The controller must generate precise timing signals (horizontal sync, vertical sync) that tell the monitor when each row and frame begins. These timings vary by resolution and refresh rate.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Color Conversion:&lt;/strong&gt; The controller may convert between color spaces (RGB to YCbCr for HDMI) and apply color calibration to match the monitor's characteristics.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Adaptive Sync:&lt;/strong&gt; Technologies like FreeSync and G-Sync allow the display controller to vary the refresh rate dynamically to match the GPU's frame output rate, eliminating tearing and stuttering.&lt;/p&gt;
            `
        },
        'monitor': {
            title: 'Monitor - Final Display of Your Character',
            content: `
                &lt;p&gt;The monitor is the final destination - it receives digital signals from the display controller and converts them into visible light that your eyes can see.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;LCD (Liquid Crystal Display):&lt;/strong&gt; Most common monitor type. Each pixel contains liquid crystals that twist to control light passing through:
                - Backlight provides white light
                - Liquid crystals block or transmit light for each subpixel (R, G, B)
                - Color filters produce the final color
                Response times: typically 1-5ms gray-to-gray&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;OLED (Organic LED):&lt;/strong&gt; Each pixel is a self-emitting organic LED. Advantages include perfect blacks (pixels can turn completely off), infinite contrast, and faster response times. Used in premium monitors and most smartphones.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Refresh Rate:&lt;/strong&gt; How many times per second the monitor updates the image (60 Hz, 120 Hz, 144 Hz, 240 Hz, or even higher). Higher refresh rates reduce perceived latency and motion blur.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Response Time:&lt;/strong&gt; How quickly pixels can change color. Important for gaming to reduce ghosting (trails behind moving objects).&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Resolution and Pixel Density:&lt;/strong&gt; 
                - 1920x1080 (Full HD)
                - 2560x1440 (QHD)  
                - 3840x2160 (4K UHD)
                Higher resolution means more pixels, requiring more frame buffer memory and GPU power.&lt;/p&gt;
                
                &lt;p&gt;&lt;strong&gt;Success!&lt;/strong&gt; After this entire journey through hardware, firmware, operating system, application, and display layers - typically taking just 10-50 milliseconds - your character finally appears on screen, ready for you to see!&lt;/p&gt;
            `
        }
    };

    // Get modal elements
    const modal = document.getElementById('modal');
    const modalTitle = document.getElementById('modal-title');
    const modalBody = document.getElementById('modal-body');
    const closeBtn = document.querySelector('.close');

    // Add click event listeners to all components
    document.querySelectorAll('.component').forEach(component =&gt; {
        component.addEventListener('click', function () {
            const infoKey = this.getAttribute('data-info');
            const info = explanations[infoKey];

            if (info) {
                modalTitle.textContent = info.title;
                modalBody.innerHTML = info.content;
                modal.style.display = 'block';
            }
        });
    });

    // Close modal when clicking the X
    closeBtn.addEventListener('click', function () {
        modal.style.display = 'none';
    });

    // Close modal when clicking outside of it
    window.addEventListener('click', function (event) {
        if (event.target === modal) {
            modal.style.display = 'none';
        }
    });

    // Close modal with Escape key
    document.addEventListener('keydown', function (event) {
        if (event.key === 'Escape' &amp;&amp; modal.style.display === 'block') {
            modal.style.display = 'none';
        }
    });
&lt;/script&gt;
</code></pre>

</div>
</body></style></head><div style="break-before: page; page-break-before: always;"></div>
<h1 id="multithreaded-executable"><a href="#multithreaded-executable" class="header">Multithreaded Executable</a></h1>

<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Running a Multithreaded Executable on Linux</title>
  <style>
    /* ── Reset & base ──────────────────────────────────────────────── */
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }
<pre><code>body {
  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
  background: linear-gradient(135deg, #0d1b2a 0%, #1a2f4e 50%, #0d1b2a 100%);
  min-height: 100vh;
  padding: 30px 20px 60px;
  color: #2d3748;
}

/* ── Outer container ───────────────────────────────────────────── */
.container {
  max-width: 1500px;
  margin: 0 auto;
  background: #f8fafc;
  border-radius: 20px;
  padding: 44px 48px 60px;
  box-shadow: 0 24px 72px rgba(0,0,0,0.45);
}

h1 {
  text-align: center;
  font-size: 2.2em;
  font-weight: 700;
  color: #1a2f4e;
  margin-bottom: 6px;
  letter-spacing: -0.5px;
}

.subtitle {
  text-align: center;
  color: #718096;
  font-size: 1em;
  margin-bottom: 36px;
}

/* ── Legend ────────────────────────────────────────────────────── */
.legend {
  display: flex;
  flex-wrap: wrap;
  gap: 14px;
  justify-content: center;
  margin-bottom: 38px;
  padding: 16px 24px;
  background: #edf2f7;
  border-radius: 12px;
  border: 1px solid #e2e8f0;
}

.legend-item {
  display: flex;
  align-items: center;
  gap: 8px;
  font-size: 0.82em;
  font-weight: 600;
  color: #4a5568;
}

.legend-dot {
  width: 14px;
  height: 14px;
  border-radius: 4px;
  flex-shrink: 0;
}

/* ── Section rows ──────────────────────────────────────────────── */
/*
 * Each .section is a horizontal band with:
 *   col 1: band label (180px)
 *   col 2: clickable components (fills remaining space)
 *   col 3: right-side annotation (300px)
 */
.section {
  display: grid;
  grid-template-columns: 180px 1fr 300px;
  gap: 20px;
  margin-bottom: 6px;
  align-items: start;
}

.section-label {
  display: flex;
  align-items: center;
  justify-content: center;
  text-align: center;
  border-radius: 12px;
  padding: 14px 10px;
  color: #fff;
  font-size: 0.78em;
  font-weight: 700;
  letter-spacing: 0.06em;
  text-transform: uppercase;
  min-height: 60px;
  box-shadow: 0 4px 12px rgba(0,0,0,0.2);
}

.section-components {
  display: flex;
  flex-wrap: wrap;
  gap: 10px;
  align-items: flex-start;
  align-content: flex-start;
  padding: 10px 0;
}

.section-note {
  font-size: 0.78em;
  color: #718096;
  line-height: 1.55;
  padding: 10px 0;
  border-left: 3px solid #e2e8f0;
  padding-left: 14px;
}

/* ── Clickable component boxes ─────────────────────────────────── */
.comp {
  background: #fff;
  border: 2px solid #e2e8f0;
  border-radius: 10px;
  padding: 11px 16px;
  cursor: pointer;
  transition: all 0.25s ease;
  font-size: 0.82em;
  font-weight: 600;
  color: #2d3748;
  line-height: 1.3;
  position: relative;
  min-width: 120px;
}

.comp:hover {
  transform: translateY(-3px);
  box-shadow: 0 8px 20px rgba(0,0,0,0.12);
}

.comp .comp-sub {
  font-size: 0.78em;
  font-weight: 400;
  color: #a0aec0;
  display: block;
  margin-top: 2px;
}

/* Click hint badge */
.comp::after {
  content: 'click';
  position: absolute;
  top: 5px;
  right: 7px;
  font-size: 0.6em;
  font-weight: 600;
  letter-spacing: 0.08em;
  color: #a0aec0;
  text-transform: uppercase;
  opacity: 0;
  transition: opacity 0.2s;
}
.comp:hover::after { opacity: 1; }

/* ── Color variants for comp borders &amp; hover ───────────────────── */
/* user-space  → teal */
.comp.user    { border-color: #b2f5ea; }
.comp.user:hover  { border-color: #38b2ac; box-shadow: 0 8px 20px rgba(56,178,172,0.18); }

/* kernel-space → indigo */
.comp.kernel  { border-color: #c3dafe; }
.comp.kernel:hover { border-color: #667eea; box-shadow: 0 8px 20px rgba(102,126,234,0.18); }

/* memory → amber */
.comp.mem     { border-color: #feebc8; }
.comp.mem:hover   { border-color: #ed8936; box-shadow: 0 8px 20px rgba(237,137,54,0.18); }

/* hardware → rose */
.comp.hw      { border-color: #fed7d7; }
.comp.hw:hover    { border-color: #e53e3e; box-shadow: 0 8px 20px rgba(229,62,62,0.18); }

/* scheduler → purple */
.comp.sched   { border-color: #e9d8fd; }
.comp.sched:hover { border-color: #805ad5; box-shadow: 0 8px 20px rgba(128,90,213,0.18); }

/* elf / loader → green */
.comp.elf     { border-color: #c6f6d5; }
.comp.elf:hover   { border-color: #38a169; box-shadow: 0 8px 20px rgba(56,161,105,0.18); }

/* ── Section label color themes ────────────────────────────────── */
.label-user    { background: linear-gradient(135deg, #2c7a7b, #38b2ac); }
.label-loader  { background: linear-gradient(135deg, #276749, #38a169); }
.label-vmem    { background: linear-gradient(135deg, #975a16, #ed8936); }
.label-kernel  { background: linear-gradient(135deg, #434190, #667eea); }
.label-sched   { background: linear-gradient(135deg, #553c9a, #805ad5); }
.label-sync    { background: linear-gradient(135deg, #285e61, #319795); }
.label-syscall { background: linear-gradient(135deg, #2b6cb0, #4299e1); }
.label-hw      { background: linear-gradient(135deg, #9b2c2c, #e53e3e); }

/* ── Inter-section arrows ──────────────────────────────────────── */
.arrow {
  display: flex;
  justify-content: center;
  align-items: center;
  margin: 2px 0;
  /* aligns with the components column */
  padding-left: 200px;
}

/* ── Special: thread swimlanes ─────────────────────────────────── */
.swimlanes {
  display: flex;
  gap: 10px;
  flex: 1;
  padding: 10px 0;
}

.thread-lane {
  flex: 1;
  border: 2px solid #e9d8fd;
  border-radius: 10px;
  padding: 10px 12px;
  background: #faf5ff;
  min-width: 130px;
}

.thread-lane:hover {
  border-color: #805ad5;
  box-shadow: 0 8px 20px rgba(128,90,213,0.15);
  cursor: pointer;
}

.thread-lane-title {
  font-size: 0.75em;
  font-weight: 700;
  color: #805ad5;
  text-transform: uppercase;
  letter-spacing: 0.08em;
  margin-bottom: 6px;
}

.thread-lane-item {
  font-size: 0.75em;
  color: #4a5568;
  padding: 3px 0;
  border-bottom: 1px solid #e9d8fd;
}

.thread-lane-item:last-child { border-bottom: none; }

/* ── Memory map strip ──────────────────────────────────────────── */
.memmap {
  display: flex;
  flex-direction: column;
  gap: 3px;
  width: 100%;
}

.memmap-row {
  display: flex;
  align-items: center;
  gap: 8px;
  cursor: pointer;
  padding: 7px 12px;
  border-radius: 8px;
  border: 2px solid transparent;
  transition: all 0.22s ease;
  background: #fff;
}

.memmap-row:hover {
  border-color: #ed8936;
  box-shadow: 0 4px 12px rgba(237,137,54,0.15);
  transform: translateX(4px);
}

.memmap-addr {
  font-family: 'Courier New', monospace;
  font-size: 0.7em;
  color: #a0aec0;
  width: 110px;
  flex-shrink: 0;
}

.memmap-bar {
  height: 22px;
  border-radius: 5px;
  flex-shrink: 0;
}

.memmap-name {
  font-size: 0.78em;
  font-weight: 600;
  color: #2d3748;
}

/* ── ELF section strip ─────────────────────────────────────────── */
.elf-strip {
  display: flex;
  gap: 6px;
  flex-wrap: wrap;
  padding: 10px 0;
}

.elf-section {
  border-radius: 8px;
  padding: 9px 14px;
  font-size: 0.78em;
  font-weight: 700;
  cursor: pointer;
  transition: all 0.22s ease;
  color: #fff;
}

.elf-section:hover {
  transform: translateY(-3px);
  box-shadow: 0 8px 18px rgba(0,0,0,0.2);
}

/* ── Modal ─────────────────────────────────────────────────────── */
.modal {
  display: none;
  position: fixed;
  z-index: 1000;
  left: 0; top: 0;
  width: 100%; height: 100%;
  background: rgba(0,0,0,0.6);
  animation: fadeIn 0.25s ease;
}

.modal-content {
  background: #fff;
  margin: 7% auto;
  padding: 40px 44px;
  border-radius: 16px;
  width: 82%;
  max-width: 740px;
  max-height: 82vh;
  overflow-y: auto;
  box-shadow: 0 24px 72px rgba(0,0,0,0.35);
  animation: slideIn 0.25s ease;
  position: relative;
}

.modal-title {
  font-size: 1.4em;
  font-weight: 700;
  color: #1a2f4e;
  margin-bottom: 18px;
  padding-right: 36px;
}

.modal-body {
  font-size: 0.9em;
  line-height: 1.7;
  color: #4a5568;
}

.modal-body p { margin-bottom: 12px; }
.modal-body ul { padding-left: 20px; margin-bottom: 12px; }
.modal-body li { margin-bottom: 6px; }
.modal-body strong { color: #2d3748; }

.modal-body .tools {
  margin-top: 18px;
  background: #f0fff4;
  border: 1px solid #c6f6d5;
  border-radius: 10px;
  padding: 14px 18px;
}

.modal-body .tools-title {
  font-size: 0.8em;
  font-weight: 700;
  text-transform: uppercase;
  letter-spacing: 0.08em;
  color: #276749;
  margin-bottom: 8px;
}

.modal-body code {
  font-family: 'Courier New', monospace;
  font-size: 0.88em;
  background: #edf2f7;
  border-radius: 4px;
  padding: 1px 6px;
  color: #2b6cb0;
}

.modal-body pre {
  font-family: 'Courier New', monospace;
  font-size: 0.82em;
  background: #1a202c;
  color: #e2e8f0;
  border-radius: 8px;
  padding: 14px 18px;
  overflow-x: auto;
  margin: 10px 0;
  line-height: 1.5;
}

.close {
  position: absolute;
  right: 18px;
  top: 16px;
  font-size: 30px;
  cursor: pointer;
  color: #a0aec0;
  line-height: 1;
  transition: color 0.2s;
}
.close:hover { color: #2d3748; }

@keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
@keyframes slideIn {
  from { transform: translateY(-40px); opacity: 0; }
  to   { transform: translateY(0);     opacity: 1; }
}

/* ── Divider ───────────────────────────────────────────────────── */
.divider {
  border: none;
  border-top: 2px dashed #e2e8f0;
  margin: 22px 0;
}

/* ── Responsive ────────────────────────────────────────────────── */
@media (max-width: 1024px) {
  .section { grid-template-columns: 150px 1fr 220px; gap: 14px; }
  .container { padding: 28px 24px 40px; }
  h1 { font-size: 1.7em; }
}

@media (max-width: 768px) {
  .section { grid-template-columns: 1fr; }
  .section-label { min-height: unset; }
  .section-note { border-left: none; border-top: 3px solid #e2e8f0; padding-left: 0; padding-top: 10px; }
  .arrow { padding-left: 0; }
  .modal-content { width: 95%; margin: 5% auto; padding: 24px 20px; }
  .swimlanes { flex-wrap: wrap; }
  h1 { font-size: 1.4em; }
}
</code></pre>
  </style>
</head>
<body>
<!-- ── Modal overlay ──────────────────────────────────────────────── -->
<div id="modal-5" class="modal">
  
<div class="modal-content">
    <span class="close" id="modal-close">×</span>
    
<h2 class="modal-title" id="modal-title-5"></h2>

    
<div class="modal-body" id="modal-body-5"></div>

  </div>

</div>

<!-- ── Main container ─────────────────────────────────────────────── -->
<div class="container">
  
<h1>Running a Multithreaded Executable on Linux</h1>

  
<p class="subtitle">From ELF on disk to threads on CPU — click any component to explore</p>

  <!-- Legend -->
  
<div class="legend">
    
<div class="legend-item">
<div class="legend-dot" style="background:#38b2ac"></div>
User Space</div>

    
<div class="legend-item">
<div class="legend-dot" style="background:#38a169"></div>
ELF / Loader</div>

    
<div class="legend-item">
<div class="legend-dot" style="background:#ed8936"></div>
Virtual Memory</div>

    
<div class="legend-item">
<div class="legend-dot" style="background:#667eea"></div>
Kernel Space</div>

    
<div class="legend-item">
<div class="legend-dot" style="background:#805ad5"></div>
Scheduler</div>

    
<div class="legend-item">
<div class="legend-dot" style="background:#319795"></div>
Sync / IPC</div>

    
<div class="legend-item">
<div class="legend-dot" style="background:#4299e1"></div>
System Calls</div>

    
<div class="legend-item">
<div class="legend-dot" style="background:#e53e3e"></div>
Hardware</div>

  </div>

  <!-- ════════════════════════════════════════════════════════════════
       SECTION 1 — ELF File on Disk
       ════════════════════════════════════════════════════════════════ -->
  
<div class="section">
    
<div class="section-label label-loader">ELF File<br>on Disk</div>

<pre><code>&lt;div class="section-components"&gt;
  &lt;div class="elf-strip"&gt;
    &lt;div class="elf-section" style="background:#2b6cb0"     data-info="elf-header"&gt;ELF Header&lt;/div&gt;
    &lt;div class="elf-section" style="background:#2c7a7b"     data-info="elf-phdrs"&gt;Program Headers&lt;/div&gt;
    &lt;div class="elf-section" style="background:#276749"     data-info="elf-text"&gt;.text&lt;/div&gt;
    &lt;div class="elf-section" style="background:#285e61"     data-info="elf-rodata"&gt;.rodata&lt;/div&gt;
    &lt;div class="elf-section" style="background:#975a16"     data-info="elf-data"&gt;.data&lt;/div&gt;
    &lt;div class="elf-section" style="background:#744210"     data-info="elf-bss"&gt;.bss&lt;/div&gt;
    &lt;div class="elf-section" style="background:#553c9a"     data-info="elf-dynamic"&gt;.dynamic / .plt / .got&lt;/div&gt;
    &lt;div class="elf-section" style="background:#702459"     data-info="elf-debug"&gt;.debug_*&lt;/div&gt;
    &lt;div class="elf-section" style="background:#4a5568"     data-info="elf-shdrs"&gt;Section Headers&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;div class="section-note"&gt;
  An ELF binary is divided into &lt;strong&gt;segments&lt;/strong&gt; (runtime view via program headers)
  and &lt;strong&gt;sections&lt;/strong&gt; (link-time view via section headers).
  The kernel only cares about segments when loading.
&lt;/div&gt;
</code></pre>
  </div>

  
<div class="arrow">
    <svg width="36" height="40"><line x1="18" y1="0" x2="18" y2="28" stroke="#a0aec0" stroke-width="2.5" stroke-dasharray="5,3" /><polyline points="8,20 18,34 28,20" fill="none" stroke="#a0aec0" stroke-width="2.5" /></svg>
  </div>

  <!-- ════════════════════════════════════════════════════════════════
       SECTION 2 — execve + Dynamic Linker
       ════════════════════════════════════════════════════════════════ -->
  
<div class="section">
    
<div class="section-label label-loader">execve &amp;<br>Dynamic Linker</div>

<pre><code>&lt;div class="section-components"&gt;
  &lt;div class="comp elf" data-info="execve"&gt;&lt;code style="font-family:monospace;font-size:0.9em"&gt;execve(2)&lt;/code&gt;&lt;span class="comp-sub"&gt;kernel entry point&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp elf" data-info="binfmt"&gt;binfmt_elf handler&lt;span class="comp-sub"&gt;kernel parses ELF headers&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp elf" data-info="ldso"&gt;ld-linux.so&lt;span class="comp-sub"&gt;dynamic linker/loader&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp elf" data-info="relocation"&gt;Relocation&lt;span class="comp-sub"&gt;PLT / GOT patching&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp elf" data-info="ldpreload"&gt;LD_PRELOAD / LD_AUDIT&lt;span class="comp-sub"&gt;interposition hooks&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp elf" data-info="init-fini"&gt;.init_array / .fini_array&lt;span class="comp-sub"&gt;ctors &amp;amp; dtors&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp elf" data-info="vdso"&gt;vDSO mapping&lt;span class="comp-sub"&gt;fast syscall page&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div class="section-note"&gt;
  &lt;code&gt;execve&lt;/code&gt; replaces the process image. The kernel maps ELF segments, sets up the initial stack with &lt;code&gt;argc/argv/envp/auxv&lt;/code&gt;, then jumps to the dynamic linker's entry point.
&lt;/div&gt;
</code></pre>
  </div>

  
<div class="arrow">
    <svg width="36" height="40"><line x1="18" y1="0" x2="18" y2="28" stroke="#a0aec0" stroke-width="2.5" stroke-dasharray="5,3" /><polyline points="8,20 18,34 28,20" fill="none" stroke="#a0aec0" stroke-width="2.5" /></svg>
  </div>

  <!-- ════════════════════════════════════════════════════════════════
       SECTION 3 — Virtual Address Space
       ════════════════════════════════════════════════════════════════ -->
  
<div class="section">
    
<div class="section-label label-vmem">Virtual<br>Address Space</div>

<pre><code>&lt;div class="section-components" style="flex-direction:column; width:100%"&gt;
  &lt;div class="memmap"&gt;
    &lt;div class="memmap-row" data-info="vma-stack"&gt;
      &lt;span class="memmap-addr"&gt;0x7fff…&lt;/span&gt;
      &lt;div class="memmap-bar" style="width:140px; background:#e53e3e"&gt;&lt;/div&gt;
      &lt;span class="memmap-name"&gt;Stack (per-thread) &amp;darr; grows down&lt;/span&gt;
    &lt;/div&gt;
    &lt;div class="memmap-row" data-info="vma-mmap"&gt;
      &lt;span class="memmap-addr"&gt;0x7f00…&lt;/span&gt;
      &lt;div class="memmap-bar" style="width:190px; background:#805ad5"&gt;&lt;/div&gt;
      &lt;span class="memmap-name"&gt;mmap region — shared libs, anonymous, files&lt;/span&gt;
    &lt;/div&gt;
    &lt;div class="memmap-row" data-info="vma-heap"&gt;
      &lt;span class="memmap-addr"&gt;0x0055…+&lt;/span&gt;
      &lt;div class="memmap-bar" style="width:100px; background:#ed8936"&gt;&lt;/div&gt;
      &lt;span class="memmap-name"&gt;Heap &amp;uarr; grows up (brk / mmap)&lt;/span&gt;
    &lt;/div&gt;
    &lt;div class="memmap-row" data-info="vma-bss"&gt;
      &lt;span class="memmap-addr"&gt;0x0055…&lt;/span&gt;
      &lt;div class="memmap-bar" style="width:60px; background:#744210"&gt;&lt;/div&gt;
      &lt;span class="memmap-name"&gt;.bss — zero-init data (CoW zero page)&lt;/span&gt;
    &lt;/div&gt;
    &lt;div class="memmap-row" data-info="vma-data"&gt;
      &lt;span class="memmap-addr"&gt;0x0055…&lt;/span&gt;
      &lt;div class="memmap-bar" style="width:70px; background:#975a16"&gt;&lt;/div&gt;
      &lt;span class="memmap-name"&gt;.data — initialised globals (RW)&lt;/span&gt;
    &lt;/div&gt;
    &lt;div class="memmap-row" data-info="vma-rodata"&gt;
      &lt;span class="memmap-addr"&gt;0x0055…&lt;/span&gt;
      &lt;div class="memmap-bar" style="width:80px; background:#285e61"&gt;&lt;/div&gt;
      &lt;span class="memmap-name"&gt;.rodata — read-only constants (R)&lt;/span&gt;
    &lt;/div&gt;
    &lt;div class="memmap-row" data-info="vma-text"&gt;
      &lt;span class="memmap-addr"&gt;0x0040…&lt;/span&gt;
      &lt;div class="memmap-bar" style="width:110px; background:#276749"&gt;&lt;/div&gt;
      &lt;span class="memmap-name"&gt;.text — executable code (RX)&lt;/span&gt;
    &lt;/div&gt;
    &lt;div class="memmap-row" data-info="vma-vdso"&gt;
      &lt;span class="memmap-addr"&gt;[vdso]&lt;/span&gt;
      &lt;div class="memmap-bar" style="width:50px; background:#4299e1"&gt;&lt;/div&gt;
      &lt;span class="memmap-name"&gt;vDSO — kernel-mapped fast-path page&lt;/span&gt;
    &lt;/div&gt;
    &lt;div class="memmap-row" data-info="vma-vsyscall"&gt;
      &lt;span class="memmap-addr"&gt;0xffff…&lt;/span&gt;
      &lt;div class="memmap-bar" style="width:40px; background:#434190"&gt;&lt;/div&gt;
      &lt;span class="memmap-name"&gt;[vsyscall] — legacy compat page&lt;/span&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;div class="section-note"&gt;
  Each VMA (&lt;code&gt;vm_area_struct&lt;/code&gt;) tracks permissions, file backing, and CoW state.
  ASLR randomises base addresses. &lt;code&gt;/proc/&amp;lt;pid&amp;gt;/maps&lt;/code&gt; lists all VMAs live.
&lt;/div&gt;
</code></pre>
  </div>

  
<div class="arrow">
    <svg width="36" height="40"><line x1="18" y1="0" x2="18" y2="28" stroke="#a0aec0" stroke-width="2.5" stroke-dasharray="5,3" /><polyline points="8,20 18,34 28,20" fill="none" stroke="#a0aec0" stroke-width="2.5" /></svg>
  </div>

  <!-- ════════════════════════════════════════════════════════════════
       SECTION 4 — Threads (user-space view)
       ════════════════════════════════════════════════════════════════ -->
  
<div class="section">
    
<div class="section-label label-sched">Threads<br>(user view)</div>

<pre><code>&lt;div class="section-components" style="flex-direction:column; width:100%"&gt;
  &lt;div style="display:flex; gap:10px; flex-wrap:wrap; padding:10px 0"&gt;
    &lt;!-- Main thread --&gt;
    &lt;div class="thread-lane" data-info="thread-main" style="flex:1.2"&gt;
      &lt;div class="thread-lane-title"&gt;Main Thread (TID=PID)&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;pthread_create() origin&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;Stack: argv, env, auxv&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;Signal handler default&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;TLS block 0&lt;/div&gt;
    &lt;/div&gt;
    &lt;!-- Worker threads --&gt;
    &lt;div class="thread-lane" data-info="thread-worker" style="flex:1"&gt;
      &lt;div class="thread-lane-title"&gt;Worker Thread N&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;clone(CLONE_VM|…)&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;Private stack (mmap)&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;Shared heap/globals&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;Own TLS block&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="thread-lane" data-info="thread-worker" style="flex:1"&gt;
      &lt;div class="thread-lane-title"&gt;Worker Thread N+1&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;clone(CLONE_VM|…)&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;Private stack (mmap)&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;Shared heap/globals&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;Own TLS block&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="thread-lane" data-info="thread-tls" style="flex:1"&gt;
      &lt;div class="thread-lane-title"&gt;TLS (Thread-Local Storage)&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;__thread / _Thread_local&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;FS register base&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;pthread_self() ptr&lt;/div&gt;
      &lt;div class="thread-lane-item"&gt;errno lives here&lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;!-- pthread constructs --&gt;
  &lt;div style="display:flex; gap:10px; flex-wrap:wrap; padding:4px 0 10px"&gt;
    &lt;div class="comp user" data-info="pthread-mutex"&gt;pthread_mutex&lt;span class="comp-sub"&gt;futex-backed lock&lt;/span&gt;&lt;/div&gt;
    &lt;div class="comp user" data-info="pthread-condvar"&gt;pthread_cond&lt;span class="comp-sub"&gt;condition variable&lt;/span&gt;&lt;/div&gt;
    &lt;div class="comp user" data-info="pthread-rwlock"&gt;pthread_rwlock&lt;span class="comp-sub"&gt;readers-writer lock&lt;/span&gt;&lt;/div&gt;
    &lt;div class="comp user" data-info="pthread-barrier"&gt;pthread_barrier&lt;span class="comp-sub"&gt;rendezvous point&lt;/span&gt;&lt;/div&gt;
    &lt;div class="comp user" data-info="pthread-sem"&gt;sem_t&lt;span class="comp-sub"&gt;POSIX semaphore&lt;/span&gt;&lt;/div&gt;
    &lt;div class="comp user" data-info="thread-cancel"&gt;Thread cancellation&lt;span class="comp-sub"&gt;deferred / async&lt;/span&gt;&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;div class="section-note"&gt;
  POSIX threads share address space, file descriptors, and signal disposition but have
  &lt;strong&gt;private&lt;/strong&gt; stacks, TLS, and scheduling attributes. All are Linux &lt;em&gt;tasks&lt;/em&gt; under the hood.
&lt;/div&gt;
</code></pre>
  </div>

  
<div class="arrow">
    <svg width="36" height="40"><line x1="18" y1="0" x2="18" y2="28" stroke="#a0aec0" stroke-width="2.5" stroke-dasharray="5,3" /><polyline points="8,20 18,34 28,20" fill="none" stroke="#a0aec0" stroke-width="2.5" /></svg>
  </div>

  <!-- ════════════════════════════════════════════════════════════════
       SECTION 5 — System Call Interface
       ════════════════════════════════════════════════════════════════ -->
  
<div class="section">
    
<div class="section-label label-syscall">System Call<br>Interface</div>

<pre><code>&lt;div class="section-components"&gt;
  &lt;div class="comp kernel" data-info="syscall-entry"&gt;syscall / sysenter&lt;span class="comp-sub"&gt;ring-3 → ring-0 transition&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="syscall-table"&gt;sys_call_table&lt;span class="comp-sub"&gt;dispatch table in kernel&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="vdso-syscall"&gt;vDSO fast-path&lt;span class="comp-sub"&gt;clock_gettime etc.&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="seccomp"&gt;seccomp BPF filter&lt;span class="comp-sub"&gt;syscall allowlisting&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="ptrace"&gt;ptrace / strace hook&lt;span class="comp-sub"&gt;tracee stops&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div class="section-note"&gt;
  On x86-64 the &lt;code&gt;syscall&lt;/code&gt; instruction saves registers, switches stacks to the per-CPU kernel stack, and jumps to &lt;code&gt;entry_SYSCALL_64&lt;/code&gt;.
&lt;/div&gt;
</code></pre>
  </div>

  
<div class="arrow">
    <svg width="36" height="40"><line x1="18" y1="0" x2="18" y2="28" stroke="#a0aec0" stroke-width="2.5" stroke-dasharray="5,3" /><polyline points="8,20 18,34 28,20" fill="none" stroke="#a0aec0" stroke-width="2.5" /></svg>
  </div>

  <!-- ════════════════════════════════════════════════════════════════
       SECTION 6 — Kernel: Task / Process Management
       ════════════════════════════════════════════════════════════════ -->
  
<div class="section">
    
<div class="section-label label-kernel">Kernel:<br>Task Mgmt</div>

<pre><code>&lt;div class="section-components"&gt;
  &lt;div class="comp kernel" data-info="task-struct"&gt;task_struct&lt;span class="comp-sub"&gt;per-thread kernel object&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="mm-struct"&gt;mm_struct&lt;span class="comp-sub"&gt;shared address space desc.&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="files-struct"&gt;files_struct&lt;span class="comp-sub"&gt;open file descriptor table&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="signal-struct"&gt;signal_struct&lt;span class="comp-sub"&gt;signal handlers &amp;amp; pending&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="cred-struct"&gt;cred (uid/gid/caps)&lt;span class="comp-sub"&gt;credentials &amp;amp; namespaces&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="pid-ns"&gt;PID / namespaces&lt;span class="comp-sub"&gt;pid_ns, mnt_ns, net_ns…&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="wait-queue"&gt;wait_queue&lt;span class="comp-sub"&gt;blocking &amp;amp; wakeup infra&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div class="section-note"&gt;
  Linux uses a single &lt;code&gt;task_struct&lt;/code&gt; for both processes and threads.
  Threads in a process share one &lt;code&gt;mm_struct&lt;/code&gt; but each has its own kernel stack.
&lt;/div&gt;
</code></pre>
  </div>

  
<div class="arrow">
    <svg width="36" height="40"><line x1="18" y1="0" x2="18" y2="28" stroke="#a0aec0" stroke-width="2.5" stroke-dasharray="5,3" /><polyline points="8,20 18,34 28,20" fill="none" stroke="#a0aec0" stroke-width="2.5" /></svg>
  </div>

  <!-- ════════════════════════════════════════════════════════════════
       SECTION 7 — Scheduler (CFS + RT)
       ════════════════════════════════════════════════════════════════ -->
  
<div class="section">
    
<div class="section-label label-sched">Scheduler<br>(CFS / RT)</div>

<pre><code>&lt;div class="section-components"&gt;
  &lt;div class="comp sched" data-info="cfs"&gt;CFS — Completely Fair Scheduler&lt;span class="comp-sub"&gt;vruntime red-black tree&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp sched" data-info="rt-sched"&gt;RT scheduler&lt;span class="comp-sub"&gt;SCHED_FIFO / SCHED_RR&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp sched" data-info="sched-domain"&gt;Scheduling domains&lt;span class="comp-sub"&gt;NUMA / CPU topology&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp sched" data-info="runqueue"&gt;Per-CPU runqueue&lt;span class="comp-sub"&gt;rq, cfs_rq, rt_rq&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp sched" data-info="load-balance"&gt;Load balancer&lt;span class="comp-sub"&gt;work-stealing across CPUs&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp sched" data-info="context-switch"&gt;Context switch&lt;span class="comp-sub"&gt;switch_to() — save/restore regs&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp sched" data-info="affinity"&gt;CPU affinity&lt;span class="comp-sub"&gt;sched_setaffinity()&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp sched" data-info="preemption"&gt;Kernel preemption&lt;span class="comp-sub"&gt;CONFIG_PREEMPT&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div class="section-note"&gt;
  CFS tracks &lt;code&gt;vruntime&lt;/code&gt; per-task and always picks the leftmost node of the red-black tree. Threads compete for slices within a &lt;strong&gt;cgroup&lt;/strong&gt; hierarchy.
&lt;/div&gt;
</code></pre>
  </div>

  
<div class="arrow">
    <svg width="36" height="40"><line x1="18" y1="0" x2="18" y2="28" stroke="#a0aec0" stroke-width="2.5" stroke-dasharray="5,3" /><polyline points="8,20 18,34 28,20" fill="none" stroke="#a0aec0" stroke-width="2.5" /></svg>
  </div>

  <!-- ════════════════════════════════════════════════════════════════
       SECTION 8 — Memory Management (kernel side)
       ════════════════════════════════════════════════════════════════ -->
  
<div class="section">
    
<div class="section-label label-vmem">Kernel:<br>Memory Mgmt</div>

<pre><code>&lt;div class="section-components"&gt;
  &lt;div class="comp mem" data-info="page-table"&gt;Page tables&lt;span class="comp-sub"&gt;PGD→PUD→PMD→PTE&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp mem" data-info="tlb"&gt;TLB / CR3&lt;span class="comp-sub"&gt;address-translation cache&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp mem" data-info="page-fault"&gt;Page fault handler&lt;span class="comp-sub"&gt;demand paging, CoW&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp mem" data-info="cow"&gt;Copy-on-Write (CoW)&lt;span class="comp-sub"&gt;fork / mmap shared pages&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp mem" data-info="slab"&gt;SLAB/SLUB allocator&lt;span class="comp-sub"&gt;kernel object caches&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp mem" data-info="buddy"&gt;Buddy allocator&lt;span class="comp-sub"&gt;page-granularity free lists&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp mem" data-info="mmap-anon"&gt;Anonymous mmap&lt;span class="comp-sub"&gt;brk, thread stacks, malloc&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp mem" data-info="oom"&gt;OOM killer&lt;span class="comp-sub"&gt;oom_badness scoring&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp mem" data-info="huge-pages"&gt;THP / HugeTLB&lt;span class="comp-sub"&gt;2 MB / 1 GB pages&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp mem" data-info="swap"&gt;Swap / zswap&lt;span class="comp-sub"&gt;paging to disk&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div class="section-note"&gt;
  The kernel maintains a 4- (or 5-) level page table per &lt;code&gt;mm_struct&lt;/code&gt;.
  A page fault is the kernel's opportunity to demand-page, CoW-break, or extend the stack.
&lt;/div&gt;
</code></pre>
  </div>

  
<div class="arrow">
    <svg width="36" height="40"><line x1="18" y1="0" x2="18" y2="28" stroke="#a0aec0" stroke-width="2.5" stroke-dasharray="5,3" /><polyline points="8,20 18,34 28,20" fill="none" stroke="#a0aec0" stroke-width="2.5" /></svg>
  </div>

  <!-- ════════════════════════════════════════════════════════════════
       SECTION 9 — Synchronisation & IPC
       ════════════════════════════════════════════════════════════════ -->
  
<div class="section">
    
<div class="section-label label-sync">Sync &amp; IPC</div>

<pre><code>&lt;div class="section-components"&gt;
  &lt;div class="comp kernel" data-info="futex"&gt;futex(2)&lt;span class="comp-sub"&gt;fast userspace mutex&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="pipe"&gt;pipe / pipe2&lt;span class="comp-sub"&gt;anonymous byte stream&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="eventfd"&gt;eventfd / timerfd&lt;span class="comp-sub"&gt;edge-triggered counters&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="mq"&gt;mq_open (POSIX MQ)&lt;span class="comp-sub"&gt;message queues&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="shm"&gt;shmget / shm_open&lt;span class="comp-sub"&gt;shared memory&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="signal-ipc"&gt;kill / sigqueue&lt;span class="comp-sub"&gt;async notification&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp kernel" data-info="membarrier"&gt;membarrier(2)&lt;span class="comp-sub"&gt;cross-thread memory order&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div class="section-note"&gt;
  &lt;code&gt;pthread_mutex_lock&lt;/code&gt; calls &lt;code&gt;futex(FUTEX_WAIT)&lt;/code&gt; only when contended — uncontended lock/unlock stays entirely in user space.
&lt;/div&gt;
</code></pre>
  </div>

  
<div class="arrow">
    <svg width="36" height="40"><line x1="18" y1="0" x2="18" y2="28" stroke="#a0aec0" stroke-width="2.5" stroke-dasharray="5,3" /><polyline points="8,20 18,34 28,20" fill="none" stroke="#a0aec0" stroke-width="2.5" /></svg>
  </div>

  <!-- ════════════════════════════════════════════════════════════════
       SECTION 10 — Hardware
       ════════════════════════════════════════════════════════════════ -->
  
<div class="section">
    
<div class="section-label label-hw">Hardware</div>

<pre><code>&lt;div class="section-components"&gt;
  &lt;div class="comp hw" data-info="cpu-core"&gt;CPU Core(s)&lt;span class="comp-sub"&gt;instruction fetch / decode / execute&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp hw" data-info="registers"&gt;Registers + RIP&lt;span class="comp-sub"&gt;GPRs, SIMD, segment regs&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp hw" data-info="cache"&gt;L1/L2/L3 Cache&lt;span class="comp-sub"&gt;coherence via MESI&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp hw" data-info="mmu"&gt;MMU + CR3&lt;span class="comp-sub"&gt;HW page-table walker&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp hw" data-info="apic"&gt;Local APIC&lt;span class="comp-sub"&gt;timer interrupt, IPI&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp hw" data-info="iommu"&gt;IOMMU (VT-d)&lt;span class="comp-sub"&gt;DMA address translation&lt;/span&gt;&lt;/div&gt;
  &lt;div class="comp hw" data-info="spectre"&gt;Spectre / Meltdown mitigations&lt;span class="comp-sub"&gt;IBRS, KPTI, STIBP&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div class="section-note"&gt;
  The scheduler timer interrupt fires via the Local APIC (~250 Hz default).
  The MMU's CR3 register holds the physical address of the top-level page table — reloaded on every context switch.
&lt;/div&gt;
</code></pre>
  </div>

  
<hr class="divider" />
  <!-- ════════════════════════════════════════════════════════════════
       FLOW SUMMARY (bottom callout row)
       ════════════════════════════════════════════════════════════════ -->
  
<div style="display:grid; grid-template-columns:repeat(4, 1fr); gap:14px; margin-top:10px">
    
<div class="comp elf" data-info="flow-exec" style="min-width:unset; text-align:center">
      <span style="font-size:1.4em">▶</span><br>
      <strong>1. execve</strong><br>
      <span class="comp-sub">ELF loaded, linker runs</span>
    </div>

    
<div class="comp mem" data-info="flow-vm" style="min-width:unset; text-align:center">
      <span style="font-size:1.4em">⬭</span><br>
      <strong>2. Virtual Memory</strong><br>
      <span class="comp-sub">VMAs mapped, ASLR applied</span>
    </div>

    
<div class="comp sched" data-info="flow-sched" style="min-width:unset; text-align:center">
      <span style="font-size:1.4em">▶</span><br>
      <strong>3. Threads Scheduled</strong><br>
      <span class="comp-sub">CFS vruntime → CPU</span>
    </div>

    
<div class="comp hw" data-info="flow-hw" style="min-width:unset; text-align:center">
      <span style="font-size:1.4em">⚙</span><br>
      <strong>4. Hardware Executes</strong><br>
      <span class="comp-sub">Fetch–decode–execute</span>
    </div>

  </div>

</div>
<!-- .container -->
<script>
// ── Explanations data ─────────────────────────────────────────────
const explanations = {

  /* ── ELF File on Disk ────────────────────────────────────────── */
  'elf-header': {
    title: 'ELF Header',
    content: `
      <p>The ELF header occupies the first 64 bytes of every ELF binary and acts as the file's
      identity card. It contains the magic bytes <code>\\x7fELF</code>, the target architecture
      (e.g. <code>EM_X86_64 = 0x3e</code>), the entry-point virtual address, and offsets to the
      program-header and section-header tables.</p>
      <p>Key fields:</p>
      <ul>
        <li><strong>e_type</strong> — <code>ET_EXEC</code> (static), <code>ET_DYN</code> (PIE/shared lib), <code>ET_CORE</code></li>
        <li><strong>e_entry</strong> — VA of <code>_start</code> (or the interpreter's entry if dynamic)</li>
        <li><strong>e_phoff / e_shoff</strong> — byte offsets to program/section header tables</li>
        <li><strong>e_flags</strong> — architecture-specific flags (e.g. ARM ABI version)</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>readelf -h &lt;binary&gt;</code> — dump all ELF header fields</li>
          <li><code>file &lt;binary&gt;</code> — quick type/arch summary from magic bytes</li>
          <li><code>xxd &lt;binary&gt; | head -4</code> — raw hex view of the first 64 bytes</li>
        </ul>
      </div>`
  },

  'elf-phdrs': {
    title: 'Program Headers (Segments)',
    content: `
      <p>Program headers describe <em>segments</em> — the runtime view of the binary.
      The kernel's ELF loader iterates only these headers; section headers are irrelevant at
      load time (they are stripped in production binaries).</p>
      <p>Critical segment types:</p>
      <ul>
        <li><strong>PT_LOAD</strong> — mapped directly into the process VAS with specified permissions (R, RW, RX)</li>
        <li><strong>PT_INTERP</strong> — path to the dynamic linker (e.g. <code>/lib64/ld-linux-x86-64.so.2</code>)</li>
        <li><strong>PT_DYNAMIC</strong> — points to the <code>.dynamic</code> section used by <code>ld.so</code></li>
        <li><strong>PT_GNU_STACK</strong> — controls executable-stack policy (<code>NX</code> bit)</li>
        <li><strong>PT_GNU_RELRO</strong> — pages to be made read-only after relocation (GOT hardening)</li>
        <li><strong>PT_TLS</strong> — thread-local storage template</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>readelf -l &lt;binary&gt;</code> — list all program headers and segment-to-section mapping</li>
          <li><code>objdump -p &lt;binary&gt;</code> — similar view plus dynamic section</li>
          <li><code>eu-readelf -l &lt;binary&gt;</code> — elfutils alternative</li>
        </ul>
      </div>`
  },

  'elf-text': {
    title: '.text — Executable Code Section',
    content: `
      <p>The <code>.text</code> section holds compiled machine instructions. It is part of a
      <code>PT_LOAD</code> segment with <strong>R+X</strong> (read + execute) permissions and is
      mapped as a private, file-backed VMA. Because it is read-only, multiple processes loading
      the same shared library share the same physical pages.</p>
      <p>Important sub-regions:</p>
      <ul>
        <li><strong>_start</strong> — CRT entry stub; sets up argc/argv, calls <code>__libc_start_main</code></li>
        <li><strong>main()</strong> and all user functions</li>
        <li><strong>PLT stubs</strong> — tiny trampolines for lazy-bound shared-library calls</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>objdump -d &lt;binary&gt;</code> — disassemble .text</li>
          <li><code>objdump -M intel -d &lt;binary&gt;</code> — Intel syntax</li>
          <li><code>perf annotate</code> — annotate hot functions with CPU cycle counts</li>
          <li><code>addr2line -e &lt;binary&gt; &lt;addr&gt;</code> — map address → source line</li>
        </ul>
      </div>`
  },

  'elf-rodata': {
    title: '.rodata — Read-Only Data',
    content: `
      <p><code>.rodata</code> holds constants that must not be modified at runtime: string literals,
      jump tables, <code>const</code> global arrays, and switch-statement dispatch tables.
      It is mapped <strong>R</strong> (read-only, non-executable) in its own <code>PT_LOAD</code>
      segment, providing an extra layer of exploit mitigation.</p>
      <p>Attempting to write to a <code>.rodata</code> address generates a <code>SIGSEGV</code>
      (page-fault on a read-only PTE).</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>objdump -s -j .rodata &lt;binary&gt;</code> — hex dump of .rodata</li>
          <li><code>strings &lt;binary&gt;</code> — extract printable strings (mostly from .rodata)</li>
          <li><code>readelf -S &lt;binary&gt;</code> — section headers showing addresses &amp; sizes</li>
        </ul>
      </div>`
  },

  'elf-data': {
    title: '.data — Initialised Read-Write Data',
    content: `
      <p><code>.data</code> contains global and static variables that have non-zero initial values
      (e.g. <code>int x = 42;</code>). These values are stored verbatim in the ELF file and
      copied into a private, writable VMA at load time. Each process gets its own copy.</p>
      <p>Because this segment is <strong>private file-backed</strong>, the initial values come
      from the file but writes are CoW-isolated per process.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>readelf -S &lt;binary&gt;</code> — shows .data offset, size, and alignment</li>
          <li><code>nm &lt;binary&gt; | grep ' D '</code> — list initialized global symbols</li>
          <li><code>gdb: info variables</code> — inspect globals at runtime</li>
        </ul>
      </div>`
  },

  'elf-bss': {
    title: '.bss — Zero-Initialised Data',
    content: `
      <p><code>.bss</code> holds global and static variables initialised to zero (or left
      uninitialised, which C guarantees is zero). Crucially, <code>.bss</code> takes up
      <strong>no space in the ELF file</strong> — only its size is recorded. The kernel maps
      it as an anonymous VMA backed by the shared <em>zero page</em> using Copy-on-Write.</p>
      <p>On first write to a .bss page, a page fault fires, the kernel allocates a fresh physical
      page of zeros, and updates the PTE — demand zeroing at minimal cost.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>size &lt;binary&gt;</code> — quick breakdown of text/data/bss sizes</li>
          <li><code>nm &lt;binary&gt; | grep ' B '</code> — list BSS symbols</li>
          <li><code>/proc/&lt;pid&gt;/smaps</code> — shows anonymous pages actually faulted in</li>
        </ul>
      </div>`
  },

  'elf-dynamic': {
    title: '.dynamic / .plt / .got — Dynamic Linking Tables',
    content: `
      <p>These three sections form the machinery of runtime dynamic linking:</p>
      <ul>
        <li><strong>.dynamic</strong> — a table of <code>DT_*</code> tags consumed by <code>ld.so</code>:
          <code>DT_NEEDED</code> (shared lib dependencies), <code>DT_RELA</code> (relocation table offset),
          <code>DT_SYMTAB</code>, <code>DT_STRTAB</code>, etc.</li>
        <li><strong>.plt</strong> (Procedure Linkage Table) — one stub per imported function.
          On first call the stub jumps to the resolver; thereafter the GOT entry is patched with the
          real address (lazy binding). With <code>BIND_NOW</code>/<code>-z now</code> all symbols are
          resolved at startup.</li>
        <li><strong>.got / .got.plt</strong> (Global Offset Table) — writable table of final symbol
          addresses. RELRO (<code>PT_GNU_RELRO</code>) marks the GOT read-only after relocation to
          prevent GOT overwrite exploits.</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>readelf -d &lt;binary&gt;</code> — dump .dynamic entries</li>
          <li><code>objdump -d -j .plt &lt;binary&gt;</code> — disassemble PLT stubs</li>
          <li><code>ldd &lt;binary&gt;</code> — list resolved shared-library dependencies</li>
          <li><code>LD_DEBUG=bindings ./binary</code> — trace every GOT resolution live</li>
        </ul>
      </div>`
  },

  'elf-debug': {
    title: '.debug_* — DWARF Debug Information',
    content: `
      <p>DWARF sections (<code>.debug_info</code>, <code>.debug_line</code>, <code>.debug_abbrev</code>,
      <code>.debug_frame</code>, etc.) store the mapping between machine code and source-level
      constructs: variable names and types, inlined functions, source line numbers, and call-frame
      unwinding rules.</p>
      <p>These sections are <strong>not loaded into the process VAS</strong> at runtime — they are
      read directly from the file by debuggers and profilers. Stripped binaries have these sections
      removed; separate <code>.debug</code> packages or <code>debuginfod</code> supply them on demand.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>readelf --debug-dump=info &lt;binary&gt;</code> — raw DWARF info</li>
          <li><code>dwarfdump &lt;binary&gt;</code> — human-readable DWARF</li>
          <li><code>gdb &lt;binary&gt;</code> — consumes DWARF for source-level debugging</li>
          <li><code>eu-stack -p &lt;pid&gt;</code> — DWARF-based stack unwind of live process</li>
          <li><code>perf report --sort=srcline</code> — source-annotated profiling via DWARF</li>
        </ul>
      </div>`
  },

  'elf-shdrs': {
    title: 'Section Headers',
    content: `
      <p>The section-header table provides a fine-grained, link-time view of the binary's
      contents — one entry per named section. Each entry records the section name (as an offset
      into <code>.shstrtab</code>), its type (<code>SHT_PROGBITS</code>, <code>SHT_SYMTAB</code>,
      <code>SHT_RELA</code>, etc.), file offset, virtual address, size, and alignment.</p>
      <p>The kernel <em>ignores</em> section headers when loading an ELF; they exist for the
      linker, debugger, and binary-analysis tools. A binary with the section-header table
      stripped runs identically.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>readelf -S &lt;binary&gt;</code> — list all sections with addresses and sizes</li>
          <li><code>objdump -h &lt;binary&gt;</code> — section headers in objdump format</li>
          <li><code>strip --strip-all &lt;binary&gt;</code> — remove section headers and symbols</li>
        </ul>
      </div>`
  },

  /* ── execve + Dynamic Linker ──────────────────────────────────── */
  'execve': {
    title: 'execve(2) — Replace Process Image',
    content: `
      <p><code>execve(path, argv, envp)</code> is the syscall that replaces the calling process's
      address space with a new program. It does <em>not</em> create a new process — PID is
      preserved; open file descriptors marked <code>FD_CLOEXEC</code> are closed.</p>
      <p>Kernel steps inside <code>do_execveat_common()</code>:</p>
      <ol style="padding-left:20px; margin-bottom:12px">
        <li>Open and <code>mmap</code> the file; read first 256 bytes to detect format</li>
        <li>Match a <strong>binfmt handler</strong> (ELF, script shebang, etc.)</li>
        <li>Flush the old VAS (<code>exec_mmap()</code>)</li>
        <li>Map ELF <code>PT_LOAD</code> segments and set up the stack</li>
        <li>Write <code>argc/argv/envp/auxv</code> onto the new stack</li>
        <li>Jump to the dynamic linker entry point (or <code>e_entry</code> for static)</li>
      </ol>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>strace -e execve ./binary</code> — trace the execve call and args</li>
          <li><code>strace -f ./binary</code> — follow forks/execs across child processes</li>
          <li><code>/proc/&lt;pid&gt;/cmdline</code> — null-delimited argv of running process</li>
          <li><code>/proc/&lt;pid&gt;/exe</code> — symlink to the executable on disk</li>
        </ul>
      </div>`
  },

  'binfmt': {
    title: 'binfmt_elf — Kernel ELF Handler',
    content: `
      <p>Linux's binary format subsystem (<code>fs/binfmt_elf.c</code>) is the kernel-side ELF
      interpreter. When <code>execve</code> opens a file and reads the magic bytes
      <code>\\x7fELF</code>, this handler is invoked.</p>
      <p>Key actions:</p>
      <ul>
        <li>Validates ELF header (architecture, ABI, entry point sanity)</li>
        <li>Iterates <code>PT_LOAD</code> segments, calling <code>elf_map()</code> for each</li>
        <li>Reads <code>PT_INTERP</code> to find the dynamic linker and maps it too</li>
        <li>Builds the <strong>auxiliary vector</strong> (<code>AT_PHDR</code>, <code>AT_ENTRY</code>,
          <code>AT_RANDOM</code>, <code>AT_HWCAP</code>, …) on the initial stack</li>
        <li>Applies <strong>ASLR</strong> (<code>mmap_base</code> randomisation)</li>
      </ul>
      <p><strong>binfmt_misc</strong> is the userspace-extensible cousin — it lets you register
      arbitrary magic bytes or file extensions to run with a specified interpreter
      (e.g. <code>.jar</code> → <code>java -jar</code>).</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/sys/fs/binfmt_misc/status</code> — list registered binfmt_misc entries</li>
          <li><code>dmesg | grep binfmt</code> — kernel messages about format detection failures</li>
          <li><code>/proc/&lt;pid&gt;/auxv</code> — binary dump of the aux vector for a live process</li>
          <li><code>LD_SHOW_AUXV=1 ./binary</code> — print auxv before main runs</li>
        </ul>
      </div>`
  },

  'ldso': {
    title: 'ld-linux.so — The Dynamic Linker',
    content: `
      <p><code>ld-linux-x86-64.so.2</code> (glibc) or <code>ld-musl-x86_64.so.1</code> (musl) is
      itself an ELF shared object that is mapped into the process VAS by the kernel and receives
      control before <code>main()</code>. It is self-contained and position-independent.</p>
      <p>Startup sequence:</p>
      <ol style="padding-left:20px; margin-bottom:12px">
        <li>Parse the executable's <code>PT_DYNAMIC</code> segment</li>
        <li>Walk <code>DT_NEEDED</code> entries recursively, opening each <code>.so</code></li>
        <li>Map each shared library into the VAS (with ASLR offsets)</li>
        <li>Process relocations: <code>R_X86_64_GLOB_DAT</code>, <code>R_X86_64_JUMP_SLOT</code>, etc.</li>
        <li>Run each library's <code>.init_array</code> in dependency order</li>
        <li>Transfer control to the executable's <code>_start</code></li>
      </ol>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>ldd &lt;binary&gt;</code> — list shared library dependencies and load addresses</li>
          <li><code>LD_DEBUG=all ./binary 2&gt;&amp;1 | less</code> — verbose linker trace</li>
          <li><code>LD_DEBUG=libs,binding ./binary</code> — library search and symbol binding only</li>
          <li><code>pmap &lt;pid&gt;</code> — show all mapped regions including .so files</li>
          <li><code>pldd &lt;pid&gt;</code> — list shared libraries of a running process</li>
        </ul>
      </div>`
  },

  'relocation': {
    title: 'Relocations — PLT / GOT Patching',
    content: `
      <p>A <strong>relocation</strong> is a directive that says "patch this address in memory with
      the resolved virtual address of symbol X". Relocations are applied by <code>ld.so</code> at
      load time (or lazily through the PLT at first call).</p>
      <p>Key relocation types on x86-64:</p>
      <ul>
        <li><code>R_X86_64_GLOB_DAT</code> — write symbol address into the GOT slot (data symbols)</li>
        <li><code>R_X86_64_JUMP_SLOT</code> — GOT entry for a PLT-bound function (lazy or eager)</li>
        <li><code>R_X86_64_RELATIVE</code> — base-address-relative fixup for PIE binaries</li>
        <li><code>R_X86_64_TPOFF64</code> — thread-pointer-relative TLS offset</li>
      </ul>
      <p>With <strong>full RELRO</strong> (<code>-Wl,-z,relro,-z,now</code>), all GOT entries are
      resolved eagerly at startup and the GOT is remapped read-only before <code>main()</code>.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>readelf -r &lt;binary&gt;</code> — dump all relocation entries</li>
          <li><code>objdump -R &lt;binary&gt;</code> — dynamic relocations</li>
          <li><code>LD_DEBUG=reloc ./binary</code> — trace every relocation applied at runtime</li>
        </ul>
      </div>`
  },

  'ldpreload': {
    title: 'LD_PRELOAD / LD_AUDIT — Library Interposition',
    content: `
      <p><code>LD_PRELOAD</code> instructs the dynamic linker to load a specified shared library
      <em>before</em> all others, allowing its symbols to shadow those in system libraries.
      Classic uses: <code>malloc</code> debugging, function hooking, and sandboxing.</p>
      <p><code>LD_AUDIT</code> loads an audit library that receives callbacks at each PLT
      resolution — useful for syscall tracing without ptrace.</p>
      <p>Security note: both are silently ignored for <strong>setuid/setgid</strong> binaries
      and those with <code>AT_SECURE</code> set in the auxv.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>LD_PRELOAD=/usr/lib/libefence.so ./binary</code> — Electric Fence malloc debugger</li>
          <li><code>LD_PRELOAD=libtsan.so.0 ./binary</code> — ThreadSanitizer via preload</li>
          <li><code>ltrace ./binary</code> — intercepts all library calls (similar mechanism)</li>
        </ul>
      </div>`
  },

  'init-fini': {
    title: '.init_array / .fini_array — Constructors & Destructors',
    content: `
      <p><code>.init_array</code> is an array of function pointers that the dynamic linker calls
      in order, for each shared library and then the executable, before transferring control to
      <code>main()</code>. <code>.fini_array</code> is called in reverse order at process exit.</p>
      <p>These are the modern replacement for the legacy <code>_init()</code> / <code>_fini()</code>
      functions. GCC's <code>__attribute__((constructor))</code> / <code>__attribute__((destructor))</code>
      populates these arrays.</p>
      <p>Common uses: C++ static object constructors, OpenSSL entropy seeding, glibc TLS setup.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>objdump -s -j .init_array &lt;binary&gt;</code> — list constructor pointers</li>
          <li><code>readelf -S &lt;binary&gt; | grep init</code> — locate init/fini sections</li>
          <li><code>gdb: break __libc_csu_init</code> — stop just before constructors run</li>
        </ul>
      </div>`
  },

  'vdso': {
    title: 'vDSO — Virtual Dynamic Shared Object',
    content: `
      <p>The <strong>vDSO</strong> is a small shared library (typically 4–8 KB) that the kernel
      maps into every process's address space. It provides a handful of high-frequency syscalls
      that can be serviced entirely in user space by reading kernel-maintained data in a shared
      memory page — <em>without</em> the cost of a ring-3→ring-0 transition.</p>
      <p>Functions in the vDSO (x86-64):</p>
      <ul>
        <li><code>clock_gettime()</code> — reads <code>vvar</code> page containing kernel time</li>
        <li><code>gettimeofday()</code></li>
        <li><code>time()</code></li>
        <li><code>getcpu()</code> — current CPU and NUMA node</li>
      </ul>
      <p>The <code>vvar</code> page is a companion read-only mapping that the kernel updates atomically using a seqlock.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/maps | grep vdso</code> — find vDSO mapping address</li>
          <li><code>LD_SHOW_AUXV=1 ./binary | grep AT_SYSINFO</code> — vDSO entry from auxv</li>
          <li><code>perf stat -e syscalls:sys_enter_clock_gettime ./binary</code> — count how often it falls back to real syscall</li>
        </ul>
      </div>`
  },

  /* ── Virtual Address Space ───────────────────────────────────── */
  'vma-stack': {
    title: 'Stack — Per-Thread Private Region',
    content: `
      <p>Each thread has its own stack VMA, typically 8 MB by default
      (<code>ulimit -s</code>). The main thread's stack is placed near the top of the user
      address space and grows <strong>downward</strong>. Additional thread stacks are allocated
      via <code>mmap(MAP_ANONYMOUS|MAP_STACK)</code> in a lower region.</p>
      <p>The kernel extends the main thread's stack automatically on page fault if the faulting
      address is within the <em>stack guard gap</em> (<code>vm.stack_guard_gap</code> sysctl,
      default 256 pages). Beyond that, the fault is fatal (<code>SIGSEGV</code>).</p>
      <p>Stack contents (top to bottom on entry to <code>main</code>): envp strings, argv strings,
      null-term envp[], null-term argv[], argc, auxv.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/maps | grep stack</code> — find stack VMA</li>
          <li><code>ulimit -s unlimited</code> — remove stack size cap</li>
          <li><code>prlimit --stack=&lt;bytes&gt; ./binary</code> — set per-process stack limit</li>
          <li><code>gdb: info frame</code> — show current stack frame</li>
          <li><code>valgrind --tool=massif ./binary</code> — heap &amp; stack profiling</li>
        </ul>
      </div>`
  },

  'vma-mmap': {
    title: 'mmap Region — Shared Libs, Files, Anonymous',
    content: `
      <p>The <code>mmap</code> region (between the heap and the stack) is where the kernel
      satisfies all <code>mmap()</code> requests that don't specify a fixed address. It holds:</p>
      <ul>
        <li><strong>Shared libraries</strong> — text (shared, read-only), data (private CoW)</li>
        <li><strong>Thread stacks</strong> — per-thread anonymous private mappings</li>
        <li><strong>Large malloc allocations</strong> — glibc uses <code>mmap</code> for allocations &gt;128 KB by default (MMAP_THRESHOLD)</li>
        <li><strong>File mappings</strong> — <code>mmap(fd)</code> for zero-copy file I/O</li>
        <li><strong>Anonymous shared memory</strong> — <code>memfd_create</code>, <code>shm_open</code></li>
      </ul>
      <p>ASLR randomises the base of this region at every <code>execve</code>.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/maps</code> — all VMAs with permissions and file backing</li>
          <li><code>cat /proc/&lt;pid&gt;/smaps</code> — per-VMA memory usage stats (RSS, PSS, swap)</li>
          <li><code>pmap -x &lt;pid&gt;</code> — formatted VMA summary</li>
          <li><code>vmstat -s</code> — system-wide virtual memory stats</li>
        </ul>
      </div>`
  },

  'vma-heap': {
    title: 'Heap — Dynamic Allocation (brk / mmap)',
    content: `
      <p>The heap is the region for dynamic memory allocation (<code>malloc</code>/<code>free</code>).
      glibc's <strong>ptmalloc2</strong> manages it using two mechanisms:</p>
      <ul>
        <li><strong>brk()</strong> — moves the program-break pointer to extend the initial heap arena.
          Fast but single-threaded; protected by a global lock in older glibc.</li>
        <li><strong>mmap(MAP_ANONYMOUS)</strong> — used for large allocations (&gt;MMAP_THRESHOLD, default 128 KB)
          and for creating additional per-thread arenas to reduce contention.</li>
      </ul>
      <p>Alternative allocators: <strong>jemalloc</strong> (Firefox, FreeBSD), <strong>tcmalloc</strong>
      (Google), <strong>mimalloc</strong> (Microsoft) — all use per-thread caches to minimise locking.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>valgrind --tool=massif ./binary</code> — heap profiling over time</li>
          <li><code>heaptrack ./binary</code> — fast heap profiler with flamegraph output</li>
          <li><code>MALLOC_TRACE=trace.txt ./binary; mtrace</code> — glibc malloc trace</li>
          <li><code>cat /proc/&lt;pid&gt;/status | grep VmRSS</code> — resident set size</li>
          <li><code>address sanitizer: -fsanitize=address</code> — detect heap bugs at compile time</li>
        </ul>
      </div>`
  },

  'vma-bss': {
    title: '.bss VMA — Demand-Zeroed Anonymous Pages',
    content: `
      <p>The <code>.bss</code> segment is mapped as an <strong>anonymous private</strong> VMA
      (not file-backed). All pages initially point to the kernel's shared <em>zero page</em>
      with read-only PTEs — no physical RAM is consumed until the first write.</p>
      <p>On first write, the MMU raises a protection fault; the page-fault handler allocates a
      fresh zeroed physical page, updates the PTE, and resumes execution — this is
      <strong>demand zeroing</strong>.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>/proc/&lt;pid&gt;/smaps</code> — <code>Private_Clean</code> vs <code>Private_Dirty</code> counts</li>
          <li><code>size &lt;binary&gt;</code> — .bss size (reported but not stored in file)</li>
        </ul>
      </div>`
  },

  'vma-data': {
    title: '.data VMA — Private File-Backed Writable',
    content: `
      <p>The <code>.data</code> segment is mapped as a <strong>private file-backed</strong> VMA
      (MAP_PRIVATE). Pages are initially shared with the on-disk file contents, but on the
      first write a Copy-on-Write fault triggers: the kernel allocates a new physical page,
      copies the original content, and maps it privately to the process.</p>
      <p>This means two instances of the same program initially share .data pages in RAM until
      one of them actually writes to a variable.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>/proc/&lt;pid&gt;/smaps | grep -A15 ' rw'</code> — find writable file-backed VMAs</li>
          <li><code>nm &lt;binary&gt; | grep ' D '</code> — list initialized data symbols</li>
        </ul>
      </div>`
  },

  'vma-rodata': {
    title: '.rodata VMA — Shared Read-Only Pages',
    content: `
      <p>The <code>.rodata</code> segment is mapped as a <strong>shared file-backed read-only</strong>
      VMA. Multiple instances of the same program (or any process loading the same shared library)
      share the exact same physical pages in RAM. The MMU enforces read-only access; any write
      attempt generates <code>SIGSEGV</code>.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>/proc/&lt;pid&gt;/smaps</code> — <code>Shared_Clean</code> for .rodata pages</li>
          <li><code>cat /proc/&lt;pid&gt;/maps | grep ' r--'</code> — read-only non-exec VMAs</li>
        </ul>
      </div>`
  },

  'vma-text': {
    title: '.text VMA — Shared Executable Pages',
    content: `
      <p>The executable code segment is mapped <strong>shared, read-only, executable</strong>
      (r-xp). Because it is read-only and file-backed, all processes executing the same binary
      or shared library share these physical pages — a 10 MB library loaded by 100 processes
      still occupies only one copy in RAM.</p>
      <p>The <strong>NX (no-execute)</strong> bit prevents non-.text pages from being executed,
      a core exploit mitigation. On x86-64 this is the XD bit in the PTE.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/maps | grep ' r-x'</code> — find executable VMAs</li>
          <li><code>perf record -g ./binary &amp;&amp; perf report</code> — CPU time per function in .text</li>
          <li><code>checkec --file &lt;binary&gt;</code> — check NX, ASLR, stack-canary, RELRO status</li>
        </ul>
      </div>`
  },

  'vma-vdso': {
    title: 'vDSO VMA — Kernel-Managed Fast Syscall Page',
    content: `
      <p>The vDSO appears as a special anonymous executable mapping in every process's VAS.
      Its physical pages are managed entirely by the kernel and are shared read-only across all
      processes. A companion <code>vvar</code> mapping (read-only data) holds kernel time values
      that the vDSO code reads directly.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/maps | grep vdso</code></li>
          <li><code>vdso_test</code> from kernel selftests</li>
        </ul>
      </div>`
  },

  'vma-vsyscall': {
    title: '[vsyscall] — Legacy Compatibility Page',
    content: `
      <p>The <code>vsyscall</code> page is a fixed-address (<code>0xffffffffff600000</code>) legacy
      mechanism from Linux 2.6 for fast <code>gettimeofday</code> and <code>time</code> syscalls.
      It predates the vDSO and is now a security liability — its fixed address makes it useful
      for return-oriented programming (ROP) gadgets.</p>
      <p>Modern kernels map it in <strong>emulation mode</strong>: the page is readable but not
      executable; a fault is caught and emulated safely, eliminating the ROP gadget surface.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/maps | grep vsyscall</code></li>
          <li><code>sysctl kernel.vsyscall64</code> — 0=disabled, 1=emulate, 2=native (legacy)</li>
        </ul>
      </div>`
  },

  /* ── Threads ─────────────────────────────────────────────────── */
  'thread-main': {
    title: 'Main Thread (TID = PID)',
    content: `
      <p>The main thread is created implicitly by <code>execve</code>. Its TID equals the PID
      of the process group leader. It is the only thread that receives signals sent to the PID
      by default, and it owns the initial stack laid out by the kernel.</p>
      <p>When the main thread calls <code>exit()</code> (or returns from <code>main()</code>),
      glibc calls <code>pthread_exit()</code> which keeps the process alive until all other
      threads finish, then calls <code>exit_group()</code> to terminate all threads.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>ps -eLf | grep &lt;pid&gt;</code> — list all threads (LWPs) of a process</li>
          <li><code>ls /proc/&lt;pid&gt;/task/</code> — one directory per thread</li>
          <li><code>htop</code> (press H) — show individual threads in tree view</li>
        </ul>
      </div>`
  },

  'thread-worker': {
    title: 'Worker Thread — clone(CLONE_VM|…)',
    content: `
      <p>POSIX threads are created by <code>pthread_create()</code>, which calls
      <code>clone(2)</code> with flags that control what is shared:</p>
      <pre>clone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND |
      CLONE_THREAD | CLONE_SETTLS | CLONE_PARENT_SETTID |
      CLONE_CHILD_CLEARTID, stack_top, ...)</pre>
      <ul>
        <li><strong>CLONE_VM</strong> — share the same <code>mm_struct</code> (address space)</li>
        <li><strong>CLONE_FILES</strong> — share file descriptor table</li>
        <li><strong>CLONE_SIGHAND</strong> — share signal handlers</li>
        <li><strong>CLONE_THREAD</strong> — place new task in the same thread group (same PID)</li>
        <li><strong>CLONE_SETTLS</strong> — set the FS register base for TLS</li>
      </ul>
      <p>Each thread gets its own kernel stack (typically 16 KB) and its own
      <code>task_struct</code> in the kernel.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/status | grep Threads</code> — thread count</li>
          <li><code>gdb: info threads</code> — list and switch between threads</li>
          <li><code>strace -f -e clone ./binary</code> — trace clone() calls</li>
          <li><code>perf sched record/report</code> — thread scheduling timeline</li>
        </ul>
      </div>`
  },

  'thread-tls': {
    title: 'TLS — Thread-Local Storage',
    content: `
      <p>TLS gives each thread its own private copy of variables declared with
      <code>__thread</code> or <code>_Thread_local</code>. At load time, the linker allocates
      a TLS template in the ELF <code>PT_TLS</code> segment; <code>ld.so</code> creates a copy
      for each thread.</p>
      <p>On x86-64, the <strong>FS segment register</strong> base is set to the thread's
      <code>pthread</code> descriptor (the TCB — Thread Control Block). All TLS accesses
      compile to <code>fs:offset</code> memory references. This is set via
      <code>arch_prctl(ARCH_SET_FS)</code> or the <code>CLONE_SETTLS</code> clone flag.</p>
      <p>Key per-thread globals stored in TLS:</p>
      <ul>
        <li><code>errno</code> — each thread has its own errno so concurrent syscalls don't clobber it</li>
        <li><code>pthread_self()</code> — returns the pthread descriptor pointer (at fs:0)</li>
        <li>Stack canary, locale state, random seed</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>readelf -S &lt;binary&gt; | grep -i tls</code> — show PT_TLS / .tdata / .tbss</li>
          <li><code>gdb: p $fs_base</code> — print current thread's TLS base address</li>
          <li><code>arch_prctl(ARCH_GET_FS, &amp;addr)</code> — programmatically read FS base</li>
        </ul>
      </div>`
  },

  'pthread-mutex': {
    title: 'pthread_mutex — Futex-Backed Mutex',
    content: `
      <p>A <code>pthread_mutex_t</code> is a 40-byte structure in user space. The lock word
      (the first 4 bytes) is manipulated with atomic compare-and-swap instructions.
      The kernel is only involved on contention:</p>
      <ul>
        <li><strong>Uncontended lock</strong>: a single <code>LOCK CMPXCHG</code> in user space; zero syscalls</li>
        <li><strong>Contended lock</strong>: losing thread calls <code>futex(FUTEX_WAIT)</code> to sleep</li>
        <li><strong>Unlock with waiters</strong>: <code>futex(FUTEX_WAKE)</code> wakes one waiter</li>
      </ul>
      <p>Mutex types: <code>PTHREAD_MUTEX_NORMAL</code>, <code>PTHREAD_MUTEX_RECURSIVE</code>,
      <code>PTHREAD_MUTEX_ERRORCHECK</code>, <code>PTHREAD_MUTEX_ADAPTIVE_NP</code> (spin then sleep).</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>strace -e futex ./binary</code> — watch futex calls (each is a contention event)</li>
          <li><code>perf lock record ./binary &amp;&amp; perf lock report</code> — lock contention analysis</li>
          <li><code>helgrind ./binary</code> (Valgrind) — data race &amp; lock-order violation detector</li>
          <li><code>-fsanitize=thread</code> (TSan) — compile-time thread sanitizer</li>
        </ul>
      </div>`
  },

  'pthread-condvar': {
    title: 'pthread_cond — Condition Variable',
    content: `
      <p>A condition variable allows threads to atomically release a mutex and sleep until a
      condition is signalled. The canonical pattern:</p>
      <pre>pthread_mutex_lock(&amp;m);
while (!condition)
    pthread_cond_wait(&amp;cv, &amp;m);  // atomically unlock &amp; sleep
// condition is now true
pthread_mutex_unlock(&amp;m);</pre>
      <p><code>pthread_cond_wait</code> calls <code>futex(FUTEX_WAIT)</code> internally.
      <code>pthread_cond_signal</code> wakes one waiter; <code>pthread_cond_broadcast</code>
      wakes all. Spurious wakeups are possible — always re-check the condition in a loop.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>strace -e futex ./binary</code> — condition waits appear as FUTEX_WAIT_BITSET</li>
          <li><code>gdb: info threads</code> — see which threads are blocked in pthread_cond_wait</li>
        </ul>
      </div>`
  },

  'pthread-rwlock': {
    title: 'pthread_rwlock — Readers-Writer Lock',
    content: `
      <p>A readers-writer lock allows multiple concurrent readers but exclusive writer access.
      Implemented in glibc using futexes. The lock state encodes reader count and writer-pending
      bit in a single atomic word.</p>
      <p>Prefer when reads heavily outnumber writes. Be cautious of <strong>writer starvation</strong>
      in heavily read-biased workloads — glibc's default implementation prefers readers.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>perf lock report</code> — shows rwlock contention alongside mutex stats</li>
          <li><code>-fsanitize=thread</code> — TSan understands rwlocks for race detection</li>
        </ul>
      </div>`
  },

  'pthread-barrier': {
    title: 'pthread_barrier — Rendezvous Point',
    content: `
      <p>A barrier blocks all participating threads until the last one arrives, then releases
      them all simultaneously. Useful for synchronising parallel computation phases.</p>
      <p>Internally implemented using a futex-based counter: each thread atomically decrements
      the count; the last thread to arrive broadcasts a wakeup.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>strace -e futex ./binary</code> — barrier waits show as FUTEX_WAIT</li>
        </ul>
      </div>`
  },

  'pthread-sem': {
    title: 'sem_t — POSIX Semaphore',
    content: `
      <p>A POSIX semaphore is a non-negative integer counter with atomic increment/decrement.
      <code>sem_wait()</code> blocks if the count is zero; <code>sem_post()</code> increments
      and wakes a waiter. Unnamed semaphores live in shared memory; named semaphores
      (<code>sem_open</code>) are accessible across processes via <code>/dev/shm</code>.</p>
      <p>Unlike mutexes, semaphores have no concept of ownership — any thread can post.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>ls /dev/shm/</code> — list named semaphores and shared memory objects</li>
          <li><code>strace -e semop,futex ./binary</code> — trace semaphore operations</li>
        </ul>
      </div>`
  },

  'thread-cancel': {
    title: 'Thread Cancellation',
    content: `
      <p><code>pthread_cancel(tid)</code> requests cancellation of a target thread. The default
      mode is <strong>deferred</strong>: cancellation is delivered only at designated
      <em>cancellation points</em> (most blocking syscalls like <code>read</code>, <code>sleep</code>,
      <code>pthread_cond_wait</code>). <strong>Asynchronous</strong> cancellation delivers
      immediately — generally unsafe due to risk of inconsistent state.</p>
      <p>Cleanup handlers registered with <code>pthread_cleanup_push()</code> run when a thread
      is cancelled, ensuring mutex unlocks and resource frees.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>gdb: thread apply all bt</code> — full backtrace of all threads at cancellation</li>
        </ul>
      </div>`
  },

  /* ── System Call Interface ───────────────────────────────────── */
  'syscall-entry': {
    title: 'syscall Instruction — Ring-3 to Ring-0 Transition',
    content: `
      <p>On x86-64, the <code>syscall</code> instruction (replacing legacy <code>int 0x80</code>
      and <code>sysenter</code>) performs a fast privilege-level transition:</p>
      <ol style="padding-left:20px; margin-bottom:12px">
        <li>Saves RIP into RCX, RFLAGS into R11</li>
        <li>Loads the kernel CS and SS from the <code>STAR</code> MSR</li>
        <li>Jumps to the kernel entry point in the <code>LSTAR</code> MSR (<code>entry_SYSCALL_64</code>)</li>
        <li>Kernel switches to the <strong>per-CPU kernel stack</strong> (saved in the TSS)</li>
        <li>KPTI flushes non-global TLB entries (Meltdown mitigation)</li>
        <li>Syscall number (in RAX) is used to index <code>sys_call_table</code></li>
      </ol>
      <p>Arguments are passed in: RDI, RSI, RDX, R10, R8, R9 (up to 6).</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>strace ./binary</code> — trace all syscalls with args and return values</li>
          <li><code>strace -c ./binary</code> — count and time syscalls (summary table)</li>
          <li><code>perf stat -e syscalls:sys_enter_* ./binary</code> — hardware-level syscall counting</li>
          <li><code>ausyscall --dump</code> — list all syscall numbers for current arch</li>
        </ul>
      </div>`
  },

  'syscall-table': {
    title: 'sys_call_table — Kernel Dispatch Table',
    content: `
      <p><code>sys_call_table</code> is a static array of function pointers in the kernel, indexed
      by syscall number. On x86-64 there are ~350 entries. The kernel invokes
      <code>sys_call_table[rax](rdi, rsi, rdx, r10, r8, r9)</code>.</p>
      <p>The table lives in read-only memory (<code>__ro_after_init</code>) to prevent rootkit
      modification. Each entry points to a <code>SYSCALL_DEFINE</code>-generated stub that
      handles argument copying from user space and audit logging.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>sudo cat /proc/kallsyms | grep sys_call_table</code> — address of the table</li>
          <li><code>sudo bpftrace -e 'tracepoint:raw_syscalls:sys_enter { @[args-&gt;id] = count(); }'</code> — live syscall frequency histogram</li>
        </ul>
      </div>`
  },

  'vdso-syscall': {
    title: 'vDSO Fast-Path Syscalls',
    content: `
      <p>Certain high-frequency syscalls are accelerated by the vDSO — they execute entirely in
      user space by reading a kernel-maintained shared data page (<code>vvar</code>). This
      eliminates the expensive ring transition, TLB flush (KPTI), and kernel stack switch.</p>
      <p>The kernel updates the <code>vvar</code> page atomically using a <strong>seqlock</strong>:
      the reader spins if the sequence counter is odd (write in progress) and re-reads until it
      sees a stable even value.</p>
      <p>Speedup: ~25 ns for a vDSO <code>clock_gettime</code> vs ~100–300 ns for a real syscall.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>perf stat -e cs ./binary</code> — context-switch count; vDSO calls avoid these</li>
          <li><code>strace</code> will <em>not</em> see vDSO calls (they never enter the kernel)</li>
        </ul>
      </div>`
  },

  'seccomp': {
    title: 'seccomp BPF — Syscall Filtering',
    content: `
      <p><code>seccomp</code> (secure computing) attaches a BPF program to a thread that is
      evaluated on every syscall entry. The filter can return:</p>
      <ul>
        <li><code>SECCOMP_RET_ALLOW</code> — continue normally</li>
        <li><code>SECCOMP_RET_KILL_PROCESS</code> — immediately terminate with SIGSYS</li>
        <li><code>SECCOMP_RET_TRAP</code> — deliver SIGSYS to the thread</li>
        <li><code>SECCOMP_RET_ERRNO</code> — return a fake error code</li>
        <li><code>SECCOMP_RET_TRACE</code> — notify a ptrace tracer (for sandboxing)</li>
      </ul>
      <p>Used by Chrome, Firefox, Docker, systemd, and OpenSSH for privilege reduction.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/status | grep Seccomp</code> — 0=off, 1=strict, 2=filter</li>
          <li><code>seccomp-tools dump ./binary</code> — extract and disassemble BPF filter</li>
          <li><code>strace -e seccomp ./binary</code> — trace seccomp installation</li>
        </ul>
      </div>`
  },

  'ptrace': {
    title: 'ptrace — Process Tracing / Debugger Interface',
    content: `
      <p><code>ptrace(2)</code> is the kernel mechanism underlying debuggers (<code>gdb</code>,
      <code>lldb</code>) and system call tracers (<code>strace</code>). The tracer process
      attaches to a tracee; the tracee is stopped on each syscall entry/exit, signal delivery,
      or single-step instruction.</p>
      <p>At each stop, the tracer can inspect/modify registers (<code>PTRACE_GETREGS</code>),
      read/write memory (<code>PTRACE_PEEKDATA</code>), inject signals, or change the syscall
      number — forming the basis of syscall sandboxing in tools like <code>gvisor</code>.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>strace -p &lt;pid&gt;</code> — attach to a running process</li>
          <li><code>gdb -p &lt;pid&gt;</code> — live debugging via ptrace</li>
          <li><code>sysctl kernel.yama.ptrace_scope</code> — 0=permissive, 1=restricted, 2=admin-only</li>
        </ul>
      </div>`
  },

  /* ── Kernel Task Management ──────────────────────────────────── */
  'task-struct': {
    title: 'task_struct — The Kernel Thread Descriptor',
    content: `
      <p><code>task_struct</code> (defined in <code>include/linux/sched.h</code>) is the central
      kernel data structure for every thread. It is approximately 10 KB in size and contains
      hundreds of fields:</p>
      <ul>
        <li><strong>Scheduling</strong>: <code>state</code>, <code>prio</code>, <code>sched_entity</code>, <code>policy</code></li>
        <li><strong>Identity</strong>: <code>pid</code>, <code>tgid</code>, <code>comm[16]</code> (name)</li>
        <li><strong>Memory</strong>: <code>mm</code> (pointer to <code>mm_struct</code>)</li>
        <li><strong>Files</strong>: <code>files</code> (pointer to <code>files_struct</code>)</li>
        <li><strong>Signals</strong>: <code>sighand</code>, <code>pending</code></li>
        <li><strong>Timing</strong>: <code>utime</code>, <code>stime</code>, <code>start_time</code></li>
        <li><strong>CPU state</strong>: <code>thread</code> (arch-specific registers on context switch)</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>sudo bpftrace -e 'kprobe:schedule { printf("%s\\n", comm); }'</code> — print task name on each schedule</li>
          <li><code>sudo crash /boot/vmlinux /proc/kcore</code> — inspect live kernel structures</li>
          <li><code>cat /proc/&lt;pid&gt;/status</code> — many task_struct fields exported here</li>
        </ul>
      </div>`
  },

  'mm-struct': {
    title: 'mm_struct — Process Address Space Descriptor',
    content: `
      <p><code>mm_struct</code> describes the complete virtual address space of a process.
      All threads in a process share a single <code>mm_struct</code> (pointed to by
      <code>task_struct.mm</code>). It contains:</p>
      <ul>
        <li><strong>pgd</strong> — physical address of the top-level page directory (loaded into CR3)</li>
        <li><strong>mmap</strong> — linked list / rbtree of all <code>vm_area_struct</code> (VMAs)</li>
        <li><strong>start_code/end_code</strong>, <strong>start_data</strong>, <strong>brk</strong>, <strong>start_stack</strong> — region boundaries</li>
        <li><strong>mm_count / mm_users</strong> — reference counts for thread sharing and <code>execve</code></li>
        <li><strong>mmap_lock</strong> (rwsem) — protects the VMA tree during modifications</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>/proc/&lt;pid&gt;/maps</code> — VMA list from mm_struct</li>
          <li><code>/proc/&lt;pid&gt;/statm</code> — total/resident/shared page counts</li>
          <li><code>sudo bpftrace -e 'kprobe:do_mmap { printf("mmap called\\n"); }'</code></li>
        </ul>
      </div>`
  },

  'files-struct': {
    title: 'files_struct — File Descriptor Table',
    content: `
      <p><code>files_struct</code> holds the per-process (shared among threads) open file
      descriptor table. Each entry in the table is a pointer to a <code>file</code> struct,
      which in turn points to the underlying <code>inode</code>.</p>
      <p>FD flags (<code>FD_CLOEXEC</code>) are stored separately from the <code>file</code>
      struct so they can differ between processes that share the same open file description
      (after <code>fork</code> or <code>dup</code>).</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>ls -la /proc/&lt;pid&gt;/fd/</code> — all open file descriptors as symlinks</li>
          <li><code>lsof -p &lt;pid&gt;</code> — detailed open file listing</li>
          <li><code>cat /proc/sys/fs/file-max</code> — system-wide open file limit</li>
          <li><code>ulimit -n</code> — per-process FD limit</li>
        </ul>
      </div>`
  },

  'signal-struct': {
    title: 'signal_struct — Signal Handling State',
    content: `
      <p>Each process has one <code>signal_struct</code> (shared by all threads), which holds
      the array of <code>sigaction</code> structures defining how each of the 64 signals is
      handled (SIG_DFL, SIG_IGN, or a handler function). Per-thread pending signal sets
      live in <code>task_struct.pending</code>; process-wide pending signals live in
      <code>signal_struct.shared_pending</code>.</p>
      <p>The kernel delivers signals at syscall return or on preemption by checking
      <code>TIF_SIGPENDING</code> in the thread info flags.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/status | grep Sig</code> — SigPnd, SigBlk, SigIgn, SigCgt bitmasks</li>
          <li><code>kill -l</code> — list all signal names and numbers</li>
          <li><code>strace -e signal ./binary</code> — trace signal-related syscalls</li>
        </ul>
      </div>`
  },

  'cred-struct': {
    title: 'cred — Credentials & Capabilities',
    content: `
      <p>The <code>cred</code> struct stores the security identity of a task:
      real/effective/saved UID and GID, supplementary groups, Linux capabilities
      (64-bit bitmask split into permitted, effective, and inheritable sets), and
      security module labels (SELinux, AppArmor).</p>
      <p>Linux capabilities divide root privilege into discrete units
      (<code>CAP_NET_ADMIN</code>, <code>CAP_SYS_PTRACE</code>, etc.), enabling
      privilege separation without full-root suid binaries.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/status | grep Cap</code> — raw capability hex bitmasks</li>
          <li><code>capsh --decode=&lt;hex&gt;</code> — decode capability bitmask to names</li>
          <li><code>getpcaps &lt;pid&gt;</code> — human-readable capabilities of a process</li>
          <li><code>id</code> — current process UID/GID/groups</li>
        </ul>
      </div>`
  },

  'pid-ns': {
    title: 'PID Namespaces & Linux Namespaces',
    content: `
      <p>Linux namespaces partition global system resources so processes inside a namespace
      have an isolated view. Key namespace types:</p>
      <ul>
        <li><strong>pid</strong> — isolated PID number space (container PID 1)</li>
        <li><strong>mnt</strong> — independent filesystem mount tree</li>
        <li><strong>net</strong> — private network interfaces, routing tables</li>
        <li><strong>uts</strong> — independent hostname and domain name</li>
        <li><strong>ipc</strong> — isolated SysV IPC and POSIX message queues</li>
        <li><strong>user</strong> — UID/GID remapping (user containers)</li>
        <li><strong>cgroup</strong> — isolated cgroup root</li>
      </ul>
      <p>Together with cgroups, namespaces form the foundation of <strong>containers</strong>
      (Docker, podman, systemd-nspawn).</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>ls -la /proc/&lt;pid&gt;/ns/</code> — symlinks to each namespace inode</li>
          <li><code>lsns</code> — list all namespaces on the system</li>
          <li><code>nsenter -t &lt;pid&gt; --all bash</code> — enter a process's namespaces</li>
          <li><code>unshare --pid --fork bash</code> — create a new PID namespace</li>
        </ul>
      </div>`
  },

  'wait-queue': {
    title: 'wait_queue — Blocking & Wakeup Infrastructure',
    content: `
      <p>The kernel's <code>wait_queue_head_t</code> is a linked list of sleeping tasks waiting
      on a condition. When a task calls <code>wait_event(wq, condition)</code>, it adds itself
      to the list and calls <code>schedule()</code>. When the condition changes,
      <code>wake_up(wq)</code> iterates the list and marks waiters as runnable.</p>
      <p>Used pervasively throughout the kernel: I/O completion, socket receive buffers,
      pipe writes, futex wake, epoll, and inotify all use wait queues.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/wchan</code> — kernel function where thread is sleeping</li>
          <li><code>ps -o pid,wchan ./binary</code> — wait channel in ps output</li>
          <li><code>sudo bpftrace -e 'kprobe:wake_up_process { @[probe] = count(); }'</code></li>
        </ul>
      </div>`
  },

  /* ── Scheduler ───────────────────────────────────────────────── */
  'cfs': {
    title: 'CFS — Completely Fair Scheduler',
    content: `
      <p>CFS (introduced in Linux 2.6.23) aims to give each runnable task a proportionally equal
      share of CPU time. It tracks a per-task <strong>virtual runtime</strong>
      (<code>vruntime</code>, in nanoseconds) that advances proportionally to the task's
      scheduling weight (derived from <code>nice</code> value).</p>
      <p>All runnable tasks are stored in a <strong>red-black tree</strong> keyed by
      <code>vruntime</code>. The scheduler always picks the <em>leftmost</em> node — the task
      with the smallest vruntime (i.e., the one that has received the least CPU time). This gives
      O(log n) pick-next and O(log n) enqueue/dequeue.</p>
      <p><strong>Target latency</strong> (default 6–24 ms) is the period within which every
      runnable task should get at least one timeslice.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/sched</code> — per-task CFS statistics (vruntime, switches)</li>
          <li><code>schedtool -r -p 99 -e ./binary</code> — set real-time priority</li>
          <li><code>chrt -f 50 ./binary</code> — run with SCHED_FIFO priority 50</li>
          <li><code>nice -n -10 ./binary</code> — increase priority (lower nice = higher weight)</li>
          <li><code>perf sched latency</code> — scheduling latency analysis</li>
        </ul>
      </div>`
  },

  'rt-sched': {
    title: 'RT Scheduler — SCHED_FIFO / SCHED_RR',
    content: `
      <p>Real-time scheduling policies preempt CFS tasks unconditionally.
      RT tasks have priorities 1–99 (higher = more urgent) and always run before any CFS task.</p>
      <ul>
        <li><strong>SCHED_FIFO</strong> — runs until it blocks or yields; no timeslice</li>
        <li><strong>SCHED_RR</strong> — like FIFO but with a round-robin timeslice among equal priorities</li>
        <li><strong>SCHED_DEADLINE</strong> — sporadic tasks with explicit runtime/deadline/period (EDF algorithm)</li>
      </ul>
      <p>To prevent RT tasks from starving the system: <code>kernel.sched_rt_runtime_us</code>
      (default 950 ms per 1000 ms) reserves 5% of CPU for non-RT tasks.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>chrt -p &lt;pid&gt;</code> — show scheduling policy and priority</li>
          <li><code>chrt -f -p 80 &lt;pid&gt;</code> — set SCHED_FIFO priority 80</li>
          <li><code>cyclictest</code> — measure real-time scheduling latency</li>
          <li><code>sysctl kernel.sched_rt_runtime_us</code></li>
        </ul>
      </div>`
  },

  'sched-domain': {
    title: 'Scheduling Domains — NUMA & CPU Topology',
    content: `
      <p>Scheduling domains form a hierarchy that mirrors the CPU topology:
      SMT siblings → cores → LLC-sharing socket → NUMA node. Load balancing respects this
      hierarchy — it's cheaper to move a task between two SMT threads on the same core than
      between NUMA nodes.</p>
      <p>The kernel builds domain topology at boot from ACPI/SMBIOS data and exposes it via
      <code>/sys/devices/system/cpu/cpu*/topology/</code>.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>lstopo</code> (hwloc) — visual CPU/NUMA topology diagram</li>
          <li><code>numactl --hardware</code> — NUMA node layout and distances</li>
          <li><code>cat /sys/devices/system/cpu/cpu0/topology/core_siblings</code></li>
          <li><code>lscpu</code> — full CPU topology summary</li>
        </ul>
      </div>`
  },

  'runqueue': {
    title: 'Per-CPU Runqueue (rq)',
    content: `
      <p>Each CPU has its own <code>struct rq</code> containing sub-queues for each scheduler
      class: <code>cfs_rq</code> (the red-black vruntime tree), <code>rt_rq</code> (bitmap of
      100 priority levels), and <code>dl_rq</code> (deadline tasks, an rbtree by deadline).</p>
      <p>The scheduler always checks queues from highest to lowest class: DL → RT → CFS → idle.
      Having per-CPU runqueues eliminates the global lock bottleneck of earlier kernels.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/schedstat</code> — per-CPU scheduler statistics</li>
          <li><code>sudo bpftrace -e 'tracepoint:sched:sched_switch { @[cpu] = count(); }'</code> — context switches per CPU</li>
          <li><code>mpstat -P ALL 1</code> — per-CPU utilisation</li>
        </ul>
      </div>`
  },

  'load-balance': {
    title: 'Load Balancer — Work Stealing',
    content: `
      <p>Linux's load balancer runs periodically (via the scheduler tick) and on CPU idle.
      It identifies imbalanced runqueues and <em>pulls</em> tasks from busy CPUs to idle ones.
      This is work-stealing: the idle CPU reaches into a busier CPU's runqueue and migrates
      the least-recently-run task.</p>
      <p>Migration is constrained by scheduling domains — the balancer won't cross a NUMA
      boundary unless the imbalance is significant, because remote NUMA memory access is slow.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/schedstat | grep 'lb'</code> — load-balance statistics</li>
          <li><code>perf sched migrate</code> — trace task migrations between CPUs</li>
          <li><code>taskset -c 0,1 ./binary</code> — pin to specific CPUs, disabling migration</li>
        </ul>
      </div>`
  },

  'context-switch': {
    title: 'Context Switch — switch_to()',
    content: `
      <p>A context switch saves the outgoing thread's CPU state and restores the incoming
      thread's state. On x86-64 this involves:</p>
      <ol style="padding-left:20px; margin-bottom:12px">
        <li>Save/restore callee-saved registers (RSP, RBP, R12–R15) on the kernel stack</li>
        <li>Load the incoming thread's <strong>CR3</strong> (top-level page table) if switching between processes — this flushes the TLB</li>
        <li>Update the TSS (<code>tss.sp0</code>) with the new kernel stack pointer</li>
        <li>Switch the FS base register (<code>arch_prctl(ARCH_SET_FS)</code>) for TLS</li>
        <li>Flush FPU/SIMD state lazily (only on first FP instruction after switch)</li>
      </ol>
      <p>Switching between threads of the <em>same process</em> is cheaper because CR3 stays
      the same — no TLB flush needed.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>perf stat -e cs ./binary</code> — total context switches</li>
          <li><code>vmstat 1</code> — context switches per second (cs column)</li>
          <li><code>pidstat -w -p &lt;pid&gt; 1</code> — voluntary vs involuntary context switches</li>
        </ul>
      </div>`
  },

  'affinity': {
    title: 'CPU Affinity — sched_setaffinity()',
    content: `
      <p>CPU affinity restricts which CPUs a task may run on, expressed as a bitmask
      (<code>cpu_set_t</code>). Pinning threads to specific CPUs can reduce cache thrashing,
      improve NUMA locality, and provide more predictable latency.</p>
      <p>The scheduler's load balancer respects affinity masks and will not migrate a task
      outside its allowed set. A task with a single-CPU affinity mask effectively has a
      dedicated core.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>taskset -c 0,2 ./binary</code> — run on CPUs 0 and 2</li>
          <li><code>taskset -cp 0,2 &lt;pid&gt;</code> — change affinity of running process</li>
          <li><code>numactl --cpunodebind=0 ./binary</code> — bind to NUMA node 0's CPUs</li>
          <li><code>cat /proc/&lt;pid&gt;/status | grep Cpus_allowed</code></li>
        </ul>
      </div>`
  },

  'preemption': {
    title: 'Kernel Preemption — CONFIG_PREEMPT',
    content: `
      <p>Kernel preemption allows the scheduler to interrupt a thread running in kernel mode
      (e.g., inside a syscall) and switch to a higher-priority task. Without preemption,
      a thread cannot be descheduled until it voluntarily yields or returns to user space.</p>
      <p>Linux offers three preemption models:</p>
      <ul>
        <li><strong>PREEMPT_NONE</strong> — no voluntary kernel preemption; lowest latency overhead</li>
        <li><strong>PREEMPT_VOLUNTARY</strong> — explicit preemption points at selected kernel locations</li>
        <li><strong>PREEMPT</strong> — full preemption except in spinlock-protected sections</li>
        <li><strong>PREEMPT_RT</strong> (PREEMPT_REALTIME patch) — nearly all spinlocks become sleeping locks; suitable for hard real-time</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>zcat /proc/config.gz | grep PREEMPT</code> — check kernel preemption config</li>
          <li><code>uname -v | grep PREEMPT</code> — visible in kernel version string for RT kernels</li>
        </ul>
      </div>`
  },

  /* ── Kernel Memory Management ────────────────────────────────── */
  'page-table': {
    title: 'Page Tables — 4-Level / 5-Level Walk',
    content: `
      <p>x86-64 Linux uses a 4-level (or 5-level with LA57) page table to translate 48-bit
      (or 57-bit) virtual addresses to 52-bit physical addresses:</p>
      <pre>VA bits [47:39] → PGD (Page Global Dir, 512 entries)
VA bits [38:30] → PUD (Page Upper Dir)
VA bits [29:21] → PMD (Page Middle Dir)
VA bits [20:12] → PTE (Page Table Entry)
VA bits [11:0]  → byte offset within 4 KB page</pre>
      <p>Each table has 512 entries × 8 bytes = 4 KB (one page). The PTE contains the physical
      page frame number, accessed/dirty bits, and protection flags (U/S, R/W, NX).</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/pagemap</code> — virtual → physical page mapping (requires root)</li>
          <li><code>page-types</code> tool from kernel tools — page frame flags</li>
          <li><code>sudo cat /proc/kpageflags</code> — per-PFN flags for all physical memory</li>
        </ul>
      </div>`
  },

  'tlb': {
    title: 'TLB — Translation Lookaside Buffer',
    content: `
      <p>The TLB is a hardware cache of recent virtual-to-physical address translations, holding
      ~64–2048 entries per CPU. A TLB <em>hit</em> resolves a virtual address in 1–4 cycles;
      a <em>miss</em> requires a hardware page-table walk costing ~100+ cycles.</p>
      <p>TLB flushes (invalidations) are required when:</p>
      <ul>
        <li>A new process is scheduled (CR3 reload — flushes all non-global entries)</li>
        <li>A VMA is unmapped or its permissions change</li>
        <li>A page is CoW-broken</li>
        <li>Meltdown mitigation: KPTI flushes on every kernel entry/exit (expensive)</li>
      </ul>
      <p>For multi-CPU flushes, the kernel sends <strong>TLB shootdown IPIs</strong> via the
      Local APIC to synchronise all cores.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>perf stat -e dTLB-load-misses,iTLB-load-misses ./binary</code> — TLB miss counts</li>
          <li><code>sudo perf stat -e tlb:tlb_flush ./binary</code> — kernel TLB flush events</li>
        </ul>
      </div>`
  },

  'page-fault': {
    title: 'Page Fault Handler — Demand Paging & CoW',
    content: `
      <p>A page fault fires when the MMU cannot translate a virtual address — either because
      the PTE is not-present or the access violates permissions. The kernel's
      <code>do_page_fault()</code> (x86: <code>exc_page_fault()</code>) handles three cases:</p>
      <ul>
        <li><strong>Minor fault</strong> — PTE valid in <code>mm_struct</code> but page not yet loaded;
          allocate a physical page and fill it (demand paging). No disk I/O. Cheap.</li>
        <li><strong>Major fault</strong> — page was swapped out; must read from swap device.
          Expensive I/O wait.</li>
        <li><strong>CoW fault</strong> — write to a read-only shared page; allocate a new page,
          copy content, update PTE.</li>
        <li><strong>SIGSEGV</strong> — address outside any VMA or wrong permissions; fatal.</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>perf stat -e page-faults,major-faults ./binary</code> — fault counts</li>
          <li><code>cat /proc/&lt;pid&gt;/status | grep VmFlt</code> — major/minor fault totals</li>
          <li><code>sudo bpftrace -e 'tracepoint:exceptions:page_fault_user { @[comm] = count(); }'</code></li>
        </ul>
      </div>`
  },

  'cow': {
    title: 'Copy-on-Write (CoW)',
    content: `
      <p>CoW is a kernel optimization where two processes (or a parent and forked child) share
      the same physical pages mapped as <em>read-only</em> in both address spaces. The data
      is only physically duplicated when one process writes to it — triggering a protection
      fault that the kernel handles by allocating a new page, copying the content, and updating
      the faulting process's PTE to point to the new page.</p>
      <p>CoW enables:</p>
      <ul>
        <li><strong>Fast fork()</strong> — duplicating mm_struct is cheap; no actual page copies until writes happen</li>
        <li><strong>Shared library .data</strong> — initial values shared until a process modifies a global</li>
        <li><strong>mmap(MAP_PRIVATE)</strong> — file-backed private mappings</li>
        <li><strong>Zero page for .bss</strong> — all zero-init data pages share one zero page</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>/proc/&lt;pid&gt;/smaps — Private_Dirty</code> shows pages that have been CoW-broken</li>
          <li><code>perf stat -e page-faults ./binary</code> — CoW breaks show as minor faults</li>
        </ul>
      </div>`
  },

  'slab': {
    title: 'SLAB / SLUB Allocator — Kernel Object Caches',
    content: `
      <p>The SLUB allocator (default since 2.6.23) is the kernel's equivalent of userspace
      <code>malloc</code>. It maintains per-CPU caches of frequently allocated objects
      (<code>task_struct</code>, <code>inode</code>, <code>file</code>, <code>dentry</code>,
      <code>socket</code>, etc.) to avoid expensive buddy-allocator calls for every object.</p>
      <p>Each <em>slab cache</em> holds objects of a single size, minimising fragmentation.
      Objects are allocated in bulk from buddy pages and recycled without zeroing (constructors
      handle initialisation).</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/slabinfo</code> — all slab caches with active/total counts</li>
          <li><code>slabtop</code> — live slab usage sorted by size (like top for slabs)</li>
          <li><code>sudo bpftrace -e 'kprobe:kmem_cache_alloc { @[comm] = count(); }'</code></li>
        </ul>
      </div>`
  },

  'buddy': {
    title: 'Buddy Allocator — Page-Granularity Free Lists',
    content: `
      <p>The buddy system manages physical memory in power-of-2 page blocks (order 0 = 4 KB,
      order 1 = 8 KB, …, order 10 = 4 MB). Allocation searches the smallest available order
      ≥ requested size and splits if necessary. Freed blocks are merged with their
      <em>buddy</em> (the adjacent same-size block) back up to order 10.</p>
      <p>Memory is divided into zones: <code>DMA</code> (&lt;16 MB), <code>DMA32</code>
      (&lt;4 GB), <code>NORMAL</code>, and optionally <code>HIGHMEM</code> (32-bit only)
      and <code>MOVABLE</code> (for page migration and huge-page promotion).</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/buddyinfo</code> — free blocks per order per zone</li>
          <li><code>cat /proc/zoneinfo</code> — detailed zone statistics</li>
          <li><code>cat /proc/meminfo</code> — system-wide memory summary</li>
        </ul>
      </div>`
  },

  'mmap-anon': {
    title: 'Anonymous mmap — Heap, Stacks, and Malloc',
    content: `
      <p><code>mmap(NULL, size, PROT_READ|PROT_WRITE, MAP_ANONYMOUS|MAP_PRIVATE, -1, 0)</code>
      allocates a region of private anonymous memory backed by physical pages on demand.
      The kernel creates a new VMA; pages are only faulted in as the program writes to them.</p>
      <p>Uses:</p>
      <ul>
        <li><strong>glibc malloc</strong> — large allocations (&gt;MMAP_THRESHOLD ~128 KB)</li>
        <li><strong>Thread stacks</strong> — each <code>pthread_create</code> calls <code>mmap</code> for the stack</li>
        <li><strong>brk() extension</strong> — small heap growth below MMAP_THRESHOLD</li>
        <li><strong>Stack overflow guard page</strong> — <code>mmap(PROT_NONE)</code> below each thread stack</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>strace -e mmap,mprotect ./binary</code> — trace all memory mapping calls</li>
          <li><code>cat /proc/&lt;pid&gt;/maps | grep 'anon'</code> — anonymous VMAs</li>
        </ul>
      </div>`
  },

  'oom': {
    title: 'OOM Killer — Out-of-Memory Process Selection',
    content: `
      <p>When the system runs out of memory and cannot reclaim any, the kernel's OOM killer
      selects a process to terminate. It computes an <strong>oom_score</strong> for each process
      based on its memory consumption (RSS + swap), runtime, and a user-configurable
      <code>oom_score_adj</code> (-1000 to +1000). The process with the highest score is killed.</p>
      <p>Setting <code>oom_score_adj = -1000</code> makes a process immune to OOM killing
      (used by system daemons). Setting it to <code>+1000</code> makes it the first victim.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/&lt;pid&gt;/oom_score</code> — current OOM score</li>
          <li><code>echo -500 > /proc/&lt;pid&gt;/oom_score_adj</code> — reduce OOM priority</li>
          <li><code>dmesg | grep -i 'oom'</code> — OOM kill events in kernel log</li>
        </ul>
      </div>`
  },

  'huge-pages': {
    title: 'Transparent Huge Pages (THP) / HugeTLB',
    content: `
      <p>Huge pages (2 MB on x86-64, 1 GB with 1G pages) reduce TLB pressure by covering
      512× more virtual address space per TLB entry. Linux supports two mechanisms:</p>
      <ul>
        <li><strong>THP (Transparent Huge Pages)</strong> — the kernel automatically promotes
          4 KB PTEs to 2 MB PMD entries when a 2 MB-aligned anonymous region is fully faulted in.
          Transparent to applications. Can cause latency spikes during promotion/demotion.</li>
        <li><strong>HugeTLB</strong> — pre-allocated huge-page pools via <code>hugetlbfs</code>;
          applications must use <code>mmap(MAP_HUGETLB)</code> or libhugetlbfs explicitly.
          Predictable but inflexible.</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /sys/kernel/mm/transparent_hugepage/enabled</code> — THP policy (always/madvise/never)</li>
          <li><code>cat /proc/meminfo | grep Huge</code> — huge page allocation stats</li>
          <li><code>perf stat -e dTLB-load-misses ./binary</code> — TLB miss reduction from huge pages</li>
        </ul>
      </div>`
  },

  'swap': {
    title: 'Swap / zswap — Paging to Disk',
    content: `
      <p>When the kernel needs physical pages and cannot reclaim clean file-backed pages,
      it <em>swaps out</em> dirty anonymous pages to a swap partition or swap file. The PTE
      is marked not-present with a swap entry encoding the location on disk; the physical page
      is freed. On access, a <strong>major page fault</strong> occurs and the page is read back.</p>
      <p><strong>zswap</strong> is a compressed in-memory swap cache: pages are compressed
      (LZO, LZ4, zstd) and stored in a pool before being evicted to disk, reducing swap I/O.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>swapon --show</code> — list swap devices and usage</li>
          <li><code>vmstat 1 | awk '{print $7,$8}'</code> — swap-in/out per second</li>
          <li><code>cat /proc/meminfo | grep Swap</code> — total/used/free swap</li>
          <li><code>cat /proc/&lt;pid&gt;/status | grep VmSwap</code> — per-process swap usage</li>
        </ul>
      </div>`
  },

  /* ── Sync & IPC ──────────────────────────────────────────────── */
  'futex': {
    title: 'futex(2) — Fast Userspace Mutex',
    content: `
      <p>A futex (fast userspace mutex) is a 32-bit integer in shared memory that threads
      manipulate with atomic CPU instructions (CAS). The kernel is only invoked in the
      contended case:</p>
      <ul>
        <li><code>FUTEX_WAIT</code> — atomically check the value and sleep if it matches; the
          thread is added to the kernel's futex hash table</li>
        <li><code>FUTEX_WAKE</code> — wake N threads sleeping on the futex address</li>
        <li><code>FUTEX_REQUEUE</code> — move waiters to a different futex (used in
          <code>pthread_cond_broadcast</code>)</li>
      </ul>
      <p>The futex key is the physical address of the 32-bit word, enabling futexes to work
      across processes sharing the same memory-mapped region.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>strace -e futex ./binary</code> — every futex syscall with arguments</li>
          <li><code>perf lock record ./binary &amp;&amp; perf lock report</code></li>
          <li><code>sudo bpftrace -e 'tracepoint:syscalls:sys_enter_futex { @[comm] = count(); }'</code></li>
        </ul>
      </div>`
  },

  'pipe': {
    title: 'pipe / pipe2 — Anonymous Byte-Stream IPC',
    content: `
      <p>A pipe is a unidirectional byte stream with a kernel-managed ring buffer (default 64 KB,
      configurable via <code>F_SETPIPE_SZ</code>). Writes block when the buffer is full; reads
      block when empty. The kernel implements pipes as a pair of file descriptors sharing a
      <code>pipe_inode_info</code> struct.</p>
      <p>Linux supports <strong>splice()</strong> and <strong>vmsplice()</strong> to move data
      between pipes and file descriptors without copying through user space (zero-copy).</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>ls -la /proc/&lt;pid&gt;/fd | grep pipe</code> — find pipe FDs</li>
          <li><code>cat /proc/&lt;pid&gt;/fdinfo/&lt;n&gt;</code> — pipe buffer position and flags</li>
          <li><code>strace -e pipe,read,write ./binary</code></li>
        </ul>
      </div>`
  },

  'eventfd': {
    title: 'eventfd / timerfd — Edge-Triggered Counters',
    content: `
      <p><code>eventfd(2)</code> creates a file descriptor wrapping a 64-bit counter. Writes
      add to the counter; reads return and reset it. It integrates with <code>epoll</code>
      and <code>select</code>, making it ideal for waking an I/O event loop from another thread
      or from a signal handler.</p>
      <p><code>timerfd_create(2)</code> creates an FD that becomes readable when a timer expires,
      again compatible with <code>epoll</code> — enabling timer events in the same event loop
      as network I/O without signals.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>strace -e eventfd,timerfd_create ./binary</code></li>
          <li><code>ls /proc/&lt;pid&gt;/fd</code> — eventfd shows as <code>anon_inode:[eventfd]</code></li>
        </ul>
      </div>`
  },

  'mq': {
    title: 'POSIX Message Queues — mq_open',
    content: `
      <p>POSIX message queues (<code>mq_open</code>, <code>mq_send</code>, <code>mq_receive</code>)
      provide typed, prioritised, kernel-buffered message passing between processes or threads.
      Messages are delivered in priority order. Queues persist as named entries in the
      <code>mqueue</code> pseudo-filesystem (<code>/dev/mqueue/</code>).</p>
      <p>Unlike pipes, message boundaries are preserved and each message has an associated
      priority. Blocking and non-blocking modes are supported, and queues can be
      <code>select()</code>/<code>poll()</code>-able.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>ls /dev/mqueue/</code> — list open named queues</li>
          <li><code>cat /proc/sys/fs/mqueue/msg_max</code> — max messages per queue</li>
        </ul>
      </div>`
  },

  'shm': {
    title: 'Shared Memory — shmget / shm_open',
    content: `
      <p>Shared memory is the fastest IPC mechanism — two or more processes map the same
      physical pages into their respective virtual address spaces. No data copying occurs;
      communication is as fast as a memory write.</p>
      <p>Two APIs:</p>
      <ul>
        <li><strong>SysV</strong> — <code>shmget</code> / <code>shmat</code> / <code>shmdt</code>;
          kernel-managed with IPC keys. Legacy.</li>
        <li><strong>POSIX</strong> — <code>shm_open</code> / <code>mmap</code>; backed by
          <code>tmpfs</code> objects in <code>/dev/shm/</code>. Preferred.</li>
      </ul>
      <p>Synchronisation must be provided separately (futex-based mutex, semaphore, etc.)
      since shared memory has no inherent ordering guarantees.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>ipcs -m</code> — list SysV shared memory segments</li>
          <li><code>ls /dev/shm/</code> — POSIX shared memory objects</li>
          <li><code>cat /proc/&lt;pid&gt;/maps | grep '/dev/shm'</code></li>
        </ul>
      </div>`
  },

  'signal-ipc': {
    title: 'kill / sigqueue — Async Signal Notification',
    content: `
      <p>Signals are the kernel's mechanism for asynchronous notification of events.
      <code>kill(pid, sig)</code> delivers a signal to a process; the kernel sets a bit in
      <code>task_struct.pending.signal</code> and sets <code>TIF_SIGPENDING</code>.
      The signal is delivered at the next opportunity (syscall return, preemption point).</p>
      <p><code>sigqueue()</code> delivers a real-time signal with a <code>sigval</code> payload
      (integer or pointer), and real-time signals (34–64) are queued rather than collapsed.</p>
      <p>Self-pipe trick / <code>signalfd(2)</code> allows signals to be consumed via
      <code>read()</code> in an event loop.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>kill -l</code> — list all signals</li>
          <li><code>kill -SIGSTOP &lt;pid&gt;</code> — pause a process</li>
          <li><code>strace -e signal ./binary</code></li>
          <li><code>cat /proc/&lt;pid&gt;/status | grep SigPnd</code></li>
        </ul>
      </div>`
  },

  'membarrier': {
    title: 'membarrier(2) — Cross-Thread Memory Ordering',
    content: `
      <p><code>membarrier(2)</code> issues a memory barrier across all threads of the calling
      process (or system-wide). This is used by lock-free data structures that need to ensure
      that all CPUs observe stores in the correct order, without the overhead of full memory
      fences on every operation.</p>
      <p>The caller issues an expensive full barrier once; all other threads implicitly execute
      a fence at their next scheduling point, allowing the fast path (reader side) to use
      relaxed loads.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>strace -e membarrier ./binary</code></li>
          <li>Used internally by glibc's POSIX <code>pthread_atfork()</code> and RCU implementations</li>
        </ul>
      </div>`
  },

  /* ── Hardware ────────────────────────────────────────────────── */
  'cpu-core': {
    title: 'CPU Core — Instruction Fetch / Decode / Execute',
    content: `
      <p>A modern x86-64 core is a deeply pipelined, out-of-order superscalar machine.
      Key stages:</p>
      <ul>
        <li><strong>Fetch</strong> — fetch up to 16–32 bytes of instructions from L1-I cache;
          branch predictor speculatively selects next PC</li>
        <li><strong>Decode</strong> — x86 macro-ops split into 1–4 micro-ops (μops)</li>
        <li><strong>Rename / Dispatch</strong> — register renaming eliminates false dependencies;
          μops issued to reservation stations</li>
        <li><strong>Execute (OOO)</strong> — up to 4–6 μops per cycle, out of program order</li>
        <li><strong>Retire</strong> — μops committed in program order to architectural state</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>perf stat ./binary</code> — IPC, cache-miss, branch-miss summary</li>
          <li><code>perf record -g ./binary &amp;&amp; perf report</code> — CPU flamegraph</li>
          <li><code>toplev.py</code> (pmu-tools) — top-down microarchitecture analysis</li>
          <li><code>likwid-perfctr</code> — hardware counter profiling</li>
        </ul>
      </div>`
  },

  'registers': {
    title: 'Registers — GPRs, SIMD, Segment Registers',
    content: `
      <p>x86-64 exposes 16 general-purpose 64-bit registers (RAX–R15), 16 SSE/AVX
      128/256/512-bit SIMD registers (XMM0–XMM15 / YMM / ZMM), and several control registers.</p>
      <p>Key roles in thread execution:</p>
      <ul>
        <li><strong>RIP</strong> — instruction pointer; the heart of a thread's execution state</li>
        <li><strong>RSP</strong> — stack pointer; points to current top of the thread stack</li>
        <li><strong>RBP</strong> — frame pointer (optional; omitted with <code>-fomit-frame-pointer</code>)</li>
        <li><strong>FS</strong> — base of TLS segment; <code>fs:0</code> = <code>pthread_self()</code></li>
        <li><strong>CR3</strong> — physical address of page table root (per-process, reloaded on context switch)</li>
        <li><strong>RFLAGS</strong> — condition codes (ZF, CF, SF, OF) + interrupt enable flag</li>
      </ul>
      <p>On context switch, callee-saved registers (RBX, RBP, R12–R15) are saved on the kernel
      stack; caller-saved registers are the thread's own responsibility.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>gdb: info registers</code> — dump all GPRs for current thread</li>
          <li><code>gdb: info all-registers</code> — include FP/SSE/AVX state</li>
          <li><code>strace</code> — displays syscall args which are register values</li>
        </ul>
      </div>`
  },

  'cache': {
    title: 'L1/L2/L3 Cache — MESI Coherence Protocol',
    content: `
      <p>Modern CPUs have a hierarchy of SRAM caches:</p>
      <ul>
        <li><strong>L1-D / L1-I</strong> — 32–64 KB, private per core, ~4 cycles</li>
        <li><strong>L2</strong> — 256 KB–2 MB, private per core (or shared between SMT threads), ~12 cycles</li>
        <li><strong>L3 (LLC)</strong> — 8–64 MB, shared across all cores on a socket, ~40 cycles</li>
        <li><strong>DRAM</strong> — GBs, ~100–300 cycles on local NUMA node; 2–4× slower on remote node</li>
      </ul>
      <p>The <strong>MESI protocol</strong> (Modified, Exclusive, Shared, Invalid) keeps cache
      lines coherent across cores. A write to a line in Shared state invalidates all other
      copies — <em>cache line bouncing</em> between threads is a major source of contention.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>perf stat -e cache-misses,cache-references ./binary</code></li>
          <li><code>perf c2c record ./binary &amp;&amp; perf c2c report</code> — cache-to-cache false sharing</li>
          <li><code>valgrind --tool=cachegrind ./binary</code> — cache simulation</li>
          <li><code>lscpu | grep cache</code> — cache sizes</li>
        </ul>
      </div>`
  },

  'mmu': {
    title: 'MMU + CR3 — Hardware Page-Table Walker',
    content: `
      <p>The Memory Management Unit is the hardware that translates virtual addresses to physical
      ones. When the TLB misses, the MMU's <strong>page-table walker</strong> performs the
      multi-level walk autonomously (without OS involvement), reading PGD/PUD/PMD/PTE entries
      from RAM.</p>
      <p><strong>CR3</strong> holds the physical base address of the PGD; it is loaded by the
      kernel on every process context switch. With PCID (Process Context ID, CR4.PCIDE),
      tagged TLB entries allow CR3 reloads without flushing all TLB entries.</p>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>perf stat -e dTLB-load-misses ./binary</code> — MMU walker invocations</li>
          <li><code>cat /proc/cpuinfo | grep pcid</code> — check for PCID support</li>
          <li><code>cat /sys/kernel/debug/x86/pti_enabled</code> — KPTI (Meltdown mitigation) status</li>
        </ul>
      </div>`
  },

  'apic': {
    title: 'Local APIC — Timer Interrupt & IPI',
    content: `
      <p>Each CPU core has a Local APIC (Advanced Programmable Interrupt Controller). It is the
      source of two critical interrupt types for the kernel:</p>
      <ul>
        <li><strong>Periodic timer interrupt</strong> — fires at <code>CONFIG_HZ</code> (100–1000 Hz,
          default 250 Hz). Each tick calls <code>update_process_times()</code> and potentially
          <code>schedule()</code>, driving the CFS timeslice mechanism.</li>
        <li><strong>IPI (Inter-Processor Interrupt)</strong> — one CPU sends a vector to another
          via the LAPIC. Used for TLB shootdowns, scheduler reschedule requests
          (<code>RESCHEDULE_VECTOR</code>), and function calls (<code>call_function_vector</code>).</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /proc/interrupts | grep LOC</code> — local timer interrupt counts per CPU</li>
          <li><code>cat /proc/interrupts | grep RES</code> — reschedule IPI counts</li>
          <li><code>cat /proc/interrupts | grep TLB</code> — TLB shootdown IPIs</li>
          <li><code>perf stat -e irq:irq_handler_entry ./binary</code></li>
        </ul>
      </div>`
  },

  'iommu': {
    title: 'IOMMU (VT-d / AMD-Vi) — DMA Address Translation',
    content: `
      <p>The IOMMU sits between PCIe devices and physical RAM. Just as the CPU's MMU translates
      process virtual addresses to physical addresses, the IOMMU translates <em>device virtual
      addresses</em> (DVAs / IOVAs) to physical addresses, restricting which memory ranges
      a device can DMA into.</p>
      <p>Benefits:</p>
      <ul>
        <li><strong>Security</strong> — a compromised NIC cannot DMA into kernel memory</li>
        <li><strong>Virtualization</strong> — enables safe device passthrough to VMs (VFIO)</li>
        <li><strong>Error isolation</strong> — DMA faults are caught and reported rather than silently corrupting memory</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>dmesg | grep -i iommu</code> — IOMMU detection and domain setup</li>
          <li><code>cat /sys/kernel/iommu_groups/*/devices/*</code> — IOMMU groupings</li>
          <li><code>intel_iommu=on</code> kernel parameter to enable</li>
        </ul>
      </div>`
  },

  'spectre': {
    title: 'Spectre / Meltdown Mitigations',
    content: `
      <p>Modern CPUs speculatively execute instructions across privilege boundaries, potentially
      leaking data via CPU side channels (cache timing). Linux applies several mitigations:</p>
      <ul>
        <li><strong>KPTI</strong> (Kernel Page-Table Isolation) — Meltdown: kernel mappings are
          removed from user-space page tables; CR3 is reloaded on every syscall/interrupt entry/exit.
          Cost: ~5–30% overhead on syscall-heavy workloads.</li>
        <li><strong>IBRS/IBPB</strong> (Indirect Branch Restricted Speculation) — Spectre v2:
          prevents cross-privilege branch-target injection. Retpoline is a software alternative.</li>
        <li><strong>STIBP</strong> (Single Thread Indirect Branch Predictors) — prevents
          cross-hyperthread Spectre v2 attacks.</li>
        <li><strong>SSB / SSBD</strong> (Speculative Store Bypass Disable) — Spectre v4.</li>
      </ul>
      <div class="tools">
        <div class="tools-title">Linux introspection tools</div>
        <ul>
          <li><code>cat /sys/devices/system/cpu/vulnerabilities/*</code> — mitigation status per vulnerability</li>
          <li><code>grep . /sys/devices/system/cpu/vulnerabilities/*</code> — one-liner summary</li>
          <li><code>spectre-meltdown-checker.sh</code> — comprehensive third-party audit script</li>
        </ul>
      </div>`
  },

  /* ── Flow Summary ────────────────────────────────────────────── */
  'flow-exec': {
    title: 'Step 1 — execve: ELF Loaded, Linker Runs',
    content: `
      <p>The lifecycle begins with a call to <code>execve(path, argv, envp)</code>.
      The kernel replaces the calling process image:</p>
      <ol style="padding-left:20px; margin-bottom:12px">
        <li>Open the ELF file; verify magic bytes and architecture</li>
        <li>Read and validate the ELF header and program headers</li>
        <li>Map all <code>PT_LOAD</code> segments into the new VAS</li>
        <li>If <code>PT_INTERP</code> is present, map <code>ld.so</code> too</li>
        <li>Build <code>argc</code>, <code>argv</code>, <code>envp</code>, auxv on the stack</li>
        <li>Jump to <code>ld.so</code> entry point; it resolves all shared library symbols</li>
        <li>Run <code>.init_array</code> constructors; call <code>main()</code></li>
      </ol>
      <p>At this point the program is ready to spawn threads and begin work.</p>`
  },

  'flow-vm': {
    title: 'Step 2 — Virtual Memory: VMAs Mapped, ASLR Applied',
    content: `
      <p>After <code>execve</code>, the process VAS contains a set of VMAs:</p>
      <ul>
        <li>File-backed read-only VMAs for <code>.text</code> and <code>.rodata</code></li>
        <li>File-backed private VMAs for <code>.data</code> (CoW on write)</li>
        <li>Anonymous private VMAs for <code>.bss</code> (demand-zeroed) and heap</li>
        <li>Thread stacks (anonymous, via <code>mmap(MAP_STACK)</code>)</li>
        <li>vDSO and vvar pages (kernel-managed)</li>
        <li>Shared library VMAs for each <code>.so</code> loaded by <code>ld.so</code></li>
      </ul>
      <p>ASLR randomises the base of the stack, mmap region, and (for PIE binaries) the
      executable itself, at a different offset on every <code>execve</code>.</p>`
  },

  'flow-sched': {
    title: 'Step 3 — Threads Scheduled: CFS vruntime → CPU',
    content: `
      <p>Each call to <code>pthread_create()</code> issues a <code>clone(CLONE_VM|…)</code>
      syscall, creating a new <code>task_struct</code> with the same <code>mm_struct</code>.
      The new task is placed on the CFS runqueue of a chosen CPU (by the load balancer)
      with an initial <code>vruntime</code> set to the minimum in the runqueue.</p>
      <p>From this point, the scheduler timer interrupt (Local APIC, ~250 Hz) periodically
      increments the running thread's <code>vruntime</code>. When another task has a smaller
      <code>vruntime</code>, the kernel preempts the current thread, saves its registers,
      and restores the new thread's context — a context switch.</p>
      <p>On a multi-core system, threads run truly in parallel, one per core, synchronised
      only when they contend on shared data structures (protected by mutexes, atomics, etc.).</p>`
  },

  'flow-hw': {
    title: 'Step 4 — Hardware Executes: Fetch–Decode–Execute',
    content: `
      <p>With a thread scheduled and its context restored, the CPU core executes instructions
      from the thread's <code>RIP</code>:</p>
      <ol style="padding-left:20px; margin-bottom:12px">
        <li>The <strong>branch predictor</strong> speculatively fetches the next cache line from L1-I</li>
        <li>The <strong>instruction decoder</strong> converts x86 macro-ops into μops</li>
        <li>The <strong>out-of-order engine</strong> dispatches μops to execution units as their operands become ready</li>
        <li>Load/store μops query the <strong>TLB</strong>; on a hit, the MMU provides the physical address and the L1-D cache is accessed</li>
        <li>On a cache miss, the request propagates to L2 → L3 → DRAM</li>
        <li>Completed μops are <strong>retired</strong> in program order</li>
      </ol>
      <p>When the thread calls a syscall, issues an I/O request, or exhausts its timeslice
      (Local APIC interrupt), the CPU transitions back to the kernel to schedule the next thread.</p>`
  }

};

// ── Modal elements ────────────────────────────────────────────────
const modal      = document.getElementById('modal');
const modalTitle = document.getElementById('modal-title');
const modalBody  = document.getElementById('modal-body');
const closeBtn   = document.getElementById('modal-close');

// ── Open modal helper ─────────────────────────────────────────────
function openModal(key) {
  const info = explanations[key];
  if (!info) return;
  modalTitle.textContent = info.title;
  modalBody.innerHTML    = info.content;
  modal.style.display    = 'block';
  modal.querySelector('.modal-content').scrollTop = 0;
  closeBtn.focus();
}

// ── Close modal helper ────────────────────────────────────────────
function closeModal() {
  modal.style.display = 'none';
}

// ── Generic wiring helper ─────────────────────────────────────────
function wireClickable(selector) {
  document.querySelectorAll(selector + '[data-info]').forEach(el => {
    el.setAttribute('tabindex', '0');
    el.setAttribute('role', 'button');
    el.addEventListener('click', () => openModal(el.dataset.info));
    el.addEventListener('keydown', e => {
      if (e.key === 'Enter' || e.key === ' ') {
        e.preventDefault();
        openModal(el.dataset.info);
      }
    });
  });
}

// ── Wire all interactive element types ───────────────────────────
wireClickable('.comp');
wireClickable('.elf-section');
wireClickable('.memmap-row');
wireClickable('.thread-lane');

// ── Close: button, backdrop click, Escape key ────────────────────
closeBtn.addEventListener('click', closeModal);

modal.addEventListener('click', e => {
  if (e.target === modal) closeModal();
});

document.addEventListener('keydown', e => {
  if (e.key === 'Escape' && modal.style.display === 'block') closeModal();
});
</script>
</body>
</html>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="networking-layers"><a href="#networking-layers" class="header">Networking Layers</a></h1>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OSI Model - Network Layers</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
<pre><code>    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background: linear-gradient(135deg, #1a3a6b 0%, #2563a8 100%);
        padding: 40px 20px;
        min-height: 100vh;
    }

    .container {
        max-width: 1400px;
        margin: 0 auto;
        background: white;
        border-radius: 20px;
        padding: 40px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
    }

    h1 {
        text-align: center;
        color: #2d3748;
        margin-bottom: 10px;
        font-size: 2.5em;
    }

    .subtitle {
        text-align: center;
        color: #718096;
        margin-bottom: 40px;
        font-size: 1.1em;
    }

    /* Use-case legend */
    .legend {
        display: flex;
        justify-content: center;
        gap: 30px;
        margin-bottom: 30px;
        flex-wrap: wrap;
    }

    .legend-item {
        display: flex;
        align-items: center;
        gap: 8px;
        font-size: 0.95em;
        color: #2d3748;
        font-weight: 600;
    }

    .legend-dot {
        width: 16px;
        height: 16px;
        border-radius: 50%;
        flex-shrink: 0;
    }

    .dot-youtube  { background: #e53e3e; }
    .dot-drone    { background: #2f855a; }
    .dot-web      { background: #2b6cb0; }

    /* Grid header */
    .grid-header {
        display: grid;
        grid-template-columns: 160px 1fr 1fr 1fr 1fr;
        gap: 12px;
        margin-bottom: 12px;
        align-items: center;
    }

    .col-header {
        text-align: center;
        font-weight: bold;
        font-size: 0.9em;
        color: white;
        padding: 12px 10px;
        border-radius: 10px;
    }

    .col-header-layer {
        background: #4a5568;
    }

    .col-header-desc {
        background: #4a5568;
    }

    .col-header-youtube {
        background: linear-gradient(135deg, #c53030, #e53e3e);
    }

    .col-header-drone {
        background: linear-gradient(135deg, #276749, #2f855a);
    }

    .col-header-web {
        background: linear-gradient(135deg, #2a4a8a, #2b6cb0);
    }

    /* Layer rows */
    .layer-row {
        display: grid;
        grid-template-columns: 160px 1fr 1fr 1fr 1fr;
        gap: 12px;
        margin-bottom: 12px;
        align-items: stretch;
    }

    /* Layer label cell */
    .layer-label {
        color: white;
        padding: 16px 12px;
        border-radius: 12px;
        font-weight: bold;
        font-size: 0.95em;
        text-align: center;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
        line-height: 1.3;
    }

    .layer-num {
        font-size: 1.6em;
        font-weight: 900;
        opacity: 0.85;
        line-height: 1;
        margin-bottom: 4px;
    }

    .layer-name {
        font-size: 0.82em;
        text-transform: uppercase;
        letter-spacing: 0.05em;
    }

    /* OSI layer colors - 7 distinct gradients */
    .l7 { background: linear-gradient(135deg, #6b21a8, #9333ea); box-shadow: 0 4px 15px rgba(147,51,234,0.4); }
    .l6 { background: linear-gradient(135deg, #1d4ed8, #3b82f6); box-shadow: 0 4px 15px rgba(59,130,246,0.4); }
    .l5 { background: linear-gradient(135deg, #0369a1, #0ea5e9); box-shadow: 0 4px 15px rgba(14,165,233,0.4); }
    .l4 { background: linear-gradient(135deg, #065f46, #10b981); box-shadow: 0 4px 15px rgba(16,185,129,0.4); }
    .l3 { background: linear-gradient(135deg, #92400e, #f59e0b); box-shadow: 0 4px 15px rgba(245,158,11,0.4); }
    .l2 { background: linear-gradient(135deg, #9a3412, #f97316); box-shadow: 0 4px 15px rgba(249,115,22,0.4); }
    .l1 { background: linear-gradient(135deg, #881337, #e11d48); box-shadow: 0 4px 15px rgba(225,29,72,0.4); }

    /* Content cells */
    .cell {
        background: #f7fafc;
        border: 2px solid #e2e8f0;
        border-radius: 10px;
        padding: 14px 16px;
        position: relative;
        transition: all 0.25s ease;
        cursor: pointer;
        display: flex;
        flex-direction: column;
        justify-content: flex-start;
        min-height: 80px;
    }

    .cell:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 16px rgba(0, 0, 0, 0.12);
    }

    /* Column-tinted borders on hover */
    .cell-desc:hover   { border-color: #718096; }
    .cell-youtube:hover { border-color: #e53e3e; box-shadow: 0 6px 16px rgba(229,62,62,0.2); }
    .cell-drone:hover   { border-color: #2f855a; box-shadow: 0 6px 16px rgba(47,133,90,0.2); }
    .cell-web:hover     { border-color: #2b6cb0; box-shadow: 0 6px 16px rgba(43,108,176,0.2); }

    /* Subtle tint on column backgrounds */
    .cell-desc     { background: #f7fafc; }
    .cell-youtube  { background: #fff5f5; border-color: #fed7d7; }
    .cell-drone    { background: #f0fff4; border-color: #c6f6d5; }
    .cell-web      { background: #ebf8ff; border-color: #bee3f8; }

    .cell-title {
        font-weight: bold;
        color: #2d3748;
        font-size: 0.9em;
        margin-bottom: 4px;
        line-height: 1.3;
    }

    .cell-detail {
        font-size: 0.8em;
        color: #718096;
        line-height: 1.4;
    }

    .cell-tag {
        display: inline-block;
        font-size: 0.7em;
        font-weight: bold;
        padding: 2px 7px;
        border-radius: 20px;
        margin-top: 6px;
        letter-spacing: 0.04em;
    }

    .tag-youtube { background: #fed7d7; color: #c53030; }
    .tag-drone   { background: #c6f6d5; color: #276749; }
    .tag-web     { background: #bee3f8; color: #2a4a8a; }

    /* Divider arrows between sections */
    .arrow {
        text-align: center;
        padding: 2px 0;
    }

    /* Modal */
    .modal {
        display: none;
        position: fixed;
        z-index: 1000;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(0, 0, 0, 0.6);
        animation: fadeIn 0.3s;
    }

    @keyframes fadeIn {
        from { opacity: 0; }
        to   { opacity: 1; }
    }

    .modal-content {
        background-color: white;
        margin: 8% auto;
        padding: 40px;
        border-radius: 15px;
        width: 80%;
        max-width: 700px;
        max-height: 82vh;
        overflow-y: auto;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        position: relative;
        animation: slideIn 0.3s;
    }

    @keyframes slideIn {
        from { transform: translateY(-40px); opacity: 0; }
        to   { transform: translateY(0);     opacity: 1; }
    }

    .close {
        color: #a0aec0;
        position: absolute;
        right: 20px;
        top: 20px;
        font-size: 35px;
        font-weight: bold;
        cursor: pointer;
        transition: color 0.3s;
        line-height: 1;
    }

    .close:hover { color: #2d3748; }

    .modal-title {
        color: #1e56b0;
        font-size: 1.7em;
        margin-bottom: 20px;
        padding-bottom: 15px;
        border-bottom: 3px solid #2563a8;
        padding-right: 40px;
    }

    .modal-body {
        color: #2d3748;
        line-height: 1.8;
        font-size: 1.02em;
    }

    .modal-body p { margin-bottom: 14px; }
    .modal-body strong { color: #1e56b0; }

    /* Summary bar */
    .summary-bar {
        background: #edf2f7;
        padding: 16px 20px;
        border-radius: 10px;
        text-align: center;
        margin-top: 30px;
        color: #2d3748;
        font-weight: 600;
        font-size: 0.95em;
    }

    /* Responsive */
    @media screen and (max-width: 900px) {
        body { padding: 20px 10px; }

        .container {
            padding: 20px 15px;
            border-radius: 12px;
        }

        h1 { font-size: 1.5em; }

        .grid-header,
        .layer-row {
            grid-template-columns: 1fr;
            gap: 8px;
        }

        .col-header { display: none; }

        .layer-label {
            flex-direction: row;
            gap: 10px;
            padding: 12px 16px;
            justify-content: flex-start;
            text-align: left;
        }

        .layer-num { font-size: 1.3em; margin-bottom: 0; }

        .cell { min-height: auto; }

        .modal-content {
            margin: 5% auto;
            padding: 25px;
            width: 95%;
            max-width: 95%;
            max-height: 90vh;
        }

        .modal-title { font-size: 1.3em; }

        .legend { gap: 16px; }
    }

    @media (hover: none) and (pointer: coarse) {
        .cell {
            padding: 16px;
            margin: 3px 0;
        }
        .cell:active {
            transform: scale(0.98);
        }
    }
&lt;/style&gt;
</code></pre>

<body>
    
<div id="modal-6" class="modal">
        
<div class="modal-content">
            <span class="close">×</span>
            
<h2 class="modal-title" id="modal-title-6"></h2>

            
<div class="modal-body" id="modal-body-6"></div>

        </div>

    </div>

<pre><code>&lt;div class="container"&gt;
    &lt;h1&gt;OSI Network Model&lt;/h1&gt;
    &lt;p class="subtitle"&gt;How data flows through seven layers — and what each layer does in three real-world scenarios&lt;/p&gt;

    &lt;div class="legend"&gt;
        &lt;div class="legend-item"&gt;
            &lt;div class="legend-dot dot-youtube"&gt;&lt;/div&gt;
            Streaming YouTube on a phone
        &lt;/div&gt;
        &lt;div class="legend-item"&gt;
            &lt;div class="legend-dot dot-drone"&gt;&lt;/div&gt;
            Laptop sending gRPC to a drone via IP radio
        &lt;/div&gt;
        &lt;div class="legend-item"&gt;
            &lt;div class="legend-dot dot-web"&gt;&lt;/div&gt;
            Accessing a webpage on a laptop
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;!-- Column headers --&gt;
    &lt;div class="grid-header"&gt;
        &lt;div class="col-header col-header-layer"&gt;OSI Layer&lt;/div&gt;
        &lt;div class="col-header col-header-desc"&gt;What This Layer Does&lt;/div&gt;
        &lt;div class="col-header col-header-youtube"&gt;📱 YouTube Stream&lt;/div&gt;
        &lt;div class="col-header col-header-drone"&gt;🚁 Drone gRPC&lt;/div&gt;
        &lt;div class="col-header col-header-web"&gt;💻 Web Page&lt;/div&gt;
    &lt;/div&gt;

    &lt;!-- Layer 7: Application --&gt;
    &lt;div class="layer-row"&gt;
        &lt;div class="layer-label l7"&gt;
            &lt;div class="layer-num"&gt;7&lt;/div&gt;
            &lt;div class="layer-name"&gt;Application&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-desc" data-info="l7-desc"&gt;
            &lt;div class="cell-title"&gt;Application Layer&lt;/div&gt;
            &lt;div class="cell-detail"&gt;User-facing protocols and data formats. The interface between software and the network.&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-youtube" data-info="l7-youtube"&gt;
            &lt;div class="cell-title"&gt;HTTPS + DASH/HLS&lt;/div&gt;
            &lt;div class="cell-detail"&gt;YouTube app requests video segments via HTTPS. Adaptive streaming (DASH/HLS) selects quality based on bandwidth.&lt;/div&gt;
            &lt;span class="cell-tag tag-youtube"&gt;HTTP/2, QUIC&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-drone" data-info="l7-drone"&gt;
            &lt;div class="cell-title"&gt;gRPC / Protobuf&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Ground control software sends typed RPC calls (e.g. SetThrottle, GetTelemetry) serialised as Protocol Buffers.&lt;/div&gt;
            &lt;span class="cell-tag tag-drone"&gt;gRPC, Protobuf&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-web" data-info="l7-web"&gt;
            &lt;div class="cell-title"&gt;HTTP/HTTPS&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Browser sends an HTTP GET request for the page URL. Server responds with HTML, CSS, JS resources.&lt;/div&gt;
            &lt;span class="cell-tag tag-web"&gt;HTTP/1.1, HTTP/2&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="32" viewBox="0 0 36 32" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="20" stroke="#a0aec0" stroke-width="2" stroke-linecap="round"/&gt;
            &lt;polyline points="9,13 18,24 27,13" fill="none" stroke="#a0aec0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Layer 6: Presentation --&gt;
    &lt;div class="layer-row"&gt;
        &lt;div class="layer-label l6"&gt;
            &lt;div class="layer-num"&gt;6&lt;/div&gt;
            &lt;div class="layer-name"&gt;Presentation&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-desc" data-info="l6-desc"&gt;
            &lt;div class="cell-title"&gt;Presentation Layer&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Data translation, encryption, and compression. Ensures both ends speak the same data format.&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-youtube" data-info="l6-youtube"&gt;
            &lt;div class="cell-title"&gt;TLS + H.264/VP9 Codec&lt;/div&gt;
            &lt;div class="cell-detail"&gt;TLS encrypts the stream. Video codec decodes compressed frames into raw pixels for the display.&lt;/div&gt;
            &lt;span class="cell-tag tag-youtube"&gt;TLS 1.3, VP9/AV1&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-drone" data-info="l6-drone"&gt;
            &lt;div class="cell-title"&gt;TLS + Protobuf Encoding&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Optional TLS secures the channel. Protobuf binary encoding translates typed structs into compact bytes.&lt;/div&gt;
            &lt;span class="cell-tag tag-drone"&gt;TLS, binary encoding&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-web" data-info="l6-web"&gt;
            &lt;div class="cell-title"&gt;TLS Encryption&lt;/div&gt;
            &lt;div class="cell-detail"&gt;TLS handshake establishes shared keys. All HTTP traffic is encrypted and decrypted transparently.&lt;/div&gt;
            &lt;span class="cell-tag tag-web"&gt;TLS 1.3, X.509&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="32" viewBox="0 0 36 32" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="20" stroke="#a0aec0" stroke-width="2" stroke-linecap="round"/&gt;
            &lt;polyline points="9,13 18,24 27,13" fill="none" stroke="#a0aec0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Layer 5: Session --&gt;
    &lt;div class="layer-row"&gt;
        &lt;div class="layer-label l5"&gt;
            &lt;div class="layer-num"&gt;5&lt;/div&gt;
            &lt;div class="layer-name"&gt;Session&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-desc" data-info="l5-desc"&gt;
            &lt;div class="cell-title"&gt;Session Layer&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Establishes, manages, and terminates conversations between applications. Handles reconnection and checkpointing.&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-youtube" data-info="l5-youtube"&gt;
            &lt;div class="cell-title"&gt;QUIC Connection / HTTP/2 Stream&lt;/div&gt;
            &lt;div class="cell-detail"&gt;A persistent QUIC session multiplexes video, audio, and metadata streams. Survives brief network interruptions.&lt;/div&gt;
            &lt;span class="cell-tag tag-youtube"&gt;QUIC, multiplexing&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-drone" data-info="l5-drone"&gt;
            &lt;div class="cell-title"&gt;HTTP/2 Session over gRPC&lt;/div&gt;
            &lt;div class="cell-detail"&gt;gRPC uses HTTP/2 which maintains a long-lived session with bidirectional streaming for real-time telemetry.&lt;/div&gt;
            &lt;span class="cell-tag tag-drone"&gt;HTTP/2 streams&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-web" data-info="l5-web"&gt;
            &lt;div class="cell-title"&gt;TCP Session / Cookie&lt;/div&gt;
            &lt;div class="cell-detail"&gt;TCP connection is the session. HTTP Keep-Alive reuses it for multiple requests. Cookies track authenticated state.&lt;/div&gt;
            &lt;span class="cell-tag tag-web"&gt;Keep-Alive, cookies&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="32" viewBox="0 0 36 32" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="20" stroke="#a0aec0" stroke-width="2" stroke-linecap="round"/&gt;
            &lt;polyline points="9,13 18,24 27,13" fill="none" stroke="#a0aec0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Layer 4: Transport --&gt;
    &lt;div class="layer-row"&gt;
        &lt;div class="layer-label l4"&gt;
            &lt;div class="layer-num"&gt;4&lt;/div&gt;
            &lt;div class="layer-name"&gt;Transport&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-desc" data-info="l4-desc"&gt;
            &lt;div class="cell-title"&gt;Transport Layer&lt;/div&gt;
            &lt;div class="cell-detail"&gt;End-to-end delivery, segmentation, error recovery, and flow control between ports on two hosts.&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-youtube" data-info="l4-youtube"&gt;
            &lt;div class="cell-title"&gt;UDP via QUIC&lt;/div&gt;
            &lt;div class="cell-detail"&gt;QUIC runs over UDP — allowing the stack to retransmit lost packets without head-of-line blocking that plagues TCP streams.&lt;/div&gt;
            &lt;span class="cell-tag tag-youtube"&gt;UDP port 443&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-drone" data-info="l4-drone"&gt;
            &lt;div class="cell-title"&gt;TCP (port 50051)&lt;/div&gt;
            &lt;div class="cell-detail"&gt;gRPC defaults to TCP for reliable, ordered delivery of commands. Lost commands are retransmitted automatically.&lt;/div&gt;
            &lt;span class="cell-tag tag-drone"&gt;TCP port 50051&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-web" data-info="l4-web"&gt;
            &lt;div class="cell-title"&gt;TCP (port 443)&lt;/div&gt;
            &lt;div class="cell-detail"&gt;TCP three-way handshake, sequence numbers, ACKs, and congestion control ensure reliable page delivery.&lt;/div&gt;
            &lt;span class="cell-tag tag-web"&gt;TCP port 443&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="32" viewBox="0 0 36 32" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="20" stroke="#a0aec0" stroke-width="2" stroke-linecap="round"/&gt;
            &lt;polyline points="9,13 18,24 27,13" fill="none" stroke="#a0aec0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Layer 3: Network --&gt;
    &lt;div class="layer-row"&gt;
        &lt;div class="layer-label l3"&gt;
            &lt;div class="layer-num"&gt;3&lt;/div&gt;
            &lt;div class="layer-name"&gt;Network&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-desc" data-info="l3-desc"&gt;
            &lt;div class="cell-title"&gt;Network Layer&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Logical addressing (IP) and routing across multiple networks. Packets find their path hop-by-hop.&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-youtube" data-info="l3-youtube"&gt;
            &lt;div class="cell-title"&gt;IP Routing via LTE/5G&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Phone has a public or NAT'd IP. Packets route from carrier core to YouTube CDN edge node nearest the user.&lt;/div&gt;
            &lt;span class="cell-tag tag-youtube"&gt;IPv4/IPv6, BGP&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-drone" data-info="l3-drone"&gt;
            &lt;div class="cell-title"&gt;IP over Radio Link&lt;/div&gt;
            &lt;div class="cell-detail"&gt;IP radio creates a point-to-point or mesh IP network. Both laptop and drone have IP addresses; packets are routed between them.&lt;/div&gt;
            &lt;span class="cell-tag tag-drone"&gt;IPv4, static routes&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-web" data-info="l3-web"&gt;
            &lt;div class="cell-title"&gt;IP + DNS Resolution&lt;/div&gt;
            &lt;div class="cell-detail"&gt;DNS resolves the domain to a server IP. Router uses IP routing table to forward packets toward the destination.&lt;/div&gt;
            &lt;span class="cell-tag tag-web"&gt;IPv4/IPv6, DNS&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="32" viewBox="0 0 36 32" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="20" stroke="#a0aec0" stroke-width="2" stroke-linecap="round"/&gt;
            &lt;polyline points="9,13 18,24 27,13" fill="none" stroke="#a0aec0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Layer 2: Data Link --&gt;
    &lt;div class="layer-row"&gt;
        &lt;div class="layer-label l2"&gt;
            &lt;div class="layer-num"&gt;2&lt;/div&gt;
            &lt;div class="layer-name"&gt;Data Link&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-desc" data-info="l2-desc"&gt;
            &lt;div class="cell-title"&gt;Data Link Layer&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Reliable transfer between adjacent nodes on the same physical medium. MAC addressing, framing, and error detection.&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-youtube" data-info="l2-youtube"&gt;
            &lt;div class="cell-title"&gt;LTE/5G Radio Frames&lt;/div&gt;
            &lt;div class="cell-detail"&gt;LTE/5G protocols (MAC sublayer) schedule radio time slots and provide HARQ error correction between the phone and base station.&lt;/div&gt;
            &lt;span class="cell-tag tag-youtube"&gt;LTE MAC, HARQ&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-drone" data-info="l2-drone"&gt;
            &lt;div class="cell-title"&gt;Radio MAC Protocol&lt;/div&gt;
            &lt;div class="cell-detail"&gt;The IP radio (e.g. 900 MHz or 2.4 GHz) uses its own link-layer framing with error correction and ARQ over the RF channel.&lt;/div&gt;
            &lt;span class="cell-tag tag-drone"&gt;TDMA/CSMA, ARQ&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-web" data-info="l2-web"&gt;
            &lt;div class="cell-title"&gt;Ethernet / Wi-Fi Frames&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Ethernet or 802.11 Wi-Fi frame wraps the IP packet. MAC addresses identify src/dst on the local segment. CRC detects bit errors.&lt;/div&gt;
            &lt;span class="cell-tag tag-web"&gt;802.3 / 802.11&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="arrow"&gt;
        &lt;svg width="36" height="32" viewBox="0 0 36 32" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;
            &lt;line x1="18" y1="0" x2="18" y2="20" stroke="#a0aec0" stroke-width="2" stroke-linecap="round"/&gt;
            &lt;polyline points="9,13 18,24 27,13" fill="none" stroke="#a0aec0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/&gt;
        &lt;/svg&gt;
    &lt;/div&gt;

    &lt;!-- Layer 1: Physical --&gt;
    &lt;div class="layer-row"&gt;
        &lt;div class="layer-label l1"&gt;
            &lt;div class="layer-num"&gt;1&lt;/div&gt;
            &lt;div class="layer-name"&gt;Physical&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-desc" data-info="l1-desc"&gt;
            &lt;div class="cell-title"&gt;Physical Layer&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Raw bit transmission over a medium. Defines voltages, frequencies, modulation, connectors, and cable specs.&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-youtube" data-info="l1-youtube"&gt;
            &lt;div class="cell-title"&gt;RF Radio Waves (LTE/5G)&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Bits are modulated onto radio frequency carriers (e.g. OFDM on LTE). The phone antenna transmits and receives electromagnetic waves.&lt;/div&gt;
            &lt;span class="cell-tag tag-youtube"&gt;OFDM, MIMO&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-drone" data-info="l1-drone"&gt;
            &lt;div class="cell-title"&gt;RF Link (900 MHz / 2.4 GHz)&lt;/div&gt;
            &lt;div class="cell-detail"&gt;IP radio modulates data onto a sub-GHz or 2.4 GHz carrier. Directional or omni antennas establish the air link.&lt;/div&gt;
            &lt;span class="cell-tag tag-drone"&gt;FSK/FHSS, RF power&lt;/span&gt;
        &lt;/div&gt;
        &lt;div class="cell cell-web" data-info="l1-web"&gt;
            &lt;div class="cell-title"&gt;Ethernet Copper / Wi-Fi RF&lt;/div&gt;
            &lt;div class="cell-detail"&gt;Wired: voltage pulses on copper (100BASE-TX) or light pulses on fibre. Wireless: OFDM modulated signals on 2.4/5/6 GHz bands.&lt;/div&gt;
            &lt;span class="cell-tag tag-web"&gt;Cat6 / 802.11ax&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="summary-bar"&gt;
        Data travels down all 7 layers on the sender — each layer adds a header (encapsulation) — and back up all 7 layers on the receiver, stripping headers as it goes.
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
    const explanations = {

        /* ── Layer 7 ── */
        'l7-desc': {
            title: 'Layer 7 — Application Layer',
            content: `
                &lt;p&gt;The Application layer is the topmost layer and the one closest to the end user. It provides the protocols and interfaces that applications use to communicate over the network.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Key protocols:&lt;/strong&gt; HTTP/HTTPS (web), DNS (name resolution), SMTP/IMAP (email), FTP (file transfer), SSH (secure shell), WebSocket, gRPC, MQTT, CoAP.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt; Defines the vocabulary of a conversation — what messages mean, what format data is in, and what operations are available (GET a resource, POST data, subscribe to a stream, call a remote function).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Common misconception:&lt;/strong&gt; The Application layer is not "the application itself" — it's the network protocol your application uses. Your browser is not the Application layer; HTTP is.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;PDU (Protocol Data Unit):&lt;/strong&gt; Message or request/response.&lt;/p&gt;
            `
        },
        'l7-youtube': {
            title: 'Layer 7 — YouTube Streaming (Application)',
            content: `
                &lt;p&gt;The YouTube app on your phone uses &lt;strong&gt;HTTPS&lt;/strong&gt; as its application-layer protocol, fetching video content over an encrypted HTTP channel.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Adaptive Bitrate Streaming (ABR):&lt;/strong&gt; YouTube uses either MPEG-DASH (Dynamic Adaptive Streaming over HTTP) or HLS (HTTP Live Streaming). The video is split into short segments (2–10 seconds). The app requests each segment individually and selects the quality level (144p → 4K) based on real-time bandwidth estimates.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Why UDP/QUIC?&lt;/strong&gt; YouTube increasingly uses HTTP/3 over QUIC. Unlike TCP, QUIC handles packet loss per-stream — a lost audio packet won't stall the video stream (head-of-line blocking elimination).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Content Delivery Network (CDN):&lt;/strong&gt; At the application layer, your phone contacts a Google CDN edge node that may be just milliseconds away, not servers in California.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Authentication:&lt;/strong&gt; OAuth 2.0 tokens in HTTP headers authenticate your Google account, enabling personalised recommendations and history tracking.&lt;/p&gt;
            `
        },
        'l7-drone': {
            title: 'Layer 7 — Drone gRPC Control (Application)',
            content: `
                &lt;p&gt;&lt;strong&gt;gRPC&lt;/strong&gt; (Google Remote Procedure Call) is a high-performance framework that lets the laptop call functions on the drone as if they were local function calls.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Protocol Buffers (Protobuf):&lt;/strong&gt; The application layer defines a &lt;code&gt;.proto&lt;/code&gt; schema file describing every message and RPC method. For example:&lt;/p&gt;
                &lt;p&gt;&lt;em&gt;SetThrottle(ThrottleRequest) → ThrottleResponse&lt;br&gt;GetTelemetry(Empty) → TelemetryStream&lt;/em&gt;&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Bidirectional streaming:&lt;/strong&gt; gRPC supports four call types: unary, server-streaming, client-streaming, and bidirectional streaming. For drone telemetry the laptop opens a server-streaming RPC and the drone continuously sends position, battery, and sensor data back.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Deadlines and cancellation:&lt;/strong&gt; gRPC has built-in support for timeouts and cancellation — critical for safety-of-flight applications where stale commands must be discarded.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Service discovery:&lt;/strong&gt; In simple deployments, the drone's IP is known statically or via mDNS/DNS-SD on the radio LAN.&lt;/p&gt;
            `
        },
        'l7-web': {
            title: 'Layer 7 — Web Page Access (Application)',
            content: `
                &lt;p&gt;Accessing a webpage is primarily an &lt;strong&gt;HTTP/HTTPS&lt;/strong&gt; conversation at the application layer. When you type a URL, the browser issues a sequence of requests.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;DNS first:&lt;/strong&gt; Before HTTP even starts, the browser calls the DNS resolver to turn the hostname into an IP address. DNS is itself an Application layer protocol (UDP port 53).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;HTTP GET:&lt;/strong&gt; The browser sends a GET request with headers including Host, User-Agent, Accept-Encoding, Cookie, and more. The server responds with a status code, headers, and the HTML body.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Parsing and sub-requests:&lt;/strong&gt; The browser parses HTML, discovers linked CSS, JavaScript, images, and fonts, and makes additional GET requests for each resource — potentially dozens or hundreds per page.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;HTTP/2 advantages:&lt;/strong&gt; Multiplexing lets the browser request many resources over a single connection simultaneously, instead of the sequential round-trips of HTTP/1.1.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;HTTP/3:&lt;/strong&gt; Modern CDNs increasingly offer HTTP/3 (over QUIC) for faster connection establishment and better performance on lossy networks.&lt;/p&gt;
            `
        },

        /* ── Layer 6 ── */
        'l6-desc': {
            title: 'Layer 6 — Presentation Layer',
            content: `
                &lt;p&gt;The Presentation layer is responsible for data &lt;strong&gt;translation, encryption, and compression&lt;/strong&gt;. It ensures that data produced by one system can be understood by another, regardless of internal representation differences.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Data translation:&lt;/strong&gt; Converts between different character encodings (ASCII ↔ EBCDIC), byte orders (big-endian ↔ little-endian), or data formats (XML ↔ JSON).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Encryption (TLS/SSL):&lt;/strong&gt; In modern practice, TLS (Transport Layer Security) lives conceptually at layer 6, encrypting application data before it's handed to the transport layer and decrypting it on receipt.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Compression:&lt;/strong&gt; HTTP content encoding (gzip, Brotli) and media codecs (H.264, VP9, AV1) are presentation-layer concerns — they change how data is represented without changing what it means.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;PDU:&lt;/strong&gt; Encoded/encrypted data blocks.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In TCP/IP practice, layers 5, 6, and 7 are often collapsed into a single "Application" layer. TLS straddles the boundary between layer 6 and the library used by the application.&lt;/p&gt;
            `
        },
        'l6-youtube': {
            title: 'Layer 6 — YouTube Streaming (Presentation)',
            content: `
                &lt;p&gt;Two presentation-layer concerns dominate YouTube streaming: &lt;strong&gt;TLS encryption&lt;/strong&gt; and &lt;strong&gt;video codec decoding&lt;/strong&gt;.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;TLS 1.3:&lt;/strong&gt; All YouTube traffic is encrypted. TLS 1.3 reduces the handshake to a single round-trip (versus two in TLS 1.2), minimising startup latency. The phone and server negotiate cipher suites, exchange keys via ECDHE, and establish an encrypted channel before any video data flows.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Video codec — VP9 / AV1:&lt;/strong&gt; The raw video stream would be enormous (4K at 60fps ≈ 12 Gbps uncompressed). Codecs compress this by 100–300× using inter-frame prediction, discrete cosine transforms, and entropy coding. The phone's presentation layer decodes each compressed segment back into raw frames.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;AV1:&lt;/strong&gt; Google's royalty-free AV1 codec offers ~30% better compression than VP9 at the same quality. Modern Android phones include hardware AV1 decoders, offloading decode from the CPU.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Audio codec:&lt;/strong&gt; Audio is typically Opus (within a WebM container) or AAC — also decoded at this layer.&lt;/p&gt;
            `
        },
        'l6-drone': {
            title: 'Layer 6 — Drone gRPC (Presentation)',
            content: `
                &lt;p&gt;The drone communication stack has two presentation-layer elements: &lt;strong&gt;Protobuf binary encoding&lt;/strong&gt; and optional &lt;strong&gt;TLS&lt;/strong&gt;.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Protocol Buffers encoding:&lt;/strong&gt; Unlike JSON (human-readable, verbose) or XML, Protobuf encodes data in a compact binary format. Field numbers replace field names; variable-length integers save bytes for small values. A message that's 200 bytes as JSON might be 40 bytes as Protobuf — significant when bandwidth over the radio link is limited.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Schema evolution:&lt;/strong&gt; Protobuf fields are identified by number, not name. New fields can be added with new numbers; old clients simply ignore unknown fields. This enables rolling firmware upgrades where ground station and drone may run different software versions.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;TLS considerations:&lt;/strong&gt; TLS adds ~50 bytes per record plus handshake overhead. On a low-bandwidth radio link (e.g. 115 kbps), this may be acceptable for security-critical commands but may be skipped for high-rate telemetry over a trusted private RF network, with application-layer HMAC used instead.&lt;/p&gt;
            `
        },
        'l6-web': {
            title: 'Layer 6 — Web Page (Presentation)',
            content: `
                &lt;p&gt;For web browsing, the primary presentation-layer activity is &lt;strong&gt;TLS&lt;/strong&gt;. Without TLS, an HTTPS URL simply wouldn't load.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;TLS Handshake:&lt;/strong&gt;&lt;/p&gt;
                &lt;p&gt;1. Browser sends ClientHello (supported cipher suites, TLS version, random nonce).&lt;br&gt;
                2. Server sends ServerHello (chosen cipher, certificate).&lt;br&gt;
                3. Browser verifies certificate against trusted CAs.&lt;br&gt;
                4. ECDHE key exchange derives a shared session key.&lt;br&gt;
                5. Both parties confirm with Finished messages.&lt;/p&gt;
                &lt;p&gt;In TLS 1.3, this takes one round-trip. With session resumption (0-RTT), repeat visits can send data in the very first packet.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Certificate chain:&lt;/strong&gt; The server presents an X.509 certificate signed by an intermediate CA signed by a root CA in the browser's trust store. This proves the server is who it claims to be.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Content encoding:&lt;/strong&gt; The server compresses HTTP response bodies with gzip or Brotli (another presentation-layer concern), reducing transfer size by 60–80% for text-heavy HTML/CSS/JS.&lt;/p&gt;
            `
        },

        /* ── Layer 5 ── */
        'l5-desc': {
            title: 'Layer 5 — Session Layer',
            content: `
                &lt;p&gt;The Session layer manages the &lt;strong&gt;dialogue&lt;/strong&gt; between two communicating processes. It establishes, coordinates, and terminates sessions — logical, sustained conversations above the level of individual packets.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Session establishment:&lt;/strong&gt; Negotiates parameters before data exchange begins (who speaks first, how long to wait, etc.).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Synchronisation:&lt;/strong&gt; Inserts checkpoints into a data stream so that if a transfer is interrupted, it can resume from the last checkpoint rather than restarting completely.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Dialog control:&lt;/strong&gt; Manages half-duplex (one side speaks at a time) vs. full-duplex (both can speak simultaneously) modes.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;In practice:&lt;/strong&gt; Modern TCP/IP protocols collapse layers 5–7. Session management is typically handled by the application-layer protocol itself (e.g. HTTP Keep-Alive, WebSocket session, gRPC stream lifecycle).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;PDU:&lt;/strong&gt; Session data / token.&lt;/p&gt;
            `
        },
        'l5-youtube': {
            title: 'Layer 5 — YouTube (Session)',
            content: `
                &lt;p&gt;YouTube\'s session layer is embodied by the &lt;strong&gt;QUIC connection&lt;/strong&gt; (or HTTP/2 session for older clients).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;QUIC connection ID:&lt;/strong&gt; QUIC assigns a connection ID independent of the underlying IP address and port. When your phone switches from Wi-Fi to LTE mid-video, the QUIC connection can survive because the server identifies it by connection ID, not the 4-tuple (src IP, src port, dst IP, dst port) that TCP requires to remain constant.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Multiplexed streams:&lt;/strong&gt; Within one QUIC session, multiple logical streams exist simultaneously: one for video segments, one for audio, one for metadata/thumbnails. Stream IDs are session-level identifiers.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Session resumption:&lt;/strong&gt; If a brief outage drops the connection, the YouTube app can establish a new QUIC session with 0-RTT resumption, replaying the session ticket and sending data before the server has even responded — reducing rebuffering events.&lt;/p&gt;
            `
        },
        'l5-drone': {
            title: 'Layer 5 — Drone gRPC (Session)',
            content: `
                &lt;p&gt;gRPC runs over HTTP/2, which maintains a persistent &lt;strong&gt;HTTP/2 session&lt;/strong&gt; between the laptop and the drone's gRPC server.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;HTTP/2 session lifecycle:&lt;/strong&gt; A single TCP connection (the session) is opened at mission start. Over this connection, multiple concurrent HTTP/2 streams carry independent RPC calls — one stream per in-flight RPC.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Bidirectional streaming RPC:&lt;/strong&gt; For continuous telemetry, the laptop opens one long-lived HTTP/2 stream. The drone sends telemetry frames continuously while the laptop sends control frames in the other direction — all within the same session, no need to re-establish connection for each reading.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Session health:&lt;/strong&gt; HTTP/2 PING frames act as keepalives, detecting if the radio link has gone dead. On timeout, gRPC raises a DEADLINE_EXCEEDED or UNAVAILABLE status, allowing the safety logic to trigger a failsafe (e.g., hover or return-to-home).&lt;/p&gt;
            `
        },
        'l5-web': {
            title: 'Layer 5 — Web Page (Session)',
            content: `
                &lt;p&gt;HTTP sessions are managed through a combination of TCP connections and application-layer cookies/tokens.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;HTTP Keep-Alive:&lt;/strong&gt; HTTP/1.1 defaults to persistent connections — the TCP connection stays open between requests, avoiding the overhead of a new TCP handshake for each resource. The server or client closes it after a timeout or explicit Connection: close header.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;HTTP/2 multiplexing:&lt;/strong&gt; HTTP/2 goes further, multiplexing dozens of requests over a single TCP connection. This is the session layer at work: one conversation channel, many simultaneous exchanges within it.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Authentication sessions:&lt;/strong&gt; Cookies carry session tokens (e.g. a signed JWT or a random session ID) that the server uses to recognise returning authenticated users without requiring a new login per request. The browser includes cookies automatically in every request to the matching domain.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;WebSockets:&lt;/strong&gt; For pages needing push updates (chat, live scores), the HTTP connection is "upgraded" to a WebSocket session — a full-duplex session over the same TCP connection.&lt;/p&gt;
            `
        },

        /* ── Layer 4 ── */
        'l4-desc': {
            title: 'Layer 4 — Transport Layer',
            content: `
                &lt;p&gt;The Transport layer provides &lt;strong&gt;end-to-end communication services&lt;/strong&gt; for applications. It segments data from upper layers into smaller units and reassembles them at the destination.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;TCP (Transmission Control Protocol):&lt;/strong&gt; Connection-oriented, reliable, ordered delivery with flow control and congestion control. Uses three-way handshake (SYN, SYN-ACK, ACK). Guarantees every byte arrives once and in order. Penalty: added latency for retransmission.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;UDP (User Datagram Protocol):&lt;/strong&gt; Connectionless, no reliability guarantees, minimal overhead. Each datagram is independent. Useful when latency matters more than reliability (video streaming, gaming, DNS, VoIP).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Ports:&lt;/strong&gt; Transport layer introduces port numbers — 16-bit identifiers that distinguish different services/applications on the same host. (HTTP=80, HTTPS=443, DNS=53, gRPC default=50051)&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Flow control:&lt;/strong&gt; TCP's sliding window prevents a fast sender from overwhelming a slow receiver.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Congestion control:&lt;/strong&gt; TCP algorithms (CUBIC, BBR) detect network congestion and reduce sending rate to avoid collapse.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;PDU:&lt;/strong&gt; Segment (TCP) or Datagram (UDP).&lt;/p&gt;
            `
        },
        'l4-youtube': {
            title: 'Layer 4 — YouTube (Transport)',
            content: `
                &lt;p&gt;YouTube uses &lt;strong&gt;UDP as the transport for QUIC&lt;/strong&gt;, which provides its own reliability mechanisms above UDP.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Why not TCP?&lt;/strong&gt; TCP suffers from head-of-line blocking: if one packet is lost, all subsequent data is buffered until the missing packet is retransmitted, stalling delivery even for unrelated streams. For adaptive video with multiple quality levels, this causes visible buffering.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;QUIC over UDP:&lt;/strong&gt; QUIC implements its own reliable, ordered delivery per-stream, but loss in one stream (say, a quality-level switch) doesn't block other streams (the audio). QUIC also handles connection migration natively at the transport level, not just the session level.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;UDP port 443:&lt;/strong&gt; QUIC uses UDP port 443 (same as HTTPS) — this helps traverse firewalls that block non-standard UDP ports, since port 443 is nearly universally allowed.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Fallback:&lt;/strong&gt; If UDP/QUIC is blocked, YouTube falls back to HTTP/2 over TCP, accepting the head-of-line blocking trade-off.&lt;/p&gt;
            `
        },
        'l4-drone': {
            title: 'Layer 4 — Drone gRPC (Transport)',
            content: `
                &lt;p&gt;gRPC uses &lt;strong&gt;TCP&lt;/strong&gt; as its transport, which is why reliable, ordered command delivery is guaranteed — a critical safety requirement for flight control.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;TCP three-way handshake:&lt;/strong&gt; Before any gRPC message is exchanged, TCP establishes the connection: laptop sends SYN → drone replies SYN-ACK → laptop sends ACK. This takes one round-trip time (RTT) on the radio link.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Reliability for safety:&lt;/strong&gt; If a SetThrottle command is lost in transit, TCP automatically retransmits it. The drone's flight controller cannot receive commands out of order. For flight, missing or reordered commands could be dangerous.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Congestion and radio:&lt;/strong&gt; TCP's congestion window can shrink aggressively when the radio link introduces packet loss. TCP interprets loss as congestion (even if it's just RF noise), reducing throughput. Some deployments use specialised TCP variants (e.g. TCP-Hybla or BBR) tuned for radio links with higher baseline loss rates.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Port 50051:&lt;/strong&gt; gRPC conventionally uses TCP port 50051, though any port can be configured.&lt;/p&gt;
            `
        },
        'l4-web': {
            title: 'Layer 4 — Web Page (Transport)',
            content: `
                &lt;p&gt;Web browsing uses &lt;strong&gt;TCP&lt;/strong&gt; on port 443 (HTTPS) or port 80 (HTTP). TCP provides the reliable, ordered byte stream that HTTP depends on.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Three-way handshake latency:&lt;/strong&gt; Before the first HTTP byte is sent, TCP needs one RTT (round-trip time) for the handshake. Add TLS on top (another 1 RTT for TLS 1.3) and the first byte of HTML arrives after 2 RTTs minimum. For a server 50ms away, that's 100ms before anything renders.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;TCP Fast Open:&lt;/strong&gt; TFO allows data to be sent in the SYN packet for repeat connections, saving one RTT. Not universally deployed.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Congestion control:&lt;/strong&gt; TCP CUBIC or BBR manages how quickly the browser can push requests. On a fast home fibre connection, the congestion window grows quickly and throughput is limited by the server or CDN, not the network.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;HTTP/3 advantage:&lt;/strong&gt; HTTP/3 (QUIC over UDP) eliminates the TCP handshake entirely, combining connection and TLS handshake in one step — reducing connection setup from 2 RTTs to 1 RTT (0 for resumption).&lt;/p&gt;
            `
        },

        /* ── Layer 3 ── */
        'l3-desc': {
            title: 'Layer 3 — Network Layer',
            content: `
                &lt;p&gt;The Network layer provides &lt;strong&gt;logical addressing and routing&lt;/strong&gt; — it determines how packets get from source to destination across potentially many intermediate networks.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;IP (Internet Protocol):&lt;/strong&gt; The dominant layer-3 protocol. Every host has a logical IP address. IPv4 uses 32-bit addresses (4.3 billion); IPv6 uses 128-bit addresses (essentially unlimited).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Routing:&lt;/strong&gt; Routers at layer 3 examine destination IP addresses and use routing tables to forward packets toward their destination, one hop at a time. No single router knows the full path — each knows only the next hop.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Routing protocols:&lt;/strong&gt; OSPF (within an organisation), BGP (between autonomous systems on the Internet) build and maintain routing tables dynamically.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Fragmentation:&lt;/strong&gt; If a packet is larger than the MTU of a link, IP can fragment it into smaller pieces (IPv4 only; IPv6 requires the source to perform path MTU discovery).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;ICMP:&lt;/strong&gt; Diagnostic protocol at layer 3 — used by ping and traceroute to probe network paths.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;PDU:&lt;/strong&gt; Packet.&lt;/p&gt;
            `
        },
        'l3-youtube': {
            title: 'Layer 3 — YouTube (Network)',
            content: `
                &lt;p&gt;Your phone's video packets traverse multiple IP networks before reaching YouTube's servers.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Mobile IP addressing:&lt;/strong&gt; Your LTE/5G carrier assigns your phone an IP address — often a private address with carrier-grade NAT (CGNAT), where thousands of subscribers share a single public IP. The carrier's CGNAT box maps your private IP:port to a public IP:port for outbound connections.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Path to CDN:&lt;/strong&gt; Packets leave your phone, traverse the carrier's core network, exit to the public Internet, and arrive at a Google CDN edge node selected by anycast routing — the same IP address is announced from multiple locations, and BGP delivers you to the closest one.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;IPv6:&lt;/strong&gt; Google and major carriers support IPv6. A phone with an IPv6 address can connect directly to YouTube's IPv6 address without CGNAT, simplifying the path and slightly reducing latency.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;QoS:&lt;/strong&gt; Carriers may implement traffic shaping at layer 3 — prioritising video streaming traffic or throttling it during congestion based on DSCP markings in the IP header.&lt;/p&gt;
            `
        },
        'l3-drone': {
            title: 'Layer 3 — Drone gRPC (Network)',
            content: `
                &lt;p&gt;The IP radio creates a private IP network between the laptop and the drone — a self-contained layer-3 domain in the field.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;IP addressing:&lt;/strong&gt; The radio manufacturer typically sets up a small subnet (e.g. 192.168.2.0/24). The laptop's radio module gets .1, the drone's radio module gets .2. Static assignment avoids the complexity of running DHCP over a radio link.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;No routing complexity:&lt;/strong&gt; With only two nodes, there is no routing — both endpoints are on the same subnet. The IP layer directly ARP-resolves the peer's MAC address (radio hardware address) and sends packets directly.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Multi-hop mesh (advanced):&lt;/strong&gt; Some deployments use mesh-capable radios (e.g. 900 MHz FHSS with OLSR routing) to relay packets through multiple ground nodes to extend range. In this case, OLSR (layer-3 routing) manages the path.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;MTU considerations:&lt;/strong&gt; IP radio links often have small MTUs (e.g. 256–512 bytes) due to radio frame size constraints. The network layer may fragment larger TCP segments; alternatively, TCP MSS clamping at the radio driver level prevents this.&lt;/p&gt;
            `
        },
        'l3-web': {
            title: 'Layer 3 — Web Page (Network)',
            content: `
                &lt;p&gt;Two layer-3 activities happen before your browser sends a single HTTP byte: &lt;strong&gt;DNS resolution&lt;/strong&gt; and &lt;strong&gt;IP routing&lt;/strong&gt;.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;DNS resolution:&lt;/strong&gt; DNS is itself a layer-7 protocol that operates over UDP (layer 4) and IP (layer 3). The browser asks the local resolver "what is the IP for example.com?" — the resolver queries the DNS hierarchy (root → TLD → authoritative) and returns an IP address. Modern DNS uses DoH (DNS over HTTPS) for privacy.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;IP routing:&lt;/strong&gt; Your laptop's IP stack looks at the destination IP: is it on the local subnet? If not, forward to the default gateway (your router). The router checks its routing table — if it doesn't have a more specific route, it forwards to the ISP. ISP routers use BGP to route across the Internet.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;NAT:&lt;/strong&gt; Most home routers perform NAT (Network Address Translation), replacing your private IP (192.168.x.x) with the router's public IP in outbound packets and reversing the mapping for responses.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;TTL:&lt;/strong&gt; Each router decrements the IP TTL field. If TTL reaches zero, the packet is discarded and an ICMP "Time Exceeded" message is sent back — this is how traceroute works.&lt;/p&gt;
            `
        },

        /* ── Layer 2 ── */
        'l2-desc': {
            title: 'Layer 2 — Data Link Layer',
            content: `
                &lt;p&gt;The Data Link layer provides &lt;strong&gt;reliable transfer between directly connected nodes&lt;/strong&gt; — a single "hop" on the network. It doesn't know about end-to-end routing; it only cares about the immediate next hop.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Framing:&lt;/strong&gt; Wraps network-layer packets in frames with a header (source/destination MAC address) and a trailer (CRC/FCS for error detection).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;MAC addresses:&lt;/strong&gt; 48-bit hardware addresses burned into network interface cards. Unique per device on the local network. Unlike IP addresses, they're not routable — only meaningful on a single network segment.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Error detection:&lt;/strong&gt; CRC (Cyclic Redundancy Check) in the frame trailer detects bit errors. Corrupted frames are discarded (layer 4 TCP handles retransmission).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Two sublayers:&lt;/strong&gt;&lt;br&gt;
                - LLC (Logical Link Control): Provides a common interface to higher layers&lt;br&gt;
                - MAC (Medium Access Control): Controls who can access the shared medium and when&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt; Ethernet (802.3), Wi-Fi (802.11), PPP, HDLC, LTE MAC.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;PDU:&lt;/strong&gt; Frame.&lt;/p&gt;
            `
        },
        'l2-youtube': {
            title: 'Layer 2 — YouTube (Data Link)',
            content: `
                &lt;p&gt;For mobile video streaming, the data link layer is the &lt;strong&gt;LTE/5G radio access technology&lt;/strong&gt; — specifically the MAC and RLC sublayers of the LTE/5G protocol stack.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;LTE MAC sublayer:&lt;/strong&gt; Schedules when your phone transmits on the shared radio spectrum. The base station (eNB/gNB) allocates resource blocks (12 subcarriers × 0.5 ms time slot) to different UEs based on their channel quality and buffer status reports.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;HARQ (Hybrid ARQ):&lt;/strong&gt; LTE uses HARQ for fast retransmission — if a transmission is received with errors, the base station sends a NACK and retransmits within 8 ms. The receiver combines the original and retransmitted signals to improve decode probability (chase combining or incremental redundancy).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;RLC (Radio Link Control):&lt;/strong&gt; Above MAC, RLC can provide additional ARQ segmentation and reordering of PDUs for reliable mode — especially important at the cell edge where errors are more frequent.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;MAC addresses in LTE:&lt;/strong&gt; LTE doesn't use traditional Ethernet MAC addresses. Instead, each UE is identified by a C-RNTI (Cell Radio Network Temporary Identifier) assigned by the base station.&lt;/p&gt;
            `
        },
        'l2-drone': {
            title: 'Layer 2 — Drone gRPC (Data Link)',
            content: `
                &lt;p&gt;The IP radio module provides the data link layer for the drone communication system — a specialised wireless link with its own framing and error correction.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Radio link framing:&lt;/strong&gt; Common IP radios (e.g. RFD900, mLRS, SiK-based radios, or commercial units like Doodle Labs) implement their own link-layer frames. A typical frame includes: sync bytes, destination address, payload, CRC.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;ARQ (Automatic Repeat reQuest):&lt;/strong&gt; Most IP radios implement ARQ at the link layer — the receiving radio ACKs each frame and the sender retransmits on NAK. This provides a degree of link-layer reliability before TCP even gets involved.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;FHSS / TDMA:&lt;/strong&gt; Frequency-hopping spread spectrum (FHSS) radios change carrier frequency thousands of times per second to resist interference and jamming. TDMA (Time Division Multiple Access) schemes coordinate transmit/receive timing to allow full-duplex communication.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Forward Error Correction (FEC):&lt;/strong&gt; Many link-layer radio protocols add redundancy bits (Reed-Solomon, convolutional codes) that allow the receiver to correct some bit errors without retransmission — important for real-time control where retransmission latency is unacceptable.&lt;/p&gt;
            `
        },
        'l2-web': {
            title: 'Layer 2 — Web Page (Data Link)',
            content: `
                &lt;p&gt;Home and office web browsing uses either &lt;strong&gt;Ethernet (IEEE 802.3)&lt;/strong&gt; for wired connections or &lt;strong&gt;Wi-Fi (IEEE 802.11)&lt;/strong&gt; for wireless.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Ethernet frame:&lt;/strong&gt;&lt;br&gt;
                - Preamble (7 bytes) + SFD (1 byte): synchronise receiver&lt;br&gt;
                - Destination MAC (6 bytes): where it's going&lt;br&gt;
                - Source MAC (6 bytes): where it came from&lt;br&gt;
                - EtherType (2 bytes): identifies the payload protocol (0x0800 = IPv4)&lt;br&gt;
                - Payload (46–1500 bytes): the IP packet&lt;br&gt;
                - FCS (4 bytes): CRC for error detection&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;ARP:&lt;/strong&gt; Before sending the first frame to the gateway, the laptop broadcasts an ARP (Address Resolution Protocol) request: "Who has IP 192.168.1.1? Tell 192.168.1.42." The router responds with its MAC address, which the laptop caches for future frames.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Wi-Fi specifics:&lt;/strong&gt; 802.11 frames carry additional fields (BSSID for the access point MAC, QoS fields, sequence number for duplication detection). Wi-Fi also uses CSMA/CA (listen before transmit) to avoid collisions on the shared radio channel.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;VLANs:&lt;/strong&gt; In enterprise networks, 802.1Q VLAN tags are added to Ethernet frames to segment traffic logically over the same physical infrastructure.&lt;/p&gt;
            `
        },

        /* ── Layer 1 ── */
        'l1-desc': {
            title: 'Layer 1 — Physical Layer',
            content: `
                &lt;p&gt;The Physical layer is the most fundamental — it defines how &lt;strong&gt;raw bits are converted into physical signals&lt;/strong&gt; and transmitted over a medium.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Transmission media:&lt;/strong&gt;&lt;br&gt;
                - Copper wire (electrical voltage pulses)&lt;br&gt;
                - Optical fibre (light pulses)&lt;br&gt;
                - Radio frequency (modulated electromagnetic waves)&lt;br&gt;
                - Infrared (IrDA, TV remotes)&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Modulation:&lt;/strong&gt; The process of encoding digital bits onto an analogue carrier. Common schemes: NRZ (Non-Return-to-Zero) for Ethernet, OFDM (Orthogonal Frequency-Division Multiplexing) for Wi-Fi and LTE, PAM4 (4-level Pulse Amplitude Modulation) for 100GbE.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Bit rate vs. baud rate:&lt;/strong&gt; Baud rate is symbols per second; bit rate depends on how many bits each symbol encodes. OFDM encodes multiple bits per symbol per subcarrier.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Specifications:&lt;/strong&gt; Layer 1 defines connector types, cable categories, pin assignments, signal voltages, frequencies, and timing.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;PDU:&lt;/strong&gt; Bit (or symbol).&lt;/p&gt;
            `
        },
        'l1-youtube': {
            title: 'Layer 1 — YouTube (Physical)',
            content: `
                &lt;p&gt;Mobile video streaming uses &lt;strong&gt;LTE or 5G radio frequency transmission&lt;/strong&gt; as the physical medium.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;OFDM modulation:&lt;/strong&gt; LTE and 5G use Orthogonal Frequency-Division Multiplexing. The available spectrum is divided into hundreds of narrow subcarriers (15 kHz spacing in LTE). Each subcarrier carries a separate modulated symbol, and all subcarriers transmit simultaneously. This provides robustness against multipath fading.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;MIMO (Multiple-Input Multiple-Output):&lt;/strong&gt; Modern phones and base stations have multiple antennas. MIMO techniques use these simultaneously to multiply throughput (spatial multiplexing) or improve link reliability (beamforming, diversity).&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Modulation order:&lt;/strong&gt; Higher-order modulation encodes more bits per symbol — QPSK (2 bits), 16-QAM (4 bits), 64-QAM (6 bits), 256-QAM (8 bits). When the signal is strong (you're near a tower), the base station uses 256-QAM for maximum throughput. At the cell edge with a weaker signal, it falls back to QPSK for reliability.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;5G NR:&lt;/strong&gt; 5G New Radio adds mmWave (24–100 GHz) for very high bandwidth in dense areas, and sub-6 GHz for broader coverage. mmWave provides multi-Gbps throughput but doesn't penetrate walls.&lt;/p&gt;
            `
        },
        'l1-drone': {
            title: 'Layer 1 — Drone gRPC (Physical)',
            content: `
                &lt;p&gt;The drone radio link operates on &lt;strong&gt;sub-GHz (e.g. 900 MHz) or 2.4 GHz ISM bands&lt;/strong&gt;, with physical layer characteristics optimised for range and reliability over raw throughput.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Frequency choice:&lt;/strong&gt; 900 MHz propagates further than 2.4 GHz and penetrates vegetation better, making it popular for UAV control links. 2.4 GHz offers higher bandwidth but shorter range.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;FSK / GFSK modulation:&lt;/strong&gt; Many narrowband radios use Frequency-Shift Keying — "0" is one frequency, "1" is another. Gaussian FSK (GFSK) smooths transitions to reduce spectral bandwidth. This is simpler and more robust than OFDM for low-data-rate links.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;FHSS (Frequency-Hopping Spread Spectrum):&lt;/strong&gt; The radio pseudo-randomly hops between dozens of frequencies per second. An interferer on one frequency only disrupts a small fraction of transmissions. Required by FCC for Part 15 spread-spectrum devices.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;TX power and antennas:&lt;/strong&gt; Link budget is critical for range. Higher TX power (up to regulatory limits — typically 30 dBm / 1W) and directional antennas (patch, helical) at the ground station increase link margin.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Duplex:&lt;/strong&gt; Most IP radios use half-duplex (TDD — Time Division Duplex): radio transmits, then switches to receive. Full-duplex would require expensive RF isolation hardware.&lt;/p&gt;
            `
        },
        'l1-web': {
            title: 'Layer 1 — Web Page (Physical)',
            content: `
                &lt;p&gt;The physical medium for home/office web browsing is typically &lt;strong&gt;twisted-pair copper Ethernet cable or Wi-Fi radio&lt;/strong&gt;.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;1000BASE-T Ethernet:&lt;/strong&gt; Gigabit Ethernet over Cat5e/Cat6 uses all four twisted pairs simultaneously. Each pair carries data using PAM-5 (5-level pulse amplitude modulation), transmitting in both directions at once (full duplex). 125 MHz clock, 250 Mbps per pair × 4 pairs = 1 Gbps.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Wi-Fi 6 (802.11ax):&lt;/strong&gt; Uses OFDMA (Orthogonal Frequency-Division Multiple Access) and 1024-QAM. In the 5 GHz band with 80 MHz channels, peak rates reach ~600 Mbps per spatial stream. Wi-Fi 6E extends into the 6 GHz band for less congestion.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Optical fibre (ISP):&lt;/strong&gt; Somewhere in the path between your home and the webserver, photons travel through glass fibre at 2/3 the speed of light. Single-mode fibre carries a single wavelength for long distances; multi-mode fibre supports short runs. DWDM multiplexes hundreds of wavelengths onto one fibre for terabit-scale backbone links.&lt;/p&gt;
                &lt;p&gt;&lt;strong&gt;Signal attenuation:&lt;/strong&gt; Copper cables lose signal over distance. Cat6 supports Gigabit up to 100 m. Beyond that, fibre or repeaters are needed. Wi-Fi range depends on transmit power, antenna gain, and obstacles (walls, furniture).&lt;/p&gt;
            `
        }
    };

    const modal = document.getElementById('modal');
    const modalTitle = document.getElementById('modal-title');
    const modalBody = document.getElementById('modal-body');
    const closeBtn = document.querySelector('.close');

    document.querySelectorAll('.cell').forEach(cell =&gt; {
        cell.addEventListener('click', function () {
            const key = this.getAttribute('data-info');
            const info = explanations[key];
            if (info) {
                modalTitle.textContent = info.title;
                modalBody.innerHTML = info.content;
                modal.style.display = 'block';
            }
        });
    });

    closeBtn.addEventListener('click', () =&gt; { modal.style.display = 'none'; });
    window.addEventListener('click', e =&gt; { if (e.target === modal) modal.style.display = 'none'; });
    document.addEventListener('keydown', e =&gt; {
        if (e.key === 'Escape' &amp;&amp; modal.style.display === 'block') modal.style.display = 'none';
    });
&lt;/script&gt;
</code></pre>
</body>

</style></head><div style="break-before: page; page-break-before: always;"></div>
<h1 id="optimization-libraries"><a class="header" href="#optimization-libraries">Optimization Libraries</a></h1>
<ul>
<li><a href="#2d-range-bearing-landmark-resolution-with-ceres">2D Range-Bearing Landmark Resolution with Ceres</a></li>
<li><a href="#ceres-solver-python-tutorial">Ceres Solver Python Tutorial</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="2d-range-bearing-landmark-resolution-with-ceres"><a class="header" href="#2d-range-bearing-landmark-resolution-with-ceres">2D Range-Bearing Landmark Resolution with Ceres</a></h1>
<img src="https://andrewtorgesen.com/res/img/rangebearing_dists.svg" width="400" style="display: block; margin-left: auto; margin-right: auto;">
<p>This article has been implemented as a Jupyter Notebook:</p>
<p><strong><a href="https://github.com/goromal/scratchpad/blob/master/optimizations/range_bearing_fusion.ipynb">THE NOTEBOOK</a></strong></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="ceres-solver-python-tutorial"><a class="header" href="#ceres-solver-python-tutorial">Ceres Solver Python Tutorial</a></h1>
<h2 id="ceres-introduction"><a class="header" href="#ceres-introduction">Ceres Introduction</a></h2>
<p>The <a href="http://ceres-solver.org/">Ceres Solver</a> is Google’s powerful and extensive C++ optimization library for solving:</p>
<ul>
<li>general unconstrained optimization problems</li>
<li>nonlinear least-squares problems with bounds (not equality!) constraints.</li>
</ul>
<p>The second application is particularly useful for perception, estimation, and control in robotics (perhaps less so for control, depending on how you implement dynamics constraints), where minimizing general nonlinear measurement or tracking residuals sequentially or in batch form is a common theme. This is further facilitated by Ceres’ support for optimizing over vector spaces as well as Lie Groups, much like GTSAM. To zoom in on the comparison between the two libraries a bit, here are some relative pros and cons:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Ceres Advantages</th><th>GTSAM Advantages</th></tr>
</thead>
<tbody>
<tr><td>Supported by Google, not just one research lab</td><td>Made specifically for robotics applications, so comes with a lot of useful tools, such as…</td></tr>
<tr><td>Has an awesome <a href="http://ceres-solver.org/automatic_derivatives.html">automatic differentiation system</a>–no time wasted computing complicated derivatives</td><td>…iSAM2 incremental optimization</td></tr>
<tr><td>Generalizes well beyond robotics applications, or even exotic robotics applications that don’t yet have pre-programmed tools</td><td>…Marginalization support (e.g., for fixed-lag smoothing)</td></tr>
</tbody>
</table>
</div>
<p>Aside from what’s mentioned in the table, GTSAM adopts the helpful <a href="http://deepdive.stanford.edu/inference">factor graph</a> modeling paradigm for estimation problems. If desired, Ceres can be used through the definition of factors as well, as will be shown in the examples below. All in all, Ceres is a fine choice for solving optimization-based inference problems, and it’s not going away any time soon. Moreover, the <a href="http://ceres-solver.org/">docs</a> are thorough and well-made; this tutorial can be thought of as an entry point to give some context to a deep-dive into the documentation.</p>
<h2 id="solving-problems-with-ceres"><a class="header" href="#solving-problems-with-ceres">Solving Problems with Ceres</a></h2>
<p>At a minimum, a Ceres program for solving <a href="#nonlinear-optimization">nonlinear least-squares problems</a> requires the following specifications:</p>
<ul>
<li>A <code>Problem()</code> object.</li>
<li>For every decision variable (<code>parameter</code>) that isn’t a vector:
<ul>
<li>Add a <code>LocalParameterization()</code> object to the problem using the function <code>AddParameterBlock()</code>.</li>
</ul>
</li>
<li>For every residual in the problem:
<ul>
<li>Add a <code>CostFunction()</code> object (can be thought of as a factor in factor graph lingo) with the relevant parameters using the function <code>AddResidualBlock()</code></li>
</ul>
</li>
</ul>
<p>See the examples below to get a sense of how these objects and functions are used in practice, particularly in the context of robotics problems.</p>
<h2 id="automatic-differentiation-in-ceres"><a class="header" href="#automatic-differentiation-in-ceres">Automatic Differentiation in Ceres</a></h2>
<p>One of the main selling points of Ceres is its powerful automatic differentiation system. As covered in the articles on <a href="#nonlinear-optimization">Nonlinear Least-Squares</a> and <a href="#optimization-over-lie-groups">Lie Group Optimizations</a>, local search requires Jacobian definitions for, at a minimum:</p>
<ul>
<li>The cost function \(J\) or residual \(r\).</li>
<li>The \(\oplus\) operator of the parameter vector <em>if</em> it exists on a manifold, because of the chain rule.</li>
</ul>
<p>Thus, any user declaration of a class that inherits from <a href="http://ceres-solver.org/nnls_modeling.html#costfunction">CostFunction</a> or <a href="http://ceres-solver.org/nnls_modeling.html#localparameterization">LocalParameterization</a> requires the specification of Jacobians. This can get really tedious really fast, which is why Ceres offers auto-diff in the form of two alternative classes to define through templating and inheritance (see the links for details):</p>
<ul>
<li><a href="http://ceres-solver.org/nnls_modeling.html#_CPPv4N5ceres20AutoDiffCostFunctionE">AutoDiffCostFunction</a>: A templated class that takes as an argument a user-defined “functor” class or struct implementing the residual function.</li>
<li><a href="http://ceres-solver.org/nnls_modeling.html#autodifflocalparameterization">AutoDiffLocalParameterization</a>: A templated class that takes as an argument a user-defined “plus” class or struct implementing the \(\oplus\) operator.</li>
</ul>
<h2 id="small-robotics-examples-with-ceres-in-python"><a class="header" href="#small-robotics-examples-with-ceres-in-python">Small Robotics Examples with Ceres (in Python)</a></h2>
<p>Ceres is a C++ library, and its speed is certainly dependent on programming in that language. That said, I’ve found it useful to use Python bindings to learn the library by doing quick experiments solving small-scale robotics problems.</p>
<p>The Jupyter notebook below contains some illustrative examples of Ceres applied to small robotics problems of increasing complexity–they should give a sense of what the library is capable of, and perhaps even facilitate your own prototyping efforts. The Python syntax translates pretty well to C++, but of course the <a href="http://ceres-solver.org/tutorial.html">Ceres website</a> serves as the best C++ API reference.</p>
<p><strong><a href="https://github.com/goromal/scratchpad/blob/master/optimizations/ceres_tutorial.ipynb">THE PYTHON EXAMPLES</a></strong></p>
<h2 id="some-slides"><a class="header" href="#some-slides">Some Slides</a></h2>
<p>As some end matter, here are some PDF slides I put together to present the above tutorial in a lab setting. The per-slide notes are also included, for reference.</p>
<p><strong><a href="https://andrewtorgesen.com/res/Ceres_Slides.pdf">THE SLIDES</a></strong></p>
<h3 id="ceres-solver-title-slide"><a class="header" href="#ceres-solver-title-slide">Ceres Solver (Title Slide)</a></h3>
<ul>
<li>Popular tool for solving “back-end” estimation and SLAM problems with nonlinear least squares
<ul>
<li>Made more accessible for rapid prototyping and for those not as comfortable with C++</li>
</ul>
</li>
<li>Hopefully useful particularly for those starting out and wanting to get real exposure to implementing and solving problems like SLAM without a huge coding learning curve</li>
<li>Or even for experienced users who want a fast prototyping tool</li>
<li>Will go over some theory (not a lot of detail) to give context to the solver, explain why Ceres is awesome, then solve a toy SLAM problem with python bindings (and a little bit of C++)</li>
</ul>
<h3 id="ceres-solver-overview"><a class="header" href="#ceres-solver-overview">Ceres Solver: Overview</a></h3>
<ul>
<li>So how do you solve estimation and SLAM problems with Ceres, and what special features does it offer?
<ul>
<li>A brief delving into estimation theory will help clarify those questions.</li>
</ul>
</li>
</ul>
<h3 id="estimation-as-nonlinear-optimization"><a class="header" href="#estimation-as-nonlinear-optimization">Estimation as Nonlinear Optimization</a></h3>
<ul>
<li>Bayesian inference:
<ul>
<li>in scenarios where you have probabilistic models for
<ul>
<li>how your system (robot) state evolves (if at all) through time</li>
<li>how your observations relate to your state</li>
</ul>
</li>
<li>…you can express your state as the one that maximizes the joint probability over all of your models, which are expressed in terms of residuals, which quantify the agreement between your state belief and what the models are telling you about your state</li>
<li>nice when your models are Gaussian; you can express them analytically and concisely in terms of covariance and residuals</li>
</ul>
</li>
<li>In practice, solved with filtering or optimization (smoothing)
<ul>
<li>Smoothing → access to entire history, unlike with filtering</li>
</ul>
</li>
<li>When you can, go with optimization! It gives you more accuracy gains per unit of computation time.</li>
</ul>
<h3 id="estimation-as-nonlinear-optimization-1"><a class="header" href="#estimation-as-nonlinear-optimization-1">Estimation as Nonlinear Optimization</a></h3>
<ul>
<li>So the process of finding the most likely state (and state history) of your robot is reduced to this nonlinear least-squares optimization over the residuals of all of your models through time
<ul>
<li>Been mentioning state, but this includes optimizing over environmental attributes (e.g., landmarks) as with bundle adjustment and SLAM</li>
</ul>
</li>
</ul>
<h3 id="nonlinear-optimization-on-the-manifold"><a class="header" href="#nonlinear-optimization-on-the-manifold">Nonlinear Optimization on the Manifold</a></h3>
<ul>
<li>Local search will treat \(\mathbf{x}\) as a vector, and it will leave the manifold as soon as you add or subtract.</li>
<li>Retractions allow you to move along the manifold using vectors.</li>
</ul>
<h3 id="ceres-solver-features"><a class="header" href="#ceres-solver-features">Ceres Solver: Features</a></h3>
<ul>
<li>With theoretical backdrop, now we can appreciate everything Ceres has to offer.</li>
<li>Jet usage requires sound knowledge of C++ templating, as we’ll see.</li>
</ul>
<h3 id="ceres-vs-gtsam"><a class="header" href="#ceres-vs-gtsam">Ceres vs GTSAM</a></h3>
<ul>
<li>GTSAM serves many of the same needs–how do they stack up?</li>
<li>Incremental optimization with ISAM2 probably GTSAM’s biggest advantage.</li>
<li>Auto-differentiation and level of support are Ceres’ biggest advantages.</li>
</ul>
<h3 id="toy-problem-pgo"><a class="header" href="#toy-problem-pgo">Toy Problem: PGO</a></h3>
<ul>
<li>Find the maximum-likelihood sequence of robot poses given a series of front-end (VIO) measurements and sparse loop closure measurements.</li>
<li>We’ll simulate the system and solve the problem all in Python.
<ul>
<li>I took some unfinished Python bindings for Ceres and “finished” them, to allow rapid prototyping and learning for myself and others.</li>
</ul>
</li>
<li>First, we’ll define local parameterization and cost function in C++ (which will are then wrapped in Python) for speed and to illustrate how templating for auto-differentiation works with Ceres.</li>
<li>Ceres will give us the Jacobians of the local parameterization and residuals for free!</li>
</ul>
<h3 id="toy-problem-local-parameterization"><a class="header" href="#toy-problem-local-parameterization">Toy Problem: Local Parameterization</a></h3>
<ul>
<li>The actual math is only one line! The rest is handling templates and pointers.</li>
</ul>
<h3 id="toy-problem-residual-definition"><a class="header" href="#toy-problem-residual-definition">Toy Problem: Residual Definition</a></h3>
<h3 id="toy-problem-dynamics-and-covariances"><a class="header" href="#toy-problem-dynamics-and-covariances">Toy Problem: Dynamics and Covariances</a></h3>
<ul>
<li>Everything from here on out is in Python</li>
<li>Dynamics: Euler integration using this local perturbation vector in position and orientation (will move forward and yaw, creating a circle)</li>
<li>Covariance and square root matrices</li>
</ul>
<h3 id="toy-problem-true-state--odom-simulation"><a class="header" href="#toy-problem-true-state--odom-simulation">Toy Problem: True State + Odom Simulation</a></h3>
<ol>
<li>Instantiate the problem.</li>
<li>Fixed noisy prior no state at the beginning, then subsequently noisy relative odometry measurements.</li>
<li>The Euler integration itself relies on the implemented SE3 geodesic map definitions.</li>
<li>Each time a measurement is created, add local parameterization (so Ceres knows this isn’t part of a vector space) as well as residual definition.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="systems-theory"><a class="header" href="#systems-theory">Systems Theory</a></h1>
<ul>
<li><a href="#mechanics">Mechanics</a>
<ul>
<li><a href="#the-transport-theorem-and-fictitious-forces">The Transport Theorem</a></li>
</ul>
</li>
<li><a href="#signals">Signals</a>
<ul>
<li><a href="#algorithms-in-continuous-vs-discrete-time">Algorithms in Continuous vs Discrete Time</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="mechanics"><a class="header" href="#mechanics">Mechanics</a></h1>
<ul>
<li><a href="#the-transport-theorem-and-fictitious-forces">The Transport Theorem</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="the-transport-theorem-and-fictitious-forces"><a class="header" href="#the-transport-theorem-and-fictitious-forces">The Transport Theorem and “Fictitious Forces”</a></h1>
<h2 id="newtons-laws-and-inertial-reference-frames"><a class="header" href="#newtons-laws-and-inertial-reference-frames">Newton’s Laws and Inertial Reference Frames</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Newton%27s_laws_of_motion">Newton’s Laws of Motion</a></p>
<p>Newton’s second law is usually introduced to engineering students (or the curious general public) in the following form:</p>
<p>$$\sum\mathbf{F}=m\mathbf{a}=m\frac{d\mathbf{v}}{dt},$$</p>
<p>which is all well and good, except that it could be re-written to more precisely communicate an oft-unspoken precondition implied by Newton’s first law: that the “observer” (or the one noting the net forces and their effects) must be observing from and <em>inertial reference frame.</em> An inertial reference frame is a reference frame that is not accelerating (including through rotation). To make this precondition explicit, we can denote \(W\) (“World”) as the canonical inertial frame for our applications and re-write the second law as</p>
<p>$$\sum\mathbf{F}^W=m\mathbf{a}^W=m\frac{d\mathbf{v}^W}{dt^W},$$</p>
<p>where \(\frac{d\square^W}{dt^W}\) is the simple derivative we all know and love, lending itself to e.g., standard numerical differentiation techniques:</p>
<p>$$\frac{d\square^W}{dt^W}=\lim_{\Delta t\rightarrow 0}\frac{\square(t+\Delta t)-\square(t)}{\Delta t}.$$</p>
<p>Here we chose to express \(\mathbf{F}^W\) in the inertial frame, but the inertial observer precondition does not actually constrain us to do so. We can denote \(B\) as a reference frame that’s rotating with respect to \(W\) as defined by the arbitrary time-dependent function \(\mathbf{\omega}^{B}_{B/W}(t)\). And we can re-express Newton’s second law for forces expressed in \(B\):</p>
<p>$$\sum\mathbf{F}^B=m\mathbf{a}^B=m\frac{d\mathbf{v}^B}{dt^W},$$</p>
<p>but what does \(\frac{d\mathbf{v}^B}{dt^W}\) mean? It’s an inertial observer’s account of the total derivative of an evolving vector expressed in a different, perhaps non-inertial reference frame. It’s certainly not a straightforward derivative, unlike its all-inertial-frame counterpart.</p>
<h2 id="the-transport-theorem"><a class="header" href="#the-transport-theorem">The Transport Theorem</a></h2>
<p>The transport theorem specifies how to calculate \(\frac{d\square^B}{dt^W}\) when \(B\) is a rotating reference frame described by \(\mathbf{\omega}^{B}_{B/W}(t)\):</p>
<blockquote>
<p>$$\frac{d\square^B}{dt^W}=\frac{d\square^B}{dt^B}+\mathbf{\omega}^{B}_{B/W}\times\square^B.$$</p>
</blockquote>
<p>In other words, an inertial observer’s account of the time derivative is equal to a non-inertial observer’s naive account of the time derivative (\(\frac{d\square^B}{dt^B}\)) plus the inertial-frame accelerations that are implied by the rotating reference frame (\(\mathbf{\omega}^{B}_{B/W}\times\square^B\)). The same logic applies to linearly accelerating reference frames, which would add another corrective term to the equation above to account for the acceleration implied by a linearly accelerating reference frame.</p>
<p>Newton’s second law can thus be fully written out for vectors expressed in rotating reference frames as</p>
<blockquote>
<p>$$\sum\mathbf{F}^B=m\mathbf{a}^B=m\frac{d\mathbf{v}^B}{dt^W}=m\left(\frac{d\mathbf{v}^B}{dt^B}+\mathbf{\omega}^{B}_{B/W}\times\mathbf{v}^B\right).$$</p>
</blockquote>
<h2 id="fictitious-forces-from-rotating-reference-frames"><a class="header" href="#fictitious-forces-from-rotating-reference-frames">Fictitious Forces from Rotating Reference Frames</a></h2>
<h3 id="application-of-the-transport-theorem-from-velocity"><a class="header" href="#application-of-the-transport-theorem-from-velocity">Application of the Transport Theorem from Velocity</a></h3>
<p>The main reason why Newton’s second law has the inertial observer precondition is that non-inertial reference frames introduce <a href="https://en.wikipedia.org/wiki/Rotating_reference_frame#Fictitious_forces">fictitious forces</a> (e.g., centrifugal, Coriolis, and Euler forces) that break Newton’s first law. Luckily, we don’t have to keep track of all of the details of these fictitious forces, because the transport theorem accurately describes all fictitious forces when they arise.</p>
<p>There is some nuance when using the transport theorem to calculate fictitious forces, however, and it’s important to understand those nuances to avoid getting confused. The simplest example to illustrate this nuance is a point mass expressed in a non-inertial reference frame that’s rotating in a 2D plane. There are two ways to conceptualize this problem. The first way (scenario <strong>A</strong>, left in the figure below) is to picture the point mass being propelled through space while anchored to the origin of the rotating reference frame by a massless string. The second way (scenario <strong>B</strong>, right in the figure below) is to remove the string, though the reference frame is still rotating in the same manner.</p>
<img src="img/mechanics/fictitious_forces_frames.svg" width="525" style="display: block; margin-left: auto; margin-right: auto;">
<p>Some relevant observations about both scenarios:</p>
<ul>
<li>Scenario <strong>A</strong> has <em>actual forces</em> acting on the point mass (coming from the tension in the string) whereas scenario <strong>B</strong> has no real forces acting anywhere.</li>
<li>The point mass in scenario <strong>A</strong> looks like it’s being acted on by a force to an inertial observer, whereas the point mass in scenario <strong>B</strong> looks like it’s being acted on by a force only to an observer who lives within the rotating reference frame.</li>
<li>The actual force in scenario <strong>A</strong> is <em>equal and opposite</em> to the fictitious force in scenario <strong>B</strong>, assuming that the rotational speeds and velocities are equal between the two.</li>
</ul>
<p>Observations 1-3 highlight the generalizable differences between “real” and “fictitious” forces. For scenarios <strong>A</strong> and <strong>B</strong>, the real and fictitious forces are the centripetal and centrifugal force, respectively. A centripetal force is a real force; it’s the force the string is imposing on the mass to <em>make</em> it rotate instead of move in a straight line as it would normally do, and this is observable to a non-rotating, inertial observer. The centrifugal force is imaginary, apparent only to an observer who’s rotating with the non-inertial reference frame; an inertial observer can easily see that the point mass is not actually veering unnaturally from its original trajectory. The centripetal and centrifugal forces are equal and opposite, which is why the centrifugal force is often referred to as a “reaction force” in scenario <strong>A</strong>.</p>
<p>The transport theorem can (and should) be used to understand and calculate both types of forces. Picture a point mass \(m\) no longer confined to the plane, but moving within an arbitrarily rotating reference frame \(B\) in 3D space. We can do all of our analysis with vectors expressed in the \(B\) frame, as those quantities are often more readily measurable.</p>
<p>Applying scenario <strong>A</strong>-like conditions to this general case, we picture the point mass moving with a scalar constant velocity \(v\) as it is constrained by some non-zero, <em>real</em> net force \(\sum\mathbf{F}^B\) (whatever it may be–another massless string?) to rotate rigidly with the same angular velocity as \(B\). We thus know the following:</p>
<ul>
<li>\(\sum\mathbf{F}^B\neq 0\) (what is it?)</li>
<li>To an observer who lives in \(B\), the point mass’s velocity is not changing over time: \(\frac{d\mathbf{v}^B}{dt^B}=0\)</li>
</ul>
<p>which gives, when applying the transport theorem:</p>
<blockquote>
<p>$$\sum\mathbf{F}^B=m\left(\mathbf{\omega}_{B/W}^B\times\mathbf{v}^B\right).$$</p>
</blockquote>
<p>This gives us a way to calculate centripetal force for the generalized scenario <strong>A</strong>.</p>
<p>Scenario <strong>B</strong> is often a more common thing to worry about in the generalized case, especially considering that on the planet Earth we are not inertial observers, but rather observers rigidly attached to a rapidly rotating reference frame. Thus, we’re beholden to observe imaginary forces like centrifugal and Coriolis forces–can we calculate the acceleration effects of these fake but convincing-looking forces according to our non-inertial vantage point? For the generalized scenario <strong>B</strong>, the following is true:</p>
<ul>
<li>There is no actual force acting: \(\sum\mathbf{F}^B= 0\)</li>
<li>Because of the above, to an <em>inertial</em> observer, the point mass’s velocity is not changing over time: \(\frac{d\mathbf{v}^B}{dt^W}=0\)</li>
</ul>
<p>which gives, when applying the transport theorem and moving some terms to the other side of the equals sign:</p>
<blockquote>
<p>$$\frac{d\mathbf{v}^B}{dt^B}=-\mathbf{\omega}_{B/W}^B\times\mathbf{v}^B.$$</p>
</blockquote>
<p>This gives us a way to calculate apparent accelerations from fake forces resulting from observing from a rotating reference frame, including the famous centrifugal and Coriolis forces we observe on Earth.</p>
<p>The transport theorem is a powerful paradigm through which to conceptualize both real and fictitious forces that arise in rotating reference frames such as our own spinning planet.</p>
<h3 id="caveat-double-application-of-the-transport-theorem"><a class="header" href="#caveat-double-application-of-the-transport-theorem">Caveat: Double Application of the Transport Theorem</a></h3>
<p>The previous section wraps up all fictitious forces into one concise equation above, but an implicit assumption was made for the sake of simplicity: we took \(\mathbf{v}^B\) for granted–that is, we just thought of it as some time-varying vector quantity, but <em>didn’t dive into any special effects that a rotating reference frame might have on constraining the apparent nature of such a velocity</em>. Thus, we obscured the explicit characterization of the fictitious centrifugal force (which is partially dependent on position, a quantity that’s obscured when you take a velocity as a given, un-characterized term in your equation), focusing instead on Coriolis effects, which are dependent on velocity and rotation alone.</p>
<p>We can amend this obscurity by not taking \(\mathbf{v}^B\) for granted and instead starting our analysis with the most fundamental quantity, position \(\mathbf{p}^B_{P/B}(t)\). \(P\) is denoted as the body-fixed reference frame of the particle, and \(\mathbf{p}\) gives the position of the origin of \(P\) relative to the origin of the rotating reference frame \(B\). Instead of taking velocity for granted, we will take position for granted as an arbitrarily time-varying quantity. This is okay, because there are no physical states “hidden behind” position, unlike with velocity–position is the most fundamental unit for translational mechanics (same as with attitude for rotational mechanics). This perspective will allow for maximal observability of all fictitious forces resulting from a rotating, non-inertial observer of an arbitrarily-moving particle; we just need to apply the transport theorem twice instead of once in order to get to the acceleration term in Newton’s second law!</p>
<p>We place ourselves once again in the perspective of a rotating observer and apply the transport theorem a first time, which gets us to a first-order differential equation:</p>
<p>$$\mathbf{v}^B_{P/B}=\frac{d\mathbf{p}^B_{P/B}}{dt^W}=\frac{d\mathbf{p}^B_{P/B}}{dt^B}+\mathbf{\omega}^B_{B/W}\times\mathbf{p}^B_{P/B}.$$</p>
<p>Now we apply the transport theorem a second time to obtain acceleration. We need the inertial derivative of velocity, \(\frac{d\mathbf{v}^B_{P/B}}{dt^W}\). Applying the transport theorem to \(\mathbf{v}^B_{P/B}\):</p>
<p>$$\mathbf{a}^B_{P/B}=\frac{d\mathbf{v}^B_{P/B}}{dt^W}=\frac{d\mathbf{v}^B_{P/B}}{dt^B}+\mathbf{\omega}^B_{B/W}\times\mathbf{v}^B_{P/B}.$$</p>
<p>We already have an expression for \(\mathbf{v}^B_{P/B}\) from the first application. To expand the \(\frac{d\mathbf{v}^B_{P/B}}{dt^B}\) term, we take the body-frame derivative of our velocity expression (assuming constant \(\mathbf{\omega}^B_{B/W}\) for simplicity):</p>
<p>$$\frac{d\mathbf{v}^B_{P/B}}{dt^B}=\frac{d^2\mathbf{p}^B_{P/B}}{(dt^B)^2}+\mathbf{\omega}^B_{B/W}\times\frac{d\mathbf{p}^B_{P/B}}{dt^B}.$$</p>
<p>Substituting both results into the acceleration equation:</p>
<p>$$\mathbf{a}^B_{P/B}=\frac{d^2\mathbf{p}^B_{P/B}}{(dt^B)^2}+\mathbf{\omega}^B_{B/W}\times\frac{d\mathbf{p}^B_{P/B}}{dt^B}+\mathbf{\omega}^B_{B/W}\times\left(\frac{d\mathbf{p}^B_{P/B}}{dt^B}+\mathbf{\omega}^B_{B/W}\times\mathbf{p}^B_{P/B}\right).$$</p>
<p>Distributing the cross product and collecting terms:</p>
<blockquote>
<p>$$\mathbf{a}^B_{P/B}=\frac{d^2\mathbf{p}^B_{P/B}}{(dt^B)^2}+2\mathbf{\omega}^B_{B/W}\times\frac{d\mathbf{p}^B_{P/B}}{dt^B}+\mathbf{\omega}^B_{B/W}\times\left(\mathbf{\omega}^B_{B/W}\times\mathbf{p}^B_{P/B}\right).$$</p>
</blockquote>
<p>This is the full inertial acceleration as seen from the rotating frame, and each term has a clear physical interpretation:</p>
<ul>
<li>\(\frac{d^2\mathbf{p}^B_{P/B}}{(dt^B)^2}\) is the acceleration as naively observed by the rotating observer.</li>
<li>\(2\mathbf{\omega}^B_{B/W}\times\frac{d\mathbf{p}^B_{P/B}}{dt^B}\) is the <strong>Coriolis acceleration</strong>, dependent on the body-frame velocity of the particle and the angular velocity of the rotating frame.</li>
<li>\(\mathbf{\omega}^B_{B/W}\times\left(\mathbf{\omega}^B_{B/W}\times\mathbf{p}^B_{P/B}\right)\) is the <strong>centrifugal acceleration</strong>, dependent on the position of the particle within the rotating frame.</li>
</ul>
<p>For the generalized scenario <strong>B</strong> (no real forces), \(\mathbf{a}^B_{P/B}=0\), so the apparent acceleration observed in the rotating frame is</p>
<blockquote>
<p>$$\frac{d^2\mathbf{p}^B_{P/B}}{(dt^B)^2}=-2\mathbf{\omega}^B_{B/W}\times\frac{d\mathbf{p}^B_{P/B}}{dt^B}-\mathbf{\omega}^B_{B/W}\times\left(\mathbf{\omega}^B_{B/W}\times\mathbf{p}^B_{P/B}\right),$$</p>
</blockquote>
<p>which decomposes the fictitious acceleration into its Coriolis and centrifugal components explicitly. This is the result that was obscured when we took velocity as a given in the previous section–by starting from position and applying the transport theorem twice, the centrifugal term emerges naturally alongside the Coriolis term.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="signals"><a class="header" href="#signals">Signals</a></h1>
<ul>
<li><a href="#algorithms-in-continuous-vs-discrete-time">Algorithms in Continuous vs Discrete Time</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="algorithms-in-continuous-vs-discrete-time"><a class="header" href="#algorithms-in-continuous-vs-discrete-time">Algorithms in Continuous vs Discrete Time</a></h1>
<p>In most of what you’ve seen so far, the question of discretization comes up always when you’re implementing either a simulation or a control scheme on a computer, which inherently deals in time-discretized operations. Really, the issue/need for distinction between discrete and continuous modeling arises wherever <strong>derivatives</strong> and <strong>integrals</strong> show up–how to deal with them when we can only perform discrete operations? There are various options, and you can choose what works best for you.</p>
<p>When it comes to dealing with <strong>integrals</strong> (as is the case with simulation) you can:</p>
<hr>
<p>Discretize our <em>model</em>. For LTI systems, we obtain difference equations of the form</p>
<p>$$x_{k+1}=A_dx_k+B_du_k.$$</p>
<p>To get the values of \(A_d\) and \(B_d\), consider the analytical solution of the continuous-time version of the \(\dot{x}=Ax+Bu\) LTI system:</p>
<p>$$x(t)=e^{At}x_0+\int_0^te^{A(t-\tau)}Bu(\tau)d\tau.$$</p>
<p>and imagine that we discretize the system by integrating over short time steps \(\Delta t\) and continuously resetting \(x_0\). If \(\Delta t\) is small enough, then we can get away with linearizing the solution to the linear ODE, if you will:</p>
<p>$$x(\Delta t)\approx e^{A\Delta t}x_0+\left(\int_0^{\Delta t}e^{A\tau}d\tau\right)Bu$$</p>
<p>$$\triangleq A_d x_0 + B_d u,$$</p>
<p>so \(A_d = e^{A\Delta t} \approx I + A \Delta t\) and \(B_d = \left(\int_0^{\Delta t}e^{A\tau}d\tau\right)B \approx A^{-1}(A_d-I)B\) (if \(A\) is nonsingular).</p>
<hr>
<p>OR</p>
<hr>
<p>Keep our continuous (perhaps nonlinear) model</p>
<p>$$\dot{x}=f(x,u)$$</p>
<p>and instead discretize the <em>integration scheme itself</em>, \(\int_0^{\Delta t}f dt\approx \mathcal{I}\):</p>
<p>$$x_{k+1}=x_k+\mathcal{I}$$</p>
<p>Here are some methods:</p>
<ul>
<li><strong>Euler integration</strong>:</li>
</ul>
<p>$$\mathcal{I}=f(x_k,u_k) \Delta t.$$</p>
<ul>
<li><strong>Trapezoidal integration</strong>:</li>
</ul>
<p>$$\mathcal{I}=(k_1+k_2) \Delta t/2,$$</p>
<p>$$k_1=f(x_{k-1},u_{k-1}),$$</p>
<p>$$k_2=f(x_k,u_k).$$</p>
<ul>
<li><strong>4th-order Runge-Kutta integration</strong>:</li>
</ul>
<p>$$\mathcal{I}=(k_1+2k_2+2k_3+k_4) \Delta t/6,$$</p>
<p>$$k_1=f(x_k,u_k),$$</p>
<p>$$k_2=f(x_k+k_1\Delta t/2,u_k),$$</p>
<p>$$k_3=f(x_k+k_2\Delta t/2,u_k),$$</p>
<p>$$k_4=f(x_k+k_3\Delta t, u_k).$$</p>
<p><em><strong>Important Note:</strong></em> If your time-varying signal has known auto correlative properties (i.e., if you have the ability to evaluate \(f(x)\) closed-form for any arbitrary \(x\)), then you can take advantage of this knowledge to construct a more accurate integral for a similar number of FLOPS using the formulations generalized by <a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods#Explicit_Runge%E2%80%93Kutta_methods">Explicit Runge-Kutta methods</a>. For example, <a href="https://en.wikipedia.org/wiki/Simpson%27s_rule">Simpson’s Rule</a> involves a similar FLOP count to 4th-order Runge-Kutta, but only requires “black box” signal sampling and will be less accurate (though still more accurate than the lower-order black box Trapezoidal method).</p>
<hr>
<p>When it comes to dealing with <strong>derivatives</strong> (as is the case with controlling off of state derivatives) you can:</p>
<hr>
<p>Use the discrete model \(x_{k+1}=A_dx_k+B_du_k\) to derive a <em>discrete controller</em>. This is the only choice, unfortunately, when your control method has to have the dynamics engrained in when calculating the control, <em>and</em> that calculation must be done online with no room for inter-step approximate derivatives and integrals. Some examples of when this happens:</p>
<ul>
<li>Some trajectory optimization techniques where you express the discrete dynamics as constraints (some programs like GPOPS-II allow you to specify the continuous derivatives, and they discretize things for you)</li>
<li>Dynamic programming, as with deriving time-varying, discrete LQR</li>
</ul>
<hr>
<p>OR</p>
<hr>
<p>Use the continuous model \(\dot{x}=Ax+Bu\) to derive the <em>continuous controller offline with calculus</em> (as with standard LQR, PID), then apply discrete //derivative/integral// operators derived with the Tustin approximation, etc. to provide inputs to the continuous controller during operation.</p>
<p>Discrete integration is often performed with the trapezoidal approximation, which is shown above.</p>
<p>Some different implementations of the discrete derivative operator:</p>
<ul>
<li><strong>Tustin approximation of “dirty derivative”</strong>:</li>
</ul>
<p>Tustin approximation is</p>
<p>$$s \rightarrow \frac{2}{\Delta t}\left(\frac{1-z^{-1}}{1+z^{-1}}\right),$$</p>
<p>and the dirty derivative (derivative + low-pass filter, since the pure differentiator is not causal) is</p>
<p>$$\dot{X}(s)=\frac{s}{\sigma s+1}X(s),$$</p>
<p>and applying the approximation yields</p>
<p>$$\dot{x}_k=\left(\frac{2\sigma-\Delta t}{2\sigma + \Delta t}\right)\dot{x}_{k-1}+\left(\frac{2}{2\sigma+\Delta t}\right)(x_k-x_{k-1}).$$</p>
<ul>
<li><strong>Finite differencing</strong></li>
<li><strong>Complex derivative</strong></li>
</ul>
<hr>
<p>The <strong>question</strong> I find myself asking, then, is whether or not I can get away with only discretizing the derivative and integral operations, if there are any, so that I can just deal with the continuous model and calculus-based controller derivation!</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="philosophy"><a class="header" href="#philosophy">Philosophy</a></h1>
<ul>
<li><a href="#aristotelian-science-review-and-evaluation">Aristotelian Science</a></li>
<li><a href="#logical-fallacies-as-failures-of-probabilistic-reasoning">Logical Fallacies as Bayesian Failures</a></li>
<li><a href="#realism-vs-nominalism">Realism vs Nominalism</a></li>
<li><a href="#thomas-aquinas-on-reason-and-revelation">Thomas Aquinas on Reason and Revelation</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="aristotelian-science-review-and-evaluation"><a class="header" href="#aristotelian-science-review-and-evaluation">Aristotelian Science: Review and Evaluation</a></h1>
<p>As a proponent of the scientific method, it was interesting to delve into Aristotle and his thoughts on empiricism–thoughts which, although somewhat flawed, arguably exist as a precursor to modern scientific thought.</p>
<hr>
<p>Aristotle’s conception of science is to develop a body of demonstrable knowledge, united by common principles, to explain observed phenomena. The scientific principles derived by Aristotle have been very influential throughout history, though some of his ideas have fallen out of favor as secure grounds for scientific knowledge. In this paper, I aim to describe Aristotle’s method for acquiring scientific, theoretical knowledge, then provide a personal evaluation of its epistemological usefulness in modern times.</p>
<p>Unlike his teacher, Plato, Aristotle sees sense observation as the highest indicator of what is ultimately real. Scientific knowledge, operating in a secondary capacity, is mankind’s tool for providing an explanation for what is observed. Thus, scientific knowledge must depend entirely on what is perceived through the senses. To arrive at scientific knowledge from observation, Aristotle advocates for the formulation of a deductive argument in the form of syllogism. He also refers to the process of deduction as demonstration. Demonstration must begin with a set of principle premises. The premises must be indemonstrable because if they were demonstrable, then all demonstration would suffer from infinite regression, never arriving at a first cause, or principle. Rather, the premises must be evident through observation alone. There are two types of principle premises which form the bedrock for scientific knowledge: postulates and axioms.</p>
<p>Postulates are basic assertions of the existence of entities which have been observed and cannot be expressed in terms of other entities. The entities described by postulates can have attributes attributed to them, though only through observation. Closely related to postulates are definitions. A definition is not strictly an affirmation of existence. Rather, it articulates what it means to be a certain object through comparison with other objects. A definition begins by placing the object to be defined, called a species, within a more general classification of object, called a genus. A meaningful definition of the species is then attained by articulating the key factor which differentiates the species from everything else within the genus. This factor is referred to as the <em>differentia</em>, or essence, of the species. As an example, the species of mankind is defined as a member of the genus animals, with its differentiating essence being the ability to reason abstractly. It is interesting to note that the chosen essence may not be found in every particular instance of the species. Aristotle claims, however, that the essence need only represent what is normally found to be true of a species. In this sense, a definition can be considered universal. Definitions ultimately group all observed entities into a tree- like structure which has usefulness in formulating an explanation. It is also important to note that species need not only have their essence associated with them as qualifiers. Aristotle conjectures that there are many categories, aside from substances, which can be attached to substances as abstract attributes. Such attributes may involve quantity, quality, location, or any other descriptor of the substance as a subject.</p>
<p>Axioms, according to Aristotle, are self-evident truths which are available to any rational thinker. Within the realm of theoretical knowledge, there are many different fields, each with their own fundamental principles. Such fields include psychology, mathematics, physics, biology, etc. While scientific knowledge in one field cannot usually be described in terms of another fields principles, a sense of consistency must still be maintained between all the fields for them to be considered knowledge. This consistency is examined and maintained through the field of metaphysics, which utilizes the axioms as tools to search for contradictions and validate relationships. A rational thinker uses the axioms to pinpoint relationships between particulars and generate abstract knowledge. In modern language, axioms can be referred to as logical principles. An example of an axiom would be that if A is equal to B, and B is equal to C, then A is equal to C.</p>
<p>With postulates, definitions, categories, and axioms established, the framework of demonstration can be built. This is done through a process that Aristotle refers to as the order of knowing. The order of knowing begins with a particular, observed phenomenon. The next step is to express the phenomenon as an attribute of a substance which belongs to a species. This species is then connected to its more general genus through a middle term, or common attribute that is relevant to explaining the phenomenon. The process continues, connecting species to more general ones using middle terms. The order of knowing finally ends when one arrives at a species which has no genus: a postulate, or principle. Once the principle has been identified, then the phenomenon has been satisfactorily explained through a valid chain of causality leading all the way back to a principle which is known to be true (and unchanging) through observation. If every premise along the syllogistic chain of explanation is to be trusted, then the explanation is sound. In stark contrast to what Plato teaches about the doctrine of recollection, Aristotle formulates a conception of knowledge which begins and ends with observation. Aristotle asserts that there are four kinds of causes of a phenomenon which can be demonstrated. The four kinds of causes are the material cause, the formal cause, the efficient cause, and the teleological cause. The material cause provides an explanation based on the attributes of the constituent materials. The formal cause derives its explanation from having new properties arise out of a constitutive structure or arrangement. The efficient cause refers to an external agent which has acted to cause what was observed. The teleological cause appeals to an ultimate sense of purpose, or end-directed course, to explain characteristics and behavior. These four causes can ultimately be used as a criterion for how thoroughly a phenomenon has been explained. Thus far, I’ve described Aristotle’s method of doing science in terms of first principles. One of the main strengths of Aristotelian science, I believe, is the primacy that it gives to what is observed. If a scientific theory, after it has been derived from first principles, is ever contradicted by a subsequent observation, then it is the theory that must be thrown out. I agree with Aristotle that of all the possible bases for ontological affirmation, observation is the one in which we can put the most trust. Similarly, our attributions of abstract characteristics to a substance are more likely to be fallible than the existence of the substance itself. Due to this pattern of prioritization, it is reasonable to assume that Aristotelian science is still capable of incremental progress as increasingly exotic observations are made. However, there are other aspects of the science which, I believe, hinder and even limit such progress. I will now proceed to highlight those aspects.</p>
<p>Aristotle extols impartial observation as the basis for all scientific knowledge. Despite this, he seems to allow his observations of order in the universe to lead him to project unnecessary constraints on the attributes of substances. One good example of this is his assertion that objects have natural and unnatural states, and that knowledge of an object can only be gained if it is found in a natural state. Such a perspective rules out any form of controlled experimentation, which is a necessary tool for overcoming limitations in our own ability to observe and isolate possible causes. Another example of unnecessary constraint is found in the process of creating definitions and categories. These, as Aristotle formulates them, are dependent on the linguistic subject-predicate structure, and cannot express any other kind of relationship. Moreover, definitions and categories for a species must be based on an attribute which is not necessarily universally applicable to all instances of the species. Basing a definition of a species on a norm is useful for everyday classifications of objects. Its relative imprecision, however, glosses over details and possible sources of insight when an abnormal observation is made, hindering the development of impartial knowledge. When attaining knowledge from scratch, it is important to place as few constraints on the universe as we can, though we will probably never be able to be perfect in this. Though we observe a certain order to the universe, we have no good reason to be certain that phenomena, or what is, should necessarily conform to any of our notions of what ought to be, based on our sense of concision and coherence.</p>
<p>Another case of the problem of imposed constraints is found in Aristotle’s insistence that phenomena can be explained in terms of their end-driven purpose, or teleological cause. Aristotle is well-known as claiming that the universe is full of purpose, even if it doesn’t happen to have a grand architect or creator. This premise for knowledge is problematic because it automatically forces models of the universe to presuppose the existence of purpose. Purpose is not observable, but rather a product of conjecture. Nor is it self-evident. It could be argued that teleological explanations exist today in the study of evolutionary biology, with the ultimate end-driven behavior being that of survival for living organisms. However, even this paradigm is based in conjecture, and its use as a fundamental tenet of knowledge is certainly not warranted, in my view. While Aristotelian science has the ability to incrementally improve its knowledge base given new observations, I believe that the knowledge which it seeks is fatally constrained by anthropocentric notions of inclination, homogeneity, and purpose. It can go far in refining its premises, categories, and definitions. However, it has too many blind spots to be considered a reliable epistemological paradigm today.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="logical-fallacies-as-failures-of-probabilistic-reasoning"><a class="header" href="#logical-fallacies-as-failures-of-probabilistic-reasoning">Logical Fallacies as Failures of Probabilistic Reasoning</a></h1>
<p><em>Every classical logical fallacy can be understood as a specific failure to construct a Bayesian network that faithfully represents reality.</em></p>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>In the <a href="#bayesian-inference">Bayesian Inference</a> article, we saw that a Bayes net is a directed acyclic graph (DAG) whose nodes are random variables and whose edges encode conditional dependencies. The entire graph specifies a joint probability distribution over all of its variables, and answering questions about the world reduces to <em>querying</em> this distribution given observations. When the graph is well-constructed—meaning its structure, variable domains, and conditional distributions accurately reflect reality—the inferences drawn from it are sound. When any of these three components are wrong, the inferences break down in predictable ways.</p>
<p>This article argues that the classical logical fallacies catalogued by philosophers since Aristotle are not merely rhetorical tricks or lapses in attention. Each one corresponds to a <em>specific, identifiable failure mode</em> in the construction or querying of a probabilistic model. A fallacious argument is, at its core, an inference drawn from a malformed Bayes net—one whose graph has the wrong shape, whose variables have the wrong domains, or whose conditional distributions are miscalibrated.</p>
<p>The failure modes fall into five natural categories:</p>
<ol>
<li><strong>Structural failures</strong> — the graph topology is wrong (missing nodes, extra edges, or cycles).</li>
<li><strong>Directional failures</strong> — the direction of inference along an edge is reversed without proper application of Bayes’ rule.</li>
<li><strong>Domain failures</strong> — the random variables represent the wrong quantities or have artificially restricted sample spaces.</li>
<li><strong>Parametric failures</strong> — the conditional probability distributions or priors are miscalibrated.</li>
<li><strong>Chain failures</strong> — errors compound along sequential inference chains.</li>
</ol>
<h2 id="quick-review-what-a-bayes-net-encodes"><a class="header" href="#quick-review-what-a-bayes-net-encodes">Quick Review: What a Bayes Net Encodes</a></h2>
<p>Recall that a Bayes net over variables \(X_1, \dots, X_n\) encodes their joint distribution by exploiting conditional independence:</p>
<p>$$P(X_1, \dots, X_n) = \prod_{i=1}^{n} P(X_i \mid \text{Parents}(X_i)).$$</p>
<p>Consider the following simple net:</p>
<div style="text-align:center; margin: 1.5em 0;">
<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 200 160" width="200">
  <defs>
    <marker id="f0-arr" markerwidth="8" markerheight="6" refx="8" refy="3" orient="auto">
      <path d="M0,0 L8,3 L0,6 Z" fill="#444" />
    </marker>
  </defs>
  <line x1="62" y1="53" x2="88" y2="101" stroke="#444" stroke-width="2" marker-end="url(#f0-arr)" />
  <line x1="138" y1="53" x2="112" y2="101" stroke="#444" stroke-width="2" marker-end="url(#f0-arr)" />
  <circle cx="50" cy="40" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="50" y="41" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">A</text>
  <circle cx="150" cy="40" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="150" y="41" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">B</text>
  <circle cx="100" cy="115" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="100" y="116" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">C</text>
</svg>
</div>

<p>This net asserts that \(A\) and \(B\) are independent root nodes and that \(C\) depends on both, giving a joint of \(P(A,B,C) = P(C|A,B) P(A) P(B)\). Three things must be correct for inferences from this model to be sound:</p>
<ol>
<li><strong>Structure:</strong> The edges must reflect genuine causal or generative relationships, and no relevant variables may be missing.</li>
<li><strong>Domains:</strong> Each variable’s sample space must include all values it can actually take.</li>
<li><strong>Distributions:</strong> The prior \(P(A)\), \(P(B)\), and the conditional \(P(C|A,B)\) must be calibrated to reality.</li>
</ol>
<p>A logical fallacy arises when a reasoner implicitly constructs a mental model that violates one or more of these requirements.</p>
<hr>
<h2 id="i-structural-fallacies-building-the-wrong-graph"><a class="header" href="#i-structural-fallacies-building-the-wrong-graph">I. Structural Fallacies: Building the Wrong Graph</a></h2>
<p>These fallacies arise when the topology of the reasoner’s implicit Bayes net does not match the causal structure of reality—edges are added where none exist, genuine causes are omitted, or the acyclicity constraint is violated.</p>
<h3 id="begging-the-question--cycles-in-the-graph"><a class="header" href="#begging-the-question--cycles-in-the-graph">Begging the Question — Cycles in the Graph</a></h3>
<p><strong>The fallacy in classical form:</strong> Using the conclusion of an argument as one of its premises. <em>“God exists because the Bible says so, and the Bible is true because it is the word of God.”</em></p>
<p><strong>Bayesian diagnosis:</strong> The reasoner has constructed a graph with a <em>cycle</em>. Node \(P\) generates evidence for \(Q\), which generates evidence for \(R\), which in turn supports \(P\). But a Bayes net must be a DAG—directed <em>acyclic</em> graph. Cycles make the joint distribution undefined because the chain rule cannot terminate: you can never reach an unconditional prior from which to begin calculating.</p>
<div style="text-align:center; margin: 1.5em 0;">
<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 470 175" width="470">
  <defs>
    <marker id="f1-arrr" markerwidth="8" markerheight="6" refx="8" refy="3" orient="auto">
      <path d="M0,0 L8,3 L0,6 Z" fill="#c0392b" />
    </marker>
    <marker id="f1-arrb" markerwidth="8" markerheight="6" refx="8" refy="3" orient="auto">
      <path d="M0,0 L8,3 L0,6 Z" fill="#2471a3" />
    </marker>
  </defs>
  <!-- Left: Cycle (invalid) -->
  <line x1="93" y1="53" x2="137" y2="112" stroke="#c0392b" stroke-width="2" marker-end="url(#f1-arrr)" />
  <line x1="126" y1="130" x2="34" y2="130" stroke="#c0392b" stroke-width="2" marker-end="url(#f1-arrr)" />
  <line x1="23" y1="112" x2="67" y2="53" stroke="#c0392b" stroke-width="2" marker-end="url(#f1-arrr)" />
  <circle cx="80" cy="35" r="22" fill="#fff" stroke="#c0392b" stroke-width="2.5" />
  <text x="80" y="36" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">P</text>
  <circle cx="150" cy="130" r="22" fill="#fff" stroke="#c0392b" stroke-width="2.5" />
  <text x="150" y="131" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">Q</text>
  <circle cx="10" cy="130" r="22" fill="#fff" stroke="#c0392b" stroke-width="2.5" />
  <text x="10" y="131" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">R</text>
  <text x="80" y="168" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#c0392b">Cycle (invalid)</text>
  <!-- Right: DAG (valid) -->
  <line x1="333" y1="53" x2="377" y2="112" stroke="#2471a3" stroke-width="2" marker-end="url(#f1-arrb)" />
  <line x1="307" y1="53" x2="263" y2="112" stroke="#2471a3" stroke-width="2" marker-end="url(#f1-arrb)" />
  <circle cx="320" cy="35" r="22" fill="#fff" stroke="#2471a3" stroke-width="2.5" />
  <text x="320" y="36" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">P</text>
  <circle cx="390" cy="130" r="22" fill="#fff" stroke="#2471a3" stroke-width="2.5" />
  <text x="390" y="131" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">Q</text>
  <circle cx="250" cy="130" r="22" fill="#fff" stroke="#2471a3" stroke-width="2.5" />
  <text x="250" y="131" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">R</text>
  <text x="320" y="168" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2471a3">DAG (valid)</text>
  <!-- Divider -->
  <line x1="200" y1="10" x2="200" y2="165" stroke="#ccc" stroke-width="1" stroke-dasharray="4,3" />
</svg>
</div>

<p>Formally, the chain rule for the cyclic graph would require</p>
<p>$$P(P) = \cdots = f(P(R)) = f(g(P(Q))) = f(g(h(P(P))))$$</p>
<p>which is a fixed-point equation, not a generative model. There is no unconditional distribution from which to begin inference. The argument provides no new information—it is self-referential.</p>
<p><strong>The fix:</strong> Every sound argument must ultimately trace back to premises whose truth is established independently of the conclusion. In Bayes net terms, the graph must be acyclic, terminating at root nodes (priors) whose distributions are specified without reference to their descendants.</p>
<h3 id="post-hoc-ergo-propter-hoc--the-missing-confounder"><a class="header" href="#post-hoc-ergo-propter-hoc--the-missing-confounder">Post Hoc Ergo Propter Hoc — The Missing Confounder</a></h3>
<p><strong>The fallacy in classical form:</strong> Assuming that because event \(A\) preceded event \(B\), \(A\) must have caused \(B\). <em>“I wore my lucky socks and we won the game; therefore the socks caused the victory.”</em></p>
<p><strong>Bayesian diagnosis:</strong> The reasoner’s model has a direct edge \(A \to B\) where none should exist. The true causal structure involves a hidden common cause \(C\) (a <em>confounder</em>) that independently generates both \(A\) and \(B\). Marginalizing out \(C\) produces a statistical correlation between \(A\) and \(B\), which the reasoner mistakes for a direct causal link.</p>
<div style="text-align:center; margin: 1.5em 0;">
<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 440 195" width="440">
  <defs>
    <marker id="f2-arrr" markerwidth="8" markerheight="6" refx="8" refy="3" orient="auto">
      <path d="M0,0 L8,3 L0,6 Z" fill="#c0392b" />
    </marker>
    <marker id="f2-arrb" markerwidth="8" markerheight="6" refx="8" refy="3" orient="auto">
      <path d="M0,0 L8,3 L0,6 Z" fill="#2471a3" />
    </marker>
  </defs>
  <!-- Left: Assumed direct cause -->
  <line x1="84" y1="95" x2="136" y2="95" stroke="#c0392b" stroke-width="2" marker-end="url(#f2-arrr)" />
  <circle cx="60" cy="95" r="22" fill="#fff" stroke="#c0392b" stroke-width="2.5" />
  <text x="60" y="96" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">A</text>
  <circle cx="160" cy="95" r="22" fill="#fff" stroke="#c0392b" stroke-width="2.5" />
  <text x="160" y="96" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">B</text>
  <text x="110" y="30" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#c0392b">Assumed Model</text>
  <!-- Divider -->
  <line x1="220" y1="10" x2="220" y2="180" stroke="#ccc" stroke-width="1" stroke-dasharray="4,3" />
  <!-- Right: True causal structure with confounder -->
  <line x1="321" y1="56" x2="283" y2="124" stroke="#2471a3" stroke-width="2" marker-end="url(#f2-arrb)" />
  <line x1="339" y1="56" x2="377" y2="124" stroke="#2471a3" stroke-width="2" marker-end="url(#f2-arrb)" />
  <circle cx="330" cy="38" r="22" fill="#fff" stroke="#2471a3" stroke-width="2.5" />
  <text x="330" y="39" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">C</text>
  <circle cx="270" cy="142" r="22" fill="#fff" stroke="#2471a3" stroke-width="2.5" />
  <text x="270" y="143" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">A</text>
  <circle cx="390" cy="142" r="22" fill="#fff" stroke="#2471a3" stroke-width="2.5" />
  <text x="390" y="143" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">B</text>
  <line x1="294" y1="142" x2="366" y2="142" stroke="#999" stroke-width="1.5" stroke-dasharray="5,4" />
  <text x="330" y="158" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#999">observed correlation</text>
  <text x="330" y="17" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2471a3">True Model</text>
</svg>
</div>

<p>In the assumed model, the reasoner computes \(P(B|A)\) using a direct conditional \(P(B|A)\). In the true model, \(A\) and \(B\) are <em>conditionally independent</em> given the confounder \(C\):</p>
<p>$$P(A,B|C) = P(A|C) P(B|C).$$</p>
<p>Their marginal correlation \(P(A,B) = \sum_C P(A|C) P(B|C) P(C) \neq P(A) P(B)\) is real but not causal. The correlation vanishes once \(C\) is observed. This is why controlled experiments—which hold \(C\) fixed—are essential for establishing causation.</p>
<h3 id="survivorship-bias--conditioning-on-a-collider"><a class="header" href="#survivorship-bias--conditioning-on-a-collider">Survivorship Bias — Conditioning on a Collider</a></h3>
<p><strong>The fallacy in classical form:</strong> Drawing conclusions from a non-representative sample that has been filtered by some selection process. <em>“Exposed buildings in this city are all well-built, so construction quality must be high.”</em> (Ignoring that poorly-built buildings collapsed and were removed from the sample.)</p>
<p><strong>Bayesian diagnosis:</strong> Two independent causes \(A\) and \(B\) both influence a common effect \(S\) (a <em>collider</em>). When we condition on \(S\)—by observing only cases where \(S\) takes a particular value—we inadvertently create a spurious statistical dependency between \(A\) and \(B\), even though they are marginally independent.</p>
<div style="text-align:center; margin: 1.5em 0;">
<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 190" width="300">
  <defs>
    <marker id="f3-arr" markerwidth="8" markerheight="6" refx="8" refy="3" orient="auto">
      <path d="M0,0 L8,3 L0,6 Z" fill="#444" />
    </marker>
  </defs>
  <line x1="66" y1="55" x2="134" y2="113" stroke="#444" stroke-width="2" marker-end="url(#f3-arr)" />
  <line x1="234" y1="55" x2="166" y2="113" stroke="#444" stroke-width="2" marker-end="url(#f3-arr)" />
  <line x1="74" y1="40" x2="226" y2="40" stroke="#c0392b" stroke-width="1.5" stroke-dasharray="5,4" />
  <text x="150" y="28" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#c0392b">spurious dependency</text>
  <circle cx="50" cy="40" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="50" y="41" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">A</text>
  <circle cx="250" cy="40" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="250" y="41" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">B</text>
  <circle cx="150" cy="130" r="22" fill="#e8e8e8" stroke="#444" stroke-width="2.5" />
  <text x="150" y="131" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">S</text>
  <text x="150" y="165" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#666">(observed / selected)</text>
</svg>
</div>

<p>This is known in statistics as <em>Berkson’s paradox</em>. Formally, \(A \perp B\) marginally, but \(A \not\perp B \mid S\). The joint factors as:</p>
<p>$$P(A,B,S) = P(S|A,B) P(A) P(B)$$</p>
<p>and conditioning on \(S\) yields \(P(A,B|S) = \eta  P(S|A,B) P(A) P(B)\), which generally does <em>not</em> factor into \(P(A|S) P(B|S)\). Knowing that \(S\) occurred and that \(A\) did not contribute makes \(B\) more likely as an explanation—hence the spurious correlation.</p>
<p><strong>Example:</strong> Among admitted university students (\(S\) = admitted), academic talent (\(A\)) and athletic talent (\(B\)) may appear negatively correlated—not because they are, but because admissions selected for at least one.</p>
<hr>
<h2 id="ii-directional-fallacies-reversing-the-arrows"><a class="header" href="#ii-directional-fallacies-reversing-the-arrows">II. Directional Fallacies: Reversing the Arrows</a></h2>
<p>These fallacies arise from confusing the direction of conditional probability—treating \(P(B|A)\) as though it were \(P(A|B)\)—without the corrective machinery of Bayes’ rule.</p>
<h3 id="affirming-the-consequent--inverting-a-conditional"><a class="header" href="#affirming-the-consequent--inverting-a-conditional">Affirming the Consequent — Inverting a Conditional</a></h3>
<p><strong>The fallacy in classical form:</strong> <em>“If it rains, the ground is wet. The ground is wet. Therefore, it rained.”</em> The argument treats \(P(\text{Rain}|\text{Wet})\) as equivalent to \(P(\text{Wet}|\text{Rain})\).</p>
<p><strong>Bayesian diagnosis:</strong> The reasoner’s model has an edge \(A \to B\) with a well-defined forward conditional \(P(B|A)\). They observe \(B\) and want to infer \(A\), but they skip Bayes’ rule and treat the forward conditional as the backward one:</p>
<div style="text-align:center; margin: 1.5em 0;">
<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 155" width="300">
  <defs>
    <marker id="f4-arr" markerwidth="8" markerheight="6" refx="8" refy="3" orient="auto">
      <path d="M0,0 L8,3 L0,6 Z" fill="#2471a3" />
    </marker>
    <marker id="f4-arrr" markerwidth="8" markerheight="6" refx="8" refy="3" orient="auto">
      <path d="M0,0 L8,3 L0,6 Z" fill="#c0392b" />
    </marker>
  </defs>
  <!-- Forward edge -->
  <line x1="99" y1="55" x2="201" y2="55" stroke="#2471a3" stroke-width="2.5" marker-end="url(#f4-arr)" />
  <text x="150" y="43" text-anchor="middle" font-family="Georgia, serif" font-style="italic" font-size="13" fill="#2471a3">P(B | A)</text>
  <!-- Reverse (fallacious) curve -->
  <path d="M201,70 C201,125 99,125 99,70" stroke="#c0392b" stroke-width="2" fill="none" stroke-dasharray="6,3" marker-end="url(#f4-arrr)" />
  <text x="150" y="115" text-anchor="middle" font-family="Georgia, serif" font-style="italic" font-size="13" fill="#c0392b">P(A | B) ≠ P(B | A)</text>
  <!-- Nodes -->
  <circle cx="75" cy="55" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="75" y="56" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">A</text>
  <circle cx="225" cy="55" r="22" fill="#e8e8e8" stroke="#444" stroke-width="2.5" />
  <text x="225" y="56" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">B</text>
  <text x="225" y="142" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#666">(B observed)</text>
</svg>
</div>

<p>Bayes’ rule provides the correct inversion:</p>
<p>$$P(A|B) = \frac{P(B|A) P(A)}{P(B)} = \frac{P(B|A) P(A)}{\sum_{a} P(B|A=a) P(A=a)}.$$</p>
<p>The key insight is that \(P(A|B)\) depends critically on the <em>prior</em> \(P(A)\) and on all other possible causes of \(B\) (captured in the denominator). The fallacy of affirming the consequent amounts to setting \(P(A) = 1\) and ignoring alternative explanations, which is equivalent to asserting that \(A\) is the <em>only</em> possible cause of \(B\).</p>
<h3 id="denying-the-antecedent--neglecting-alternative-parents"><a class="header" href="#denying-the-antecedent--neglecting-alternative-parents">Denying the Antecedent — Neglecting Alternative Parents</a></h3>
<p><strong>The fallacy in classical form:</strong> <em>“If it rains, the ground is wet. It didn’t rain. Therefore, the ground is not wet.”</em> This ignores that a sprinkler, a burst pipe, or a spill could also wet the ground.</p>
<p><strong>Bayesian diagnosis:</strong> The reasoner’s model has only a single parent \(A\) for child node \(C\), when in reality \(C\) has multiple parents \(A, B, \dots\) In the true model:</p>
<p>$$P(C | A, B) \neq P(C | A).$$</p>
<p>Even when \(A\) is observed to be false (\(A = 0\)), the child \(C\) can still be true if another parent \(B\) is active:</p>
<p>$$P(C=1 | A=0) = \sum_b P(C=1|A=0, B=b) P(B=b).$$</p>
<p>This is generally nonzero. The fallacy is a structural error: the reasoner’s graph is <em>missing parent nodes</em>. By leaving out \(B\), the model artificially couples \(C\)’s fate entirely to \(A\), making \(\neg A \Rightarrow \neg C\) seem valid when it is not.</p>
<hr>
<h2 id="iii-domain-fallacies-misspecifying-the-variables"><a class="header" href="#iii-domain-fallacies-misspecifying-the-variables">III. Domain Fallacies: Misspecifying the Variables</a></h2>
<p>These fallacies arise not from wrong edges or wrong distributions, but from defining the random variables themselves incorrectly—truncating their domains, substituting one variable for another, or conflating two distinct quantities under one name.</p>
<h3 id="the-false-dilemma--truncating-the-sample-space"><a class="header" href="#the-false-dilemma--truncating-the-sample-space">The False Dilemma — Truncating the Sample Space</a></h3>
<p><strong>The fallacy in classical form:</strong> Presenting only two options when more exist. <em>“You’re either with us or against us.”</em></p>
<p><strong>Bayesian diagnosis:</strong> A random variable \(X\) in the reasoner’s model has been assigned the domain \(\{a, b\}\) when its true domain is \(\{a, b, c, d, \dots\}\). Since probabilities must sum to one over the domain, the artificial restriction forces</p>
<p>$$P(X = a) + P(X = b) = 1$$</p>
<p>which inflates the probabilities of \(a\) and \(b\) at the expense of the missing alternatives.</p>
<div style="text-align:center; margin: 1.5em 0;">
<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 380 140" width="380">
  <!-- Left: truncated domain -->
  <circle cx="80" cy="55" r="28" fill="#fff" stroke="#c0392b" stroke-width="2.5" />
  <text x="80" y="52" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="20" fill="#333">X</text>
  <text x="80" y="100" text-anchor="middle" font-family="Georgia, serif" font-size="14" fill="#c0392b">{A, B}</text>
  <text x="80" y="130" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#c0392b">Truncated Domain</text>
  <!-- Divider -->
  <line x1="190" y1="10" x2="190" y2="130" stroke="#ccc" stroke-width="1" stroke-dasharray="4,3" />
  <!-- Right: full domain -->
  <circle cx="300" cy="55" r="28" fill="#fff" stroke="#2471a3" stroke-width="2.5" />
  <text x="300" y="52" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="20" fill="#333">X</text>
  <text x="300" y="100" text-anchor="middle" font-family="Georgia, serif" font-size="14" fill="#2471a3">{A, B, C, D, ...}</text>
  <text x="300" y="130" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2471a3">Full Domain</text>
</svg>
</div>

<p>In practice, the false dilemma distorts every conditional in which \(X\) participates. If a downstream node \(Y\) depends on \(X\), then \(P(Y) = \sum_x P(Y|X=x) P(X=x)\) is computed over the wrong support, yielding incorrect marginals for \(Y\) as well. The error propagates through the entire graph.</p>
<h3 id="the-straw-man--substituting-the-query-variable"><a class="header" href="#the-straw-man--substituting-the-query-variable">The Straw Man — Substituting the Query Variable</a></h3>
<p><strong>The fallacy in classical form:</strong> Refuting a distorted version of an opponent’s argument rather than the actual argument. <em>“My opponent wants to improve public transit”</em> becomes <em>“My opponent wants to ban cars.”</em></p>
<p><strong>Bayesian diagnosis:</strong> The reasoner wishes to evaluate \(P(Q)\) for some query variable \(Q\), but instead evaluates \(P(\tilde{Q})\) for a <em>different</em> variable \(\tilde{Q}\) that is easier to attack. Even if \(\tilde{Q}\) is correlated with \(Q\), they are not the same random variable:</p>
<p>$$P(\tilde{Q}=\text{false}) \not\Rightarrow P(Q=\text{false}).$$</p>
<p>This is akin to answering the wrong query on a Bayes net. The computational machinery may be perfectly correct, but it is applied to the wrong node. The resulting inference is valid for \(\tilde{Q}\) and irrelevant for \(Q\).</p>
<h3 id="equivocation--conflating-distinct-variables"><a class="header" href="#equivocation--conflating-distinct-variables">Equivocation — Conflating Distinct Variables</a></h3>
<p><strong>The fallacy in classical form:</strong> Using the same word to refer to different concepts within a single argument. <em>“A feather is light. What is light cannot be dark. Therefore, a feather cannot be dark.”</em></p>
<p><strong>Bayesian diagnosis:</strong> The reasoner has created a single node in their Bayes net where two nodes should exist. If “light” in the sense of weight is variable \(L_w\) and “light” in the sense of brightness is variable \(L_b\), then the correct model has:</p>
<p>$$P(L_w) \perp P(L_b)$$</p>
<p>(assuming they are independent). The equivocator collapses these into one node \(L\), illicitly transferring the evidence or conditional distribution associated with \(L_w\) to \(L_b\). The resulting graph has fewer nodes than reality, and the joint distribution it encodes is wrong.</p>
<hr>
<h2 id="iv-parametric-fallacies-miscalibrating-the-distributions"><a class="header" href="#iv-parametric-fallacies-miscalibrating-the-distributions">IV. Parametric Fallacies: Miscalibrating the Distributions</a></h2>
<p>Even when the graph topology and variable domains are correct, inference fails if the prior distributions or the conditional probability tables are wrong. These fallacies correspond to specific miscalibrations.</p>
<h3 id="base-rate-neglect--dropping-the-prior"><a class="header" href="#base-rate-neglect--dropping-the-prior">Base Rate Neglect — Dropping the Prior</a></h3>
<p><strong>The fallacy in classical form:</strong> Ignoring the prevalence of a condition when interpreting the significance of a positive test. <em>“The test is 99% accurate and I tested positive, so I almost certainly have the disease.”</em></p>
<p><strong>Bayesian diagnosis:</strong> This is the most famous Bayesian fallacy. The reasoner correctly understands the likelihood \(P(\text{Test}^+|\text{Disease})\) but ignores the prior \(P(\text{Disease})\).</p>
<div style="text-align:center; margin: 1.5em 0;">
<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 340 210" width="340">
  <defs>
    <marker id="f6-arr" markerwidth="8" markerheight="6" refx="8" refy="3" orient="auto">
      <path d="M0,0 L8,3 L0,6 Z" fill="#444" />
    </marker>
  </defs>
  <!-- Edge -->
  <line x1="170" y1="62" x2="170" y2="118" stroke="#444" stroke-width="2" marker-end="url(#f6-arr)" />
  <!-- Disease node -->
  <circle cx="170" cy="40" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="170" y="41" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">D</text>
  <!-- Test node -->
  <circle cx="170" cy="140" r="22" fill="#e8e8e8" stroke="#444" stroke-width="2.5" />
  <text x="170" y="141" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">T</text>
  <!-- Annotations -->
  <text x="65" y="44" text-anchor="end" font-family="Georgia, serif" font-size="13" fill="#c0392b">P(D) = 0.001</text>
  <text x="56" y="60" text-anchor="end" font-family="Arial, sans-serif" font-size="10" fill="#c0392b">(often ignored!)</text>
  <text x="255" y="95" text-anchor="start" font-family="Georgia, serif" font-size="13" fill="#2471a3">P(T⁺|D) = 0.99</text>
  <text x="255" y="111" text-anchor="start" font-family="Georgia, serif" font-size="13" fill="#2471a3">P(T⁺|¬D) = 0.05</text>
  <!-- Query -->
  <text x="170" y="185" text-anchor="middle" font-family="Georgia, serif" font-size="14" fill="#333">P(D | T⁺) = ?</text>
  <text x="170" y="204" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#666">(observed: T⁺)</text>
</svg>
</div>

<p>Bayes’ rule gives:</p>
<p>$$P(D|T^+) = \frac{P(T^+|D) P(D)}{P(T^+|D) P(D) + P(T^+|\neg D) P(\neg D)} = \frac{0.99 \times 0.001}{0.99 \times 0.001 + 0.05 \times 0.999} \approx 0.019.$$</p>
<p>Despite the 99% sensitivity, the posterior probability of disease given a positive test is only about 2%—because the disease is rare (\(P(D) = 0.001\)). The base-rate-neglecting reasoner, effectively substituting \(P(D|T^+) \approx P(T^+|D) = 0.99\), is off by a factor of fifty. This is precisely the error of ignoring the prior in the Bayesian update.</p>
<h3 id="the-gamblers-fallacy--fabricating-dependencies"><a class="header" href="#the-gamblers-fallacy--fabricating-dependencies">The Gambler’s Fallacy — Fabricating Dependencies</a></h3>
<p><strong>The fallacy in classical form:</strong> Believing that past outcomes of independent events influence future outcomes. <em>“The coin has landed heads five times in a row, so tails is due.”</em></p>
<p><strong>Bayesian diagnosis:</strong> The outcomes \(X_1, X_2, \dots, X_n\) of independent trials are, by definition, root nodes with no edges between them. The correct joint is simply</p>
<p>$$P(X_1, \dots, X_n) = \prod_i P(X_i).$$</p>
<p>The gambler’s implicit model adds spurious edges, typically \(X_{i} \to X_{i+1}\), creating a Markov chain where none exists:</p>
<div style="text-align:center; margin: 1.5em 0;">
<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 420 165" width="420">
  <defs>
    <marker id="f7-arrr" markerwidth="8" markerheight="6" refx="8" refy="3" orient="auto">
      <path d="M0,0 L8,3 L0,6 Z" fill="#c0392b" />
    </marker>
  </defs>
  <!-- Top row: Reality (independent) -->
  <text x="10" y="40" text-anchor="start" font-family="Arial, sans-serif" font-size="11" fill="#2471a3">Reality:</text>
  <circle cx="100" cy="35" r="20" fill="#fff" stroke="#2471a3" stroke-width="2.5" />
  <text x="100" y="36" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="14" fill="#333">X₁</text>
  <circle cx="180" cy="35" r="20" fill="#fff" stroke="#2471a3" stroke-width="2.5" />
  <text x="180" y="36" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="14" fill="#333">X₂</text>
  <circle cx="260" cy="35" r="20" fill="#fff" stroke="#2471a3" stroke-width="2.5" />
  <text x="260" y="36" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="14" fill="#333">X₃</text>
  <circle cx="340" cy="35" r="20" fill="#fff" stroke="#2471a3" stroke-width="2.5" />
  <text x="340" y="36" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="14" fill="#333">X₄</text>
  <!-- Bottom row: Fallacy (dependent chain) -->
  <text x="10" y="130" text-anchor="start" font-family="Arial, sans-serif" font-size="11" fill="#c0392b">Fallacy:</text>
  <line x1="122" y1="125" x2="158" y2="125" stroke="#c0392b" stroke-width="2" marker-end="url(#f7-arrr)" />
  <line x1="202" y1="125" x2="238" y2="125" stroke="#c0392b" stroke-width="2" marker-end="url(#f7-arrr)" />
  <line x1="282" y1="125" x2="318" y2="125" stroke="#c0392b" stroke-width="2" marker-end="url(#f7-arrr)" />
  <circle cx="100" cy="125" r="20" fill="#fff" stroke="#c0392b" stroke-width="2.5" />
  <text x="100" y="126" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="14" fill="#333">X₁</text>
  <circle cx="180" cy="125" r="20" fill="#fff" stroke="#c0392b" stroke-width="2.5" />
  <text x="180" y="126" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="14" fill="#333">X₂</text>
  <circle cx="260" cy="125" r="20" fill="#fff" stroke="#c0392b" stroke-width="2.5" />
  <text x="260" y="126" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="14" fill="#333">X₃</text>
  <circle cx="340" cy="125" r="20" fill="#fff" stroke="#c0392b" stroke-width="2.5" />
  <text x="340" y="126" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="14" fill="#333">X₄</text>
</svg>
</div>

<p>In the gambler’s model, \(P(X_{i+1}|X_i = \text{heads})\) is biased toward tails (to “balance out”), so the joint becomes \(\prod_i P(X_i|X_{i-1})\) with a compensatory conditional. This model is simply wrong—it adds edges to the Bayes net that do not exist in reality.</p>
<p>It is worth noting that the <em>inverse</em> error also occurs: treating genuinely dependent events as independent (ignoring edges that do exist). This is the fallacy of <strong>neglecting serial correlation</strong>, common in financial modeling.</p>
<h3 id="the-conjunction-fallacy--inflating-joint-probabilities"><a class="header" href="#the-conjunction-fallacy--inflating-joint-probabilities">The Conjunction Fallacy — Inflating Joint Probabilities</a></h3>
<p><strong>The fallacy in classical form:</strong> Judging that the conjunction of two events is more likely than one of the events alone. The classic example due to Tversky and Kahneman: <em>“Linda is a bank teller AND a feminist activist”</em> is judged more likely than <em>“Linda is a bank teller.”</em></p>
<p><strong>Bayesian diagnosis:</strong> For any two events \(A\) and \(B\), the axioms of probability require</p>
<p>$$P(A \cap B) \leq P(A).$$</p>
<p>This is not a property of any particular Bayes net—it is an axiom of the probability calculus itself. The conjunction fallacy occurs when the reasoner’s internal probability assignments violate this axiom, typically because a vivid narrative (the conjunction) is more <em>representative</em> of the available evidence than the less specific single event.</p>
<p>In Bayes net terms, the reasoner has constructed a model where the joint distribution assigns \(P(A=1, B=1) &gt; P(A=1)\), which is impossible. The “distribution” in their mental model is not a valid probability distribution at all—it fails to normalize correctly. This is a parametric error at the most fundamental level.</p>
<h3 id="hasty-generalization--undersampled-evidence"><a class="header" href="#hasty-generalization--undersampled-evidence">Hasty Generalization — Undersampled Evidence</a></h3>
<p><strong>The fallacy in classical form:</strong> Drawing a broad conclusion from too few observations. <em>“I met two rude people from that city, so everyone there must be rude.”</em></p>
<p><strong>Bayesian diagnosis:</strong> Consider a static Bayes net (a naive Bayes classifier) where a hidden state \(X\) generates observations \(Y_1, Y_2, \dots, Y_n\). The posterior after \(n\) observations is</p>
<p>$$P(X|Y_1, \dots, Y_n) = \eta  P(X) \prod_{i=1}^{n} P(Y_i|X).$$</p>
<p>When \(n\) is small, the posterior is dominated by the prior and the few observations. With only \(n = 2\) observations, the likelihood ratio \(\prod P(Y_i|X=x)/P(Y_i|X=\bar{x})\) may strongly favor one hypothesis, but the <em>confidence</em> in this conclusion should be low—the posterior is broad, not sharply peaked.</p>
<p>The hasty generalizer treats a weakly updated posterior as if it were a delta function: they observe \(Y_1, Y_2\) and act as though \(X\) has been determined with certainty. The Bayesian corrective is simple: keep the full posterior distribution and recognize that sparse evidence yields a wide, uncertain belief.</p>
<hr>
<h2 id="v-chain-fallacies-compounding-errors-along-inference-paths"><a class="header" href="#v-chain-fallacies-compounding-errors-along-inference-paths">V. Chain Fallacies: Compounding Errors Along Inference Paths</a></h2>
<h3 id="the-slippery-slope--ignoring-accumulated-uncertainty"><a class="header" href="#the-slippery-slope--ignoring-accumulated-uncertainty">The Slippery Slope — Ignoring Accumulated Uncertainty</a></h3>
<p><strong>The fallacy in classical form:</strong> Arguing that a single step will inevitably lead, through a chain of consequences, to an extreme outcome. <em>“If we allow A, then B will follow, then C, then D, and eventually catastrophe E.”</em></p>
<p><strong>Bayesian diagnosis:</strong> The reasoner’s implicit model is a Markov chain \(A \to B \to C \to D \to E\), where each conditional \(P(X_{k+1}|X_k)\) has some probability \(p_k &lt; 1\) of the “bad” transition occurring. The probability of the final catastrophe is the <em>product</em> of these conditionals:</p>
<p>$$P(E|A) = \sum_{B,C,D} P(E|D) P(D|C) P(C|B) P(B|A).$$</p>
<div style="text-align:center; margin: 1.5em 0;">
<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 520 165" width="520">
  <defs>
    <marker id="f8-arr" markerwidth="8" markerheight="6" refx="8" refy="3" orient="auto">
      <path d="M0,0 L8,3 L0,6 Z" fill="#444" />
    </marker>
  </defs>
  <!-- Uncertainty ellipses (growing) -->
  <ellipse cx="60" cy="70" rx="28" ry="30" fill="none" stroke="#2471a3" stroke-width="1.5" stroke-dasharray="4,3" opacity="0.6" />
  <ellipse cx="170" cy="70" rx="33" ry="35" fill="none" stroke="#2471a3" stroke-width="1.5" stroke-dasharray="4,3" opacity="0.6" />
  <ellipse cx="280" cy="70" rx="40" ry="42" fill="none" stroke="#2471a3" stroke-width="1.5" stroke-dasharray="4,3" opacity="0.6" />
  <ellipse cx="390" cy="70" rx="48" ry="50" fill="none" stroke="#2471a3" stroke-width="1.5" stroke-dasharray="4,3" opacity="0.5" />
  <ellipse cx="500" cy="70" rx="57" ry="58" fill="none" stroke="#2471a3" stroke-width="1.5" stroke-dasharray="4,3" opacity="0.4" />
  <!-- Edges -->
  <line x1="84" y1="70" x2="147" y2="70" stroke="#444" stroke-width="2" marker-end="url(#f8-arr)" />
  <line x1="194" y1="70" x2="257" y2="70" stroke="#444" stroke-width="2" marker-end="url(#f8-arr)" />
  <line x1="304" y1="70" x2="367" y2="70" stroke="#444" stroke-width="2" marker-end="url(#f8-arr)" />
  <line x1="414" y1="70" x2="477" y2="70" stroke="#444" stroke-width="2" marker-end="url(#f8-arr)" />
  <!-- Nodes -->
  <circle cx="60" cy="70" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="60" y="71" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">A</text>
  <circle cx="170" cy="70" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="170" y="71" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">B</text>
  <circle cx="280" cy="70" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="280" y="71" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">C</text>
  <circle cx="390" cy="70" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="390" y="71" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">D</text>
  <circle cx="500" cy="70" r="22" fill="#fff" stroke="#444" stroke-width="2.5" />
  <text x="500" y="71" text-anchor="middle" dominant-baseline="central" font-family="Georgia, serif" font-style="italic" font-size="18" fill="#333">E</text>
  <!-- Label -->
  <text x="280" y="152" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2471a3">Uncertainty compounds at each step</text>
</svg>
</div>

<p>Even if each individual transition is moderately probable—say \(p_k = 0.7\)—the chain probability drops rapidly:</p>
<p>$$P(E|A) \leq 0.7^4 = 0.24.$$</p>
<p>The slippery slope fallacy treats each \(p_k\) as though it were 1.0 (certainty), collapsing the probabilistic chain into a deterministic one. In the language of HMMs from the <a href="#bayesian-inference">Bayesian Inference</a> article, this is equivalent to assuming zero process noise in every state transition—a modeling assumption that grows increasingly unrealistic with each additional link in the chain.</p>
<p>The dashed ellipses in the diagram represent the growing uncertainty envelope around the chain’s trajectory. By the time we reach \(E\), the distribution is so broad that the “catastrophic” outcome is only one of many—and likely not the most probable.</p>
<hr>
<h2 id="conclusion-thinking-in-graphs"><a class="header" href="#conclusion-thinking-in-graphs">Conclusion: Thinking in Graphs</a></h2>
<p>The unifying thesis of this article is simple: <strong>all reasoning is inference, and all inference has a model</strong>. When that model is implicit—as it always is in everyday human reasoning—its assumptions go unexamined, and errors creep in. The classical logical fallacies are not arbitrary categories of bad thinking. They are a remarkably systematic taxonomy of the ways a probabilistic model can be wrong:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Failure Mode</th><th>What’s Wrong</th><th>Example Fallacies</th></tr>
</thead>
<tbody>
<tr><td>Wrong graph structure</td><td>Missing nodes, extra edges, or cycles</td><td>Circular reasoning, Post hoc, Survivorship bias</td></tr>
<tr><td>Wrong edge direction</td><td>Confusing \(P(B|A)\) with \(P(A|B)\)</td><td>Affirming the consequent, Denying the antecedent</td></tr>
<tr><td>Wrong variable domains</td><td>Truncated sample spaces, substituted variables</td><td>False dilemma, Straw man, Equivocation</td></tr>
<tr><td>Wrong distributions</td><td>Ignored priors, fabricated dependencies</td><td>Base rate neglect, Gambler’s fallacy, Conjunction fallacy</td></tr>
<tr><td>Wrong chain inference</td><td>Treating uncertain chains as deterministic</td><td>Slippery slope</td></tr>
</tbody>
</table>
</div>
<p>The Bayesian framework does not merely <em>classify</em> these errors—it <em>quantifies</em> them. For each fallacy, there is a precise mathematical statement of what the reasoner assumed versus what is true, and Bayes’ rule provides the corrective. Learning to recognize these failure modes is, in effect, learning to build better mental models of the world: models with the right variables, the right structure, and honestly calibrated uncertainty.</p>
<p>As the <a href="#bayesian-inference">Bayesian Inference</a> article demonstrates in the engineering context, these same principles underpin the estimation algorithms that allow autonomous systems to navigate uncertain environments. The parallel is not a metaphor—human reasoning and robotic estimation are both instances of probabilistic inference over graphical models. The difference is that the robot’s model is explicit and auditable. The aspiration of clear thinking is to make our own models equally so.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="realism-vs-nominalism"><a class="header" href="#realism-vs-nominalism">Realism vs Nominalism</a></h1>
<p>I’ve been interested in epistemological questions, and the question of Realism (the notion that logical ideas possess a kind of “physical existence”) versus Nominalism (that logical ideas do not exist physically) gets down to several fundamental questions in both epistemology and ontology.</p>
<hr>
<p>There is a divide in philosophical discourse which has continued to persist for thousands of years. The ideological divide concerns a fundamental question about how the universe is rationally perceived: do immaterial objects of rational thought truly exist independently of the mind? How one answers this question determines whether one is a metaphysical realist or a nominalist; a realist would answer the question in the affirmative, and the nominalist in the negative. The fundamental ideas behind this difference in ontological reasoning are largely present in the ancient clash between Plato’s and Aristotle’s views of how knowledge of the universe is obtained. Both philosophers formulate their theories in terms of physical entities and their respective properties; everything must be explained in terms of these two things. Plato emphasizes the preeminence of properties, whereas Aristotle extols the concreteness of physical entities. Thus, one of the catalysts that leads to debate on the ontological status of immaterial entities is an examination of Aristotle’s work on categories. The question arises: are genera and species real, or do they consist solely in human imagination?</p>
<p>Part of what makes this question of existence so important is the inevitable entanglement between epistemology and ontology. In the end, one can only have a justified true belief about that which truly exists. This entanglement is encompassed by a definition that has been posited to describe what is ultimately real: that which constrains thought. During the Middle Ages, this discussion of realism versus nominalism explicitly surfaces, at first addressing questions concerning the omnipotence of God, then gradually moving to questions specifically concerning what can possibly be known.</p>
<p>Realism and nominalism are doctrines which can each be expressed as pertaining to different domains of knowledge. Before comparing the two, I aim to first distinguish the type of knowledge that I will focus on. Nominalism objects to realism on two independent grounds: the existence of universals and the existence of abstract thoughts. Universals are ideas which can be instantiated, either by a particular or by another universal. An example of a universal’s being instantiated by a particular would be having the universal of redness instantiated by a red apple. An abstract object, on the other hand, refers to any entity of the mind that isn’t found in the material world and doesn’t cause anything to happen of its own volition. Under these definitions, universals are not strictly a subset of abstract objects. However, a question one may ask is whether a universal somehow exists within each instantiating particular, or whether it exists independently of them. If the latter is argued, then it could be argued by extension that nominalism’s argument against universals is very similar to its argument against abstract objects. For this analysis, I will focus mainly on the domain of universals. One important thing to note is that there are universals which are used to differentiate physical entities merely because everyone has agreed that such distinctions should exist. For example, we humans have created the construct of the pet universal. Classifying an animal as a pet is largely a matter of individual opinion, and if everyone were to agree that keeping pets is wrong, then there would be no more distinguishing any particular animal as a pet. The real battleground in the ideological battle between realism and nominalism (and the domain I will focus on) does not consist in these kinds of agreed-upon universals, but rather in the universals involved in Aristotelian science. These are the universals used to define species, for they are supposed to capture the essence of a material entity, are not subjective, and are supposedly fundamental to providing a complete, empirical description of the universe.</p>
<p>The doctrine of realism, as it applies to universals, relates deeply to the notion that the universe is as it is independently of how humans or other inquiring agents perceive it to be. During the Middle Ages, realism manifests itself in various circles of thought pertaining to Gods omnipotence. According to Thomas Aquinas, God must necessarily have created not only an intelligible universe, but also intelligent beings capable of slowly comprehending the universe through intelligence, thereby approaching the perfection of God. John Wycliffe postulated a God similarly constrained by order in the universe. According to Wycliffe, God could not have created the universe in any other way, for everything in the universe perfectly reflects the universals associated with Gods nature and thoughts, as manifested by what is called the divine intellect. Thus, Gods omnipotence is bounded by the universals, for He cannot create anything outside of what’s encompassed by them, nor can he annihilate them.</p>
<p>Aside from explicitly theological subject matter, the claims of realism expand to more explicit ontological and epistemological questions. The claim of realism is that physical entities and properties are both equally existent. Because properties are real whether or not they’re instantiated, they take precedence over particulars in providing true knowledge. In essence, a particular possesses a property because it instantiates the universal which corresponds to that property. This means that categories, inasmuch as they capture the essence of material entities, are not arbitrary. Rather, they are discovered and exist outside and independently of the mind. For example, the universal of redness would exist even if there were no eyes to behold and recognize it. Proponents of realism thus believe that, given enough time, human reason can come to know the true classifications of things in the universe through iterative searching, despite individual flaws in human reasoning.</p>
<p>The realist doctrine possesses what could be referred to as a strong metaphysics. The realist doctrine allows one to make true statements about kinds of objects, not just particulars. This, in turn, opens the door to robust deduction and reasoning about groups. Being able to reason about groups allows one to come to possess theoretically unlimited insight into the underlying structure of the universe. Unfortunately, the conditions which contribute to a strong metaphysics also make for a weaker epistemology. When properties are to take precedent over particulars, it takes much more time to discredit bad explanations of the universe which exist in the minds of others. For example, there’s a nearly limitless amount of different ways to attribute universals to particulars through classification. Although many errant classifications could be shot down by reason and limited observation, many others would be much harder to argue against in any reasonable amount of time without extensive observation.</p>
<p>Something should also be said for the implications of the realist doctrine on the question of morality. Morality consists of a set of axioms and paradigms for viewing the universe and other people, imposing a kind of order on the analysis of behavior. These are not observable, yet can be used to classify actions and events in a universal manner. Thus, although the realist view does not appear to guarantee the existence of universals which constitute morality, it clearly allows for them to theoretically exist, and argues for their eminence if they do.</p>
<p>The doctrine of nominalism directly questions the realist assertion that universals exist independently of observable particulars. In the theological domain, William of Occam famously argues for a version of Gods omnipotence that is much different from Aquinas or Wycliffe’s. According to his view, God is not a being limited by reason; everything in the universe is governed by His divine will, and not His divine intellect. Therefore, if God wanted to create a creature which directly contradicted any currently-held species classification, then He could do so arbitrarily. Such a model of the universe renders any classification of species arbitrary, in turn. Such a view of divine omnipotence naturally leads to a reevaluation of the relationship between particulars and categories.</p>
<p>When properties are rendered arbitrary, physical entities must carry all the weight in leading to truth. Concerning the status of properties and relations, one can either reject the existence of such universals outright or accept them, yet claim that they’re not actually universals. As an example of the second option, one could consider the minimal amount of properties, or descriptors, that account for the similarity and causal power of everything in the universe. The nominalist could argue that all of these properties could be expressed entirely in terms of particulars. Surely, this would require a much greater number of particulars to provide an equally broad description of the universe nevertheless, such a formulation would ultimately be no less descriptive. Instead of referring to the redness of all apples of a certain kind, the nominalist refers to the redness of this particular apple, which exists exactly where and when this apple is red nothing more can be reliably said on the matter. No conclusion can be made about its resemblance to other red apples; each must be examined on its own. Universals are not given in observations, yet they are used to make sense of observation show can their veracity ever be totally verified? Full knowledge consists in learning of the particular, and claims about similarity between objects are merely used when one lacks sufficient knowledge or wherewithal to get a good look at the particular. Under this view of universals, any use of classification is purely a pragmatic exercise, at times necessary to make decisions and to act. Classifications can be useful, but they are impositions on reality.</p>
<p>Whereas realism boasts a relatively strong metaphysics, nominalism claims a stronger epistemology. According to the nominalist, to resolve disagreements about the world, one must appeal to something outside of reason: observation of the particulars. Simple observations leave less up to interpretation in fact, ideally, they leave nothing to subjective interpretation. This stronger epistemology comes at the price of a weaker metaphysics. Under the nominalist doctrine, all classifications are man-made, and so one cannot actually speak to the true essence of a thing beyond what is immediately observable. One can identify the essences of sets which are created for pragmatic purposes, such as odd numbers, but never of observable things. Thus, there can be no discovery of universal properties. Constructs such as the laws of physics are not actually laws, but particular behaviors observed at a particular point in time. Broadly, nominalism denies that it is necessary that the universe be governed by order at least in the way that human beings understand order as it arises from interrelation. This pattern is evident in the way that Protestant Reformers come to embrace nominalism, for they come very close to practicing a form of mysticism. Perhaps the only thing keeping Protestants from becoming mystics is their staunch anchoring of their doctrine on both the literal word of the Bible and personal revelation.</p>
<p>Under the nominalist doctrine, the question of morality becomes muddled, as well. If the conclusions from observing an object can go no further in their application than that particular object at that particular point in time, then an is-ought problem arises. By this, I mean that what ought to be can never be concluded from observing what is. Under this paradigm, there are no moral absolutes. Morality becomes purely a pragmatic tool, used for its observably desirable outcomes under certain circumstances, though never logically justified absolutely.</p>
<p>By my own estimation, it appears that it would not be practical to espouse both the doctrine of realism and nominalism simultaneously. The reason has to do with the application of Occam’s razor. As mentioned in the description of the nominalist doctrine, one could plausibly conceive of a descriptive duality between properties and particulars. The nominalist could argue that the minimal set of universally descriptive properties could be equally represented by particulars. In this case, all the theoretical roles of universals would be equally fulfilled by material entities. If this were so (it is, admittedly, a big if), then Occam’s razor would urge the rational thinker to not unnecessarily multiply the number of entities in the universe. In general, universals rely on their supposed function as proof that they actually exist, and if they were shown to be entirely redundant in their function, then one would be inclined to reject universals altogether for the sake of concision.</p>
<p>I personally find the nominalist viewpoint to be very attractive, mainly because it appears to have built into it a constant call for intellectual humility. I have long been cautious in my estimation of the limits of human reason, and my study of engineering and mathematics has caused me to develop the view that mathematics constitute a useful yet approximate structure for modelling reality. Moreover, the analysis of nominalist philosophers such as Immanuel Kant has opened my eyes to the very real possibility that the way in which we perceive the world is distorted by our particular notions of space and time, which form the backbone of human reasoning. It is also difficult for me to argue against Aristotle’s conjecture that categories appear to be existentially dependent on particulars, for it aligns with my intuition that the mind formulates models for the sake of its own survival, and not necessarily for the sake of obtaining absolute truth. Given all of this, however, I realize that there is a big difference between encouraging intellectual humility and throwing out the merits of human reasoning altogether.</p>
<p>Although I cannot claim to be able to prove the supremacy of either doctrine, it seems to me that nominalism leads to a fundamentally unsettling conclusion when taken to its logical end. As a rational thinker, if I were to embrace nominalism as the lens through which to see the world, then I would have to continually reconcile the fact that I have to constantly appeal to immaterial ideas and classifications in order to make any intellectual progress that is useful to me. Supposedly, I could reason about groups, all while viewing it as a purely pragmatic endeavor. But, then, what meaning would the word pragmatic even have? What universal principle would compel me to do what is useful? How could I ever justify a belief concerning what is actually useful? I would be doomed to spending the rest of my life questioning the merits of every thought, and every thought concerning a thought, if I were to hold myself to intellectual honesty. The nominalist viewpoint would destroy any semblance of inner compass that I have if I were to wholeheartedly embrace it. That is why I choose to believe it is more plausible than not that there is a fundamental order to the universe which can, given time, ultimately be comprehended, even if only in part.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="thomas-aquinas-on-reason-and-revelation"><a class="header" href="#thomas-aquinas-on-reason-and-revelation">Thomas Aquinas on Reason and Revelation</a></h1>
<p>The question of reconciling faith with reason and science is one that is relevant to many, including myself. Aquinas offers some early thoughts on addressing this question. Some of his notions are perhaps outdated, but nevertheless serve as one of many decent starting points for organized thought on the issue.</p>
<hr>
<p>For much of the Medieval era, the theoretical sciences, as championed anciently by Aristotle, are popularly seen as being either in direct conflict with or extremely subservient to the study of the word of God as it is revealed by canonized scripture. The theoretical sciences entail the pursuit of all truth through reason, and the prevailing Augustinian view is that the only worthwhile use of reason falls within the domain of direct religious application all other intellectual pursuits are deemed superfluous and symptomatic of the lust of the eyes. This viewpoint can be characterized as faith seeking knowledge. St. Thomas Aquinas, who lives at a time when the writings of Aristotle have been revealed once again to western civilization as they are translated into Latin, offers a substantially different view of the pursuit of knowledge. His ideas champion the notion that revelation and the use of reason for the theoretical sciences are equally necessary in Gods plan for mankind. In contrast to the Augustinian model of faith seeking knowledge, Aquinas advocates for knowledge seeking faith. In spite of my finding the occasional lack of nuance in Aquinas conception of the relationship between reason and revelation, I sympathize much more strongly with his view than St. Augustine’s, for it gives equal weight to the words and acts of God in a manner that is comprehensible, while granting fundamental importance to mankind’s chief defining characteristic.</p>
<p>To justify the comparable significance of both reason and revelation, Aquinas addresses the concerns of those who extol reason and revelation as the supreme source of truth, respectively. This is not surprising, for the believer and the philosopher tend to harbor very different models of the universe. According to Aquinas, the philosopher thinks about creatures according to their proper natures, whereas the believer only concerns himself with how those creatures are related to God. Aquinas must bridge the gap between these two models. To do this, he must justify the usefulness of one model to those who espouse the other. He must also prove that the two epistemological models do not pose relative threats to one another, as would be the case in the Augustinian conception of a zero-sum game.</p>
<p>Aquinas justifies the use of revelation to the philosopher in part by distinguishing between two kinds of theology derived from revelation: positive and negative. Positive theology speaks to scriptural proclamations and demonstrations of what God has done, and these lend themselves to the examination of reason. For example, revelation reveals the nature of mankind, as well as what humanity must do to live in harmony with goodness. These principles can be reflected on by the philosopher, not falling outside the domain of reason. Moreover, the theologian may even turn to reason to find interrelations between divine principles and defend those principles against the accusation of being nonsense. One may ask: if positive theology can be traversed by the tools of reason, then what is the need of approaching such points from a theological point of view? In response to this question, Aquinas claims that diverse ways of knowing give rise to different sciences, appealing to the Aristotelian conception of coexisting domains of knowledge. If the astronomer and the philosopher can both come to the conclusion that the earth is round by different reasonable means, then positive theology can give rise to familiar conclusions with a perspective that still brings much needed insight.</p>
<p>A similar question may be posed: why should God rely on supernatural means to communicate knowledge which can be obtained by the senses? Aquinas answers this question by envisioning what the world would be like if there were no revelation. If God did not use revelation to reveal reasonable truths about His works, then few would ever come to possess a knowledge of God in this life. This is because most individuals do not pursue knowledge for its own sake, and many lack the resources, mental faculties, or freedom from mortal responsibilities necessary to dedicate time to such a monumental pursuit of knowledge. In addition, given the nature of human reason, which is subject to all manner of biases and false associations, it would be too easy for lies to become intermingled with truth were there no mediating force. It would be too difficult to dispel all the interspersed lies in the minds of the many, especially in the minds of those who are not well-versed in the process of demonstration. To counteract these unfortunate phenomena, Aquinas argues that the certitude which comes from faith is needed as a buttress to support reasons search for the knowledge of God. I agree with this sentiment, though for subtly different reasons. As the rational mind attempts to comprehend and attribute meaning to natural phenomena, it runs up against a large roadblock. The roadblock is the sheer volume of knowledge which can be attained in this life; how is one to know which objects of knowledge are more important to pursue? This problem is exacerbated by the deep separation which I believe exists between what is (that is, what can be observed through the senses) and what ought to be. In other words, I do not think there is any way to justifiably impose direction-giving meaning onto phenomena, using pure reason, without presupposing the existence of a particular narrative through which to view life. Pure demonstration cannot lead one to that which is not observable, including finding a purpose and source of all things in the universe. Thus, faith, inasmuch as it conforms to a coherent narrative about the purpose of creation and all things pertaining to it, acts as a guiding light in the pursuit of knowledge through reason.</p>
<p>To further justify the value of revelation to the philosopher, Aquinas must give a convincing argument that there can exist revealed truths whose full meaning defies all comprehension. These are truths which cannot be grasped by the senses, which, according to Aquinas, is because the senses are lower than He who created them, and something lower cannot comprehend what is higher unless a bridge is created by what is higher. For justification of this notion, Aquinas offers the premise that men are ordained by God to a purpose which extends beyond anything that can be experienced or thought of in this life. Thus, in order for mankind to be motivated to work toward such a lofty goal, mankind must first learn of the existence of such higher forms of being and knowing. I find nothing logically inconsistent in this argument. However, it is difficult for me to conceive of any fully satisfactory logical bridge between what is actionable (what can be done by man) and what is incomprehensible (the nature of God) that is useful for man’s betterment. For man to be truly motivated, I believe that a more understandable God and gospel is needed no one can wholeheartedly love something of which one has no real conception. Partially addressing this line of reasoning, Aquinas offers the promise that an admittance that there are divine truths beyond human comprehension leads to a fomenting of intellectual humility. Knowing that God comprehends what man cannot, Aquinas argues, will counteract the disposition of many to put their own opinions in the highest regard, thus opening the door to improvement for the soul. I mostly agree with this point, though I also recognize that, historically, forcing reason to take a backseat to revelation in the name of pious humility has sometimes resulted in atrocities of varying degrees. I can only assume that Aquinas presupposes that every word revealed by God, fully comprehensible or not, will only inspire mankind to do good. After all, he claims that even the most imperfect knowledge about the most noble realities brings the greatest perfection of the soul. I cannot personally make such a sweeping statement.</p>
<p>There are still others who would claim that reason has no place in the face of divine revelation. Even among the strongest critics of reason, it is acknowledged that human beings are naturally seekers of knowledge a point raised anciently by Aristotle. The Augustinian view holds that everything which man does through the natural urges alienates him from God. Aquinas, in contrast, asserts that man has the ability to perform works which gradually become perfected by the grace of God, rather than destroyed. For Aquinas, man’s ability to reason constitutes the works to be perfected, and faith is a gift of perfecting grace. Thus, the natural desire for knowledge is fundamentally tied to the natural desire for perfection. Perfection is defined as attaining the fullest form of what is naturally given. For example, humans do not naturally have wings, so flying is not included in the perfection of humans. The differentiating characteristic of humans is rationality, however, and the mind desires to be developed as a potential for perfection. In essence, man desires to acquire and be shaped by knowledge, just as matter desires to be shaped by form. I find this argument to be compelling, though I don’t see anything barring one from using the same argument to justify the development of any arbitrary characteristic found to be unique to humans, such as the ability to formulate elaborate deceptions. That is, unless one could argue that the development of knowledge simultaneously diminishes ones desire for the development of other, less holy characteristics of the human condition.</p>
<p>An important idea in Aquinas conception of the relationship between reason and revelation is that reason can never truly oppose what is accepted on faith. One reason is that faith encompasses truths which lie beyond the senses, and reason cannot reach what is beyond the senses. I agree with this point, just as I think that what ought to be (constituting an unobservable ideal) cannot be derived directly from what is. Regarding truths accepted on faith which lie within the realm of the senses, Aquinas claims that the theoretical sciences cannot muster an opposing truth which is, at the same time, constrained to be the only possible conclusion. While this may often be the case, I do not believe that this argument holds for cases in which reason is able to uncover a logical inconsistency among the revealed truths themselves. Science, due to its conjectural nature, is unable to ever make definitive statements of truth. However, science can definitively reject theories which demonstrate internal inconsistencies; this is how progress is made within the sciences as bad explanations which make false predictions are soundly rejected.</p>
<p>If one is to accept the relative importance and relevance of both reason and revelation, then Aquinas offers a compelling picture of their roles within Gods plan for mankind. For Aquinas, viewing both reason and revelation through Aristotle’s epistemological lens of demonstration, the major difference between reason-based philosophy and revelation-based theology is found in their principles, or starting points. The principles of philosophy are, to a certain extent, knowable through deep reflection as being self-evident. The principles of theology are based in faith, and cannot be learned through experience or pure reflection. By revelation, God is believed to be the first cause, and the movement of everything in the universe can be traced back to His design. The bridge between philosophy and theology is created after one first seeks to learn about the world through the senses, according to the order of knowing. Because mankind naturally desires knowledge, it will never cease searching until it has arrived at the first cause. Direction in the search is given by what has been given by revelation to be examined by reason. There inevitably comes a point when reasoning through the senses ceases to find more truths which can be derived from experience. That is when reason comes to rely on revelation, which knows the cause before the effect and can thus pick up the search for the first cause. It is after the limits of the senses have been exhausted that mankind comes to truly appreciate the truths revealed beyond the realm of experience. For Aquinas, the fullest form of happiness lies in these truths, which can never be fully comprehended in this life.</p>
<p>In the end, Aquinas says that our appreciation of the knowledge revealed by God gives a rationale for Gods creating the universe. The unchanging God, as the first cause, creates the universe, and His creations are separated from Him through a loss of intelligence and perfection. The perfection of the universe occurs when everything in it reunites with its source. According to Aquinas, it is man’s intellect which allows this union to occur. The intellect allows man to bear an increasing likeness to his source, and man will not stop inquiring until he arrives at the source. Therefore, mankind makes Gods creation worthwhile by its ability to recognize and move closer to God through increasing intelligence. Coming to know God through the application of reason, as guided and extended by the application of revelation, represents the height of human intellect, and the incremental realization of human perfection.</p>
<p>I agree with Aquinas that exercising faith in the revealed word of God for the purpose of directing and extending the intellect is, overall, extremely beneficial for the human condition. It provides a reliable sense of meaning, and motivates us to be better to each other, most of the time. For this reason, I believe that faith must be accepted alongside the use of reason. Also for this reason, I think that this acceptance of faith is ultimately based in a desire to believe, and not in epistemological certainty, which I believe is impossible to acquire in this life. There will always be alternative descriptions of reality which appeal to propositions beyond the reach of the senses while in this life, and our models of reality always hinge on the validity of the fundamental principles and axioms which we have no way of definitively proving true. Aquinas offers the comforting notion that at least living a life directed by faith in revelation can be seen as consistent with a noble and enlarging purpose for all mankind.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="random"><a class="header" href="#random">Random</a></h1>
<ul>
<li><a href="#money-balancing-math">Money Balancing Math</a></li>
<li><a href="#tenet-timelines">Tenet Timelines</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="money-balancing-math"><a class="header" href="#money-balancing-math">Money Balancing Math</a></h1>
<p>Occasionally situations arise where multiple parties are paying different amounts for various “shared” items (could be dishes for a dinner, or groceries and meals for a vacation) and at the end everyone wants to make sure that no one party paid more than everyone else. I’ll refer to these situations as the “money balancing” problem, which can be stated more precisely as follows:</p>
<hr>
<p><strong>The Money Balancing Problem</strong></p>
<p>Given \(n\) parties that have paid \(c_1,c_2,\cdots,c_n\) amounts toward a shared fund with a mean value of \(\mu\triangleq \sum_i{c_i}/n\), determine the <em>minimal exchanging of funds</em> that must occur between parties after the fact to ensure that \(c_i\rightarrow\mu\) for all \(i\).</p>
<hr>
<p>For small party sizes, the solutions to this problem are pretty intuitive (I’ll explain why that is). Some illustrative examples:</p>
<hr>
<p><strong>Example:</strong> (\(n=2\))</p>
<ul>
<li>Party 1 pays $20</li>
<li>Party 2 pays $10</li>
</ul>
<p>The mean amount is $15, and to make everyone whole Party 2 must pay Party 1 $5.</p>
<hr>
<hr>
<p><strong>Example:</strong> (\(n=3\))</p>
<ul>
<li>Party 1 pays $4</li>
<li>Party 2 pays $5</li>
<li>Party 3 pays $6</li>
</ul>
<p>The mean amount is $5, and to make everyone whole Party 1 must pay Party 3 $1. Part 2 doesn’t have to do anything.</p>
<hr>
<p>The above examples with \(n&lt;4\) are quick to reason through to get to the minimal list of needed transactions to make everyone whole. This is because of a convenient fact: that no matter how large \(n\) is, the total amount that was paid above the mean \(\mu\) is perfectly balanced by the total amount that was paid below the mean. In case that fact isn’t intuitive to you, see the proof below.</p>
<hr>
<p><strong>Proof</strong></p>
<p>\(\sum_i{\left(\mu-x_i\right)}\)</p>
<p>\(=\sum_i{\left(\left(\frac{1}{n}\sum_j{x_j}\right)-x_i\right)}\)</p>
<p>\(=n\sum_i{\left(\left(\sum_j{x_j}\right)-nx_i\right)}\)</p>
<p>\(=n\left(n\sum_i{x_i}-n\sum_i{x_i}\right)\)</p>
<p>\(=0\)</p>
<hr>
<p>Thus, when \(n&lt;4\), there is a finite amount of cases to consider, each with an obvious optimal solution:</p>
<ul>
<li>\(n=2\)
<ul>
<li><strong>Case 1:</strong> \(x_1=x_2=\mu\) \(\rightarrow\) No one does anything.</li>
<li><strong>Case 2:</strong> \(x_1&lt;\mu,x_2&gt;\mu\) \(\rightarrow\) Party 1 pays Party 2 exactly \(\mu-x_1\).</li>
</ul>
</li>
<li>\(n=3\)
<ul>
<li><strong>Case 1:</strong> \(x_1=x_2=x_3=\mu\) \(\rightarrow\) No one does anything.</li>
<li><strong>Case 2:</strong> \(x_1&lt;\mu,x_2&lt;\mu,x_3&gt;\mu\) \(\rightarrow\) Party 1 pays Party 3 \(\mu-x_1\) and Party 2 pays Party 3 \(\mu-x_2\).</li>
<li><strong>Case 3:</strong> \(x_1&lt;\mu,x_2=\mu,x_3&gt;\mu\) \(\rightarrow\) Party 1 pays Party 3 \(\mu-x_1\).</li>
<li><strong>Case 4:</strong> \(x_1&lt;\mu,x_2&gt;\mu,x_3&gt;\mu\) \(\rightarrow\) Party 1 pays Party 2 \(\mu-x_2\) and pays Party 3 \(\mu-x_3\).</li>
</ul>
</li>
</ul>
<p>It’s when \(n&gt;=4\) that things start to get a little hairier, since now we open ourselves to the possibility of simultaneously having multiple people pay below and above the mean. In that case, there are now an infinite number of <em>a posteriori</em> transactions that could take place to make each other whole, but we’d like to know the <em>optimal</em> set of transactions that entails a minimal amount of money exchanging hands.</p>
<p>A neat visualization of this optimal solution is to picture \(n\) water columns with different heights, initially segregated from each other (imagine connecting pipes with negligible cross-sectional area) by closed valves. Once the valves open, the water will auto-distribute itself to make it so that all the column heights regress to the mean. And if the connecting pipes have a small enough cross-section, then the inter-column transfer will be slow enough that the water will seamlessly transfer between columns in an optimal fashion such that no unnecessary water molecules are moved:</p>
<img src="img/money_bal_col.svg" width="600" style="display: block; margin-left: auto; margin-right: auto;">
<p>The same effect can be achieved for arbitrary values of \(n\) by formulating a <a href="https://en.wikipedia.org/wiki/Linear_programming">constrained linear program</a> where we minimize the sum of all balancing <em>a posteriori</em> transactions and constrain each party sum (i.e., initial amounts spent \(x_i\) plus any balancing transactions for each respective party) to be equal to \(\mu\). Since computers can solve linear programs in their sleep, here’s a Python script that will:</p>
<ul>
<li>Prompt you for party info and how much they spent toward the “shared fund.”</li>
<li>Formulate and solve the linear program from the info you provided.</li>
<li>Report the results in a human-understandable fashion.</li>
</ul>
<pre><code class="language-python">import numpy as np
from scipy.optimize import linprog

party_names = []
party_expenses = []

# Get party info
n = 0
while True:
    party_name = input(f"Enter the name of Party {n+1} (ENTER to stop adding parties): ")
    if not party_name:
        break
    n += 1
    party_expense = None
    while party_expense is None:
        try:
            party_expense = float(input(f"Enter total expense amount of Party {n}: "))
        except:
            print("Must enter a valid, positive floating-point number.")
        if party_expense &lt;= 0:
            print("Must enter a valid, positive floating-point number.")
            party_expense = None
    party_names.append(party_name)
    party_expenses.append(party_expense)

if n &lt;= 1:
    print("Must input more than one party.")
    exit()

# Formulate and solve linear program
b_p = np.array(party_expenses)
mu = np.mean(b_p)
b_eq = mu - b_p[:-1]
m = n * (n - 1)
m2 = int(m / 2)
b_ub = np.zeros(m)
indices = [(source, sink) for source in range(n) for sink in range(n) if source &gt; sink]
c = np.zeros(m)
for i in range(m2):
    c[m2 + i] = 1.0
A_eq = np.zeros((n - 1, m))
for i in range(n - 1):
    for j, (source, sink) in enumerate(indices):
        if source == i:
            A_eq[i, j] = -1
        elif sink == i:
            A_eq[i, j] = 1
A_ub = np.zeros((m, m))
for i in range(m2):
    A_ub[2 * i, i] = 1.0
    A_ub[2 * i, m2 + i] = -1.0
    A_ub[2 * i + 1, i] = -1.0
    A_ub[2 * i + 1, m2 + i] = -1.0
x_bounds = []
for i in range(m2):
    x_bounds.append((None, None))
for i in range(m2):
    x_bounds.append((0, None))
res = linprog(c, A_eq=A_eq, b_eq=b_eq, A_ub=A_ub, b_ub=b_ub, bounds=x_bounds)

# Interpret and report results
print("----")
for i in range(m2):
    amount = round(res.x[i], 2)
    if abs(amount) &gt;= 0.01:
        source, sink = indices[i]
        if amount &gt; 0:
            print(f"{party_names[sink]} should pay {party_names[source]} ${amount:.2f}.")
        else:
            print(f"{party_names[source]} should pay {party_names[sink]} ${-amount:.2f}.")
</code></pre>
<p>Here’s an example run of the above program with user inputs from \(n=5\):</p>
<pre><code class="language-bash">Enter the name of Party 1 (ENTER to stop adding parties): Jerry
Enter total expense amount of Party 1: 9.20
Enter the name of Party 2 (ENTER to stop adding parties): Joe
Enter total expense amount of Party 2: 10.12
Enter the name of Party 3 (ENTER to stop adding parties): John
Enter total expense amount of Party 3: 2.30
Enter the name of Party 4 (ENTER to stop adding parties): Jeff
Enter total expense amount of Party 4: 3.55
Enter the name of Party 5 (ENTER to stop adding parties): Jim
Enter total expense amount of Party 5: 7.89
Enter the name of Party 6 (ENTER to stop adding parties): 
----
John should pay Jerry $1.43.
John should pay Joe $2.26.
Jeff should pay Jerry $1.16.
Jeff should pay Joe $1.25.
John should pay Jim $0.62.
Jeff should pay Jim $0.66.
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="tenet-timelines"><a class="header" href="#tenet-timelines">Tenet Timelines</a></h1>
<p>The movie <em>Tenet</em> makes use of nonlinear storytelling in its purest form: the main characters literally “zig-zag” through time within the bounds of a two-week period, as illustrated in the “stacked timeline” below. This is my attempt to make sense of the timelines as well as some of the essential mechanics of the storyline after an initial viewing. The timeline below is by no means precise (hence no metric indicators on the time axis), but I do believe that the shapes are basically correct.</p>
<img src="img/tenet-timelines.svg" style="display: block; margin-left: auto; margin-right: auto;">
<h2 id="timeline-legend"><a class="header" href="#timeline-legend">Timeline Legend</a></h2>
<ul>
<li><strong>Red:</strong> The Protagonist’s (John David Washington) Timeline</li>
<li><strong>Blue:</strong> Neil’s (Robert Pattinson) Timeline</li>
<li><strong>Purple:</strong> Kat’s (Elizabeth Debicki) Timeline</li>
<li><strong>Gray:</strong> Andrei Sator’s (Kenneth Branagh) Timeline</li>
<li><strong>Black:</strong> The Universe’s (i.e., laws of physics) Timeline</li>
<li><strong>Labeled Circles:</strong> Key Movie Events (see below)</li>
</ul>
<h2 id="key-movie-events"><a class="header" href="#key-movie-events">Key Movie Events</a></h2>
<ol>
<li>The opera house in Kiev is sieged. The Protagonist is unwittingly saved by Neil, who sports his backpack with red lanyard attached (face not seen).</li>
<li>The Protagonist and Neil break into the penthouse suite in India by bungee jumping, and learn of Sator, who is communicating somehow with the future.</li>
<li>The Protagonist meets Kat and Sator in London, and agrees to steal plutonium for Sator.</li>
<li>Neil and the Protagonist break into the Norwegian vault by crashing a plane into it, and are met by a mysterious masked character: <strong>(A)</strong> The protagonist fights with the mysterious figure, who is actually himself traveling backwards through time. <strong>(B)</strong> Neil simultaneously struggles with the Protagonist who has flipped back to going forwards in time, then realizes who he is, causing him to warn the current version of the Protagonist to not inadvertently kill himself by killing the mysterious figure.</li>
<li>(Told in flashback by Kat) Sator and Kat have a massive fight on a yacht in Vietnam when Sator offers to stop blackmailing her if she agrees to never see her son again.</li>
<li>The Protagonist and Neil steal the plutonium (which actually turns out to be the last piece needed to assemble The Algorithm) and are tricked/manipulated by Sator to give it up, especially when Kat’s life is threatened with a gunshot wound and radiation exposure.</li>
<li>The climax events of the movie: <strong>(A)</strong> The Protagonist and Neil take part in a huge offensive to take hold of The Algorithm before the bad guys can set off a homing beacon, alerting the enemies in the future to where it is so that they can set it off, destroying the past. In a final act of heroism which we see from The Protagonist’s perspective (but actually is carried out after their final exchange, offscreen), Neil descends into the hole where The Algorithm is so that he can unlock the gate and take a bullet for The Protagonist. Once again, the lanyard on the backpack gives this fact away. <strong>(B)</strong> Simultaneously, Kat and Sator have returned to Vietnam to relive an important moment alluded to earlier. Sator wants to have one last enjoyable moment before telling his henchmen to set the homing beacon for The Algorithm. He thinks he’s interacting with the Kat from the original event, whereas the Kat who has been experiencing all the events of this movie up to this point has actually snuck onto the Yacht, and her mission is to have him die without it setting off the homing beacon.</li>
<li>After the film’s resolution, The Protagonist saves Kat from being killed off as a loose end. As a rule of the Tenet organization (to be founded by The Protagonist in the future), all who see The Algorithm must be killed off at some point (hence the cyanide pill test at the beginning of the movie for those who would be admitted to the program—they need to demonstrate that they are willing to die for a good cause) so that they can’t be interrogated in the future and reveal the location of The Algorithm in the past. The Protagonist violates his own organization’s rules by saving her, and the two of them become the only main characters to live beyond the events of the movie.</li>
</ol>
<h2 id="notes"><a class="header" href="#notes">Notes</a></h2>
<ul>
<li>To understand the implications of the zig-zagged timelines, you have to take them at face value, which is to say that for much of the movie, there are other “copies” of the main characters going around doing things which you don’t know about. For example, around the same point in time corresponding to (1) on the timeline, there’s one copy of The Protagonist and Neil at the opera house, but <em>at the same point in time</em>, there are two copies of The Protagonist and <em>three</em> copies of Neil, all running around the place where the climactic battle for The Algorithm happened. Similarly, around the time of (4), there were five different copies of The Protagonist running around, with three of them within just a few feet of each other in that Norwegian vault.
<ul>
<li>You don’t have to think too hard about this to see where issues of free will might come up, as they mention at the start of the movie (e.g., “If I see my future inverted self do \(\chi\), then can I just choose to do \(\mathcal{Y}\) instead? In that case, why did I see my future self do \(\chi\)?”) The movie kind of brushes this off with the phrase “what’s done is done” as well as what seems like a pseudo-<a href="https://plato.stanford.edu/entries/compatibilism/">compatibilist</a> philosophical argument, but that would be fun to discuss beyond the scope of these notes.</li>
<li>It also follows from the zig-zag timeline lengths that while the entire movie takes place within the span of about two weeks, the different main characters age different amounts during this time. For example, The Protagonist appears to age about six weeks during the course of the film, whereas Sator only experiences/ages about four weeks’ time.</li>
</ul>
</li>
<li>Alongside the bi-directional, piecewise main character timelines, it may seem trivial to include the linear universal timeline at the bottom. However, it’s actually really important to think of each character’s timeline <em>in terms of how it relates to the universal timeline</em>. For example, in the movie, they claim that inverted people will experience physics (e.g., friction, sounds, heat transfer, etc.) in a backwards, counter-intuitive manner. <em>But</em>, if the universal timeline were pointing to the left instead of to the right (that is, if the universe itself were inverted), then it would be the opposite—those moving forward in time would be the ones experiencing the weird physics (The notion of inverted heat transfer, etc. as a result of inverted entropy/time perception is a bit bogus, but still a cool idea for the film)!
<ul>
<li>This is what the nameless enemies of the future wanted to accomplish by activating The Algorithm; they wanted to reverse the direction of the universal timeline so that the people of the future could travel in the other direction, back to a time before the Earth was ruined by human mismanagement.</li>
<li>Now imagine the universal timeline reversing direction, zig-zagging like the main character timelines. In the movie, they claimed that touching your alternate, inverted self (without a protective suit on) would result in your spatial-temporal annihilation. If the whole universe inverted, then everything would fold back on itself for just this sort of annihilation, spelling catastrophe for anything to the left of the universal folding point and presumably leaving an empty space for the future to occupy in their newly-inverted timeline.</li>
</ul>
</li>
</ul>
<p><em><strong>All in all, very cool movie!</strong></em> For me, it wasn’t quite as emotionally fulfilling as most of Nolan’s other films, but was still a blast in its own right.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="recipes"><a class="header" href="#recipes">Recipes</a></h1>
<ul>
<li><a href="#appetizer-recipes">Appetizers</a></li>
<li><a href="#breakfast-recipes">Breakfast</a></li>
<li><a href="#dessert-recipes">Dessert</a></li>
<li><a href="#dinner-recipes">Dinner</a></li>
<li><a href="#quick-stats">Quick Stats</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="appetizer-recipes"><a class="header" href="#appetizer-recipes">Appetizer Recipes</a></h1>
<h3 id="guacamole"><a class="header" href="#guacamole">Guacamole</a></h3>
<p><em>Single-person version: use 1 avocado.</em></p>
<hr>
<ul>
<li>3 ripe avocados</li>
<li>1 lime</li>
<li>\(&lt;1\) teaspoons of minced garlic</li>
<li>1 large pinch of salt</li>
<li>(little bit of) cilantro</li>
<li>(little bit of) chopped onion</li>
<li>1 pinch of cumin</li>
</ul>
<hr>
<ul>
<li>Place peeled avocado into a medium-sized bowl.</li>
<li>Cut the lime in half and squeeze both halves into the bowl.</li>
<li>Add garlic, salt, cilantro, onion, and cumin.</li>
<li>Mash the avocados with a fork and mix everything together evenly.</li>
</ul>
<h3 id="5-layer-dip"><a class="header" href="#5-layer-dip">5-Layer Dip</a></h3>
<p><em>Add some additional excitement to your guacamole.</em></p>
<hr>
<ul>
<li>Refried beans</li>
<li>Guacamole</li>
<li>Sour cream</li>
<li>Taco seasoning</li>
<li>Salsa</li>
<li>Shredded cheese</li>
<li>Chopped Cilantro</li>
</ul>
<hr>
<ul>
<li>Mix sour cream with taco seasoning.</li>
<li>In a 9-inch dish, layer bottom-to-top:
<ul>
<li>Refried beans</li>
<li>Guacamole</li>
<li>Taco-spiced sour cream</li>
<li>Salsa</li>
</ul>
</li>
<li>Top with shredded cheese.</li>
<li>Garnish with chopped cilantro.</li>
<li>Serve with tortilla chips or cover/refrigerate immediately!</li>
</ul>
<h3 id="almost-kanes-sauce"><a class="header" href="#almost-kanes-sauce">(Almost) Kane’s Sauce</a></h3>
<p><em>Makes enough for one oven-full of chicken.</em></p>
<hr>
<ul>
<li>\(\frac{1}{2}\) cup of mayo</li>
<li>\(\frac{1}{4}\) cup of ketchup</li>
<li>1 tsp of worcestershire sauce</li>
<li>\(\frac{1}{2}\) tsp of black pepper</li>
<li>\(\frac{1}{2}\) tsp of garlic salt <strong>OR</strong> \(\frac{3}{8}\) tsp of salt and \(\frac{1}{8}\) tsp of garlic powder</li>
</ul>
<hr>
<ul>
<li>Mix all the ingredients together.</li>
</ul>
<h3 id="garlic-parmesan-roasted-broccoli"><a class="header" href="#garlic-parmesan-roasted-broccoli">Garlic Parmesan Roasted Broccoli</a></h3>
<p><em>Makes great dinner side. Makes 6 servings. Prep 5 min., cook 10 min.</em></p>
<hr>
<ul>
<li>5 Cups (24 oz) of Broccoli Florets</li>
<li>3 Tablespoons of Olive Oil</li>
<li>2 Teaspoons of Minced Garlic</li>
<li>Salt and Pepper</li>
<li>\(\frac{1}{4}\) Cup of Parmesan</li>
<li>Juice of 1 Lemon</li>
</ul>
<hr>
<ul>
<li>Preheat oven to 425\(^\circ\) F. Lightly oil a baking sheet or coat with nonstick spray.</li>
<li>Place broccoli florets in a single layer onto the prepared baking sheet. Add olive oil and garlic; season with salt and pepper, to taste. Gently toss to combine.</li>
<li>Place into oven and bake for 10-12 minutes, or until tender.</li>
<li>Serve immediately, sprinkled with Parmesan and lemon juice.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="breakfast-recipes"><a class="header" href="#breakfast-recipes">Breakfast Recipes</a></h1>
<h3 id="pancakes-from-scratch"><a class="header" href="#pancakes-from-scratch">Pancakes from Scratch</a></h3>
<hr>
<ul>
<li>1 \(\frac{1}{2}\) cups all-purpose flour</li>
<li>3 \(\frac{1}{2}\) teaspoons baking powder</li>
<li>1 teaspoon salt</li>
<li>1 tablespoon white sugar</li>
<li>1 \(\frac{1}{4}\) cups milk</li>
<li>1 egg</li>
<li>3 tablespoons butter, melted</li>
</ul>
<hr>
<ul>
<li>In a large bowl, sift together the flour, baking powder, salt, and sugar.</li>
<li>Make a well in the center and pour in the milk, egg, and melted butter; mix until smooth.</li>
<li>Make the pancakes with \(\frac{1}{4}\)-cup scoops; should be nice and fluffy!</li>
</ul>
<h3 id="french-toast-roll-ups"><a class="header" href="#french-toast-roll-ups">French Toast Roll-Ups</a></h3>
<hr>
<ul>
<li>8 slices of white sandwich bread</li>
<li>Filling (one or the other):
<ul>
<li>softened cream cheese &amp; diced strawberries</li>
<li>Nutella and banana slices</li>
</ul>
</li>
<li>2 eggs</li>
<li>3 tablespoons of milk</li>
<li>\(\frac{1}{3}\) cup of granulated sugar</li>
<li>1 heaping teaspoon of ground cinnamon</li>
<li>butter for greasing the pan</li>
</ul>
<hr>
<ul>
<li>Cut the crust off of each slice of bread, flatten them out with a rolling pin</li>
<li>Place 1-2 teaspoons of filling 1 inch from one end of the bread in a strip, and roll up tightly</li>
<li>In a shallow bowl, whisk the eggs and milk until well combined</li>
<li>In another shallow bowl, mix the sugar and cinammon</li>
<li>Melt a tablespoon of butter on a skillet over medium heat</li>
<li>Dip each roll in the egg mixture, then place on skillet seam-side down
<ul>
<li>Cook in batches until golden brown, turning to cook and brown on all sides (\(\approx\) 2 minutes per side). Butter the pan as needed</li>
</ul>
</li>
<li>Once cooked, roll the rolls immediately in the cinnamon-sugar mixture, then set aside for serving</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="dessert-recipes"><a class="header" href="#dessert-recipes">Dessert Recipes</a></h1>
<h3 id="chocolate-chip-cookies"><a class="header" href="#chocolate-chip-cookies">Chocolate Chip Cookies</a></h3>
<hr>
<ul>
<li>1 cup of softened butter</li>
<li>1 cup of white sugar</li>
<li>1 cup of brown sugar</li>
<li>2 eggs</li>
<li>2 teaspoons of vanilla</li>
<li>\(2~\frac{1}{2}\) cups of flour\(^*\)</li>
<li>1 teaspoon of baking soda</li>
<li>1 teaspoon of salt</li>
<li>2 cups of chocolate chips</li>
</ul>
<p>\(^*\) If you don’t double the recipe, a little bit of extra flour (like a couple of tablespoons) might be needed if the cookies seem too thin.</p>
<hr>
<ul>
<li>Preheat oven to 350\(^\circ\)</li>
<li>Mix the butter, white sugar, and brown sugar in a large bowl</li>
<li>Mix in eggs and vanilla</li>
<li>Mix in flour, baking soda, and salt</li>
<li>Add the chocolate chips</li>
<li>Use cookie scoop to place round, even amounts on the cookie sheet(s)</li>
<li>Bake (top rack) for (8-10 minutes? Definitely 12 if you’re doubling)</li>
</ul>
<h3 id="air-fried-oreos"><a class="header" href="#air-fried-oreos">Air Fried Oreos</a></h3>
<p><a href="https://vm.tiktok.com/JjGvhJ3/">Inspired by TikTok</a>.</p>
<hr>
<ul>
<li>1 package of 8-count Pillsbury “Crescents” croissants</li>
<li>1 package of oreos</li>
<li>Powdered sugar</li>
</ul>
<hr>
<ul>
<li>Cut croissant rolls (laid flat) in half so they form squares</li>
<li>Wrap oreos on croissant squares</li>
<li>Place oreos in air fryer: 5-6 minutes at 320\(^\circ\) (until they are golden brown)</li>
<li>Sprinkle powdered sugar on your now beignet-like oreos!</li>
</ul>
<h3 id="super-simple-peanut-butter-cookies"><a class="header" href="#super-simple-peanut-butter-cookies">Super Simple Peanut Butter Cookies</a></h3>
<hr>
<ul>
<li>1 cup of peanut butter</li>
<li>1 cup of sugar</li>
<li>1 egg</li>
</ul>
<hr>
<ul>
<li>Preheat oven to 350\(^\circ\)</li>
<li>Mix all ingredients in bowl</li>
<li>Bake for :::6-8 minutes?:::</li>
</ul>
<h3 id="normal-peanut-butter-cookies"><a class="header" href="#normal-peanut-butter-cookies">Normal Peanut Butter Cookies</a></h3>
<p><em>Yield: 24 cookies. Prep: 15 min. <strong>+ 1 hr.</strong> Cook: 10 min.</em></p>
<hr>
<ul>
<li>1 cup of butter</li>
<li>1 cup of peanut butter</li>
<li>1 cup of white sugar</li>
<li>1 cup of brown sugar</li>
<li>2 eggs</li>
<li>\(2\frac{1}{2}\) cups of flour</li>
<li>1 teaspoon of baking powder</li>
<li>\(\frac{1}{2}\) teaspoon of salt</li>
<li>\(1\frac{1}{2}\) teaspoons of baking soda</li>
</ul>
<hr>
<ul>
<li>In a bowl, cream the butter, peanut butter, and sugars. Beat in eggs.</li>
<li>In a separate bowl, sift flour, baking powder, baking soda, and salt.</li>
<li>Stir the two bowl contents into each other, then place in the fridge <strong>for 1 hour</strong>.</li>
<li>Preheat oven to \(375^\circ\).</li>
<li>Place refrigerated dough balls on cookie sheets and bake <strong>for about 10 minutes</strong> or until they start to brown.</li>
</ul>
<h3 id="texas-sheet-cake"><a class="header" href="#texas-sheet-cake">Texas Sheet Cake</a></h3>
<hr>
<ul>
<li>2 cups of flour</li>
<li>2 cups of sugar</li>
<li>\(\frac{1}{4}\) teaspoons of salt</li>
<li>8 tablespoons of (heaping) cocoa</li>
<li>1 cup of boiling water</li>
<li>\(\frac{1}{2}\) cup of buttermilk</li>
<li>2 whole beaten eggs</li>
<li>1 teaspoon of baking soda</li>
<li>2 teaspoons of vanilla</li>
<li>\(\frac{1}{2}\) cup of finely chopped peacans</li>
<li>\(3\frac{3}{4}\) stick of butter</li>
<li>6 tablespoons of milk</li>
<li>1 pound (minus \(\frac{1}{2}\) cup) of powdered sugar–about 3 cups</li>
<li>\(18\times 13\)-inch sheet cake pan</li>
</ul>
<hr>
<ul>
<li>In a mixing bowl, combine the flour, sugar, and salt.</li>
<li>In a saucepan, melt 2 of the sticks of butter. Add 4 tablespoons of the cocoa and stir. Add the boiling water and allow the mixture to boil for 30 seconds before turning off the heat.</li>
<li>Pour the cocoa mixture over the flour mixture and stir lightly to cool.</li>
<li>In a measuring cup, pour the buttermilk and add beaten eggs, baking soda, and 1 teaspoon of the vanilla.</li>
<li>Stir the buttermilk mixture into the butter + chocolate mixture.</li>
<li>Pour the whole thing into the sheet cake pan and bake at 350 degrees for 20 minutes.</li>
<li>While the cake is baking, melt the remaining butter in a saucepan.</li>
<li>Add the remaining cocoa, stir to combine, then turn off the heat.</li>
<li>Add the milk, remaining vanilla, and powdered sugar. Stir together.</li>
<li>Add the pecans and stir together.</li>
<li>Pour the frosting over the warm cake.</li>
</ul>
<h3 id="brazo-gitano-swiss-roll"><a class="header" href="#brazo-gitano-swiss-roll">Brazo Gitano (Swiss Roll)</a></h3>
<hr>
<ul>
<li>1 cup of sugar</li>
<li>1 cup of flour (i.e. <em>harina presto</em>)</li>
<li>3 eggs</li>
<li>3 tablespoons of water</li>
<li>\(\frac{1}{2}\) can of dulce de leche</li>
</ul>
<hr>
<ul>
<li>Preheat oven to 350\(^\circ\)</li>
<li>Separate egg yolks from egg whites into separate bowls</li>
<li>Whisk egg whites to the point of foaming</li>
<li>Add sugar to the yolk, then mix together</li>
<li>Add flour to the yolk mixture</li>
<li>Add water to flour-yolk mixture and mix</li>
<li>Fold egg whites into yolk mixture</li>
<li>Place parchment paper on cookie sheet, and pour a handful of sugar over it</li>
<li>Pour the batter evenly on the parchment paper</li>
<li>Bake for 10 minutes (avoid the urge to open the door a bunch of times)</li>
<li>Remove from oven and let cool for 5 minutes</li>
<li>Pour dulce de leche over the bread</li>
<li>Detach bread from parchment paper at the edge and begin rolling it up longways</li>
<li>Pour powdered sugar on top</li>
<li>Slice it up and enjoy!</li>
</ul>
<h3 id="tres-leches-cake"><a class="header" href="#tres-leches-cake">Tres Leches Cake</a></h3>
<hr>
<p><strong>Cake</strong></p>
<ul>
<li>1 box of Pillsbury (1 lb 2.25-oz) yellow cake mix with pudding</li>
<li>1 cup of water</li>
<li>\(\frac{1}{3}\) cup of vegetable oil</li>
<li>3 eggs
<strong>Sauce</strong></li>
<li>1 cup of whipping cream</li>
<li>1 (14-oz) can of sweetened condensed milk (<em>not</em> evaporated)</li>
<li>1 (12-oz) can of evaporated milk
<strong>Topping</strong></li>
<li>1 cup of whipping cream</li>
<li>\(\frac{1}{4}\) teaspoon of vanilla extract</li>
</ul>
<hr>
<ul>
<li>Preheat oven to 350\(^\circ\)</li>
<li>Grease a \(13\times 9\) in. (3-quart) glass baking dish</li>
<li>In a large bowl, beat cake mix, water, oil, and eggs with electric mixer on low speed (\(\approx 30\) seconds) until blended. Then beat on medium speed for 2 minutes.</li>
<li>Pour batter into baking dish</li>
<li>Bake 20 minutes or until toothpick inserted in center comes out with crumbs</li>
</ul>
<hr>
<ul>
<li>In a large bowl, mix sauce ingredients</li>
<li>Using long-tined fork, pierce hot cake in baking dish every 1 to 2 inches</li>
<li>Slowly pour sauce mixture over cake</li>
<li>Refrigerate cake at least 3 hours to chill (cake will absorb most of sauce mixture)</li>
</ul>
<hr>
<p><em>Before serving</em>:</p>
<ul>
<li>In a small bowl, beat whipping cream until stiff peaks form</li>
<li>Stir in vanilla</li>
<li>Spread over cold cake</li>
<li>Cover and refrigerate</li>
</ul>
<h3 id="turtles"><a class="header" href="#turtles">Turtles</a></h3>
<hr>
<ul>
<li>48 caramels</li>
<li>\(\frac{1}{2}\) cup of cream (heavy or whipping)</li>
<li>\(1~\frac{1}{2}\) cups of flour</li>
<li>\(1~\frac{1}{4}\) cups of brown sugar</li>
<li>\(1~\frac{1}{4}\) cups of <em>melted</em> butter</li>
<li>\(\frac{1}{4}\) teaspoon of salt</li>
<li>\(\frac{2}{3}\) teaspoon of baking soda</li>
<li>\(1~\frac{1}{2}\) cup of oatmeal</li>
<li>A 6-oz package of chocolate chips</li>
</ul>
<hr>
<ul>
<li>Preheat oven to 350\(^\circ\)</li>
<li>Melt caramels and cream in a double broiler</li>
<li>Separately combine remaining ingredients (except chocolate chips) and press half of the mixture into a \(13\times9\) cake pan</li>
<li>Bake for 10 minutes</li>
<li>Remove from oven and sprinkle chocolate chips over it</li>
<li>Pour hot caramel sauce over chips</li>
<li>Add remaining oatmeal mixture</li>
<li>Finish baking for 15 minutes</li>
<li>Cool and cut into squares</li>
</ul>
<h3 id="cowboy-cookies"><a class="header" href="#cowboy-cookies">Cowboy Cookies</a></h3>
<hr>
<ul>
<li>2 cups of brown sugar</li>
<li>2 cups of sugar</li>
<li>2 cups of shortening/butter</li>
<li>4 eggs</li>
<li>2 teaspoons of vanilla</li>
<li>1 large package of chocolate chips</li>
<li>4 cups of regular oatmeal</li>
<li>4 cups of flour</li>
<li>1 teaspoon of salt</li>
<li>1 teaspoon of baking powder</li>
<li>2 teaspoons of baking soda</li>
</ul>
<hr>
<ul>
<li>Preheat oven to 350\(^\circ\)</li>
<li>Mix all ingredients together in Bosch mixer</li>
<li>Drop by spoonfuls on a greased cookie sheet</li>
<li>Bake for 10 minutes</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="dinner-recipes"><a class="header" href="#dinner-recipes">Dinner Recipes</a></h1>
<p><a href="https://www.brit.co/beginner-instant-pot-recipes/">45 Beginner Instant Pot Recipes</a></p>
<h3 id="taco-soup-chili"><a class="header" href="#taco-soup-chili">Taco Soup (Chili)</a></h3>
<hr>
<ul>
<li>1 can of black beans</li>
<li>1 can of kidney beans</li>
<li>2 cans of petite diced tomatoes</li>
<li>1 can of corn</li>
<li>1 packet of ranch mix</li>
<li>1 packet of taco mix</li>
<li>1 pound of ground beef</li>
</ul>
<hr>
<ul>
<li>In the bottom of a large pot, cook the meat fully.</li>
<li>Drain all cans except for the tomatoes, and empty all cans in the pot.</li>
<li>Add up to 1 can of water, for desired consistency.</li>
<li>Heat everything up, then serve.</li>
</ul>
<h3 id="mashed-potatoes-instant-pot"><a class="header" href="#mashed-potatoes-instant-pot">Mashed Potatoes (Instant Pot)</a></h3>
<hr>
<ul>
<li>1 pound of baby yellow, gold, <strong>or</strong> red potatoes (<em>gold preferred</em>)</li>
<li>\(\frac{1}{2}\) cup of water, <strong>or</strong> vegetable/chicken broth for more flavor</li>
<li>2 tablespoons of butter</li>
<li>1-2 cloves of minced garlic (<em>optional</em>)</li>
<li>\(\frac{1}{4}\) to \(\frac{1}{2}\) teaspoons of salt</li>
<li>\(\frac{1}{4}\) to \(\frac{1}{2}\) teaspoons of black pepper</li>
<li>2-4 tablespoons of milk</li>
<li>fresh parsley (<em>optional</em>)</li>
</ul>
<hr>
<ul>
<li>Peel the potatoes and cut into \(\approx\) 1-inch uniform chunks.</li>
<li>Place chunks and the water/broth in the instant pot and cook on HIGH pressure for 5 minutes. Release the pressure valve as soon as the 5 minutes are up.</li>
<li>Check on the potatoes to make sure they’re soft and easy to mash. If not, then put the lid back on and “keep warm” for 5-10 minutes more.</li>
<li>With the water still in the pot, use a potato masher or large fork to mash the potatoes halfway to the consistency that you want.</li>
<li>Add the butter, optional garlic, and salt/pepper.</li>
<li>Mash the potatoes the rest of the way to their desired consistency.
<ul>
<li>Use the milk to thin out the potatoes, if needed.</li>
</ul>
</li>
<li>Serve hot, and garnish with parsley if you want. Leftovers can be stored in the refrigerator for 3-4 days.</li>
</ul>
<h3 id="beef-stew-instant-pot"><a class="header" href="#beef-stew-instant-pot">Beef Stew (Instant Pot)</a></h3>
<hr>
<ul>
<li>\(1 \frac{1}{2}\) Pounds of Beef Stew Meat</li>
<li>1 Tablespoon of Olive Oil</li>
<li>1 Teaspoon of Salt</li>
<li>1 Teaspoon of Pepper</li>
<li>1 Teaspoon of Italian Seasoning</li>
<li>2 Tablespoons of Worcestershire Sauce</li>
<li>3 Cloves of Minced Garlic</li>
<li>1 Large, Chopped Onion</li>
<li>\(1\times 16\)-oz Bag of Baby Carrots (cut into slices)</li>
<li>1 Pound of Cubed Potatoes</li>
<li>\(2 \frac{1}{2}\) Cups of Beef Broth</li>
<li>\(1\times 10\)-oz Can of Tomato Sauce</li>
<li>2 Tablespoons of Cornstarch</li>
<li>2 Tablespoons of Water</li>
</ul>
<hr>
<ul>
<li>Add the olive oil to the instant pot and turn on the saute function. When the oil starts to sizzle, add the meat and season with the salt, pepper, and Italian seasoning.</li>
<li>Cook the meat until Browned on all sides.</li>
<li>Add the beef broth to the instant pot and use a spoon to scrape the brown bits from the bottom of the pan.</li>
<li>Add the Worcestershire sauce, garlic, onion, carrots, potatoes, and tomato sauce.</li>
<li>Close the lid and steam valve on the instant pot.</li>
<li>Cook on <strong>high</strong> pressure for <strong>35 minutes</strong>, then allow the pressure to release naturally for <strong>10 minutes</strong> before doing a quick release.</li>
<li>Mix together the cornstarch and cold water in a small bowl and stir into the stew <em>while it’s still piping hot</em> until thickened.</li>
</ul>
<h3 id="taco-soup"><a class="header" href="#taco-soup">Taco Soup</a></h3>
<hr>
<ul>
<li>1 can black beans</li>
<li>1 can kidney beans</li>
<li>2 cans petite diced tomatoes</li>
<li>1 can corn</li>
<li>1 packet of ranch mix</li>
<li>1 packet of taco mix</li>
<li>1 lb of ground beef</li>
</ul>
<hr>
<ul>
<li>Cook the beef separately.</li>
<li>Drain all cans.</li>
<li>Put everything in a pot. Add 1 can of water if you want a more soup-ey consistency.</li>
<li>Heat up.</li>
<li>Add anything you want in it:
<ul>
<li>chips</li>
<li>avocado</li>
<li>sour cream</li>
<li>etc.</li>
</ul>
</li>
</ul>
<h3 id="barbecue-chicken-pizza-bagels"><a class="header" href="#barbecue-chicken-pizza-bagels">Barbecue Chicken Pizza Bagels</a></h3>
<hr>
<ul>
<li>Plain white bagels, sliced</li>
<li>1 Chicken breast</li>
<li>BBQ sauce (like Sweet Baby Ray’s)</li>
<li>Lots of grated mozzarella</li>
<li>Diced red onion</li>
</ul>
<hr>
<ul>
<li>Cook, then cube the chicken</li>
<li>Preheat oven to 425\(^\circ\)</li>
<li>Layer on each bagel slice in following order, starting from the bottom:
<ul>
<li>Chicken</li>
<li>BBQ sauce</li>
<li>Mozzarella</li>
<li>Onion</li>
</ul>
</li>
<li>Bake in oven for \(\approx\) 10-15 minutes, until cheese is melted.</li>
</ul>
<h3 id="buffalo-dip"><a class="header" href="#buffalo-dip">Buffalo Dip</a></h3>
<hr>
<ul>
<li>\(\frac{3}{4}\) cup of Frank buffalo hot sauce</li>
<li>1 cup of ranch dressing</li>
<li>16-oz of softened cream cheese</li>
<li>2 cans of canned chicken (drained)</li>
<li>2 cups of shredded cheddar cheese</li>
</ul>
<hr>
<ul>
<li>Preheat oven to 350\(^\circ\)</li>
<li>Drain chicken and mix with hot sauce</li>
<li>In a separate bowl, mix the ranch and cream cheese</li>
<li>Mix everything together</li>
<li>Grease the bottom of a small, square pan.</li>
<li>Pour mixture into pan, then sprinkle cheddar cheese on top</li>
<li>Bake for 25 minutes.</li>
</ul>
<h3 id="white-chicken-chili-crockpot"><a class="header" href="#white-chicken-chili-crockpot">White Chicken Chili (Crockpot)</a></h3>
<p><em>Single recipe serves 5+.</em></p>
<hr>
<ul>
<li>2 frozen (or fresh) boneless chicken breasts</li>
<li>1 can of corn</li>
<li>1 can of black beans</li>
<li>\(1\times 10\)-oz can of “original” or “mild” Rotel tomatoes</li>
<li>1 package of Hidden Valley ranch dressing mix (1-oz size)</li>
<li>1 teaspoon of cumin</li>
<li>1 teaspoon of chili powder</li>
<li>1 teaspoon of onion powder</li>
<li>\(1\times 8\)-oz block of cream cheese</li>
</ul>
<hr>
<ul>
<li>Get out your crockpot</li>
<li>Place the chicken at the bottom</li>
<li>Mix in the corn (undrained), black beans (drained), tomatoes, and mix/powders</li>
<li>Place cream cheese on top</li>
<li>Cook on <em>low</em> for 4 hours, but 3 hours in, remove the chicken to break it up before placing it back in and mixing up the cream cheese</li>
<li>Serve over rice or with tortilla chips!</li>
</ul>
<h3 id="white-chicken-chili-instant-pot"><a class="header" href="#white-chicken-chili-instant-pot">White Chicken Chili (Instant Pot)</a></h3>
<p><em>Serves 8 people. 30 min prep + 20 min cook.</em></p>
<hr>
<ul>
<li>2 large <em>thawed</em> chicken breasts</li>
<li>1 can of corn</li>
<li>1 can of black beans</li>
<li>\(1\times 10\)-oz can of “original” or “mild” Rotel tomatoes</li>
<li>1 package of Hidden Valley ranch dressing mix (1-oz size)</li>
<li>1 teaspoon of cumin</li>
<li>1 teaspoon of chili powder</li>
<li>1 teaspoon of onion powder</li>
<li>\(1\times 8\)-oz block of cream cheese</li>
<li>\(\frac{1}{2}\) cup of chicken broth or stock</li>
</ul>
<hr>
<ul>
<li>Place ingredients in the instant pot bowl in this order:
<ul>
<li>chicken</li>
<li>beans</li>
<li>corn</li>
<li>tomatoes</li>
<li>broth</li>
</ul>
</li>
<li>Add the spices and powders.</li>
<li>Stir everything together; make sure some juice gets underneath the chicken to prevent scorching.</li>
<li>Slice the cream cheese into six large pieces and place over the top.</li>
<li>Cook on <strong>high pressure</strong> for <strong>20 minutes</strong>.</li>
<li><strong>Depressurize</strong> for <strong>10</strong> minutes, <em>then</em> turn the valve to the <strong>venting</strong> position.</li>
<li>Remove and shred the chicken breasts, then return them to the pot and stir everything together, melting the cream cheese.</li>
<li>Serve over rice or with tortilla chips!</li>
</ul>
<h3 id="creamy-macaroni-and-cheese"><a class="header" href="#creamy-macaroni-and-cheese">Creamy Macaroni and Cheese</a></h3>
<p><em>Makes 6 servings. Prep 20 min., cook 15 min., bake 20 min.</em></p>
<hr>
<ul>
<li>1 (8-oz) package of elbow macaroni</li>
<li>\(\frac{1}{4}\) cup of butter or margarine</li>
<li>\(\frac{1}{4}\) cup of all-purpose flour</li>
<li>\(\frac{1}{4}\) teaspoon of salt</li>
<li>\(\frac{1}{4}\) teaspoon of ground black pepper</li>
<li>\(\frac{1}{8}\) teaspoon of ground red pepper</li>
<li>\(\frac{1}{8}\) teaspoon of granulated garlic</li>
<li>1 cup of half-and-half</li>
<li>1 cup of milk</li>
<li>\(\frac{1}{2}\) (10-oz) block of extra-sharp Cheddar cheese, <em>shredded</em></li>
<li>1 (10-oz) block of sharp Cheddar cheese, <em>shredded and divided</em></li>
</ul>
<hr>
<ul>
<li>Prepare pasta according to package directions; drain and set aside</li>
<li>Preheat oven to 375\(^\circ\)</li>
<li>Melt butter in a large skillet over medium-high heat. Gradually whisk in flour until smooth; cook, whisking constantly, 2 minutes. Stir in salt and next 3 ingredients. Gradually whisk in half-and-half and milk; cook, whisking constantly, 8-10 minutes or until thickened.</li>
<li>Stir in extra-sharp cheese and <em>half</em> of sharp cheese until smooth. Remove from heat.</li>
<li>Combine pasta and cheese mixture and pour into 6 lightly greased (6-oz) ramekins <em>or</em> 1 (8 in\(^2\)) baking dish. Sprinkle evenly with remaining sharp Cheddar cheese.</li>
<li>Bake for 20 minutes. Optionally add 15 minutes for a crusty top.</li>
</ul>
<h3 id="pasta-bolognese"><a class="header" href="#pasta-bolognese">Pasta Bolognese</a></h3>
<p><em>4 servings</em>.</p>
<hr>
<ul>
<li>2 tablespoons of butter</li>
<li>\(\frac{1}{4}\) pound of sliced bacon, cut crosswise into \(\frac{1}{4}\)-inch strips</li>
<li>1 onion, finely chopped</li>
<li>1 pound of ground beef</li>
<li>1 cup of canned low-sodium beef or chicken broth</li>
<li>\(\frac{1}{2}\) cup of dry white wine (or apple cider vinegar)</li>
<li>2 tablespoons of tomato paste</li>
<li>\(\frac{1}{2}\) teaspoon of dried oregano</li>
<li>\(\frac{3}{4}\) teaspoon of salt</li>
<li>\(\frac{1}{4}\) teaspoon of fresh-ground black pepper</li>
<li>\(\frac{1}{2}\) cup of heavy cream</li>
<li>1 pound of spaghetti</li>
<li>2 tablespoons of chopped fresh parsley (optional)</li>
</ul>
<hr>
<ul>
<li>In a large frying pan, heat butter and bacon over moderately low heat, until bacon renders some of its fat (\(&gt;3\) minutes)</li>
<li>Add onion and stir occasionally until starting to soften (\(&gt;3\) minutes)</li>
<li>Stir in ground beef and cook until meat no longer pink (\(\approx 2\) minutes)</li>
<li>Add broth, wine, tomato paste, oregano, salt, pepper</li>
<li>Simmer on very low heat, stirring occasionally, until sauce thickens (\(\approx 1\) hour)</li>
<li>When ready to serve, stir in cream and remove from heat</li>
</ul>
<hr>
<ul>
<li>In large pot of boiling, salted water, cook spaghetti until just done (\(\approx 12\) minutes)</li>
<li>Drain and toss with sauce and parsley</li>
</ul>
<h3 id="super-simple-salmon"><a class="header" href="#super-simple-salmon">Super Simple Salmon</a></h3>
<hr>
<ul>
<li>1 tablespoon of garlic powder</li>
<li>1 tablespoon of dried basil leaves</li>
<li>\(\frac{1}{2}\) teaspoon of table salt</li>
<li>\(4\times 6\)-oz salmon</li>
<li>2 tablespoons of salted butter</li>
<li>4 raw lemon wedges</li>
</ul>
<hr>
<ul>
<li>Stir garlic powder, basil, and salt in a small bowl</li>
<li>Rub the powder mix in equal amounts onto the salmon fillets</li>
<li>Melt butter in skillet over medium heat</li>
<li>Cook the salmon in the butter until browned and flaky (about <em>5 minutes</em> per side)</li>
<li>Serve each salmon piece with a lemon wedge</li>
</ul>
<h3 id="cuban-black-beans"><a class="header" href="#cuban-black-beans">Cuban Black Beans</a></h3>
<hr>
<ul>
<li>Avocado oil (enough to cover the bottom of a frying pan in a thin layer</li>
<li>\(\frac{1}{2}\) tablespoon of minced garlic</li>
<li>2 Bay leaves</li>
<li>1 can of black beans</li>
<li>salt</li>
<li>black pepper</li>
<li>cumin</li>
<li>\(1\frac{1}{2}\) cap-fulls of white vinegar</li>
</ul>
<hr>
<ul>
<li>Heat up the oil in a frying pan on medium heat for 2-3 minutes</li>
<li>Add a minced garlic and two bay leaves to the oil and stir until fragrant</li>
<li>Empty half of the liquid from the can of black beans, then poor what’s left in the can (beans and remaining liquid) into the pan</li>
<li>Sprinkle on the salt, pepper, and cumin, then stir</li>
<li>Add vinegar and stir</li>
<li>Let simmering for another 2-3 minutes. It will start bubbling when done</li>
<li>Remove from heat and serve. You’ll want to remove the bay leaves.</li>
</ul>
<h3 id="filet-mignon"><a class="header" href="#filet-mignon">Filet Mignon</a></h3>
<hr>
<p>For <em>one</em> piece of meat:</p>
<ul>
<li>\(1\times 6\)-oz filet mignon</li>
<li>coarse salt to taste</li>
<li>freshly ground black pepper to taste</li>
<li>1 tablespoon of grapeseed oil\(^*\)</li>
<li>2 tablespoons of unsalted butter</li>
<li>2 sprigs of fresh rosemary</li>
<li>1 clove of garlic</li>
</ul>
<p>\(^*\)You can substitute in another high-heat, neutral oil of choice.</p>
<hr>
<ul>
<li>On a cutting board, pat the filet dry with paper towels and let sit at room temperature for 20-30 minutes</li>
<li>Preheat oven to 450\(^\circ\)</li>
<li>Generously season all sides of the filet with salt and pepper</li>
<li>Heat a medium, oven-safe stainless steel or cast iron skillet over high heat for 5 minutes and add the oil</li>
<li>Once the oil begins to smoke, add the filet to the pan. Cook without moving for 2–3 minutes, until a crust has formed</li>
<li>Use tongs to flip the steak over, then add the butter, rosemary, and garlic to the pan</li>
<li>Tilt the pan and spoon the butter continuously over the steak for 2-3 minutes</li>
<li>Transfer the pan to the oven for <em>7 minutes</em> for a <em>medium rare</em> steak</li>
<li>Transfer the steak to a cutting board and let rest for at least 10 minutes before slicing</li>
</ul>
<h3 id="fish-tacos"><a class="header" href="#fish-tacos">Fish Tacos</a></h3>
<hr>
<ul>
<li>1 pound of lean white fish fillets (like tilapia)</li>
<li>Salt</li>
<li>Black pepper</li>
<li>Lime juice</li>
<li>2 tablespoons of vegetable or canola oil</li>
<li>1 clove of minced garlic</li>
<li>1 \(\frac{1}{2}\) teaspoons of chili powder</li>
<li>1 \(\frac{1}{2}\) teaspoons of ground cumin</li>
<li>\(\frac{1}{2}\) teaspoon of paprika</li>
<li>Flour tortillas</li>
<li>\(\frac{1}{2}\) cup of sour cream</li>
<li>\(\frac{1}{3}\) cup of mayonnaise</li>
<li>\(\frac{1}{2}\) teaspoon of garlic powder</li>
<li>1 teaspoon of buffalo sauce</li>
<li>shredded cheese</li>
<li>shredded lettuce</li>
<li>avocado</li>
</ul>
<hr>
<ul>
<li>Season the fish with a little salt and pepper on both sides</li>
<li>In a mixing bowl, whisk together the oil, some lime juice, garlic, chili powder, cumin (1 teaspoon), and paprika</li>
<li>Place fish and mixed marinade in a large ziplock bag, seal, and let sit in the fridge for 20-30 minutes</li>
<li>Meanwhile, make the sauce with the sour cream, mayonnaise, some lime juice, garlic powder, cumin (1/2 teaspoon), salt (1/4 teaspoon), and buffalo sauce. Mix well and place in the fridge.</li>
<li>Preheat grill to medium-high heat. Grill fish filets for about 3-4 minutes on each side, flipping only once.</li>
<li>Warm up tortillas, gather everything together, and enjoy!</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="quick-stats"><a class="header" href="#quick-stats">Quick Stats</a></h1>
<h3 id="instant-pot"><a class="header" href="#instant-pot">Instant Pot</a></h3>
<p><strong><a href="https://s3-us-west-2.amazonaws.com/byjillee/printables/ogt-instantpot.pdf">Instant Pot cooking times cheatsheet</a></strong></p>
<h4 id="rice"><a class="header" href="#rice">Rice</a></h4>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Rice Type</th><th>Rice Cups</th><th>Water Cups</th><th>High Pressure Min.</th><th>Natural Release Min.</th></tr>
</thead>
<tbody>
<tr><td>Jasmine</td><td>1.5</td><td>2</td><td>6</td><td>10</td></tr>
<tr><td>Basmati</td><td>1.5</td><td>2</td><td>6</td><td>10</td></tr>
</tbody>
</table>
</div>
<h3 id="air-fryer"><a class="header" href="#air-fryer">Air Fryer</a></h3>
<ul>
<li>Trader Joe’s Hash Browns: 390F for 10 minutes</li>
<li>Polish dogs:
<ul>
<li>400F</li>
<li>3-6 minutes (depending on quantity), turn once</li>
<li>Add in buns for the last 30-45 seconds</li>
<li><strong>For crispier hot dogs:</strong> 8 minutes with the buns in for the last 3 minutes</li>
</ul>
</li>
<li>Chicken breasts
<ul>
<li>375 F</li>
<li>Marinated, diced Costco chicken: 17 minutes (9 + 4 + 4)</li>
<li>Small (5 to 7 ounces): 7 to 10 minutes</li>
<li>Medium (8 to 10 ounces): 10 to 12 minutes</li>
<li>Large (11 ounces or more): 12 to 16 minutes</li>
<li><strong>flip halfway</strong></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="software-runbooks"><a class="header" href="#software-runbooks">Software Runbooks</a></h1>
<ul>
<li><a href="#avahi-runbook">Avahi Runbook</a></li>
<li><a href="#metrics-pipeline-debugging-runbook">Metrics Pipeline Debugging</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="avahi-runbook"><a class="header" href="#avahi-runbook">Avahi Runbook</a></h1>
<p>When debugging mDNS issues with Avahi on a LAN, particularly when a <code>.local</code> hostname like <code>ats.local</code> suddenly disappears despite the host being up, here’s a systematic approach to debug it:</p>
<hr>
<h3 id="1-check-if-the-host-is-still-advertising-via-avahi"><a class="header" href="#1-check-if-the-host-is-still-advertising-via-avahi"><strong>1. Check if the host is still advertising via Avahi</strong></a></h3>
<p>On another machine on the LAN, run:</p>
<pre><code class="language-bash">avahi-browse -a -t
</code></pre>
<p>Look for the <code>ats.local</code> hostname in the output.</p>
<p>You can also be more specific:</p>
<pre><code class="language-bash">avahi-resolve-host-name ats.local
</code></pre>
<p>If this fails, then it confirms that the mDNS record is no longer available or has expired.</p>
<hr>
<h3 id="2-check-avahi-status-on-the-target-host-eg-ats"><a class="header" href="#2-check-avahi-status-on-the-target-host-eg-ats"><strong>2. Check Avahi status on the target host (e.g., <code>ats</code>)</strong></a></h3>
<p>On the <code>ats</code> host, run:</p>
<pre><code class="language-bash">sudo systemctl status avahi-daemon
</code></pre>
<p>If it’s not active, start or restart it:</p>
<pre><code class="language-bash">sudo systemctl restart avahi-daemon
</code></pre>
<p>Also check for errors in logs:</p>
<pre><code class="language-bash">journalctl -u avahi-daemon
</code></pre>
<p>Look for signs of:</p>
<ul>
<li>Interface failures</li>
<li>Conflicts (e.g., another device trying to register <code>ats.local</code>)</li>
<li>Crashes or socket errors</li>
</ul>
<hr>
<h3 id="3-check-hostname-and-avahi-publishing-config-on-ats"><a class="header" href="#3-check-hostname-and-avahi-publishing-config-on-ats"><strong>3. Check hostname and Avahi publishing config on <code>ats</code></strong></a></h3>
<p>Ensure that <code>ats</code> is still using the expected hostname:</p>
<pre><code class="language-bash">hostname
</code></pre>
<p>Check if Avahi is advertising it correctly:</p>
<pre><code class="language-bash">avahi-publish -a -v ats.local &lt;IP_ADDRESS&gt;
</code></pre>
<p>If <code>ats.local</code> has been “taken” by another host due to a race condition or network issue, Avahi might auto-rename it (e.g., to <code>ats-2.local</code>). Look for such names with:</p>
<pre><code class="language-bash">avahi-browse -a
</code></pre>
<hr>
<h3 id="4-confirm-networking-and-firewall-settings"><a class="header" href="#4-confirm-networking-and-firewall-settings"><strong>4. Confirm networking and firewall settings</strong></a></h3>
<p>Make sure:</p>
<ul>
<li>UDP port 5353 is open (used by mDNS)</li>
<li>Your firewall isn’t blocking multicast traffic</li>
<li>You’re on the same subnet</li>
</ul>
<p>You can test multicast reachability with:</p>
<pre><code class="language-bash">ping -b 224.0.0.251
</code></pre>
<p>Or use <code>tcpdump</code> to confirm mDNS traffic:</p>
<pre><code class="language-bash">sudo tcpdump -i &lt;interface&gt; port 5353
</code></pre>
<p>Watch for queries and responses involving <code>ats.local</code>.</p>
<hr>
<h3 id="5-restart-avahi-and-re-announce-services"><a class="header" href="#5-restart-avahi-and-re-announce-services"><strong>5. Restart Avahi and re-announce services</strong></a></h3>
<p>If things still look stale or broken, try a full Avahi restart on the <code>ats</code> host:</p>
<pre><code class="language-bash">sudo systemctl restart avahi-daemon
</code></pre>
<p>Then re-check service announcements with <code>avahi-browse</code>.</p>
<hr>
<h3 id="6-tools-for-further-debugging"><a class="header" href="#6-tools-for-further-debugging"><strong>6. Tools for further debugging</strong></a></h3>
<ul>
<li><code>avahi-discover</code>: GUI tool to browse mDNS services.</li>
<li><code>dns-sd</code> (on macOS): e.g., <code>dns-sd -B _services._dns-sd._udp</code></li>
<li><code>nss-mdns</code>: make sure the system resolves <code>.local</code> via Avahi (not some other resolver or caching DNS system).</li>
</ul>
<p>In <code>/etc/nsswitch.conf</code> you should see:</p>
<pre><code>hosts: files mdns4_minimal [NOTFOUND=return] dns
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="metrics-pipeline-debugging-runbook"><a class="header" href="#metrics-pipeline-debugging-runbook">Metrics Pipeline Debugging Runbook</a></h1>
<h2 id="overview-3"><a class="header" href="#overview-3">Overview</a></h2>
<p>This runbook provides step-by-step guidance for diagnosing and resolving issues in a metrics pipeline consisting of:</p>
<ul>
<li>A Python program emitting StatsD metrics</li>
<li>Vector (StatsD source → Prometheus exporter sink)</li>
<li>Prometheus (scraping metrics from Vector)</li>
<li>Grafana (visualizing Prometheus data)</li>
</ul>
<h2 id="debugging-workflow"><a class="header" href="#debugging-workflow">Debugging Workflow</a></h2>
<h3 id="1-verify-python-program-is-emitting-statsd-metrics"><a class="header" href="#1-verify-python-program-is-emitting-statsd-metrics"><strong>1. Verify Python Program is Emitting StatsD Metrics</strong></a></h3>
<h4 id="check-if-metrics-are-being-sent"><a class="header" href="#check-if-metrics-are-being-sent"><strong>Check if metrics are being sent</strong></a></h4>
<p>Run the following command to manually send a StatsD metric:</p>
<pre><code class="language-bash">echo "orchestrator_jobs_active:1|g" | nc -u -w1 127.0.0.1 9000
</code></pre>
<h4 id="check-vector-logs-for-received-metrics"><a class="header" href="#check-vector-logs-for-received-metrics"><strong>Check Vector logs for received metrics</strong></a></h4>
<pre><code class="language-bash">journalctl -u vector -f | grep statsd
</code></pre>
<p><strong>OK:</strong> If logs indicate received metrics → Vector is receiving data.</p>
<p><strong>FAIL:</strong> If no logs appear → The Python program might not be sending metrics correctly or is targeting the wrong address/port.</p>
<hr>
<h3 id="2-verify-vector-is-exposing-metrics"><a class="header" href="#2-verify-vector-is-exposing-metrics"><strong>2. Verify Vector is Exposing Metrics</strong></a></h3>
<h4 id="check-if-vectors-prometheus-exporter-is-publishing-metrics"><a class="header" href="#check-if-vectors-prometheus-exporter-is-publishing-metrics"><strong>Check if Vector’s Prometheus exporter is publishing metrics</strong></a></h4>
<pre><code class="language-bash">curl -s http://127.0.0.1:9598/metrics | grep orchestrator
</code></pre>
<p><strong>OK:</strong> If metrics appear → Vector is working correctly.</p>
<p><strong>FAIL:</strong> If no metrics appear →</p>
<ul>
<li>Ensure that Vector’s <code>flush_period_secs</code> is correctly configured.</li>
<li>Check Vector logs for errors: <code>journalctl -u vector -f</code>.</li>
</ul>
<hr>
<h3 id="3-verify-prometheus-is-scraping-metrics"><a class="header" href="#3-verify-prometheus-is-scraping-metrics"><strong>3. Verify Prometheus is Scraping Metrics</strong></a></h3>
<h4 id="check-prometheus-targets"><a class="header" href="#check-prometheus-targets"><strong>Check Prometheus targets</strong></a></h4>
<pre><code class="language-bash">curl -s "http://localhost:9090/api/v1/targets" | jq '.data.activeTargets[] | {scrapeUrl, lastScrape, lastError, health}'
</code></pre>
<p><strong>OK:</strong> If <code>health</code> is <code>"up"</code> and <code>lastError</code> is empty → Prometheus is successfully scraping.</p>
<p><strong>FAIL:</strong> If <code>health</code> is <code>"down"</code> → There is a scraping issue (check <code>lastError</code>).</p>
<h4 id="check-if-prometheus-has-seen-the-metric"><a class="header" href="#check-if-prometheus-has-seen-the-metric"><strong>Check if Prometheus has seen the metric</strong></a></h4>
<pre><code class="language-bash">curl -s "http://localhost:9090/api/v1/series?match[]=orchestrator_jobs_active" | jq .
</code></pre>
<p><strong>OK:</strong> If the query returns data → Prometheus has recorded the metric.</p>
<p><strong>FAIL:</strong> If empty → Check Vector and StatsD configuration.</p>
<h4 id="query-latest-metric-values"><a class="header" href="#query-latest-metric-values"><strong>Query latest metric values</strong></a></h4>
<pre><code class="language-bash">curl -s "http://localhost:9090/api/v1/query?query=orchestrator_jobs_active" | jq .
</code></pre>
<p><strong>OK:</strong> If a value is returned → The metric is stored.</p>
<p><strong>FAIL:</strong> If no value is returned → Metrics may be expiring before they are scraped.</p>
<hr>
<h3 id="4-fix-potential-issues"><a class="header" href="#4-fix-potential-issues"><strong>4. Fix Potential Issues</strong></a></h3>
<h4 id="a-vectors-flush_period_secs-is-too-short"><a class="header" href="#a-vectors-flush_period_secs-is-too-short"><strong>A. Vector’s <code>flush_period_secs</code> is Too Short</strong></a></h4>
<p>If metrics disappear before Prometheus scrapes them, increase <code>flush_period_secs</code> in <code>vector.toml</code>:</p>
<pre><code class="language-toml">[sinks.prometheus_exporter]
type = "prometheus_exporter"
inputs = ["statsd"]
address = "0.0.0.0:9598"
flush_period_secs = 30  # Set higher than Prometheus scrape interval
</code></pre>
<p>Restart Vector:</p>
<pre><code class="language-bash">systemctl restart vector
</code></pre>
<h4 id="b-prometheus-scrape-interval-is-too-long"><a class="header" href="#b-prometheus-scrape-interval-is-too-long"><strong>B. Prometheus Scrape Interval is Too Long</strong></a></h4>
<p>Ensure Prometheus scrapes more frequently than Vector’s flush interval (<code>prometheus.yml</code>):</p>
<pre><code class="language-yaml">scrape_configs:
- job_name: "vector"
  scrape_interval: 5s  # Must be less than Vector’s flush_period_secs
  static_configs:
    - targets: ["0.0.0.0:9598"]
</code></pre>
<p>Restart Prometheus:</p>
<pre><code class="language-bash">systemctl restart prometheus
</code></pre>
<h4 id="c-metrics-are-not-updating"><a class="header" href="#c-metrics-are-not-updating"><strong>C. Metrics Are Not Updating</strong></a></h4>
<p>Manually send a StatsD metric:</p>
<pre><code class="language-bash">echo "orchestrator_jobs_active:5|g" | nc -u -w1 127.0.0.1 9000
</code></pre>
<p>Immediately query Prometheus:</p>
<pre><code class="language-bash">curl -s "http://localhost:9090/api/v1/query?query=orchestrator_jobs_active" | jq .
</code></pre>
<p>If the metric appears but disappears later, Vector may be expiring stale metrics too soon.</p>
<h4 id="d-verify-prometheus-retention-settings"><a class="header" href="#d-verify-prometheus-retention-settings"><strong>D. Verify Prometheus Retention Settings</strong></a></h4>
<p>Check retention settings:</p>
<pre><code class="language-bash">prometheus --storage.tsdb.retention.time
</code></pre>
<p>If retention is low (e.g., <code>1h</code>), increase it:</p>
<pre><code class="language-bash">prometheus --storage.tsdb.retention.time=7d
</code></pre>
<hr>
<h2 id="final-debugging-checklist"><a class="header" href="#final-debugging-checklist"><strong>Final Debugging Checklist</strong></a></h2>
<ul>
<li><input disabled="" type="checkbox"> <strong>Python program emits StatsD metrics</strong> (<code>nc -u -w1 127.0.0.1 9000</code>)</li>
<li><input disabled="" type="checkbox"> <strong>Vector receives metrics</strong> (<code>journalctl -u vector -f | grep statsd</code>)</li>
<li><input disabled="" type="checkbox"> <strong>Vector exposes metrics correctly</strong> (<code>curl -s http://127.0.0.1:9598/metrics</code>)</li>
<li><input disabled="" type="checkbox"> <strong>Prometheus scrapes successfully</strong> (<code>api/v1/targets</code> with <code>health: "up"</code>)</li>
<li><input disabled="" type="checkbox"> <strong>Metrics are stored in Prometheus</strong> (<code>api/v1/query?query=orchestrator_jobs_active</code>)</li>
</ul>
<p>Following this runbook will help identify and resolve issues efficiently when debugging the metrics pipeline.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>


    </div>
    </body>
</html>
